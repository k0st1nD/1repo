# coding: utf-8

import json
import os
from datetime import datetime
from dateutil.parser import parse as dtparse
from atlassian import Jira
import configparser
import jira_helper

# ==========================
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
# ==========================

config = configparser.ConfigParser()
config.read("config.ini")

jira_config = config["jira"]
data_prefix = config["statusflow"]["prefix"]

JIRA = Jira(
    url=jira_config["host"],
    username=jira_config["username"],
    password=jira_config["password"],
    verify_ssl=False
)

ISSUES_FILE = f"data/{data_prefix}.2.issues.raw.json"
SPRINTS_FILE = f"data/{data_prefix}.1.sprints.json"
OUTPUT_FILE = f"data/{data_prefix}.3.processed.json"
EPIC_CACHE_FILE = "data/epic_cache.json"

# ==========================
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ —Ä–æ–ª–∏
# ==========================

TEAM_ROLES = {
    "–•–æ–º–µ–Ω–∫–æ–≤ –ì—Ä–∏–≥–æ—Ä–∏–π –í—è—á–µ—Å–ª–∞–≤–æ–≤–∏—á": "PO",
    "–ë—Ä–æ–≤–∫–∏–Ω –ú–∏—Ö–∞–∏–ª –í—Å–µ–≤–æ–ª–æ–¥–æ–≤–∏—á": "BA",
    "–¢–∞—Ä–∞–±–∞–Ω—å–∫–æ –¢–∞—Ç—å—è–Ω–∞ –í–∞–ª–µ—Ä—å–µ–≤–Ω–∞": "BA",
    "–Ø–∫–æ–≤–µ—Ü –û–ª—å–≥–∞ –°–µ—Ä–≥–µ–µ–≤–Ω–∞": "Design",
    "–ê—Ñ–∞–Ω–∞—Å—å–µ–≤ –ê–ª–µ–∫—Å–µ–π –ò–≤–∞–Ω–æ–≤–∏—á": "Java",
    "–ë–∞–ª–º–∞—à–æ–≤ –°–µ—Ä–≥–µ–π –ê–Ω–∞—Ç–æ–ª—å–µ–≤–∏—á": "System Analysis",
    "–í–æ–ª–Ω–µ–π–∫–æ –í–∞—Å–∏–ª–∏–π –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤–∏—á": "QA Fullstack",
    "–ö–æ–ª–æ—Å –í–ª–∞–¥–∏—Å–ª–∞–≤ –ò–≥–æ—Ä–µ–≤–∏—á": "JS",
    "–ö—É–¥–∏–º–æ–≤ –ò–ª—å—è –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤–∏—á": "Java",
    "–û—Ä–æ–ª–±–∞–µ–≤–∞ –¢–æ–∫—Ç–æ–±—É–±—É –¢–æ–∫—Ç–æ–Ω–∞–ª–∏–µ–≤–Ω–∞": "QA Fullstack",
    "–¶—ã–≥–∞–Ω–∫–æ–≤ –ù–∏–∫–æ–ª–∞–π –í–∞–ª–µ—Ä—å–µ–≤–∏—á": "System Analysis",
    "–ö—É–ª–∞–µ–≤–∞ –ù–∞—Ç–∞–ª–∏—è –ò–≥–æ—Ä–µ–≤–Ω–∞ [X]": "System Analysis",
    "–ì–∞–≤—Ä–∏–ª–æ–≤ –í—è—á–µ—Å–ª–∞–≤ –°–µ—Ä–≥–µ–µ–≤–∏—á [X]": "Design",
}

# ==========================
# –ó–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∞ —ç–ø–∏–∫–æ–≤
# ==========================

if os.path.exists(EPIC_CACHE_FILE):
    with open(EPIC_CACHE_FILE, "r", encoding="utf-8") as f:
        EPIC_CACHE = json.load(f)
else:
    EPIC_CACHE = {}

def get_role(name: str):
    if not name:
        return "unknown"
    for k, v in TEAM_ROLES.items():
        if name.strip().lower() == k.lower():
            return v
    return "unknown"

def get_epic_data(epic_key: str):
    """–ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ–± —ç–ø–∏–∫–µ —Å –∫—ç—à–µ–º"""
    if not epic_key:
        return None
    if epic_key in EPIC_CACHE:
        return EPIC_CACHE[epic_key]

    print(f"üì° –ó–∞–≥—Ä—É–∂–∞–µ–º —ç–ø–∏–∫ {epic_key}...")
    epic = JIRA.issue(epic_key)

    fields = epic["fields"]
    epic_data = {
        "key": epic_key,
        "summary": fields.get("summary"),
        "created": fields.get("created"),
        "plannedStart": fields.get("customfield_21675"),
        "plannedEnd": fields.get("customfield_21471"),
        "duedate": fields.get("duedate"),
    }

    EPIC_CACHE[epic_key] = epic_data

    # –æ–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à –Ω–∞ –¥–∏—Å–∫
    with open(EPIC_CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(EPIC_CACHE, f, indent=2, ensure_ascii=False)

    return epic_data

# ==========================
# –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–¥–∞—á –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞
# ==========================

print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –∑–∞–¥–∞—á–∏...")
with open(ISSUES_FILE, "r", encoding="utf-8") as f:
    issues = json.load(f)

print(f"üîç –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–¥–∞—á: {len(issues)}")

processed = []

for issue in issues:
    key = issue["key"]
    fields = issue["fields"]
    changelog = issue.get("changelog", {}).get("histories", [])

    # --- –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è ---
    assignee = fields.get("assignee", {}).get("displayName")
    issue_type = fields.get("issuetype", {}).get("name")
    status = fields.get("status", {}).get("name")
    summary = fields.get("summary")
    epic_key = fields.get("customfield_10376")
    created = fields.get("created")

    # --- –≠–ø–∏–∫ ---
    epic_info = get_epic_data(epic_key) if epic_key else None

    # --- –ò—Å—Ç–æ—Ä–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π ---
    status_flow = []
    assignee_changes = []
    sprint_changes = []

    for item in changelog:
        author = item.get("author", {}).get("displayName")
        author_role = get_role(author)
        when = item.get("created")

        for change in item.get("items", []):
            field = change.get("field", "").lower()

            # —Å–º–µ–Ω–∞ —Å—Ç–∞—Ç—É—Å–∞
            if field == "status":
                from_status = change.get("fromString")
                to_status = change.get("toString")

                if to_status.lower() == '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ':
                    print(key, summary)

                # # –µ—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤—ã–π –ø–µ—Ä–µ—Ö–æ–¥ –∏ from –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî —Å–æ–∑–¥–∞–µ–º —Å—Ç–∞—Ä—Ç–æ–≤—ã–π —Å—Ç–∞—Ç—É—Å
                # if not status_flow and not from_status and to_status:
                #     # –¥–æ–±–∞–≤–ª—è–µ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π "–Ω–∞—á–∞–ª—å–Ω—ã–π" —à–∞–≥, —á—Ç–æ–±—ã –≤—ã—Ä–æ–≤–Ω—è—Ç—å —Ü–µ–ø–æ—á–∫—É
                #     status_flow.append({
                #         "from": None,
                #         "to": from_status or "Created",
                #         "by": author,
                #         "by_role": author_role,
                #         "at": created
                #     })

                status_flow.append({
                    "from": from_status,
                    "to": to_status,
                    "by": author,
                    "by_role": author_role,
                    "at": when
                })

            # —Å–º–µ–Ω–∞ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è
            elif field == "assignee":
                assignee_changes.append({
                    "from": change.get("fromString"),
                    "to": change.get("toString"),
                    "by": author,
                    "by_role": author_role,
                    "at": when
                })

            # —Å–º–µ–Ω–∞ —Å–ø—Ä–∏–Ω—Ç–∞
            elif field == "sprint":
                sprint_changes.append({
                    "from": change.get("fromString", ""),
                    "to": change.get("toString", ""),
                    "by": author,
                    "by_role": author_role,
                    "at": when
                })

    # --- —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Ü–µ–ø–æ—á–∫—É —Å—Ç–∞—Ç—É—Å–æ–≤ ---
    status_flow_sorted = sorted(status_flow, key=lambda x: dtparse(x["at"]))
    status_chain = []

    # –¥–æ–±–∞–≤–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å (–µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–µ–Ω)
    if status_flow_sorted:
        first_from = status_flow_sorted[0].get("from") or fields.get("status", {}).get("name")
        if first_from:
            status_chain.append(first_from)

        for s in status_flow_sorted:
            to_status = s.get("to")
            # –∏–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ–¥—Ä—è–¥
            if to_status and (not status_chain or status_chain[-1] != to_status):
                status_chain.append(to_status)

    processed.append({
        "key": key,
        "summary": summary,
        "type": issue_type,
        "status": status,
        "assignee": assignee,
        "role": get_role(assignee),
        "statusFlow": status_flow_sorted,
        "statusChain": status_chain,  # <--- –≤–æ—Ç —ç—Ç–æ –Ω–æ–≤–æ–µ –ø–æ–ª–µ
        "assigneeChanges": assignee_changes,
        "sprintChanges": sprint_changes,
        "epic": epic_info
    })

# ==========================
# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
# ==========================

os.makedirs("data", exist_ok=True)
with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
    json.dump(processed, f, indent=2, ensure_ascii=False)

print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(processed)} –∑–∞–¥–∞—á –≤ {OUTPUT_FILE}")
