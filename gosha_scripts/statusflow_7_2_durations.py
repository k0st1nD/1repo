# coding: utf-8

import json
import configparser
import numpy as np
from pathlib import Path
from collections import defaultdict, Counter
from datetime import datetime

# ==========================
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
# ==========================

config = configparser.ConfigParser()
config.read("config.ini")
data_prefix = config["statusflow"]["prefix"]

INPUT_FILE = f"data/{data_prefix}.3.processed.json"
OUTPUT_FILE = f"data/{data_prefix}.7.2.durations.json"
REPORT_FILE = f"data/{data_prefix}.7.2.durations_report.md"

Path("data").mkdir(exist_ok=True, parents=True)

# ==========================
# –ó–∞–≥—Ä—É–∑–∫–∞
# ==========================

with open(INPUT_FILE, "r", encoding="utf-8") as f:
    issues = json.load(f)

print(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–¥–∞—á: {len(issues)}")

# ==========================
# –ü–æ–¥—Å—á—ë—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –ø–µ—Ä–µ—Ö–æ–¥–æ–≤
# ==========================

def parse_jira_date(s: str):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç JIRA-–¥–∞—Ç—É –≤ ISO-—Å–æ–≤–º–µ—Å—Ç–∏–º—É—é."""
    if not s:
        return None
    if len(s) >= 26 and (s[-5] in ['+', '-']) and s[-2] != ':':
        s = s[:-2] + ':' + s[-2:]
    try:
        return datetime.fromisoformat(s.replace('Z', '+00:00'))
    except Exception:
        return None

durations_by_type = defaultdict(lambda: defaultdict(list))

for issue in issues:
    issue_type = issue.get("type", "Unknown")
    flow = issue.get("statusFlow", [])
    if not flow or len(flow) < 2:
        continue

    # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    flow_sorted = sorted(flow, key=lambda x: x.get("at") or "")

    # –∏–¥—ë–º –ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–º –ø–æ–¥—Ä—è–¥, –≤–∫–ª—é—á–∞—è –ø–µ—Ä–≤—É—é (Created ‚Üí Backlog)
    for i in range(1, len(flow_sorted)):
        prev = flow_sorted[i - 1]
        curr = flow_sorted[i]

        t1 = parse_jira_date(prev.get("at"))
        t2 = parse_jira_date(curr.get("at"))
        if not t1 or not t2:
            continue

        delta_days = (t2 - t1).total_seconds() / 86400
        if delta_days <= 0 or delta_days > 365:
            continue  # —Ñ–∏–ª—å—Ç—Ä –∞–Ω–æ–º–∞–ª–∏–π

        # —Å—á–∏—Ç–∞–µ–º, —Å–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–¥–∞—á–∞ –ø—Ä–æ–≤–µ–ª–∞ –≤ —Å—Ç–∞—Ç—É—Å–µ prev["to"]
        key = (prev["to"], curr["to"])
        durations_by_type[issue_type][key].append(delta_days)

print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ –ø–∞—Ä: {sum(len(v) for v in durations_by_type.values())}")

# ==========================
# –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
# ==========================

summary = {}
report_lines = ["# ‚è± –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –ø–æ —Ç–∏–ø–∞–º –∑–∞–¥–∞—á\n"]

for issue_type, pairs in durations_by_type.items():
    report_lines.append(f"\n## üß© {issue_type}")
    report_lines.append("| –ò–∑ —Å—Ç–∞—Ç—É—Å–∞ | –í —Å—Ç–∞—Ç—É—Å | –ö–æ–ª-–≤–æ | –°—Ä–µ–¥–Ω–µ–µ (–¥–Ω) | 85-–π –ø–µ—Ä—Ü. | 95-–π –ø–µ—Ä—Ü. |")
    report_lines.append("|-------------|-----------|---------|---------------|-------------|-------------|")

    stats = {}
    for (frm, to), values in pairs.items():
        arr = np.array(values)
        stats[f"{frm} ‚Üí {to}"] = {
            "count": len(values),
            "mean": float(np.mean(arr)),
            "p85": float(np.percentile(arr, 85)),
            "p95": float(np.percentile(arr, 95)),
        }

        report_lines.append(
            f"| {frm} | {to} | {len(values)} | {np.mean(arr):.1f} | {np.percentile(arr,85):.1f} | {np.percentile(arr,95):.1f} |"
        )

    summary[issue_type] = stats

    # ==========================
    # üë• –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —Ä–æ–ª—è–º –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
    # ==========================
    role_counter = Counter()
    for issue in issues:
        if issue.get("type") != issue_type:
            continue
        for h in issue.get("statusFlow", []):
            role = h.get("by_role", "unknown")
            role_counter[role] += 1

    if role_counter:
        report_lines.append(f"\n\n### üë• –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —Ä–æ–ª—è–º ({issue_type})")
        report_lines.append("| –†–æ–ª—å | –ö–æ–ª-–≤–æ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ |")
        report_lines.append("|------|------------------|")
        for role, count in sorted(role_counter.items(), key=lambda x: -x[1]):
            report_lines.append(f"| {role} | {count} |")


# ==========================
# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
# ==========================

with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
    json.dump(summary, f, ensure_ascii=False, indent=2)

Path(REPORT_FILE).write_text("\n".join(report_lines), encoding="utf-8")

print(f"\n‚úÖ –†–∞—Å—á—ë—Ç –∑–∞–≤–µ—Ä—à—ë–Ω.")
print(f"üìä JSON —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {OUTPUT_FILE}")
print(f"üìù –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {REPORT_FILE}")
