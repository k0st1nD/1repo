# coding: utf-8
"""
export_users_from_jql.py
–í—ã–≥—Ä—É–∂–∞–µ—Ç –∏–∑ Jira —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ —á—Ç–æ-–ª–∏–±–æ –º–µ–Ω—è–ª–∏
–≤ –∑–∞–¥–∞—á–∞—Ö, –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö JQL-–∑–∞–ø—Ä–æ—Å–æ–º. –ü–∏—à–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.

–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
    pip install atlassian-python-api python-dateutil simplejson tqdm

–ü—Ä–∏–º–µ—Ä—ã:
    python export_users_from_jql.py --jql "project = CLM AND updated >= -30d"
    python export_users_from_jql.py --jql-file my_query.jql --limit 200 --outfile data/my_activity.csv
"""

import csv
import sys
import json
import argparse
import configparser
from pathlib import Path
from math import ceil
from datetime import datetime
from dateutil.parser import parse as dtparse
from tqdm import tqdm

try:
    from atlassian import Jira
except ImportError:
    print("–ù–µ –Ω–∞–π–¥–µ–Ω –ø–∞–∫–µ—Ç atlassian-python-api. –£—Å—Ç–∞–Ω–æ–≤–∏: pip install atlassian-python-api")
    sys.exit(1)


def read_config():
    cfg = configparser.ConfigParser()
    cfg.read("config.ini", encoding="utf-8")
    if "jira" not in cfg:
        raise RuntimeError("–í config.ini –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å–µ–∫—Ü–∏—è [jira]")
    j = cfg["jira"]
    return j.get("host"), j.get("username"), j.get("password")


def load_jql_from_args(args):
    if args.jql:
        return args.jql.strip()
    if args.jql_file:
        return Path(args.jql_file).read_text(encoding="utf-8").strip()
    raise RuntimeError("–ù—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å --jql –∏–ª–∏ --jql-file")


def connect_jira(host, username, password, verify_ssl=False):
    return Jira(url=host, username=username, password=password, verify_ssl=verify_ssl)


def fetch_issues_by_jql(jira, jql, fields, expand, page_limit=100, hard_limit=None):
    """
    –ó–∞–±–∏—Ä–∞–µ—Ç –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–æ JQL —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π (startAt).
    """
    # –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
    page = jira.jql(jql, fields=fields, expand=expand, limit=page_limit)
    issues = list(page.get("issues", []))
    total = int(page.get("total", len(issues)))

    if hard_limit:
        total = min(total, hard_limit)

    # –¥–æ–≥—Ä—É–∂–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    pages = ceil(total / page_limit)
    for i in tqdm(range(1, pages), desc="üì¶ –ü–∞–≥–∏–Ω–∞—Ü–∏—è –ø–æ JQL"):
        start = i * page_limit
        if hard_limit:
            # –Ω–µ –≤—ã—Ö–æ–¥–∏–º –∑–∞ –ø—Ä–µ–¥–µ–ª
            left = hard_limit - len(issues)
            if left <= 0:
                break
            limit = min(page_limit, left)
        else:
            limit = page_limit

        more = jira.jql(jql, fields=fields, expand=expand, limit=limit, start=start)
        issues.extend(more.get("issues", []))

    # –¥–µ–¥—É–ø–ª–∏–∫–∞—Ç –ø–æ –∫–ª—é—á—É
    uniq = {it["key"]: it for it in issues if "key" in it}
    return list(uniq.values()), total


def iter_changelog_rows(issue):
    """
    –ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç changelog.issue –≤ –∑–∞–ø–∏—Å–∏ –¥–ª—è CSV: (key, summary, at, author, field, from, to)
    """
    key = issue.get("key")
    fields = issue.get("fields", {})
    summary = fields.get("summary", "")
    changelog = issue.get("changelog", {}) or {}
    histories = changelog.get("histories", []) or []

    for item in histories:
        when = item.get("created")
        author = (item.get("author") or {}).get("displayName") or ""
        for ch in item.get("items", []) or []:
            field = ch.get("field") or ""
            from_s = ch.get("fromString")
            to_s = ch.get("toString")
            yield (key, summary, when, author, field, from_s, to_s)


def main():
    parser = argparse.ArgumentParser(description="–í—ã–≥—Ä—É–∑–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –∑–∞–¥–∞—á –ø–æ JQL")
    parser.add_argument("--jql", help="JQL —Å—Ç—Ä–æ–∫–∞")
    parser.add_argument("--jql-file", help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å JQL")
    parser.add_argument("--limit", type=int, default=None, help="–ñ—ë—Å—Ç–∫–∏–π –ª–∏–º–∏—Ç –∑–∞–¥–∞—á (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)")
    parser.add_argument("--outfile", default="data/jql_users_activity.csv", help="CSV —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é")
    parser.add_argument("--usersfile", default="data/jql_users_unique.csv", help="CSV —Å–æ —Å–ø–∏—Å–∫–æ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
    parser.add_argument("--verify-ssl", action="store_true", help="–ü—Ä–æ–≤–µ—Ä—è—Ç—å SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç")
    args = parser.parse_args()

    jql = load_jql_from_args(args)
    host, username, password = read_config()

    print(f"üîó Jira: {host}")
    print(f"üîé JQL: {jql}")

    jira = connect_jira(host, username, password, verify_ssl=args.verify_ssl)

    # –¢–µ –∂–µ –ø—Ä–∏—ë–º—ã —á—Ç–æ –∏ –≤ —Å—Ç–∞—Ç—É—Å–Ω—ã—Ö —Å–∫—Ä–∏–ø—Ç–∞—Ö: fields –∏ expand=changelog
    FIELDS = "key,summary"  # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è
    EXPAND = "changelog"

    issues, total_est = fetch_issues_by_jql(
        jira, jql, fields=FIELDS, expand=EXPAND, page_limit=100, hard_limit=args.limit
    )
    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ –∑–∞–¥–∞—á: {len(issues)} (–∏–∑ ~{total_est})")

    Path("data").mkdir(exist_ok=True, parents=True)

    # –ü–æ–¥—Ä–æ–±–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
    activity_path = Path(args.outfile)
    users_path = Path(args.usersfile)

    users = set()
    rows = []

    for issue in tqdm(issues, desc="üßæ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏–∏"):
        for row in iter_changelog_rows(issue):
            # row: (key, summary, when, author, field, from, to)
            rows.append(row)
            users.add(row[3].strip())

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å)
    def _safe_dt(x):
        try:
            return dtparse(x[2])
        except Exception:
            return datetime.max

    rows.sort(key=_safe_dt)

    # –ó–∞–ø–∏—Å—å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    with activity_path.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f, delimiter=";")
        w.writerow(["Issue", "Summary", "When", "Author", "Field", "From", "To"])
        for r in rows:
            w.writerow(r)

    # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
    users_list = sorted(u for u in users if u)
    with users_path.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f, delimiter=";")
        w.writerow(["Author"])
        for u in users_list:
            w.writerow([u])

    print(f"üìù –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∞–Ω–∞: {activity_path}")
    print(f"üë• –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏: {len(users_list)} ‚Üí {users_path}")


if __name__ == "__main__":
    main()
