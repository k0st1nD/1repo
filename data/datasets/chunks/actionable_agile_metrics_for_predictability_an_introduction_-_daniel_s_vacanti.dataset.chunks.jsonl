{"type": "header", "source_dataset": "actionable_agile_metrics_for_predictability_an_introduction_-_daniel_s_vacanti.dataset.jsonl", "source_file": null, "book": "actionable_agile_metrics_for_predictability_an_introduction_-_daniel_s_vacanti", "title": null, "total_chunks": 265, "chunk_size": 512, "chunk_overlap": 128, "stage": "chunks", "version": "2.0.0", "created_at": "2025-11-05T10:17:17Z"}
{"type": "chunk", "text": "Actionable Agile Metrics for Predictability\n\nAn Introduction\n\nDaniel S. Vacanti\n\nThis book is for sale at http://leanpub.com/actionableagilemetrics\nThis version was published on 2015-03-23\n\n* * * * *\nThis is a Leanpub book. Leanpub empowers authors and publishers\n\nwith the Lean Publishing process. Lean Publishing is the act of publishing\nan in-progress ebook using lightweight tools and many iterations to get\nreader feedback, pivot until you have the right book and build traction once\nyou do. * * * * *\n© 2015 Daniel S. Vacanti\n\nISBN for EPUB version: 978-0-9864363-0-7\nISBN for MOBI version: 978-0-9864363-1-4", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf\n\nActionable Agile Metrics for Predictability\n\nAn Introduction\n\nDaniel S. Vacanti\n\nThis book is for sale at http://leanpub.com/actionableagilemetrics\nThis version was published on 2015-03-23\n\n* * * * *\nThis is a Leanpub book. Leanpub empowers authors and publishers\n\nwith the Lean Publishing process. Lean Publishing is the act of publishing\nan in-progress ebook using lightweight tools and many iterations to get\nreader feedback, pivot until you have the right book and build traction once\nyou do. * * * * *\n© 2015 Daniel S. Vacanti\n\nISBN for EPUB version: 978-0-9864363-0-7\nISBN for MOBI version: 978-0-9864363-1-4", "tokens": 164, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 2, "segment_id": "00002", "chapter_num": null, "chapter_title": null, "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "chunk_id": "00000000"}
{"type": "chunk", "text": "Table of Contents\n\nPreface\n\nPART ONE - FLOW FOR PREDICTABILITY\n\nChapter 1 - Flow, Flow Metrics, and Predictability\n\nChapter 2 - The Basic Metrics of Flow\n\nChapter 3 - Introduction to Little’s Law\n\nPART TWO - CUMULATIVE FLOW DIAGRAMS FOR\nPREDICTABILITY\n\nChapter 4 - Introduction to CFDs\n\nChapter 5 - Flow Metrics and CFDs\n\nChapter 6 - Interpreting CFDs\n\nChapter 7 - Conservation of Flow Part I\n\nChapter 8 - Conservation of Flow Part II\n\nChapter 9 - Flow Debt\n\nPART THREE - CYCLE TIME SCATTERPLOTS FOR\nPREDICTABILITY\n\nChapter 10 - Introduction to Cycle Time Scatterplots\n\nChapter 10a - Cycle Time Histograms\n\nChapter 11 - Interpreting Cycle Time Scatterplots\n\nChapter 12 - Service Level Agreements\n\nPART FOUR - PUTTING IT ALL TOGETHER FOR\nPREDICTABILITY", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf\n\nTable of Contents\n\nPreface\n\nPART ONE - FLOW FOR PREDICTABILITY\n\nChapter 1 - Flow, Flow Metrics, and Predictability\n\nChapter 2 - The Basic Metrics of Flow\n\nChapter 3 - Introduction to Little’s Law\n\nPART TWO - CUMULATIVE FLOW DIAGRAMS FOR\nPREDICTABILITY\n\nChapter 4 - Introduction to CFDs\n\nChapter 5 - Flow Metrics and CFDs\n\nChapter 6 - Interpreting CFDs\n\nChapter 7 - Conservation of Flow Part I\n\nChapter 8 - Conservation of Flow Part II\n\nChapter 9 - Flow Debt\n\nPART THREE - CYCLE TIME SCATTERPLOTS FOR\nPREDICTABILITY\n\nChapter 10 - Introduction to Cycle Time Scatterplots\n\nChapter 10a - Cycle Time Histograms\n\nChapter 11 - Interpreting Cycle Time Scatterplots\n\nChapter 12 - Service Level Agreements\n\nPART FOUR - PUTTING IT ALL TOGETHER FOR\nPREDICTABILITY", "tokens": 204, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 4, "segment_id": "00004", "chapter_num": null, "chapter_title": null, "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "chunk_id": "00000001"}
{"type": "chunk", "text": "Preface\n\nYour process is unpredictable. What you may not realize, though, is that\nyou are the one responsible for making it that way. But that is not\nnecessarily your fault. You have been taught to collect the wrong metrics,\nimplement the wrong policies, and make the wrong decisions. Together, we\ncan do better. Up until now you have probably assumed that the reason your process\nis unpredictable is due to circumstances completely outside of your control. However, you have much more control over the way you work than you\nthink you do. Whether explicit or not, you have put policies in place that\nspecifically prevent you from being predictable. Amongst other things you\nstart new work at a faster rate than you finish old work, you work on too\nmany items at the same time, you ignore systemic dependencies and\nimpediments, and you expedite requests that do not need to be expedited. You, in effect, initiate a denial of service attack on yourself, and then\nwonder why it takes so long for things to get things done. But all of those policies are under your control. If we, as knowledge workers, want to get to a predictable world, we\n\nmust first start by controlling the policies we can control. Taking this\ncontrol will seem uncomfortable at first. It will mean saying no to customer\nrequests to start new work immediately. It will mean placing much less\nemphasis on upfront estimation and planning. It will mean looking at a\ndifferent set of metrics than the ones you have been trained to track. Those\nmetrics will tell you how predictable you are and what actions to take to\nimprove. If you choose to collect the metrics suggested by this book, you\nwill see that the data provided by them will immediately reflect policies you\nhave in place. That data will in turn suggest the changes to your policies\nnecessary to be more predictable. Those policy changes will themselves be\nreflected in the new data you collect after the change. And so on and so on. Your process is unpredictable. You know it. Your customers know it. Now it is time to do something about it.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nPreface\n\nYour process is unpredictable. What you may not realize, though, is that\nyou are the one responsible for making it that way. But that is not\nnecessarily your fault. You have been taught to collect the wrong metrics,\nimplement the wrong policies, and make the wrong decisions. Together, we\ncan do better. Up until now you have probably assumed that the reason your process\nis unpredictable is due to circumstances completely outside of your control. However, you have much more control over the way you work than you\nthink you do. Whether explicit or not, you have put policies in place that\nspecifically prevent you from being predictable. Amongst other things you\nstart new work at a faster rate than you finish old work, you work on too\nmany items at the same time, you ignore systemic dependencies and\nimpediments, and you expedite requests that do not need to be expedited. You, in effect, initiate a denial of service attack on yourself, and then\nwonder why it takes so long for things to get things done. But all of those policies are under your control. If we, as knowledge workers, want to get to a predictable world, we\n\nmust first start by controlling the policies we can control. Taking this\ncontrol will seem uncomfortable at first. It will mean saying no to customer\nrequests to start new work immediately. It will mean placing much less\nemphasis on upfront estimation and planning. It will mean looking at a\ndifferent set of metrics than the ones you have been trained to track. Those\nmetrics will tell you how predictable you are and what actions to take to\nimprove. If you choose to collect the metrics suggested by this book, you\nwill see that the data provided by them will immediately reflect policies you\nhave in place. That data will in turn suggest the changes to your policies\nnecessary to be more predictable. Those policy changes will themselves be\nreflected in the new data you collect after the change. And so on and so on. Your process is unpredictable. You know it. Your customers know it. Now it is time to do something about it.", "tokens": 438, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 6, "segment_id": "00006", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000002"}
{"type": "chunk", "text": "Why Write this Book? Because our customers demand predictability. Because you need someone\non your side who has been asked tough questions and has found a way to\ngive meaningful answers. Because most organizations that I visit are either\nuninformed or have been misinformed about what metrics and analytics\nthey need to track to be predictable. But to get you where you need to be, I am going to ask you\nprovocative questions. I am going to challenge your assumptions about\nwhat true Agility is. I may make you uncomfortable with some of the\nconclusions that I draw. I hope you will forgive me for all of these as my\nonly intention is to make your process better. After all, as I just said, I am\non your side. Who Should Read this Book\nAnyone who has ever been asked to give an estimate should read this book. Likewise, anyone who has ever asked for an estimate should read this book. Analysts, developers and testers need to know how to stop giving\n\nestimates and how to start making accurate predictions. Product owners, project managers, and executives need to know what\n\nmakes for a meaningful prediction and how to hold teams accountable to\nmake those predictions. Conventions Used\nAll metrics and analytics will be capitalized. For example: Work In\nProgress, Cycle Time, Throughput, Cumulative Flow Diagram, Scatterplot,\netc. I am also going to capitalize all methodology names. For example:\n\nAgile, Scrum, Kanban, etc. Lastly, I am going to use the words “process” and “system”\n\ninterchangeably. I will try to make the distinction clear when a distinction is\nnecessary. How to Read\nThis book is intended to be read in order as the concepts in later chapters\nare built on the concepts developed in earlier ones. However, each chapter", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nWhy Write this Book? Because our customers demand predictability. Because you need someone\non your side who has been asked tough questions and has found a way to\ngive meaningful answers. Because most organizations that I visit are either\nuninformed or have been misinformed about what metrics and analytics\nthey need to track to be predictable. But to get you where you need to be, I am going to ask you\nprovocative questions. I am going to challenge your assumptions about\nwhat true Agility is. I may make you uncomfortable with some of the\nconclusions that I draw. I hope you will forgive me for all of these as my\nonly intention is to make your process better. After all, as I just said, I am\non your side. Who Should Read this Book\nAnyone who has ever been asked to give an estimate should read this book. Likewise, anyone who has ever asked for an estimate should read this book. Analysts, developers and testers need to know how to stop giving\n\nestimates and how to start making accurate predictions. Product owners, project managers, and executives need to know what\n\nmakes for a meaningful prediction and how to hold teams accountable to\nmake those predictions. Conventions Used\nAll metrics and analytics will be capitalized. For example: Work In\nProgress, Cycle Time, Throughput, Cumulative Flow Diagram, Scatterplot,\netc. I am also going to capitalize all methodology names. For example:\n\nAgile, Scrum, Kanban, etc. Lastly, I am going to use the words “process” and “system”\n\ninterchangeably. I will try to make the distinction clear when a distinction is\nnecessary. How to Read\nThis book is intended to be read in order as the concepts in later chapters\nare built on the concepts developed in earlier ones. However, each chapter", "tokens": 377, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 7, "segment_id": "00007", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000003"}
{"type": "chunk", "text": "can stand alone, and, where possible, when I re-examine a concept that has\nalready been explained, I will try to reference the part of the book that\ncontains the more detailed explanation. PART ONE -- FLOW FOR PREDICTABILITY\nChapter 1 defines my notion of predictability. It introduces the\n\nmetrics that are necessary to track to become predictable, and it will explain\nwhat it means to turn those metrics into actionable interventions. Chapter 2 is a detailed discussion of the basic metrics of flow. The\n\nrest of the book will assume knowledge of what those metrics are and how\nthey are defined. Chapter 3 is an introduction to Little’s Law. If you want to be\npredictable, you have to understand why Little’s Law works. Period. PART TWO -- CUMULATIVE FLOW DIAGRAMS FOR\n\nPREDICTABILITY\n\nChapter 4 is an in depth explanation of what Cumulative Flow\nDiagrams (CFDs) are and what they are not. This chapter is a must read\nbecause most previous agile publications that deal with CFDs are erroneous\nand most agile electronic tools build them incorrectly. I will attempt to\nremedy all of that. Chapter 5 explains how to read all of the basic metrics of flow off of a\n\nCFD. The ability to read these metrics is one of the biggest reasons to use\nCFDs in the first place. Chapter 6 explains how to interpret the results of a generated CFD. Many common patterns that appear in CFDs are explained. Chapter 7 begins the exploration of the assumptions behind Little’s\n\nLaw and CFDs by looking at process arrivals and departures. If you get\nthese right then you have gone a long way toward predictability. Not\ninconsequentially, arrivals and departures represents the first part of a\nprinciple known as the Conservation of Flow\n\nChapter 8 continues the discussion of Little’s Law’s assumptions by\n\nlooking at the second part of the principle of Conservation of Flow. This\nsecond part explains why just-in-time commitments and just-in-time\nprioritization is possible and necessary for predictability. Chapter 9 introduces the little-known concept of Flow Debt, how to\n\nsee it on a CFD, and why it kills predictability. What actions to take when it\naccumulates are also discussed.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\ncan stand alone, and, where possible, when I re-examine a concept that has\nalready been explained, I will try to reference the part of the book that\ncontains the more detailed explanation. PART ONE -- FLOW FOR PREDICTABILITY\nChapter 1 defines my notion of predictability. It introduces the\n\nmetrics that are necessary to track to become predictable, and it will explain\nwhat it means to turn those metrics into actionable interventions. Chapter 2 is a detailed discussion of the basic metrics of flow. The\n\nrest of the book will assume knowledge of what those metrics are and how\nthey are defined. Chapter 3 is an introduction to Little’s Law. If you want to be\npredictable, you have to understand why Little’s Law works. Period. PART TWO -- CUMULATIVE FLOW DIAGRAMS FOR\n\nPREDICTABILITY\n\nChapter 4 is an in depth explanation of what Cumulative Flow\nDiagrams (CFDs) are and what they are not. This chapter is a must read\nbecause most previous agile publications that deal with CFDs are erroneous\nand most agile electronic tools build them incorrectly. I will attempt to\nremedy all of that. Chapter 5 explains how to read all of the basic metrics of flow off of a\n\nCFD. The ability to read these metrics is one of the biggest reasons to use\nCFDs in the first place. Chapter 6 explains how to interpret the results of a generated CFD. Many common patterns that appear in CFDs are explained. Chapter 7 begins the exploration of the assumptions behind Little’s\n\nLaw and CFDs by looking at process arrivals and departures. If you get\nthese right then you have gone a long way toward predictability. Not\ninconsequentially, arrivals and departures represents the first part of a\nprinciple known as the Conservation of Flow\n\nChapter 8 continues the discussion of Little’s Law’s assumptions by\n\nlooking at the second part of the principle of Conservation of Flow. This\nsecond part explains why just-in-time commitments and just-in-time\nprioritization is possible and necessary for predictability. Chapter 9 introduces the little-known concept of Flow Debt, how to\n\nsee it on a CFD, and why it kills predictability. What actions to take when it\naccumulates are also discussed.", "tokens": 482, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 8, "segment_id": "00008", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000004"}
{"type": "chunk", "text": "PART THREE -- CYCLE TIME SCATTERPLOTS FOR\n\nPREDICTABILITY\n\nChapter 10 is an in depth examination of the second most important\n\nanalytical chart: the Cycle Time Scatterplot. Chapter 11 explains how to interpret a Cycle Time Scatterplot. Many\n\ncommon patterns that appear on Scatterplots are explained. Chapter 12 introduces one of the least known and least understood\n\npractices needed for predictability: the Cycle Time Service Level\nAgreement (SLA). Some thoughts on how to set SLAs and manage to them\nare explored. PART FOUR -- PUTTING IT ALL TOGETHER FOR\n\nPREDICTABILITY\n\nChapter 13 explores pull policies and how those policies are one of\n\nthe main sources of variability in your process. Chapter 14 presents a survey of some forecasting techniques and the\n\npros and cons of each. Chapter 15 is my take on some of the advantages and pitfalls of the\n\nMonte Carlo Method as they pertain to predictability. Chapter 16 presents a short guide on how to get started and outlines\nsome pitfalls to watch out for as you begin. If you get overwhelmed with\nyour own data initiative, this chapter is a good place to start. PART FIVE -- A CASE STUDY FOR PREDICTABILITY\nChapter 17 re-examines a previously published case study from\n\nSiemens Health Services. This case study has been updated with an\nemphasis on how Siemens put into practice all of the principles in this\nbook. There is another disclaimer I should mention up front. The concepts in\n\nthe book are based on the principles of flow. What flow is and how to\nachieve it is a topic for a whole book in itself, so I will not spend much time\non those definitions. I refer you to the work of Don Reinertsen and some of\nthe other authors listed in the Bibliography for a more detailed discussion of\nflow. Also, I believe the concepts presented throughout are relevant\nregardless of your chosen Agile implementation. Where applicable, I will\ntry to point out how actions might differ based on a specific Agile\nmethodology.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: is an in depth examination of the second most important\n\nPART THREE -- CYCLE TIME SCATTERPLOTS FOR\n\nPREDICTABILITY\n\nChapter 10 is an in depth examination of the second most important\n\nanalytical chart: the Cycle Time Scatterplot. Chapter 11 explains how to interpret a Cycle Time Scatterplot. Many\n\ncommon patterns that appear on Scatterplots are explained. Chapter 12 introduces one of the least known and least understood\n\npractices needed for predictability: the Cycle Time Service Level\nAgreement (SLA). Some thoughts on how to set SLAs and manage to them\nare explored. PART FOUR -- PUTTING IT ALL TOGETHER FOR\n\nPREDICTABILITY\n\nChapter 13 explores pull policies and how those policies are one of\n\nthe main sources of variability in your process. Chapter 14 presents a survey of some forecasting techniques and the\n\npros and cons of each. Chapter 15 is my take on some of the advantages and pitfalls of the\n\nMonte Carlo Method as they pertain to predictability. Chapter 16 presents a short guide on how to get started and outlines\nsome pitfalls to watch out for as you begin. If you get overwhelmed with\nyour own data initiative, this chapter is a good place to start. PART FIVE -- A CASE STUDY FOR PREDICTABILITY\nChapter 17 re-examines a previously published case study from\n\nSiemens Health Services. This case study has been updated with an\nemphasis on how Siemens put into practice all of the principles in this\nbook. There is another disclaimer I should mention up front. The concepts in\n\nthe book are based on the principles of flow. What flow is and how to\nachieve it is a topic for a whole book in itself, so I will not spend much time\non those definitions. I refer you to the work of Don Reinertsen and some of\nthe other authors listed in the Bibliography for a more detailed discussion of\nflow. Also, I believe the concepts presented throughout are relevant\nregardless of your chosen Agile implementation. Where applicable, I will\ntry to point out how actions might differ based on a specific Agile\nmethodology.", "tokens": 434, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 9, "segment_id": "00009", "chapter_num": "10", "chapter_title": "is an in depth examination of the second most important", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: is an in depth examination of the second most important", "chunk_id": "00000005"}
{"type": "chunk", "text": "Lastly, this book has a distinct software development bent to it, but\n\nyou need not be in the software product development industry nor do you\nneed to be familiar with any Agile methodology to understand these\nprinciples. They can be equally applied to any process regardless of\ndomain. ActionableAgile.com\nFinally, and unless otherwise noted, all of the analytics presented in this\nbook were built using the ActionableAgileTM Analytics tool. This tool is\none that I helped to develop and can be found at:\n\nhttps://actionableagile.com\n\nIn addition to the tool, accompanying blog posts, book updates and\n\nerrata, videos, etc. can also be found at this website.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: is an in depth examination of the second most important\n\nLastly, this book has a distinct software development bent to it, but\n\nyou need not be in the software product development industry nor do you\nneed to be familiar with any Agile methodology to understand these\nprinciples. They can be equally applied to any process regardless of\ndomain. ActionableAgile.com\nFinally, and unless otherwise noted, all of the analytics presented in this\nbook were built using the ActionableAgileTM Analytics tool. This tool is\none that I helped to develop and can be found at:\n\nhttps://actionableagile.com\n\nIn addition to the tool, accompanying blog posts, book updates and\n\nerrata, videos, etc. can also be found at this website.", "tokens": 145, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 10, "segment_id": "00010", "chapter_num": "10", "chapter_title": "is an in depth examination of the second most important", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: is an in depth examination of the second most important", "chunk_id": "00000006"}
{"type": "chunk", "text": "Chapter 1 - Flow, Flow Metrics, and Predictability\n\nI first met Bennet Vallet in the spring of 2012. At the time, Bennet was a\nDirector of Product Development for Siemens Health Services (HS) located\njust outside of Philadelphia, Pennsylvania. We met one night at an Agile\nPhilly event where I was giving a talk on the principles of flow. He came up\nto me after my presentation and asked if we could set up some time later to\ndiscuss the problems he was facing at HS. Of course I agreed. We spoke on the phone the following day and during that call Bennet\n\noutlined his thoughts on all the issues he was facing at HS. Those issues are\nfully documented in the case study presented in Chapter 17 so I will not go\ninto any detail here. Suffice it to say, however, that toward the end of the\ncall, I suggested to Bennet that to fix these problems we must first consider\nwhat is most important to his customers. In other words, if I were to speak\nto his customers, what would they tell me were the three most important\nthings to them? “Oh, that’s easy,” Bennet replied. “The three most important things to\n\nour customers are predictability, predictability, and predictability.”\n\nPredictability\n“When will it be done?”\n\nThat is the first question your customers ask you once you start work\n\nfor them. And, for the most part, it is the only thing they are interested in\nuntil you deliver. Whether your process is predictable or not is judged by\nthe accuracy of your answer. Think about how many times you have been\nasked that question and think how many times you have been wrong. Now think about some of the practices you have put in place to come\nup with your answer. Maybe you have an Agile methodology you are fond\nof. Maybe you prefer a more traditional project management approach. But\nare either of those practices actually helping? As a case in point, Bennet had been working with mature Agile teams\n\nfor a long time, and those teams had been adhering to established Agile\npractices. In his mind he was doing everything right, so he reasonably", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability\n\nChapter 1 - Flow, Flow Metrics, and Predictability\n\nI first met Bennet Vallet in the spring of 2012. At the time, Bennet was a\nDirector of Product Development for Siemens Health Services (HS) located\njust outside of Philadelphia, Pennsylvania. We met one night at an Agile\nPhilly event where I was giving a talk on the principles of flow. He came up\nto me after my presentation and asked if we could set up some time later to\ndiscuss the problems he was facing at HS. Of course I agreed. We spoke on the phone the following day and during that call Bennet\n\noutlined his thoughts on all the issues he was facing at HS. Those issues are\nfully documented in the case study presented in Chapter 17 so I will not go\ninto any detail here. Suffice it to say, however, that toward the end of the\ncall, I suggested to Bennet that to fix these problems we must first consider\nwhat is most important to his customers. In other words, if I were to speak\nto his customers, what would they tell me were the three most important\nthings to them? “Oh, that’s easy,” Bennet replied. “The three most important things to\n\nour customers are predictability, predictability, and predictability.”\n\nPredictability\n“When will it be done?”\n\nThat is the first question your customers ask you once you start work\n\nfor them. And, for the most part, it is the only thing they are interested in\nuntil you deliver. Whether your process is predictable or not is judged by\nthe accuracy of your answer. Think about how many times you have been\nasked that question and think how many times you have been wrong. Now think about some of the practices you have put in place to come\nup with your answer. Maybe you have an Agile methodology you are fond\nof. Maybe you prefer a more traditional project management approach. But\nare either of those practices actually helping? As a case in point, Bennet had been working with mature Agile teams\n\nfor a long time, and those teams had been adhering to established Agile\npractices. In his mind he was doing everything right, so he reasonably", "tokens": 457, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 12, "segment_id": "00012", "chapter_num": "1", "chapter_title": "Flow, Flow Metrics, and Predictability", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability", "chunk_id": "00000007"}
{"type": "chunk", "text": "believed that predictability would inevitably follow. Yet he constantly\nstruggled to accurately answer the most important questions that his\ncustomers were asking. To illustrate why Bennet struggled (and why you probably struggle as\n\nwell), I would like you to look through the following set of questions and\nsee if one or more apply to your current situation: - Are you constantly\nasked to start new work before you have had a chance to finish old work? -\nAre you constantly asked to expedite new requests in addition to being\nexpected to get all of your other current work done according to original\nestimates and commitments? - How many features do you start but do not\nfinish because they get cancelled while you are working on them? How\nlikely is it that the new items that replace the cancelled work will\nthemselves get cancelled? - When something that you are working on gets\nblocked (for whatever reason), do you simply put that blocked work aside\nand start to work on something new? - Do your estimates give consideration\nto how many other items will be in progress at the time you start work? -\nDo you ignore the order in which you work on items currently in progress? - Do you constantly add new scope or acceptance criteria to items in\nprogress because it is easier to modify an existing feature rather than to\nopen a new one? - When an item takes too long to complete, have you ever\nsaid or heard someone say “it is just bigger than we thought it was” and/or\n“it will get done when it gets done”? - When things take too long to\ncomplete, is management’s first response always to have the team work\novertime? I could list many more, but the point is that these behaviors are\nsymptomatic of something seriously wrong with your process. Regrettably,\nyour chosen project management framework (including any Agile\nmethodology you may be using) may be perpetuating the underlying illness. When it comes to unpredictability, the thing that really ails you is a lack of\nflow. Flow and the Basic Metrics of Flow\nSimply stated, flow is the movement and delivery of customer value\nthrough a process. In knowledge work, our whole reason for existence is to\ndeliver value to the customer. Therefore, it stands to reason that our whole\nprocess should be oriented around optimizing flow.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability\n\nbelieved that predictability would inevitably follow. Yet he constantly\nstruggled to accurately answer the most important questions that his\ncustomers were asking. To illustrate why Bennet struggled (and why you probably struggle as\n\nwell), I would like you to look through the following set of questions and\nsee if one or more apply to your current situation: - Are you constantly\nasked to start new work before you have had a chance to finish old work? -\nAre you constantly asked to expedite new requests in addition to being\nexpected to get all of your other current work done according to original\nestimates and commitments? - How many features do you start but do not\nfinish because they get cancelled while you are working on them? How\nlikely is it that the new items that replace the cancelled work will\nthemselves get cancelled? - When something that you are working on gets\nblocked (for whatever reason), do you simply put that blocked work aside\nand start to work on something new? - Do your estimates give consideration\nto how many other items will be in progress at the time you start work? -\nDo you ignore the order in which you work on items currently in progress? - Do you constantly add new scope or acceptance criteria to items in\nprogress because it is easier to modify an existing feature rather than to\nopen a new one? - When an item takes too long to complete, have you ever\nsaid or heard someone say “it is just bigger than we thought it was” and/or\n“it will get done when it gets done”? - When things take too long to\ncomplete, is management’s first response always to have the team work\novertime? I could list many more, but the point is that these behaviors are\nsymptomatic of something seriously wrong with your process. Regrettably,\nyour chosen project management framework (including any Agile\nmethodology you may be using) may be perpetuating the underlying illness. When it comes to unpredictability, the thing that really ails you is a lack of\nflow. Flow and the Basic Metrics of Flow\nSimply stated, flow is the movement and delivery of customer value\nthrough a process. In knowledge work, our whole reason for existence is to\ndeliver value to the customer. Therefore, it stands to reason that our whole\nprocess should be oriented around optimizing flow.", "tokens": 482, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 13, "segment_id": "00013", "chapter_num": "1", "chapter_title": "Flow, Flow Metrics, and Predictability", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability", "chunk_id": "00000008"}
{"type": "chunk", "text": "If your process is unpredictable, the first thing to investigate is poor\n\nflow. A telltale sign of a suboptimal flow is a large buildup of work\nsomewhere in your process. This buildup of work is most commonly called\na “queue”. Large queues generally mean no flow. Queues form when work items that have been started just get stuck\n\nsomewhere in your process (without completing). Items may get stuck\nbecause: - There are no more resources available to continue working on\nthem. - Some manager mandates that more new work be started before\ncurrent work has finished. - Resources that are actually doing the work are\nconstantly pulled in multiple different directions and are not allowed to\nfocus on any one thing. - There is a dependency on some external team or\nvendor. Work may get stuck for all of those reasons and more. Management of\n\nflow, therefore, usually begins by attempting to “unstick” stuck work. Unfortunately, your project management framework makes you blind\n\nto queues. You are blind to them because you are never asked to look for\nthem in the first place. If you are doing some sort of Agile, then you might\nassume that iterations or sprints insulate you from large queues. However, if\nyou answered “yes” to any of the questions I asked above, then there is a\ngood chance you have a large buildup of work somewhere in your process. Even though you do not see these large queues, you are constantly\nfeeling their effect. The most obvious effect that you feel is that work takes\ntoo long to complete. Traditional project management responses to\nelongated completion times might be to constantly refigure project plans, to\ncontinuously revisit resource assignments, and to force teams to work\novertime. Not only do those actions not solve the core problem, but in most\ninstances they tend to make things worse. But what if we could see these problems before they happen? What if\n\nwe could take action to prevent them from happening in the first place? That is where actionable metrics come in. Actionable Metrics for Predictability\nThe best way to fix the problem of large queues is not to allow them to form\nin the first place. To do that we must somehow measure our queues. The\nbest way to measure a queue is to simply count the number of items you are\nworking on at any given time. When that number gets too big then no new\nwork gets started until something old has finished.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability\n\nIf your process is unpredictable, the first thing to investigate is poor\n\nflow. A telltale sign of a suboptimal flow is a large buildup of work\nsomewhere in your process. This buildup of work is most commonly called\na “queue”. Large queues generally mean no flow. Queues form when work items that have been started just get stuck\n\nsomewhere in your process (without completing). Items may get stuck\nbecause: - There are no more resources available to continue working on\nthem. - Some manager mandates that more new work be started before\ncurrent work has finished. - Resources that are actually doing the work are\nconstantly pulled in multiple different directions and are not allowed to\nfocus on any one thing. - There is a dependency on some external team or\nvendor. Work may get stuck for all of those reasons and more. Management of\n\nflow, therefore, usually begins by attempting to “unstick” stuck work. Unfortunately, your project management framework makes you blind\n\nto queues. You are blind to them because you are never asked to look for\nthem in the first place. If you are doing some sort of Agile, then you might\nassume that iterations or sprints insulate you from large queues. However, if\nyou answered “yes” to any of the questions I asked above, then there is a\ngood chance you have a large buildup of work somewhere in your process. Even though you do not see these large queues, you are constantly\nfeeling their effect. The most obvious effect that you feel is that work takes\ntoo long to complete. Traditional project management responses to\nelongated completion times might be to constantly refigure project plans, to\ncontinuously revisit resource assignments, and to force teams to work\novertime. Not only do those actions not solve the core problem, but in most\ninstances they tend to make things worse. But what if we could see these problems before they happen? What if\n\nwe could take action to prevent them from happening in the first place? That is where actionable metrics come in. Actionable Metrics for Predictability\nThe best way to fix the problem of large queues is not to allow them to form\nin the first place. To do that we must somehow measure our queues. The\nbest way to measure a queue is to simply count the number of items you are\nworking on at any given time. When that number gets too big then no new\nwork gets started until something old has finished.", "tokens": 508, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 14, "segment_id": "00014", "chapter_num": "1", "chapter_title": "Flow, Flow Metrics, and Predictability", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability", "chunk_id": "00000009"}
{"type": "chunk", "text": "But what if we could see these problems before they happen? What if\n\nwe could take action to prevent them from happening in the first place? That is where actionable metrics come in. Actionable Metrics for Predictability\nThe best way to fix the problem of large queues is not to allow them to form\nin the first place. To do that we must somehow measure our queues. The\nbest way to measure a queue is to simply count the number of items you are\nworking on at any given time. When that number gets too big then no new\nwork gets started until something old has finished. The total count of items", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability\n\nBut what if we could see these problems before they happen? What if\n\nwe could take action to prevent them from happening in the first place? That is where actionable metrics come in. Actionable Metrics for Predictability\nThe best way to fix the problem of large queues is not to allow them to form\nin the first place. To do that we must somehow measure our queues. The\nbest way to measure a queue is to simply count the number of items you are\nworking on at any given time. When that number gets too big then no new\nwork gets started until something old has finished. The total count of items", "tokens": 127, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 14, "segment_id": "00014", "chapter_num": "1", "chapter_title": "Flow, Flow Metrics, and Predictability", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability", "chunk_id": "00000010"}
{"type": "chunk", "text": "currently being worked on is the flow metric commonly known as Work In\nProgress. As I just mentioned, the direct consequence of large buildup of work is\nthat all of that queued work itself takes longer to complete. The flow metric\nthat represents how long it takes for work to complete is called Cycle Time. Cycle Time ultimately answers the question of “When will it be done?” A\nprocess with elongated Cycle Times makes it harder to answer that\nquestion. The direct consequence of elongated Cycle Times is a decrease in\nThroughput. Throughput is the metric that represents how much work\ncompletes per unit of time. A decrease in Throughput therefore means that\nless work is getting done. The less work that gets done, the less value we\ndeliver. To manage flow we are going to need to closely monitor those three\n\nmetrics:\n\n1. Work In Progress (the number of items that we are working on at any\n\ngiven time),\n\n2. Cycle Time (how long it takes each of those items to get through our\n\nprocess), and\n\n3. Throughput (how many of those items complete per unit of time). The rest of this book will explain that if your process is not\npredictable, or is veering away from predictability, these metrics will\nsuggest specific interventions that you can make to get back on track. In a\nword, these metrics are actionable. Actionable Metrics for Predictability: The set of metrics that will suggest specific\ninterventions that will result in the outcomes you are expecting. Once we know what metrics to track, we can visualize those metrics in\n\nflow-based analytics. These analytics will bring visibility to any problems\nwith flow much more quickly so that we can proactively deal with issues\nrather than retroactively fight fires. Items taking too long? Not enough getting done? These metrics and\n\nanalytics will give us some of the magic levers we can pull to make things", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability\n\ncurrently being worked on is the flow metric commonly known as Work In\nProgress. As I just mentioned, the direct consequence of large buildup of work is\nthat all of that queued work itself takes longer to complete. The flow metric\nthat represents how long it takes for work to complete is called Cycle Time. Cycle Time ultimately answers the question of “When will it be done?” A\nprocess with elongated Cycle Times makes it harder to answer that\nquestion. The direct consequence of elongated Cycle Times is a decrease in\nThroughput. Throughput is the metric that represents how much work\ncompletes per unit of time. A decrease in Throughput therefore means that\nless work is getting done. The less work that gets done, the less value we\ndeliver. To manage flow we are going to need to closely monitor those three\n\nmetrics:\n\n1. Work In Progress (the number of items that we are working on at any\n\ngiven time),\n\n2. Cycle Time (how long it takes each of those items to get through our\n\nprocess), and\n\n3. Throughput (how many of those items complete per unit of time). The rest of this book will explain that if your process is not\npredictable, or is veering away from predictability, these metrics will\nsuggest specific interventions that you can make to get back on track. In a\nword, these metrics are actionable. Actionable Metrics for Predictability: The set of metrics that will suggest specific\ninterventions that will result in the outcomes you are expecting. Once we know what metrics to track, we can visualize those metrics in\n\nflow-based analytics. These analytics will bring visibility to any problems\nwith flow much more quickly so that we can proactively deal with issues\nrather than retroactively fight fires. Items taking too long? Not enough getting done? These metrics and\n\nanalytics will give us some of the magic levers we can pull to make things", "tokens": 394, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 15, "segment_id": "00015", "chapter_num": "1", "chapter_title": "Flow, Flow Metrics, and Predictability", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability", "chunk_id": "00000011"}
{"type": "chunk", "text": "better. Why These Metrics\nIn addition to being actionable, there are certain other criteria that must be\nmet when deciding what metrics to capture. Eric Reis, of Lean Startup\nfame, gives one perspective: “The only metrics that entrepreneurs should\ninvest in are those that help them make decisions.” Well said. Troy\nMagennis, of Lean Forecasting fame, goes even further: “If a metric does\nnot offer predictive power, then capturing that metric is waste.” I discussed\nearlier how the important questions that our customers ask are going to\nrequire us to make predictions. I have further suggested that these flow\nmetrics in and of themselves are the answers to those questions. By\ndefinition, then, tracking these metrics offer predictive power and will help\nus make better decisions. Yet another vital criterion exists that should be considered when\ndetermining what metrics to capture: cost. There is no point in tracking a\nmetric if it is going to bankrupt you to do so. Herein lies yet another\nadvantage of tracking these metrics of flow: these metrics are very\ninexpensive to gather. Any Agile tool should track these metrics (how easy\nit is to mine this data from a given tool and how accurately those tools\ndisplay the analytics is a different story that we will get to in Chapter 16). Even if you do not have an Agile tool, these metrics are very easy to\nmanually track using a simple spreadsheet. WIP, Cycle Time, and\nThroughput take very little time to collect, and offer the biggest bang for the\nbuck in terms of gaining precious insight into the overall health,\nperformance, and predictability of your process. Why Not Traditional Agile Metrics? For the most part, the types of actionable metrics and analytics to be\ndiscussed in this book do not exist in traditional Agile guidance and\ntraditional methodologies. They do not exist because, as I discussed earlier,\nmost of those earlier methodologies were not designed from the premise\nthat managing flow is the best strategy for predictability. Further, traditional\nAgile metrics and analytics give no visibility nor any suggestion of what to\ndo when things go wrong. “Work Harder”, “Estimate Better”, “Plan Better”,\n“Hope”, “Pray”, “Cry” are not viable nor sustainable strategies.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability\n\nbetter. Why These Metrics\nIn addition to being actionable, there are certain other criteria that must be\nmet when deciding what metrics to capture. Eric Reis, of Lean Startup\nfame, gives one perspective: “The only metrics that entrepreneurs should\ninvest in are those that help them make decisions.” Well said. Troy\nMagennis, of Lean Forecasting fame, goes even further: “If a metric does\nnot offer predictive power, then capturing that metric is waste.” I discussed\nearlier how the important questions that our customers ask are going to\nrequire us to make predictions. I have further suggested that these flow\nmetrics in and of themselves are the answers to those questions. By\ndefinition, then, tracking these metrics offer predictive power and will help\nus make better decisions. Yet another vital criterion exists that should be considered when\ndetermining what metrics to capture: cost. There is no point in tracking a\nmetric if it is going to bankrupt you to do so. Herein lies yet another\nadvantage of tracking these metrics of flow: these metrics are very\ninexpensive to gather. Any Agile tool should track these metrics (how easy\nit is to mine this data from a given tool and how accurately those tools\ndisplay the analytics is a different story that we will get to in Chapter 16). Even if you do not have an Agile tool, these metrics are very easy to\nmanually track using a simple spreadsheet. WIP, Cycle Time, and\nThroughput take very little time to collect, and offer the biggest bang for the\nbuck in terms of gaining precious insight into the overall health,\nperformance, and predictability of your process. Why Not Traditional Agile Metrics? For the most part, the types of actionable metrics and analytics to be\ndiscussed in this book do not exist in traditional Agile guidance and\ntraditional methodologies. They do not exist because, as I discussed earlier,\nmost of those earlier methodologies were not designed from the premise\nthat managing flow is the best strategy for predictability. Further, traditional\nAgile metrics and analytics give no visibility nor any suggestion of what to\ndo when things go wrong. “Work Harder”, “Estimate Better”, “Plan Better”,\n“Hope”, “Pray”, “Cry” are not viable nor sustainable strategies.", "tokens": 475, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 16, "segment_id": "00016", "chapter_num": "1", "chapter_title": "Flow, Flow Metrics, and Predictability", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability", "chunk_id": "00000012"}
{"type": "chunk", "text": "Adding to this problem is that all of the tooling that has been\ndeveloped around these legacy Agile metrics provide incorrect or\nincomplete information. In the absence of a tool to do it for them, a team’s\nonly option is to manually track flow metrics and build the corresponding\nanalytics themselves. However, most teams do not want to invest in\nmanually collecting new types of data when they have already made an\ninvestment in their current toolset. Therefore these metrics never get\ncollected and the proper analytics never get built. Because of these points,\neven when presented with the correct metrics, most teams do not know how\nto interpret or take action on them. What Makes these Metrics Lean and Agile? To begin with a counterexample, it is incomprehensible to me that metrics\nlike Story Points and Velocity are accepted as Agile. I am being\npurposefully provocative here, but those metrics---and the corresponding\nanalytics like Burn Down charts---are about as far from Agile as one can\nget. Let’s explore why for a second. Part of the Agile Manifesto mentions “Customer Collaboration”. I\n\nfully support that notion that our work should involve close collaboration\nwith the customer. However, to me, collaboration means speaking the\nlanguage of the customer. And that language should extend to cover all the\nmetrics and analytics that we use. Have you ever had to explain what a\nStory Point is to a customer? How about Velocity? If you do not like\nyourself very much, march into your CFO’s office someday and try to\nexplain what a Story Point is. However, I guarantee all of your stakeholders understand the concept\n\nof elapsed time. I guarantee they understand the concept of the total number\nof features to be delivered in a release. If we truly want to be Agile, we are\ngoing to have to adopt the language of our customers. To that end, we must\nchoose words and concepts that they are comfortable with---not force them\nto learn a new, arbitrary, and unhelpful vocabulary. Additionally, one of the key tenants of Lean is respect for people. To\ndemonstrate why flow and flow metrics are Lean, I would like you to try\nthe following experiment at home sometime (if you have a spouse or\npartner). I have a wife so I will explain it with her in mind. In this\nexperiment, I would start by asking my wife to do something for me.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability\n\nAdding to this problem is that all of the tooling that has been\ndeveloped around these legacy Agile metrics provide incorrect or\nincomplete information. In the absence of a tool to do it for them, a team’s\nonly option is to manually track flow metrics and build the corresponding\nanalytics themselves. However, most teams do not want to invest in\nmanually collecting new types of data when they have already made an\ninvestment in their current toolset. Therefore these metrics never get\ncollected and the proper analytics never get built. Because of these points,\neven when presented with the correct metrics, most teams do not know how\nto interpret or take action on them. What Makes these Metrics Lean and Agile? To begin with a counterexample, it is incomprehensible to me that metrics\nlike Story Points and Velocity are accepted as Agile. I am being\npurposefully provocative here, but those metrics---and the corresponding\nanalytics like Burn Down charts---are about as far from Agile as one can\nget. Let’s explore why for a second. Part of the Agile Manifesto mentions “Customer Collaboration”. I\n\nfully support that notion that our work should involve close collaboration\nwith the customer. However, to me, collaboration means speaking the\nlanguage of the customer. And that language should extend to cover all the\nmetrics and analytics that we use. Have you ever had to explain what a\nStory Point is to a customer? How about Velocity? If you do not like\nyourself very much, march into your CFO’s office someday and try to\nexplain what a Story Point is. However, I guarantee all of your stakeholders understand the concept\n\nof elapsed time. I guarantee they understand the concept of the total number\nof features to be delivered in a release. If we truly want to be Agile, we are\ngoing to have to adopt the language of our customers. To that end, we must\nchoose words and concepts that they are comfortable with---not force them\nto learn a new, arbitrary, and unhelpful vocabulary. Additionally, one of the key tenants of Lean is respect for people. To\ndemonstrate why flow and flow metrics are Lean, I would like you to try\nthe following experiment at home sometime (if you have a spouse or\npartner). I have a wife so I will explain it with her in mind. In this\nexperiment, I would start by asking my wife to do something for me.", "tokens": 500, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 17, "segment_id": "00017", "chapter_num": "1", "chapter_title": "Flow, Flow Metrics, and Predictability", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability", "chunk_id": "00000013"}
{"type": "chunk", "text": "To that end, we must\nchoose words and concepts that they are comfortable with---not force them\nto learn a new, arbitrary, and unhelpful vocabulary. Additionally, one of the key tenants of Lean is respect for people. To\ndemonstrate why flow and flow metrics are Lean, I would like you to try\nthe following experiment at home sometime (if you have a spouse or\npartner). I have a wife so I will explain it with her in mind. In this\nexperiment, I would start by asking my wife to do something for me. The\nparticular task I ask her to do does not really matter as long as it will take a", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability\n\nTo that end, we must\nchoose words and concepts that they are comfortable with---not force them\nto learn a new, arbitrary, and unhelpful vocabulary. Additionally, one of the key tenants of Lean is respect for people. To\ndemonstrate why flow and flow metrics are Lean, I would like you to try\nthe following experiment at home sometime (if you have a spouse or\npartner). I have a wife so I will explain it with her in mind. In this\nexperiment, I would start by asking my wife to do something for me. The\nparticular task I ask her to do does not really matter as long as it will take a", "tokens": 137, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 17, "segment_id": "00017", "chapter_num": "1", "chapter_title": "Flow, Flow Metrics, and Predictability", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability", "chunk_id": "00000014"}
{"type": "chunk", "text": "non-trivial amount of time to complete. Before she is finished I will ask her\nto stop what she is working on to do something else for me. Before she is\nfinished with that new task, I will ask her to stop and do something else. At\nsome point after I have requested her to do the third or fourth thing I will\nask her why she is not finished with the first thing I requested and why it is\ntaking so long. I will continue to do this until the nearest blunt instrument\nshe beats me to death with is marked as “Prosecution’s Exhibit A”. The Solution to Poor Predictability\nToday’s economic climate has caused a heated competition for companies\nto acquire customers, retain them, and deliver the products they want when\nthey want them. You know this all too well because you bear the brunt of this heated\n\ncompetition; because you are expected to create, manage, and maintain the\nproducts that customers desire; because you are expected to reduce the time\nand resources needed to launch products quickly to meet ever-changing\ncustomer demands. Solving these problems will require a new strategy. That new strategy\n\nis to focus on the management of flow. A focus on flow necessitates not\nonly a shift in thinking (away from capacity utilization and estimation and\nplanning) but also a shift in the quantities used to evaluate process\nperformance (away from ideal hours, level of effort, points, velocity, etc.)\nThat is where the metrics of flow come in. Observing and measuring\n\nflow is going to provide the missing component that you need to make your\nprocess more predictable. If you can get to a process that has stable,\npredictable flow, then the act of estimating and planning---the act of making\npredictions---becomes trivial. The measurement of flow and its resultant\nmetrics will take care of all that for us. I began this chapter by talking about Bennet’s predictability problems\nat HS. In the months that followed our first meeting in Philadelphia, I had\nthe great opportunity to work with Bennet and to reflect with him on the\nrelationship between flow and predictability. During one of those\nconversations, Bennet said, “You know, most people think of predictability\nas a noun. It’s not. It’s a verb.” Exactly right. It is not that you are\npredictable or are not predictable. It is that you “do” predictability. Predictability is proactive and not reactive.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability\n\nnon-trivial amount of time to complete. Before she is finished I will ask her\nto stop what she is working on to do something else for me. Before she is\nfinished with that new task, I will ask her to stop and do something else. At\nsome point after I have requested her to do the third or fourth thing I will\nask her why she is not finished with the first thing I requested and why it is\ntaking so long. I will continue to do this until the nearest blunt instrument\nshe beats me to death with is marked as “Prosecution’s Exhibit A”. The Solution to Poor Predictability\nToday’s economic climate has caused a heated competition for companies\nto acquire customers, retain them, and deliver the products they want when\nthey want them. You know this all too well because you bear the brunt of this heated\n\ncompetition; because you are expected to create, manage, and maintain the\nproducts that customers desire; because you are expected to reduce the time\nand resources needed to launch products quickly to meet ever-changing\ncustomer demands. Solving these problems will require a new strategy. That new strategy\n\nis to focus on the management of flow. A focus on flow necessitates not\nonly a shift in thinking (away from capacity utilization and estimation and\nplanning) but also a shift in the quantities used to evaluate process\nperformance (away from ideal hours, level of effort, points, velocity, etc.)\nThat is where the metrics of flow come in. Observing and measuring\n\nflow is going to provide the missing component that you need to make your\nprocess more predictable. If you can get to a process that has stable,\npredictable flow, then the act of estimating and planning---the act of making\npredictions---becomes trivial. The measurement of flow and its resultant\nmetrics will take care of all that for us. I began this chapter by talking about Bennet’s predictability problems\nat HS. In the months that followed our first meeting in Philadelphia, I had\nthe great opportunity to work with Bennet and to reflect with him on the\nrelationship between flow and predictability. During one of those\nconversations, Bennet said, “You know, most people think of predictability\nas a noun. It’s not. It’s a verb.” Exactly right. It is not that you are\npredictable or are not predictable. It is that you “do” predictability. Predictability is proactive and not reactive.", "tokens": 508, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 18, "segment_id": "00018", "chapter_num": "1", "chapter_title": "Flow, Flow Metrics, and Predictability", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability", "chunk_id": "00000015"}
{"type": "chunk", "text": "I began this chapter by talking about Bennet’s predictability problems\nat HS. In the months that followed our first meeting in Philadelphia, I had\nthe great opportunity to work with Bennet and to reflect with him on the\nrelationship between flow and predictability. During one of those\nconversations, Bennet said, “You know, most people think of predictability\nas a noun. It’s not. It’s a verb.” Exactly right. It is not that you are\npredictable or are not predictable. It is that you “do” predictability. Predictability is proactive and not reactive. The actions you take today have\nthe biggest impact on your predictability tomorrow.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability\n\nI began this chapter by talking about Bennet’s predictability problems\nat HS. In the months that followed our first meeting in Philadelphia, I had\nthe great opportunity to work with Bennet and to reflect with him on the\nrelationship between flow and predictability. During one of those\nconversations, Bennet said, “You know, most people think of predictability\nas a noun. It’s not. It’s a verb.” Exactly right. It is not that you are\npredictable or are not predictable. It is that you “do” predictability. Predictability is proactive and not reactive. The actions you take today have\nthe biggest impact on your predictability tomorrow.", "tokens": 141, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 18, "segment_id": "00018", "chapter_num": "1", "chapter_title": "Flow, Flow Metrics, and Predictability", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability", "chunk_id": "00000016"}
{"type": "chunk", "text": "Key Learnings and Takeaways\n\nTo get more predictable in knowledge work, we must abandon old\nproject management paradigms and adopt new ones. The new\nparadigm we must adopt is the focus on and the management of flow. A lack of flow manifests itself as a buildup of work (large queues of\nwork). The best way to fix the problem of large queues is not to allow\nthem to form in the first place. Managing for flow necessitates a new, different set of metrics than\ntraditional project management frameworks would ever prescribe or\nsuggest. Observing and measuring the metrics of flow is the true path to\npredictability. Flow metrics are defined in the language of the customer and are the\nproper metrics to track in order to be lean and agile. Flow metrics will suggest the actionable interventions needed to make\nus more predictable.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability\n\nKey Learnings and Takeaways\n\nTo get more predictable in knowledge work, we must abandon old\nproject management paradigms and adopt new ones. The new\nparadigm we must adopt is the focus on and the management of flow. A lack of flow manifests itself as a buildup of work (large queues of\nwork). The best way to fix the problem of large queues is not to allow\nthem to form in the first place. Managing for flow necessitates a new, different set of metrics than\ntraditional project management frameworks would ever prescribe or\nsuggest. Observing and measuring the metrics of flow is the true path to\npredictability. Flow metrics are defined in the language of the customer and are the\nproper metrics to track in order to be lean and agile. Flow metrics will suggest the actionable interventions needed to make\nus more predictable.", "tokens": 173, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 19, "segment_id": "00019", "chapter_num": "1", "chapter_title": "Flow, Flow Metrics, and Predictability", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 1: Flow, Flow Metrics, and Predictability", "chunk_id": "00000017"}
{"type": "chunk", "text": "Chapter 2 - The Basic Metrics of Flow\n\nAs I discussed in the previous chapter, understanding flow and managing for\nit requires a different paradigm than that espoused by traditional processes\nand frameworks. The answers to the essential questions of predictable\nprocess execution are not found in project plans, resource utilization charts,\nor team members’ estimates. The answers will come from the monitoring,\nmeasurement, and management of a specific set of metrics. This chapter is\nall about defining these metrics: Work In Progress (WIP), Cycle Time, and\nThroughput. The good news is that these flow metrics are exactly the ones we need\nto track in order to answer the questions that our customers are asking. The\ncustomer question “How long to complete?” is best answered by the flow\nmetric known as Cycle Time. The customer question “How many new\nfeatures am I going to get in the next release?” is a question best answered\nby the flow metric known as Throughput. The last of the three, Work In\nProgress (WIP), does not directly answer any particular customer question,\nbut it is the metric that will most greatly influence the other two. For that\nreason, I will start this discussion with it. Work In Progress\nWork In Progress is the most important flow metric to track for two reasons. First, as we will see in the coming chapters, WIP is the best predictor of\noverall system performance. Second, the other two metrics of flow---Cycle\nTime and Throughput---will themselves both be defined in terms of WIP. Even so, WIP is probably the hardest metric to define. That is because\n\nthe definition of WIP is two dimensional: it must cover both the notion of\n“work” and the notion of “in progress”. Let’s look at the idea of work first. For the purposes of this book, I\n\nregard any direct or indirect discrete unit of customer value as a candidate\nfor work. The generic term I will use for these candidate units of customer\nvalue is “work item”. A work item might be a user story, an epic, a feature,\nor a project. It might be a requirement, use case, or enhancement. How you", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nChapter 2 - The Basic Metrics of Flow\n\nAs I discussed in the previous chapter, understanding flow and managing for\nit requires a different paradigm than that espoused by traditional processes\nand frameworks. The answers to the essential questions of predictable\nprocess execution are not found in project plans, resource utilization charts,\nor team members’ estimates. The answers will come from the monitoring,\nmeasurement, and management of a specific set of metrics. This chapter is\nall about defining these metrics: Work In Progress (WIP), Cycle Time, and\nThroughput. The good news is that these flow metrics are exactly the ones we need\nto track in order to answer the questions that our customers are asking. The\ncustomer question “How long to complete?” is best answered by the flow\nmetric known as Cycle Time. The customer question “How many new\nfeatures am I going to get in the next release?” is a question best answered\nby the flow metric known as Throughput. The last of the three, Work In\nProgress (WIP), does not directly answer any particular customer question,\nbut it is the metric that will most greatly influence the other two. For that\nreason, I will start this discussion with it. Work In Progress\nWork In Progress is the most important flow metric to track for two reasons. First, as we will see in the coming chapters, WIP is the best predictor of\noverall system performance. Second, the other two metrics of flow---Cycle\nTime and Throughput---will themselves both be defined in terms of WIP. Even so, WIP is probably the hardest metric to define. That is because\n\nthe definition of WIP is two dimensional: it must cover both the notion of\n“work” and the notion of “in progress”. Let’s look at the idea of work first. For the purposes of this book, I\n\nregard any direct or indirect discrete unit of customer value as a candidate\nfor work. The generic term I will use for these candidate units of customer\nvalue is “work item”. A work item might be a user story, an epic, a feature,\nor a project. It might be a requirement, use case, or enhancement. How you", "tokens": 451, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 20, "segment_id": "00020", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000018"}
{"type": "chunk", "text": "capture work as work items and how name your work items is entirely up to\nyou. Secondly, to define in progress we must first consider the boundaries of\nyour process. To do so, let’s use the metaphor of a simple queuing system. I\nwould argue that all processes can be modelled in the manner depicted in\nFigure 2.1:\n\nFigure 2.1: A Simple Queuing System\n\nIn a queuing system there is work that arrives to a process and there is\n\nwork that departs a process. When making a determination of whether\nsomething counts as in progress or not, the first aspect of system that needs\nto be considered is what does it mean for something to have “arrived”? That\nis to say, your team needs to define a specific point where a unit of work\ntransforms from being just some arbitrary idea into being a legitimate work\nitem that is to immediately be acted on and completed. Before that arrival\npoint, the item is just some candidate for work. After that arrival point, the\nitem is counted as Work In Progress. In a pull-based system, an entry (or boundary) point is fairly easy to define. That is\nbecause in a pull system, a team only starts work when it has capacity to do so. Thus, a\nwork item can only count as Work In Progress if it has been voluntarily pulled into the\nprocess by the individual, team, or organization responsible for operating that process. The “arrival point” of the system, therefore, is the point at which the team performs its\nfirst pull transaction on the work. After that first pull transaction, an item is considered\nWIP until it departs the process. (This arrival point is also considered a point of\n“commitment”. An in-depth look at how just-in-time commitment and just-in-time\nprioritization work are topics that I will cover in Chapter 8). For push-based systems, an entry point is much harder to define. That is because there is\nno consideration for a team’s capacity when deciding when work should be started. In a\npush system work can be considered started when any stakeholder has a reasonable\nexpectation that work has been committed to (whether the team responsible for\nperforming the work knows about it or agrees to it or not).", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\ncapture work as work items and how name your work items is entirely up to\nyou. Secondly, to define in progress we must first consider the boundaries of\nyour process. To do so, let’s use the metaphor of a simple queuing system. I\nwould argue that all processes can be modelled in the manner depicted in\nFigure 2.1:\n\nFigure 2.1: A Simple Queuing System\n\nIn a queuing system there is work that arrives to a process and there is\n\nwork that departs a process. When making a determination of whether\nsomething counts as in progress or not, the first aspect of system that needs\nto be considered is what does it mean for something to have “arrived”? That\nis to say, your team needs to define a specific point where a unit of work\ntransforms from being just some arbitrary idea into being a legitimate work\nitem that is to immediately be acted on and completed. Before that arrival\npoint, the item is just some candidate for work. After that arrival point, the\nitem is counted as Work In Progress. In a pull-based system, an entry (or boundary) point is fairly easy to define. That is\nbecause in a pull system, a team only starts work when it has capacity to do so. Thus, a\nwork item can only count as Work In Progress if it has been voluntarily pulled into the\nprocess by the individual, team, or organization responsible for operating that process. The “arrival point” of the system, therefore, is the point at which the team performs its\nfirst pull transaction on the work. After that first pull transaction, an item is considered\nWIP until it departs the process. (This arrival point is also considered a point of\n“commitment”. An in-depth look at how just-in-time commitment and just-in-time\nprioritization work are topics that I will cover in Chapter 8). For push-based systems, an entry point is much harder to define. That is because there is\nno consideration for a team’s capacity when deciding when work should be started. In a\npush system work can be considered started when any stakeholder has a reasonable\nexpectation that work has been committed to (whether the team responsible for\nperforming the work knows about it or agrees to it or not).", "tokens": 476, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 21, "segment_id": "00021", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000019"}
{"type": "chunk", "text": "(This arrival point is also considered a point of\n“commitment”. An in-depth look at how just-in-time commitment and just-in-time\nprioritization work are topics that I will cover in Chapter 8). For push-based systems, an entry point is much harder to define. That is because there is\nno consideration for a team’s capacity when deciding when work should be started. In a\npush system work can be considered started when any stakeholder has a reasonable\nexpectation that work has been committed to (whether the team responsible for\nperforming the work knows about it or agrees to it or not). This expectation could be set\nfor such arbitrary reasons as the work has been requested, the project has been funded, or\nsome manager somewhere thinks it is a good idea to start---regardless of whether there is\nany capacity to do so. Obviously I have a bias for pull systems over push systems, but the concept of WIP\napplies regardless of context. If you find yourself operating within a push system, then\nthe best, first predictability exercise you might want to undertake is to define the", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\n(This arrival point is also considered a point of\n“commitment”. An in-depth look at how just-in-time commitment and just-in-time\nprioritization work are topics that I will cover in Chapter 8). For push-based systems, an entry point is much harder to define. That is because there is\nno consideration for a team’s capacity when deciding when work should be started. In a\npush system work can be considered started when any stakeholder has a reasonable\nexpectation that work has been committed to (whether the team responsible for\nperforming the work knows about it or agrees to it or not). This expectation could be set\nfor such arbitrary reasons as the work has been requested, the project has been funded, or\nsome manager somewhere thinks it is a good idea to start---regardless of whether there is\nany capacity to do so. Obviously I have a bias for pull systems over push systems, but the concept of WIP\napplies regardless of context. If you find yourself operating within a push system, then\nthe best, first predictability exercise you might want to undertake is to define the", "tokens": 229, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 21, "segment_id": "00021", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000020"}
{"type": "chunk", "text": "boundaries around your process. Getting a handle on what you consider WIP is a\nnecessary (but unfortunately not sufficient) step down the road to predictability. For a work item to no longer count as in progress, there must be a\nspecific point of departure from the process. Departure could be defined as\ndelivery to an actual end user or delivery to some other downstream team or\nprocess. For example, if a development team is responsible for its own\ndeployments to production, then that team might consider an item only to\nhave departed once a deployment to production has been made. Or a\ndifferent team who is not responsible for deployments might consider an\nitem to only have departed once it has been reasonably handed off to a\ndownstream operations team who would then handle deployments. Again,\nthe definition of a point of departure holds true whether you are operating a\npull or a push system. To sum up, for in progress definition purposes your team must a\nspecific point when it considers work to have arrived to the process and it\nmust define a specific point where work has departed the process. The\ndefinition of those two system boundaries is the crucial starting point in\npredictable process design. Once you have made those decisions, then all\nwork items between those two points will count as Work In Progress:\n\nWIP: All discrete units of customer value that have entered a given process but have not\nexited. If defining WIP is the hard part, then measuring it is the easy part. To\ncalculate WIP you simply count the discrete number of work items within\nyour process boundaries as defined above. That’s it: just count. Your natural objection might be, “doesn’t that mean you have to make\n\nall of your work items the same size?” After all, the work items that come\nthrough your process are of different durations, are of disparate\ncomplexities, and may require a wide mix of resources to work on them. How can you possibly account for all of that variability and come up with a\npredictable system by just counting work items? While that is a reasonable\nquestion, it is not something to get hung up on. I will spend more time on this topic a little bit later, so I am going to\n\nask you to just suspend disbelief here and accept that when it comes to WIP\nand predictability, there is no requirement to have all of your work items be", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nboundaries around your process. Getting a handle on what you consider WIP is a\nnecessary (but unfortunately not sufficient) step down the road to predictability. For a work item to no longer count as in progress, there must be a\nspecific point of departure from the process. Departure could be defined as\ndelivery to an actual end user or delivery to some other downstream team or\nprocess. For example, if a development team is responsible for its own\ndeployments to production, then that team might consider an item only to\nhave departed once a deployment to production has been made. Or a\ndifferent team who is not responsible for deployments might consider an\nitem to only have departed once it has been reasonably handed off to a\ndownstream operations team who would then handle deployments. Again,\nthe definition of a point of departure holds true whether you are operating a\npull or a push system. To sum up, for in progress definition purposes your team must a\nspecific point when it considers work to have arrived to the process and it\nmust define a specific point where work has departed the process. The\ndefinition of those two system boundaries is the crucial starting point in\npredictable process design. Once you have made those decisions, then all\nwork items between those two points will count as Work In Progress:\n\nWIP: All discrete units of customer value that have entered a given process but have not\nexited. If defining WIP is the hard part, then measuring it is the easy part. To\ncalculate WIP you simply count the discrete number of work items within\nyour process boundaries as defined above. That’s it: just count. Your natural objection might be, “doesn’t that mean you have to make\n\nall of your work items the same size?” After all, the work items that come\nthrough your process are of different durations, are of disparate\ncomplexities, and may require a wide mix of resources to work on them. How can you possibly account for all of that variability and come up with a\npredictable system by just counting work items? While that is a reasonable\nquestion, it is not something to get hung up on. I will spend more time on this topic a little bit later, so I am going to\n\nask you to just suspend disbelief here and accept that when it comes to WIP\nand predictability, there is no requirement to have all of your work items be", "tokens": 494, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 22, "segment_id": "00022", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000021"}
{"type": "chunk", "text": "of the same size or complexity. There is not going to be need for any further\ncomplexity to be added to the calculation such as estimating your WIP in\nStory Points or assigning ideal hours to each work item. This concept is\nprobably very uncomfortable to those of you who are used to thinking about\nwork in terms of relative complexity or level of effort. As I mentioned in the\nintroduction, you need to abandon that type of thinking if you truly want to\nbuild predictable processes. For those of you who do not want to wait, an explanation of why size\n\ndoes not matter (said the actress to the bishop) will be given in Chapter 3\n(the chapter on Little’s Law). For now, all you need to know is that WIP is\ncalculated by counting individual work items. Nor is there any restriction on the level at which you track work items. You can track WIP at the portfolio, project, feature, epic, or story level---just\nto name a few. All of these types of decisions will be completely up to you. For you Kanban practitioners out there, you will also want to note that\nthere is a difference between WIP and WIP limits. You cannot calculate WIP\nsimply by adding up all the WIP limits on your board. It should work that\nway, but it does not. This result should be obvious as most Kanban boards do\nnot always have columns that are at their full WIP limit. A more common\nsituation is to have a Kanban board with WIP limit violations in multiple\ncolumns. In either of those cases simply adding up WIP limits will not give\nyou an accurate WIP calculation. Even in a Kanban world, you still have to\nactively track the total number of work items in your process. An implication of all of this is that most often items located in a\nbacklog do not meet the definition of being included in a WIP calculation. There is a subtlety here that is going to require further discussion as it refers\nto the “point of commitment” that I mentioned a little earlier (for this deeper\ndiscussion, please see Chapter 8). Just know that---for the most part---when I\ntalk about WIP, I do not include backlog items in that discussion. As an interesting aside, you should know that you will have the option\n\nto segment and report on your WIP as you see fit.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nof the same size or complexity. There is not going to be need for any further\ncomplexity to be added to the calculation such as estimating your WIP in\nStory Points or assigning ideal hours to each work item. This concept is\nprobably very uncomfortable to those of you who are used to thinking about\nwork in terms of relative complexity or level of effort. As I mentioned in the\nintroduction, you need to abandon that type of thinking if you truly want to\nbuild predictable processes. For those of you who do not want to wait, an explanation of why size\n\ndoes not matter (said the actress to the bishop) will be given in Chapter 3\n(the chapter on Little’s Law). For now, all you need to know is that WIP is\ncalculated by counting individual work items. Nor is there any restriction on the level at which you track work items. You can track WIP at the portfolio, project, feature, epic, or story level---just\nto name a few. All of these types of decisions will be completely up to you. For you Kanban practitioners out there, you will also want to note that\nthere is a difference between WIP and WIP limits. You cannot calculate WIP\nsimply by adding up all the WIP limits on your board. It should work that\nway, but it does not. This result should be obvious as most Kanban boards do\nnot always have columns that are at their full WIP limit. A more common\nsituation is to have a Kanban board with WIP limit violations in multiple\ncolumns. In either of those cases simply adding up WIP limits will not give\nyou an accurate WIP calculation. Even in a Kanban world, you still have to\nactively track the total number of work items in your process. An implication of all of this is that most often items located in a\nbacklog do not meet the definition of being included in a WIP calculation. There is a subtlety here that is going to require further discussion as it refers\nto the “point of commitment” that I mentioned a little earlier (for this deeper\ndiscussion, please see Chapter 8). Just know that---for the most part---when I\ntalk about WIP, I do not include backlog items in that discussion. As an interesting aside, you should know that you will have the option\n\nto segment and report on your WIP as you see fit.", "tokens": 504, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 23, "segment_id": "00023", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000022"}
{"type": "chunk", "text": "There is a subtlety here that is going to require further discussion as it refers\nto the “point of commitment” that I mentioned a little earlier (for this deeper\ndiscussion, please see Chapter 8). Just know that---for the most part---when I\ntalk about WIP, I do not include backlog items in that discussion. As an interesting aside, you should know that you will have the option\n\nto segment and report on your WIP as you see fit. In some contexts it may be\nbeneficial to lump all of your WIP together and examine it from a holistic\nsystem’s view. Or it may be beneficial to segment that WIP into types or\ncategories and examine each one of those subgroups on its own. For example, let’s say your team performs work for the sales\ndepartment, the marketing department, and the finance department. Let’s\nalso say that your team is responsible for maintenance on a variety of", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nThere is a subtlety here that is going to require further discussion as it refers\nto the “point of commitment” that I mentioned a little earlier (for this deeper\ndiscussion, please see Chapter 8). Just know that---for the most part---when I\ntalk about WIP, I do not include backlog items in that discussion. As an interesting aside, you should know that you will have the option\n\nto segment and report on your WIP as you see fit. In some contexts it may be\nbeneficial to lump all of your WIP together and examine it from a holistic\nsystem’s view. Or it may be beneficial to segment that WIP into types or\ncategories and examine each one of those subgroups on its own. For example, let’s say your team performs work for the sales\ndepartment, the marketing department, and the finance department. Let’s\nalso say that your team is responsible for maintenance on a variety of", "tokens": 195, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 23, "segment_id": "00023", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000023"}
{"type": "chunk", "text": "existing applications. When looking at WIP you may want to combine all of\nthose requests together into one big group. Or your team may choose to just\nlook at the part of your WIP that pertains to sales. Or your team may choose\nto look at the part of your WIP that pertains to marketing. Or you may just\nwant to look at how your maintenance items are doing. From a metrics\nperspective, performing that type segmentation is not only going to be\nperfectly okay, but also, as mentioned earlier, in some instances is going to\nbe desirable. If your team does segment WIP into different categories, then it\nis also going to be valid to talk about the Cycle Time and Throughput of\nthose different type segments. Segmenting (or filtering) WIP into different\ntypes may also be important from a reporting and analytics perspective\nwhich is why I will revisit this topic in the flow analytics chapters to come\n(Chapter 5 and Chapter 10). Not only are the other two metrics of flow defined in terms of WIP, but\n---it turns out---those other two are also best predicted by WIP. This result is\nso important that I am going to dedicate much of the following chapters to it. My point here is only to suggest that if your team ever wants to have any\nhope of operating a predictable process, then you are going to have to get\ncontrol of WIP. If you are not currently tracking WIP, then you are going to\nwant to start. Sooner is better than later. Cycle Time\nAs I mentioned in Chapter 1, the first question our customers ask when we\nstart work for them is “When will it be done?” Answering that question will\nrequire us to measure the flow metric of Cycle Time. Measuring Cycle Time\nbecomes much easier now that you have a basic understanding of WIP. In the previous section I stated that a process has specific arrival and\ndeparture boundaries and that any item of customer value between those two\nboundaries can reasonably be counted as WIP. Once your team determines\nthe points of delineation that define Work In Progress, the definition of\nCycle Time becomes very easy:\n\nCycle Time: The amount of elapsed time that a work item spends as Work In Progress.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nexisting applications. When looking at WIP you may want to combine all of\nthose requests together into one big group. Or your team may choose to just\nlook at the part of your WIP that pertains to sales. Or your team may choose\nto look at the part of your WIP that pertains to marketing. Or you may just\nwant to look at how your maintenance items are doing. From a metrics\nperspective, performing that type segmentation is not only going to be\nperfectly okay, but also, as mentioned earlier, in some instances is going to\nbe desirable. If your team does segment WIP into different categories, then it\nis also going to be valid to talk about the Cycle Time and Throughput of\nthose different type segments. Segmenting (or filtering) WIP into different\ntypes may also be important from a reporting and analytics perspective\nwhich is why I will revisit this topic in the flow analytics chapters to come\n(Chapter 5 and Chapter 10). Not only are the other two metrics of flow defined in terms of WIP, but\n---it turns out---those other two are also best predicted by WIP. This result is\nso important that I am going to dedicate much of the following chapters to it. My point here is only to suggest that if your team ever wants to have any\nhope of operating a predictable process, then you are going to have to get\ncontrol of WIP. If you are not currently tracking WIP, then you are going to\nwant to start. Sooner is better than later. Cycle Time\nAs I mentioned in Chapter 1, the first question our customers ask when we\nstart work for them is “When will it be done?” Answering that question will\nrequire us to measure the flow metric of Cycle Time. Measuring Cycle Time\nbecomes much easier now that you have a basic understanding of WIP. In the previous section I stated that a process has specific arrival and\ndeparture boundaries and that any item of customer value between those two\nboundaries can reasonably be counted as WIP. Once your team determines\nthe points of delineation that define Work In Progress, the definition of\nCycle Time becomes very easy:\n\nCycle Time: The amount of elapsed time that a work item spends as Work In Progress.", "tokens": 474, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 24, "segment_id": "00024", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000024"}
{"type": "chunk", "text": "This definition is based on one offered by Hopp and Spearman in their\nFactory Physics book and, I believe, holds up well in most knowledge work\ncontexts. Defining Cycle Time in terms of WIP removes much---if not all---\nof the arbitrariness of some of the other explanations of Cycle Time that you\nmay have seen (and been confused by) and gives us a tighter definition to\nstart measuring this metric. The moral of this story is: you essentially have\ncontrol over when something is counted as Work In Progress in your\nprocess. Take some time to define those policies around what it means for an\nitem to be “Work In Progress” in your system and start and stop your Cycle\nTime clock accordingly. Not only does defining Cycle Time in terms of Work In Progress make\nit more concrete and easier for people to understand, but it also brings some\nneeded consistency when talking about Cycle Time with respect to Little’s\nLaw (Chapter 3) and with respect to how Cycle Time is (or is not!)\nvisualized on a Cumulative Flow Diagram (Chapter 5). Lastly, notice the emphasis on “elapsed time”. The use of elapsed time\n\nis probably very different from the guidance you have previously been\ngiven. Most other methodologies ask you to measure only the actual amount\nof time spent actively working on a given item (if they ask you to measure\ntime at all). I happen to think this guidance is wrong. I have a couple of\nreasons why. First, and most importantly, your customers probably think about the\n\nworld in terms of elapsed time. For example, let’s say that on March 1, you\ncommunicate to your customers that something will be done in 30 days. My\nguess would be that your customer’s expectation would be that they would\nget their item on or before March 31. However, if you meant 30 “business\ndays” then your expectation is the customer would get something sometime\naround the middle of April. I am sure you can see where that difference in\nexpectations might be a problem. Second, if you only measure active time, you are ignoring a large part\nof your predictability problem. It is the time that an item spends waiting or\ndelayed (i.e., not actively being worked) that is usually where most of your\nunpredictability lies. It is precisely that area that we are going to look at for\nmost substantial predictability improvements.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nThis definition is based on one offered by Hopp and Spearman in their\nFactory Physics book and, I believe, holds up well in most knowledge work\ncontexts. Defining Cycle Time in terms of WIP removes much---if not all---\nof the arbitrariness of some of the other explanations of Cycle Time that you\nmay have seen (and been confused by) and gives us a tighter definition to\nstart measuring this metric. The moral of this story is: you essentially have\ncontrol over when something is counted as Work In Progress in your\nprocess. Take some time to define those policies around what it means for an\nitem to be “Work In Progress” in your system and start and stop your Cycle\nTime clock accordingly. Not only does defining Cycle Time in terms of Work In Progress make\nit more concrete and easier for people to understand, but it also brings some\nneeded consistency when talking about Cycle Time with respect to Little’s\nLaw (Chapter 3) and with respect to how Cycle Time is (or is not!)\nvisualized on a Cumulative Flow Diagram (Chapter 5). Lastly, notice the emphasis on “elapsed time”. The use of elapsed time\n\nis probably very different from the guidance you have previously been\ngiven. Most other methodologies ask you to measure only the actual amount\nof time spent actively working on a given item (if they ask you to measure\ntime at all). I happen to think this guidance is wrong. I have a couple of\nreasons why. First, and most importantly, your customers probably think about the\n\nworld in terms of elapsed time. For example, let’s say that on March 1, you\ncommunicate to your customers that something will be done in 30 days. My\nguess would be that your customer’s expectation would be that they would\nget their item on or before March 31. However, if you meant 30 “business\ndays” then your expectation is the customer would get something sometime\naround the middle of April. I am sure you can see where that difference in\nexpectations might be a problem. Second, if you only measure active time, you are ignoring a large part\nof your predictability problem. It is the time that an item spends waiting or\ndelayed (i.e., not actively being worked) that is usually where most of your\nunpredictability lies. It is precisely that area that we are going to look at for\nmost substantial predictability improvements.", "tokens": 507, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 25, "segment_id": "00025", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000025"}
{"type": "chunk", "text": "However, if you meant 30 “business\ndays” then your expectation is the customer would get something sometime\naround the middle of April. I am sure you can see where that difference in\nexpectations might be a problem. Second, if you only measure active time, you are ignoring a large part\nof your predictability problem. It is the time that an item spends waiting or\ndelayed (i.e., not actively being worked) that is usually where most of your\nunpredictability lies. It is precisely that area that we are going to look at for\nmost substantial predictability improvements. Remember, delay is the enemy\nof flow!", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nHowever, if you meant 30 “business\ndays” then your expectation is the customer would get something sometime\naround the middle of April. I am sure you can see where that difference in\nexpectations might be a problem. Second, if you only measure active time, you are ignoring a large part\nof your predictability problem. It is the time that an item spends waiting or\ndelayed (i.e., not actively being worked) that is usually where most of your\nunpredictability lies. It is precisely that area that we are going to look at for\nmost substantial predictability improvements. Remember, delay is the enemy\nof flow!", "tokens": 134, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 25, "segment_id": "00025", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000026"}
{"type": "chunk", "text": "Lead Time vs. Cycle Time\n\nIf you have been exposed to Lean or Kanban concepts before reading this book, then\nwhat I have just defined as Cycle Time may sound a lot like what you have come to\nrecognize as Lead Time. I understand that most people in the Kanban community prefer\nthe term Lead Time to Cycle Time, but I am not one of them. My intention here is not to\ndive headlong into an academic (and ultimately useless) debate about which\nnomenclature is better, but I feel that I should at least present my thoughts on why I have\nchosen the terms that I have. You may agree or disagree with my reasoning, but I hope\nyou understand my intention here is not to be provocative or antagonistic (yet). I am\ngoing to talk about nomenclature in general a little later, but these specific terms require\nsome special attention. So why choose the term Cycle Time over Lead Time? My first argument is that regardless\nof whether you are talking about Cycle Time or Lead Time, you still have to qualify the\nboundaries of your time calculation. That is do say, both terms are very dependent on\none’s perspective: one person’s Lead Time is another person’s Cycle Time and vice versa. For example, the development team’s Lead Time is just the Product Manager’s Cycle\nTime through the development phase. While it is true that Lead Time gives more of a\nsense of an end-to-end calculation, what “end-to-end” means must still be defined for any\ngiven context. Given that in both cases boundaries must be qualified, I see no clear\nadvantage of the term Lead Time over the term Cycle Time. Further, defining Cycle Time\nin terms of when something is counted as WIP clears up a lot of this ambiguity. Secondly, I do not buy the argument that we, the Lean-Agile community, should shy\naway from using the term Cycle Time because the manufacturing industry has already\ndefined it in a different way that may or may not be in agreement with how we use the\nname. I do not subscribe to the thinking that the “Lean” we are talking about here is just\nmanufacturing theory wholly and blindly applied to knowledge work. I fully reject this\nthesis. The fact that manufacturing has its own definition of Cycle Time should be neither\ninfluential nor consequential to how we in knowledge work choose to define the term.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nLead Time vs. Cycle Time\n\nIf you have been exposed to Lean or Kanban concepts before reading this book, then\nwhat I have just defined as Cycle Time may sound a lot like what you have come to\nrecognize as Lead Time. I understand that most people in the Kanban community prefer\nthe term Lead Time to Cycle Time, but I am not one of them. My intention here is not to\ndive headlong into an academic (and ultimately useless) debate about which\nnomenclature is better, but I feel that I should at least present my thoughts on why I have\nchosen the terms that I have. You may agree or disagree with my reasoning, but I hope\nyou understand my intention here is not to be provocative or antagonistic (yet). I am\ngoing to talk about nomenclature in general a little later, but these specific terms require\nsome special attention. So why choose the term Cycle Time over Lead Time? My first argument is that regardless\nof whether you are talking about Cycle Time or Lead Time, you still have to qualify the\nboundaries of your time calculation. That is do say, both terms are very dependent on\none’s perspective: one person’s Lead Time is another person’s Cycle Time and vice versa. For example, the development team’s Lead Time is just the Product Manager’s Cycle\nTime through the development phase. While it is true that Lead Time gives more of a\nsense of an end-to-end calculation, what “end-to-end” means must still be defined for any\ngiven context. Given that in both cases boundaries must be qualified, I see no clear\nadvantage of the term Lead Time over the term Cycle Time. Further, defining Cycle Time\nin terms of when something is counted as WIP clears up a lot of this ambiguity. Secondly, I do not buy the argument that we, the Lean-Agile community, should shy\naway from using the term Cycle Time because the manufacturing industry has already\ndefined it in a different way that may or may not be in agreement with how we use the\nname. I do not subscribe to the thinking that the “Lean” we are talking about here is just\nmanufacturing theory wholly and blindly applied to knowledge work. I fully reject this\nthesis. The fact that manufacturing has its own definition of Cycle Time should be neither\ninfluential nor consequential to how we in knowledge work choose to define the term.", "tokens": 499, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 26, "segment_id": "00026", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000027"}
{"type": "chunk", "text": "Secondly, I do not buy the argument that we, the Lean-Agile community, should shy\naway from using the term Cycle Time because the manufacturing industry has already\ndefined it in a different way that may or may not be in agreement with how we use the\nname. I do not subscribe to the thinking that the “Lean” we are talking about here is just\nmanufacturing theory wholly and blindly applied to knowledge work. I fully reject this\nthesis. The fact that manufacturing has its own definition of Cycle Time should be neither\ninfluential nor consequential to how we in knowledge work choose to define the term. Lastly, and, I must stress, most importantly, the authors that I quote most---Reinertsen\nand Little---both favor the use of the term Cycle Time. If it is good enough for them, then\nit is good enough for me. By the way, Hopp and Spearman also sometimes refer to Cycle Time as “Flow Time”. I\nwould suggest that the term “Flow Time” might be a better way for us to communicate\nwhat we really mean by Cycle Time in our context anyway. Even so, for the rest of the\nbook, I will use the more common term, Cycle Time, and I will use it in the way that I\nhave defined it here. As I will show you in the chapter on Forecasting (Chapter 14), Cycle\nTime is going to be one of the main metrics you will need to come up with\nan accurate forecast for a project’s (or story’s or feature’s) completion. That\nis to say, the reason that you want to track Cycle Time is because it provides\nthe answer to the question, “When will it be done?” While that is certainly\ntrue, there are other important reasons to track Cycle Time.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nSecondly, I do not buy the argument that we, the Lean-Agile community, should shy\naway from using the term Cycle Time because the manufacturing industry has already\ndefined it in a different way that may or may not be in agreement with how we use the\nname. I do not subscribe to the thinking that the “Lean” we are talking about here is just\nmanufacturing theory wholly and blindly applied to knowledge work. I fully reject this\nthesis. The fact that manufacturing has its own definition of Cycle Time should be neither\ninfluential nor consequential to how we in knowledge work choose to define the term. Lastly, and, I must stress, most importantly, the authors that I quote most---Reinertsen\nand Little---both favor the use of the term Cycle Time. If it is good enough for them, then\nit is good enough for me. By the way, Hopp and Spearman also sometimes refer to Cycle Time as “Flow Time”. I\nwould suggest that the term “Flow Time” might be a better way for us to communicate\nwhat we really mean by Cycle Time in our context anyway. Even so, for the rest of the\nbook, I will use the more common term, Cycle Time, and I will use it in the way that I\nhave defined it here. As I will show you in the chapter on Forecasting (Chapter 14), Cycle\nTime is going to be one of the main metrics you will need to come up with\nan accurate forecast for a project’s (or story’s or feature’s) completion. That\nis to say, the reason that you want to track Cycle Time is because it provides\nthe answer to the question, “When will it be done?” While that is certainly\ntrue, there are other important reasons to track Cycle Time.", "tokens": 375, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 26, "segment_id": "00026", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000028"}
{"type": "chunk", "text": "The first supporting reason is that Cycle Time can be a rather good\npredictor of cost. Very generally speaking, the longer something takes to\ncomplete the more it is going to cost. Project, feature, or even user story cost\ncan be one of the biggest determiners of whether a company chooses to\ninvest in development or not. Like it or not, we are going to need Cycle\nTime data to figure out development cost. There is still a more important reason to understand Cycle Time. Cycle\n\nTime represents the amount of time it takes to get customer feedback. Customer feedback is of vital importance in our knowledge work world. Value itself is ultimately determined by the customer, which means your\nteam is going to want to make sure it gets that value feedback as quickly as\npossible. The last thing you want is to develop something that the customer\ndoes not need---especially if it takes you forever to do so. Shortening Cycle\nTime will shorten the customer feedback loop. And to shorten Cycle Time,\nyou are going to first need to measure it. A final reason to monitor Cycle Time is that it can give you an overall\n\npicture of your process’s health. The diagnostic tool needed for that is\nsomething called Flow Efficiency. Simply put, Flow Efficiency is the ratio of\nthe total elapsed time that an item was actively worked on to the total\nelapsed time that it took for an item to complete (its total Cycle Time). There’s a subtlety in this definition that bears some explanation. As an item\nis flowing through a process it is in either one of two states. It is either being\nactively worked on or it is not being actively worked on. Examples of an\nitem not being actively worked on is it is blocked by some external\ndependency (team, vendor, etc.), or it is queuing waiting to be pulled. In\nboth of those examples, an item is accumulating Cycle Time but no one is\nactively working on it. To get Flow Efficiency, you take the Total Cycle\nTime, subtract out inactive time and then divide that result by the Total\nCycle Time. It is not uncommon for teams just starting out with managing for flow\n\nto have Flow Efficiencies in the 15% range. Think about that for a second. If\na user story took 20 days to complete and had a Flow Efficiency of 15% that\nmeans that it spent only 3 days having someone actively work on it and it\nspent 17 days in some type of inactive state.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nThe first supporting reason is that Cycle Time can be a rather good\npredictor of cost. Very generally speaking, the longer something takes to\ncomplete the more it is going to cost. Project, feature, or even user story cost\ncan be one of the biggest determiners of whether a company chooses to\ninvest in development or not. Like it or not, we are going to need Cycle\nTime data to figure out development cost. There is still a more important reason to understand Cycle Time. Cycle\n\nTime represents the amount of time it takes to get customer feedback. Customer feedback is of vital importance in our knowledge work world. Value itself is ultimately determined by the customer, which means your\nteam is going to want to make sure it gets that value feedback as quickly as\npossible. The last thing you want is to develop something that the customer\ndoes not need---especially if it takes you forever to do so. Shortening Cycle\nTime will shorten the customer feedback loop. And to shorten Cycle Time,\nyou are going to first need to measure it. A final reason to monitor Cycle Time is that it can give you an overall\n\npicture of your process’s health. The diagnostic tool needed for that is\nsomething called Flow Efficiency. Simply put, Flow Efficiency is the ratio of\nthe total elapsed time that an item was actively worked on to the total\nelapsed time that it took for an item to complete (its total Cycle Time). There’s a subtlety in this definition that bears some explanation. As an item\nis flowing through a process it is in either one of two states. It is either being\nactively worked on or it is not being actively worked on. Examples of an\nitem not being actively worked on is it is blocked by some external\ndependency (team, vendor, etc.), or it is queuing waiting to be pulled. In\nboth of those examples, an item is accumulating Cycle Time but no one is\nactively working on it. To get Flow Efficiency, you take the Total Cycle\nTime, subtract out inactive time and then divide that result by the Total\nCycle Time. It is not uncommon for teams just starting out with managing for flow\n\nto have Flow Efficiencies in the 15% range. Think about that for a second. If\na user story took 20 days to complete and had a Flow Efficiency of 15% that\nmeans that it spent only 3 days having someone actively work on it and it\nspent 17 days in some type of inactive state.", "tokens": 512, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 27, "segment_id": "00027", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000029"}
{"type": "chunk", "text": "To get Flow Efficiency, you take the Total Cycle\nTime, subtract out inactive time and then divide that result by the Total\nCycle Time. It is not uncommon for teams just starting out with managing for flow\n\nto have Flow Efficiencies in the 15% range. Think about that for a second. If\na user story took 20 days to complete and had a Flow Efficiency of 15% that\nmeans that it spent only 3 days having someone actively work on it and it\nspent 17 days in some type of inactive state. If a user story took only 3 active\ndays of work yet had 17 days of inactivity built into its Cycle Time, where\ndo you think you should focus your process improvement activities? It is\nprobably going to be very hard to improve on that 3 days of active time, but", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nTo get Flow Efficiency, you take the Total Cycle\nTime, subtract out inactive time and then divide that result by the Total\nCycle Time. It is not uncommon for teams just starting out with managing for flow\n\nto have Flow Efficiencies in the 15% range. Think about that for a second. If\na user story took 20 days to complete and had a Flow Efficiency of 15% that\nmeans that it spent only 3 days having someone actively work on it and it\nspent 17 days in some type of inactive state. If a user story took only 3 active\ndays of work yet had 17 days of inactivity built into its Cycle Time, where\ndo you think you should focus your process improvement activities? It is\nprobably going to be very hard to improve on that 3 days of active time, but", "tokens": 173, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 27, "segment_id": "00027", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000030"}
{"type": "chunk", "text": "my guess there are tons of opportunities to get that 17 day number down. Any reduction of inactive time will by definition improve overall Cycle\nTime. Looking at wait time is usually the best, easiest, cheapest area to\ninvestigate first for process improvement. Throughput\nI have saved the easiest metric to define for last. Simply put, Throughput is\ndefined as:\n\nThroughput: the amount of WIP (number of work items) completed per unit of time. Stated a slightly different way, Throughput is a measure of how fast\nitems depart a process. The unit of time that your team chooses for your\nThroughput measurement is completely up to you. Your team can choose to\nmeasure the number of items that it gets done per day, per week, per\niteration, etc. For example, you might state that the Throughput of your\nsystem as “three stories per day” (for a given day) or “five features per\nmonth” (for a given month). A further thing to know about Throughput, however, is that this metric\n\nas I have defined it here is very different from the Scrum metric of\n“Velocity”. Velocity, as you may know, is measured in terms of Story Points\nper sprint or iteration. You have to remember, though, that for Throughput I\nam talking about actual counts of work items (e.g., actual number of discrete\nstories and not Story Points) per unit of time. As I have just mentioned, the\nunit of time you choose for Throughput is completely up to you. The\nimplication being that your choice of a time period need not necessarily\ncoincide with an iteration boundary. I say all of this because many agile\ncoaches and consultants use the words “Velocity” and “Throughput”\ninterchangeably. Just know that these two terms are definitely not\nsynonymous. If Throughput is how fast items depart from a process, then Arrival\n\nRate is how fast items arrive to a process. I mention this fact here because\ndepending on your perspective, Arrival Rate can be thought of as an analog\nto Throughput. For example, let’s say that the “Development” step and\n“Test” step are adjacent in your workflow. Then the Throughput from the", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nmy guess there are tons of opportunities to get that 17 day number down. Any reduction of inactive time will by definition improve overall Cycle\nTime. Looking at wait time is usually the best, easiest, cheapest area to\ninvestigate first for process improvement. Throughput\nI have saved the easiest metric to define for last. Simply put, Throughput is\ndefined as:\n\nThroughput: the amount of WIP (number of work items) completed per unit of time. Stated a slightly different way, Throughput is a measure of how fast\nitems depart a process. The unit of time that your team chooses for your\nThroughput measurement is completely up to you. Your team can choose to\nmeasure the number of items that it gets done per day, per week, per\niteration, etc. For example, you might state that the Throughput of your\nsystem as “three stories per day” (for a given day) or “five features per\nmonth” (for a given month). A further thing to know about Throughput, however, is that this metric\n\nas I have defined it here is very different from the Scrum metric of\n“Velocity”. Velocity, as you may know, is measured in terms of Story Points\nper sprint or iteration. You have to remember, though, that for Throughput I\nam talking about actual counts of work items (e.g., actual number of discrete\nstories and not Story Points) per unit of time. As I have just mentioned, the\nunit of time you choose for Throughput is completely up to you. The\nimplication being that your choice of a time period need not necessarily\ncoincide with an iteration boundary. I say all of this because many agile\ncoaches and consultants use the words “Velocity” and “Throughput”\ninterchangeably. Just know that these two terms are definitely not\nsynonymous. If Throughput is how fast items depart from a process, then Arrival\n\nRate is how fast items arrive to a process. I mention this fact here because\ndepending on your perspective, Arrival Rate can be thought of as an analog\nto Throughput. For example, let’s say that the “Development” step and\n“Test” step are adjacent in your workflow. Then the Throughput from the", "tokens": 469, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 28, "segment_id": "00028", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000031"}
{"type": "chunk", "text": "“Development” step could also be thought of as the Arrival Rate to the\n“Test” step. Even more importantly, though, comparing the Arrival Rate of one step\n\nin your process to the Throughput in another, different step may give you\nsome much needed insight into predictability problems. I will be going into\nmuch more detail about this comparison in the coming chapters. However,\nmy more immediate reason in discussing Arrival Rate is simply to point out\nthat how fast things arrive to your process could be just as important as how\nfast things depart. The Throughput metric answers the very important question of “How\nmany features am I going to get in the next release?” At some point you are\ngoing to need to answer that question, so track Throughput and be prepared. As with the other metrics, though, the most obvious reason to track a\nmetric is not necessarily the best reason to do so. While I am on record as\nbeing skeptical of applying the Theory of Constraints (ToC) to knowledge\nwork, I will acknowledge that understanding Throughput at each step of\nyour process will help you to identify the constraints in your workflow\n(assuming variability has been taken into account---but more on that later). Understanding what the constraints are and where they are will assist you in\ntrying to determine (among other things) the best places to look for overall\nprocess improvement. Does your team require more staff? What type of staff\ndo you need? Should you introduce some type of automation? These are all\nexamples of questions that can only be answered by understanding and\ntracking Throughput. Conclusion\nWhat I have shown here are just the basic metrics of flow to get you started:\nWIP, Cycle Time, and Throughput. There are most certainly other metrics\nthat you will want to track in your own environment, but these represent the\nmetrics common to all flow implementations. If your goal is predictability,\nthen these are the metrics that you are going to want to track. I would also like to say one final word on vocabulary. No doubt if you\n\nhave done any reading on this topic that you have come across different\nnames for the concepts that I have defined in this chapter (I discussed the\nmost contentious example of this in the “Lead Time vs. Cycle Time” section\nabove). As I mentioned earlier, the point of this discussion is not to spark\nany religious wars over nomenclature. I am in no way trying to suggest that", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\n“Development” step could also be thought of as the Arrival Rate to the\n“Test” step. Even more importantly, though, comparing the Arrival Rate of one step\n\nin your process to the Throughput in another, different step may give you\nsome much needed insight into predictability problems. I will be going into\nmuch more detail about this comparison in the coming chapters. However,\nmy more immediate reason in discussing Arrival Rate is simply to point out\nthat how fast things arrive to your process could be just as important as how\nfast things depart. The Throughput metric answers the very important question of “How\nmany features am I going to get in the next release?” At some point you are\ngoing to need to answer that question, so track Throughput and be prepared. As with the other metrics, though, the most obvious reason to track a\nmetric is not necessarily the best reason to do so. While I am on record as\nbeing skeptical of applying the Theory of Constraints (ToC) to knowledge\nwork, I will acknowledge that understanding Throughput at each step of\nyour process will help you to identify the constraints in your workflow\n(assuming variability has been taken into account---but more on that later). Understanding what the constraints are and where they are will assist you in\ntrying to determine (among other things) the best places to look for overall\nprocess improvement. Does your team require more staff? What type of staff\ndo you need? Should you introduce some type of automation? These are all\nexamples of questions that can only be answered by understanding and\ntracking Throughput. Conclusion\nWhat I have shown here are just the basic metrics of flow to get you started:\nWIP, Cycle Time, and Throughput. There are most certainly other metrics\nthat you will want to track in your own environment, but these represent the\nmetrics common to all flow implementations. If your goal is predictability,\nthen these are the metrics that you are going to want to track. I would also like to say one final word on vocabulary. No doubt if you\n\nhave done any reading on this topic that you have come across different\nnames for the concepts that I have defined in this chapter (I discussed the\nmost contentious example of this in the “Lead Time vs. Cycle Time” section\nabove). As I mentioned earlier, the point of this discussion is not to spark\nany religious wars over nomenclature. I am in no way trying to suggest that", "tokens": 506, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 29, "segment_id": "00029", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000032"}
{"type": "chunk", "text": "the names that I use here are the only correct ones. The point of this chapter\nis only to get you thinking about the basic concepts that are communicated\nby these metrics. For example, for us to have a conversation about predictability, we are\n\nfirst going to need some notion of the total amount of items in a system. I am\nchoosing to call that notion Work In Progress. If you prefer the term Work in\nProcess or something else, then by all means use that name. We are also\ngoing to need some notion of the amount of time that items spend in the\nsystem. I am choosing to call that Cycle Time. If you prefer Lead Time,\nFlow Time, Time In Process, or something else, then, please do not let me\nstand in your way. Lastly, we need some notion of the amount of items that\nleave the system per unit of time. I am choosing to call that Throughput. But\nplease feel free to use the terms Completion Rate, Departure Rate, or\nanything else that you may make you comfortable (so long as you do not use\nthe term Velocity!). Just know that it is the definitions of these concepts that are important\n---not the names. However, to be clear, the rest of this book will utilize the\nnames and definitions of these metrics as I have outlined in this chapter. Lastly, one of the fundamental hypotheses of this chapter is that all\n\nprocesses can be modeled as queuing systems. When thinking about your\nprocess in this way, you are able to bring to bear the real reason why it is so\ncrucial to track WIP, Cycle Time, and Throughput. This real reason is\nbecause these flow metrics are inextricably linked by a fundamental and\npowerful bond. Understanding this connection is going to be the key to\nbuilding and operating a predictable process. An exploration of this link is\nwhere I will go next in my discussion of actionable metrics. The name of this remarkable relationship, by the way, is Little’s Law. Key Learnings and Takeaways\n\nAny work item can be counted as WIP when it is between the defined\nentry point of a process and the defined exit point of a process. The choice of what work items you count as WIP when between those\ntwo points is completely up to you. WIP can be segmented into several different types.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nthe names that I use here are the only correct ones. The point of this chapter\nis only to get you thinking about the basic concepts that are communicated\nby these metrics. For example, for us to have a conversation about predictability, we are\n\nfirst going to need some notion of the total amount of items in a system. I am\nchoosing to call that notion Work In Progress. If you prefer the term Work in\nProcess or something else, then by all means use that name. We are also\ngoing to need some notion of the amount of time that items spend in the\nsystem. I am choosing to call that Cycle Time. If you prefer Lead Time,\nFlow Time, Time In Process, or something else, then, please do not let me\nstand in your way. Lastly, we need some notion of the amount of items that\nleave the system per unit of time. I am choosing to call that Throughput. But\nplease feel free to use the terms Completion Rate, Departure Rate, or\nanything else that you may make you comfortable (so long as you do not use\nthe term Velocity!). Just know that it is the definitions of these concepts that are important\n---not the names. However, to be clear, the rest of this book will utilize the\nnames and definitions of these metrics as I have outlined in this chapter. Lastly, one of the fundamental hypotheses of this chapter is that all\n\nprocesses can be modeled as queuing systems. When thinking about your\nprocess in this way, you are able to bring to bear the real reason why it is so\ncrucial to track WIP, Cycle Time, and Throughput. This real reason is\nbecause these flow metrics are inextricably linked by a fundamental and\npowerful bond. Understanding this connection is going to be the key to\nbuilding and operating a predictable process. An exploration of this link is\nwhere I will go next in my discussion of actionable metrics. The name of this remarkable relationship, by the way, is Little’s Law. Key Learnings and Takeaways\n\nAny work item can be counted as WIP when it is between the defined\nentry point of a process and the defined exit point of a process. The choice of what work items you count as WIP when between those\ntwo points is completely up to you. WIP can be segmented into several different types.", "tokens": 491, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 30, "segment_id": "00030", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000033"}
{"type": "chunk", "text": "Understanding this connection is going to be the key to\nbuilding and operating a predictable process. An exploration of this link is\nwhere I will go next in my discussion of actionable metrics. The name of this remarkable relationship, by the way, is Little’s Law. Key Learnings and Takeaways\n\nAny work item can be counted as WIP when it is between the defined\nentry point of a process and the defined exit point of a process. The choice of what work items you count as WIP when between those\ntwo points is completely up to you. WIP can be segmented into several different types. If WIP is segmented into several types, then it is also valid to talk about\nthe Cycle Time and Throughput of those type segments.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nUnderstanding this connection is going to be the key to\nbuilding and operating a predictable process. An exploration of this link is\nwhere I will go next in my discussion of actionable metrics. The name of this remarkable relationship, by the way, is Little’s Law. Key Learnings and Takeaways\n\nAny work item can be counted as WIP when it is between the defined\nentry point of a process and the defined exit point of a process. The choice of what work items you count as WIP when between those\ntwo points is completely up to you. WIP can be segmented into several different types. If WIP is segmented into several types, then it is also valid to talk about\nthe Cycle Time and Throughput of those type segments.", "tokens": 152, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 30, "segment_id": "00030", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000034"}
{"type": "chunk", "text": "Cycle Time and Throughput are always defined in terms of WIP. Cycle Time is the amount of elapsed time that an item spends as Work\nIn Progress. Throughput is the amount of Work In Progress completed during some\narbitrary interval of time. The names of metrics are not as important as their definitions. Use\nwhatever names you want for these metrics, but make sure you define\nthem as they are defined here. Track these metrics because they have predictive power, are\ninexpensive to gather, and answer the important questions that your\ncustomers are asking. Track these metrics because they form the basis for Little’s Law.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow\n\nCycle Time and Throughput are always defined in terms of WIP. Cycle Time is the amount of elapsed time that an item spends as Work\nIn Progress. Throughput is the amount of Work In Progress completed during some\narbitrary interval of time. The names of metrics are not as important as their definitions. Use\nwhatever names you want for these metrics, but make sure you define\nthem as they are defined here. Track these metrics because they have predictive power, are\ninexpensive to gather, and answer the important questions that your\ncustomers are asking. Track these metrics because they form the basis for Little’s Law.", "tokens": 128, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 31, "segment_id": "00031", "chapter_num": "2", "chapter_title": "The Basic Metrics of Flow", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 2: The Basic Metrics of Flow", "chunk_id": "00000035"}
{"type": "chunk", "text": "Chapter 3 - Introduction to Little’s Law\n\nThe previous chapter dealt with the basic metrics of flow: WIP, Cycle Time,\nand Throughput. In what may be one of the most miraculous results in the\nhistory of process analysis, these three metrics are intrinsically linked by a\nvery straightforward and very powerful relationship known as Little’s Law:\n\nAverage Cycle Time = Average Work In Progress / Average Throughput\n\nIf you have ever seen Little’s Law before, you have probably seen it in\n\nthe form of the above equation. What few Agile practitioners realize,\nhowever, is that Little’s Law was originally stated in a slightly different\nform:\n\nAverage Items In Queue = Average Arrival Rate * Average Wait Time\n\nThis fact is important because different assumptions need to be\n\nsatisfied depending on which form of the law you are using. And\nunderstanding the assumptions behind the equation is the key to\nunderstanding the law itself. Once you understand the assumptions, then\nyou can use those assumptions as a guide to some process policies that you\ncan put in place to aid predictability. The math of Little’s Law is simple. But this chapter is about how we\ndo not care about the math. What we do care about---and I cannot stress this\npoint enough if we want to gain a greater appreciation of the law’s\napplicability to our world---is looking far beyond the elegance of the\nequation to get a deeper understanding of the background assumptions\nneeded to make the law work. That is where things get more complicated,\nbut it is also where we will find the greatest benefit. A thorough\ncomprehension of why Little’s Law works the way it does is going to be the", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nChapter 3 - Introduction to Little’s Law\n\nThe previous chapter dealt with the basic metrics of flow: WIP, Cycle Time,\nand Throughput. In what may be one of the most miraculous results in the\nhistory of process analysis, these three metrics are intrinsically linked by a\nvery straightforward and very powerful relationship known as Little’s Law:\n\nAverage Cycle Time = Average Work In Progress / Average Throughput\n\nIf you have ever seen Little’s Law before, you have probably seen it in\n\nthe form of the above equation. What few Agile practitioners realize,\nhowever, is that Little’s Law was originally stated in a slightly different\nform:\n\nAverage Items In Queue = Average Arrival Rate * Average Wait Time\n\nThis fact is important because different assumptions need to be\n\nsatisfied depending on which form of the law you are using. And\nunderstanding the assumptions behind the equation is the key to\nunderstanding the law itself. Once you understand the assumptions, then\nyou can use those assumptions as a guide to some process policies that you\ncan put in place to aid predictability. The math of Little’s Law is simple. But this chapter is about how we\ndo not care about the math. What we do care about---and I cannot stress this\npoint enough if we want to gain a greater appreciation of the law’s\napplicability to our world---is looking far beyond the elegance of the\nequation to get a deeper understanding of the background assumptions\nneeded to make the law work. That is where things get more complicated,\nbut it is also where we will find the greatest benefit. A thorough\ncomprehension of why Little’s Law works the way it does is going to be the", "tokens": 348, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 32, "segment_id": "00032", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000036"}
{"type": "chunk", "text": "basis for understanding how the basic metrics of flow can become\npredictably actionable. We Need a Little Help\nFirst, some background. Dr. John Little spent much of his early career studying queuing\nsystems like Figure 2.1 (the queuing systems picture from the previous\nchapter). In fact, one of the best definitions of such a queuing system comes\nfrom Dr. Little himself: “A queuing system consists of discrete objects we\nshall call items, which arrive at some rate to the system. The items could be\ncars at a toll booth, people in a cafeteria line, aircraft on a production line,\nor instructions waiting to be executed inside a computer. The stream of\narrivals enters the system, joins one or more queues and eventually receives\nservice, and exits in a stream of departures. The service might be a taxi ride\n(travelers), a bowl of soup (lunch eaters), or auto repair (car owners). In\nmost cases, service is the bottleneck that creates the queue, and so we\nusually have a service operation with a service time, but this is not required. In such a case we assume there is nevertheless a waiting time. Sometimes a\ndistinction is made between number in queue and total number in queue\nplus service, the latter being called number in system.” The diversity of\ndomains that he mentions here is extraordinary. While he does not\nspecifically mention software development or knowledge work in general, I\nam going to suggest that these areas can also be readily modeled in this\nway. In 1961, Dr. Little set out to prove what seemed to be a very general\nand very common result exhibited by all queuing systems. The result that he\nwas researching was a connection between the average Arrival Rate of a\nqueue, the average number of items in the queue, and the average amount of\ntime an item spent in the queue (for the purpose of this chapter, when I say\n“average” I am really talking about “arithmetic mean”). Mathematically, the\nrelationship between these three metrics looks like:\n\nEquation (1): L = λ* W\n\nWhere:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nbasis for understanding how the basic metrics of flow can become\npredictably actionable. We Need a Little Help\nFirst, some background. Dr. John Little spent much of his early career studying queuing\nsystems like Figure 2.1 (the queuing systems picture from the previous\nchapter). In fact, one of the best definitions of such a queuing system comes\nfrom Dr. Little himself: “A queuing system consists of discrete objects we\nshall call items, which arrive at some rate to the system. The items could be\ncars at a toll booth, people in a cafeteria line, aircraft on a production line,\nor instructions waiting to be executed inside a computer. The stream of\narrivals enters the system, joins one or more queues and eventually receives\nservice, and exits in a stream of departures. The service might be a taxi ride\n(travelers), a bowl of soup (lunch eaters), or auto repair (car owners). In\nmost cases, service is the bottleneck that creates the queue, and so we\nusually have a service operation with a service time, but this is not required. In such a case we assume there is nevertheless a waiting time. Sometimes a\ndistinction is made between number in queue and total number in queue\nplus service, the latter being called number in system.” The diversity of\ndomains that he mentions here is extraordinary. While he does not\nspecifically mention software development or knowledge work in general, I\nam going to suggest that these areas can also be readily modeled in this\nway. In 1961, Dr. Little set out to prove what seemed to be a very general\nand very common result exhibited by all queuing systems. The result that he\nwas researching was a connection between the average Arrival Rate of a\nqueue, the average number of items in the queue, and the average amount of\ntime an item spent in the queue (for the purpose of this chapter, when I say\n“average” I am really talking about “arithmetic mean”). Mathematically, the\nrelationship between these three metrics looks like:\n\nEquation (1): L = λ* W\n\nWhere:", "tokens": 445, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 33, "segment_id": "00033", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000037"}
{"type": "chunk", "text": "L = the average number of items in the queuing system. λ = the average number of items arriving per unit time. W = the average wait time in the system for an item. Notice that Equation (1) is stated strictly in terms of a queuing\nsystem’s Arrival Rate. This point is going to be of special interest a little\nlater in this chapter. Also notice that---if it is not obvious already---Little’s Law is a\n\nrelationship of averages. Most knowledge work applications and\ndiscussions of the law neglect this very important detail. The fact that\nLittle’s Law is based on averages is not necessarily good or bad. It is only\nbad when people to try to apply the law for uses that it was never intended. Dr. Little was the first to provide a rigorous proof for Equation (1) and,\n\nas such, this relationship has since been known as Little’s Law. According\nto him, one of the reasons why the law is so important is the fact that\n(emphasis is mine): “L, λ, and W are three quite different and important\nmeasures of effectiveness of system performance, and Little’s Law insists\nthat they must obey the ‘law.’... Little’s Law locks the three measures\ntogether in a unique and consistent way for any system in which it applies. Little’s Law will not tell the managers how to handle trade-offs or provide\ninnovations to improve their chosen measures, but it lays down a necessary\nrelation. As such, it provides structure for thinking about any operation that\ncan be cast as a queue and suggests what data might be valuable to collect.”\nThe great advantage of Little’s Law is the overall simplicity of its\n\ncalculation. Specifically, if one has any two of the above three statistics,\nthen one can easily calculate the third. This result is extremely useful as\nthere are many situations in many different domains where the\nmeasurement of all three metrics of interest is difficult, expensive, or even\nimpossible. Little’s Law shows us that if we can measure any two attributes,\nthen we automatically get the third. To illustrate this point, Dr. Little used the very simple example of a\nwine rack. Let’s say you have a wine rack that, on average, always has 100\nbottles in it. Let’s further say that you replenish the rack at an average rate\nof two bottles per week.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nL = the average number of items in the queuing system. λ = the average number of items arriving per unit time. W = the average wait time in the system for an item. Notice that Equation (1) is stated strictly in terms of a queuing\nsystem’s Arrival Rate. This point is going to be of special interest a little\nlater in this chapter. Also notice that---if it is not obvious already---Little’s Law is a\n\nrelationship of averages. Most knowledge work applications and\ndiscussions of the law neglect this very important detail. The fact that\nLittle’s Law is based on averages is not necessarily good or bad. It is only\nbad when people to try to apply the law for uses that it was never intended. Dr. Little was the first to provide a rigorous proof for Equation (1) and,\n\nas such, this relationship has since been known as Little’s Law. According\nto him, one of the reasons why the law is so important is the fact that\n(emphasis is mine): “L, λ, and W are three quite different and important\nmeasures of effectiveness of system performance, and Little’s Law insists\nthat they must obey the ‘law.’... Little’s Law locks the three measures\ntogether in a unique and consistent way for any system in which it applies. Little’s Law will not tell the managers how to handle trade-offs or provide\ninnovations to improve their chosen measures, but it lays down a necessary\nrelation. As such, it provides structure for thinking about any operation that\ncan be cast as a queue and suggests what data might be valuable to collect.”\nThe great advantage of Little’s Law is the overall simplicity of its\n\ncalculation. Specifically, if one has any two of the above three statistics,\nthen one can easily calculate the third. This result is extremely useful as\nthere are many situations in many different domains where the\nmeasurement of all three metrics of interest is difficult, expensive, or even\nimpossible. Little’s Law shows us that if we can measure any two attributes,\nthen we automatically get the third. To illustrate this point, Dr. Little used the very simple example of a\nwine rack. Let’s say you have a wine rack that, on average, always has 100\nbottles in it. Let’s further say that you replenish the rack at an average rate\nof two bottles per week.", "tokens": 493, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 34, "segment_id": "00034", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000038"}
{"type": "chunk", "text": "This result is extremely useful as\nthere are many situations in many different domains where the\nmeasurement of all three metrics of interest is difficult, expensive, or even\nimpossible. Little’s Law shows us that if we can measure any two attributes,\nthen we automatically get the third. To illustrate this point, Dr. Little used the very simple example of a\nwine rack. Let’s say you have a wine rack that, on average, always has 100\nbottles in it. Let’s further say that you replenish the rack at an average rate\nof two bottles per week. Knowing just these two numbers (and nothing\nelse!) allows us to determine how long, on average, a given bottle spends\nsitting in the rack. By applying Equation (1), we have L equal to 100 and λ\nequal to 2. Plugging those numbers into the formula tells us that a given\nwine bottle spends, on average, 50 weeks in the rack.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nThis result is extremely useful as\nthere are many situations in many different domains where the\nmeasurement of all three metrics of interest is difficult, expensive, or even\nimpossible. Little’s Law shows us that if we can measure any two attributes,\nthen we automatically get the third. To illustrate this point, Dr. Little used the very simple example of a\nwine rack. Let’s say you have a wine rack that, on average, always has 100\nbottles in it. Let’s further say that you replenish the rack at an average rate\nof two bottles per week. Knowing just these two numbers (and nothing\nelse!) allows us to determine how long, on average, a given bottle spends\nsitting in the rack. By applying Equation (1), we have L equal to 100 and λ\nequal to 2. Plugging those numbers into the formula tells us that a given\nwine bottle spends, on average, 50 weeks in the rack.", "tokens": 201, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 34, "segment_id": "00034", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000039"}
{"type": "chunk", "text": "Before we get much further, it is worth exploring what necessary\ncontextual conditions are required for the law to hold. When stated in the\nform of Equation (1) the only assumption necessary is that the system under\nconsideration has some guarantee of being in a steady state. That’s it. Really, that’s it. To illustrate the things we do not need, notice that we can\narrive at the wine rack result without tracking the specific arrival or\ndeparture dates for each or any individual bottle. We also do not need to\nknow the specific order that the bottles were placed in the rack, or the\nspecific order that the bottles were taken off the rack. We do not need to\nunderstand anything fancy like the underlying probability distributions of\nthe Arrival and Departure Rates. Interestingly, we do not even need to track\nthe size of the bottles in the rack. We could have some small 20cl bottles or\nsome large 2 litre bottles in addition to the more standard 750ml bottles. The variation in size has no impact on the basic result. (You should know\nthat, in the interest of thoroughness, I am in the process of independently\nverifying this wine rack result on my own. Rest assured that no detail has\nbeen overlooked in the research of this book.)\n\nAs remarkable as all of this may be, the mathematics are not really\n\nwhat is important for our purposes here. What is important is that we\nacknowledge that the fundamental relationship exists. Understanding the\ninextricable link among these metrics is one of the most powerful tools at\nour disposal in terms of predictable process design. But before we can get into how Little’s Law can help us with\npredictability, it is probably helpful to first state the relationship in more\nfamiliar terms. Little’s Law from a Different Perspective\nIn the late 1980s (or early 1990s depending on whom you ask) Little’s Law\nwas usurped by the Operations Management (OM) community and was\nchanged to emphasize OM’s focus on Throughput. The OM crowd thus\nchanged the terms in Little’s Law to reflect their different perspective as\nshown by Equation (2):\n\nEquation (2): Cycle Time = Work In Progress / Throughput", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nBefore we get much further, it is worth exploring what necessary\ncontextual conditions are required for the law to hold. When stated in the\nform of Equation (1) the only assumption necessary is that the system under\nconsideration has some guarantee of being in a steady state. That’s it. Really, that’s it. To illustrate the things we do not need, notice that we can\narrive at the wine rack result without tracking the specific arrival or\ndeparture dates for each or any individual bottle. We also do not need to\nknow the specific order that the bottles were placed in the rack, or the\nspecific order that the bottles were taken off the rack. We do not need to\nunderstand anything fancy like the underlying probability distributions of\nthe Arrival and Departure Rates. Interestingly, we do not even need to track\nthe size of the bottles in the rack. We could have some small 20cl bottles or\nsome large 2 litre bottles in addition to the more standard 750ml bottles. The variation in size has no impact on the basic result. (You should know\nthat, in the interest of thoroughness, I am in the process of independently\nverifying this wine rack result on my own. Rest assured that no detail has\nbeen overlooked in the research of this book.)\n\nAs remarkable as all of this may be, the mathematics are not really\n\nwhat is important for our purposes here. What is important is that we\nacknowledge that the fundamental relationship exists. Understanding the\ninextricable link among these metrics is one of the most powerful tools at\nour disposal in terms of predictable process design. But before we can get into how Little’s Law can help us with\npredictability, it is probably helpful to first state the relationship in more\nfamiliar terms. Little’s Law from a Different Perspective\nIn the late 1980s (or early 1990s depending on whom you ask) Little’s Law\nwas usurped by the Operations Management (OM) community and was\nchanged to emphasize OM’s focus on Throughput. The OM crowd thus\nchanged the terms in Little’s Law to reflect their different perspective as\nshown by Equation (2):\n\nEquation (2): Cycle Time = Work In Progress / Throughput", "tokens": 464, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 35, "segment_id": "00035", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000040"}
{"type": "chunk", "text": "Where:\n\n1. Cycle Time (CT) = the average amount of time it takes for an item to\n\nflow through the system. 2. Work In Progress (WIP) = the average total inventory in the system. 3. Throughput (TH) = the average Throughput of the system. In the interest of completeness, it is ok to perform the algebra on\n\nLittle’s Law so that it takes the different, yet still valid forms:\n\nEquation (3): TH = WIP / CT\n\nand\n\nEquation (4): WIP = CT * TH\n\nWhere CT, WIP, and TH are defined the same way as in Equation (2). Because of its roots in Operations Management, the Lean and Kanban\nknowledge work community has adopted this “Throughput” form of Little’s\nLaw as their own. If you have seen Little’s Law before, you have almost\ncertainly seen it in the form of Equation (2)---even though Equation (2)\ndoes not represent the law’s original format. The upshot of Little’s Law is that, in general, the more things that you\n\nwork on at any given time (on average) the longer it is going to take for\neach of those things to finish (on average). As a case in point, managers\nwho are ignorant of this law panic when they see that their Cycle Times are\ntoo long and perform the exact opposite intervention of what they should\ndo: they start more work. After all, they reason, if things take so long, then\nthey need to start new items as soon as possible so that those items finish on\ntime---regardless of what is currently in progress. The result is that items\nonly take longer and longer to complete. Thus, managers feel more and\nmore pressure to start things sooner and sooner. You can see how this\nvicious cycle gets started and perpetuates itself. After studying Little’s Law,\nyou should realize that if Cycle Times are too long then the first thing you", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nWhere:\n\n1. Cycle Time (CT) = the average amount of time it takes for an item to\n\nflow through the system. 2. Work In Progress (WIP) = the average total inventory in the system. 3. Throughput (TH) = the average Throughput of the system. In the interest of completeness, it is ok to perform the algebra on\n\nLittle’s Law so that it takes the different, yet still valid forms:\n\nEquation (3): TH = WIP / CT\n\nand\n\nEquation (4): WIP = CT * TH\n\nWhere CT, WIP, and TH are defined the same way as in Equation (2). Because of its roots in Operations Management, the Lean and Kanban\nknowledge work community has adopted this “Throughput” form of Little’s\nLaw as their own. If you have seen Little’s Law before, you have almost\ncertainly seen it in the form of Equation (2)---even though Equation (2)\ndoes not represent the law’s original format. The upshot of Little’s Law is that, in general, the more things that you\n\nwork on at any given time (on average) the longer it is going to take for\neach of those things to finish (on average). As a case in point, managers\nwho are ignorant of this law panic when they see that their Cycle Times are\ntoo long and perform the exact opposite intervention of what they should\ndo: they start more work. After all, they reason, if things take so long, then\nthey need to start new items as soon as possible so that those items finish on\ntime---regardless of what is currently in progress. The result is that items\nonly take longer and longer to complete. Thus, managers feel more and\nmore pressure to start things sooner and sooner. You can see how this\nvicious cycle gets started and perpetuates itself. After studying Little’s Law,\nyou should realize that if Cycle Times are too long then the first thing you", "tokens": 415, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 36, "segment_id": "00036", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000041"}
{"type": "chunk", "text": "should consider is lowering WIP. It feels uncomfortable, but it is true. In\norder to get stuff done faster, you need to work on less (again, on average). What Dr. Little demonstrated is that the three flow metrics are all\nessentially three sides of the same coin (if a coin could have three sides). By\nchanging one of them, you will almost certainly affect one or both of the\nother two. In other words, Little’s Law reveals what levers that we can pull\nwhen undertaking process improvement. Further, as we are about to see,\nLittle’s Law will suggest the specific interventions that we should explore\nwhen our process is not performing the way we think it should. At the risk of repeating myself, what I am talking about here is simple,\n\nincontrovertible mathematical fact. A change in one metric almost always\nresults in a change in the others. Most companies that I talk to that complain\nof poor predictability are almost always ignorant of the negative implication\nof too much WIP on Cycle Time or Throughput. Ignore this correlation at\nyour own peril. It is all about the Assumptions\nThis is all straightforward enough so far, right? Well, unfortunately, it is not. Remember I said at the outset that Little’s Law is deceptively simple? Here\nis where things get more complicated. It is easy to see from a purely mathematical perspective that Equation\n(1) is logically equivalent to Equation (2). But it is more important to focus\non the difference between the two. As I mentioned earlier, Equation (1) is\nexpressly stated in terms of the Arrival Rate to the system whereas\nEquation (2) is expressly stated in terms of the Departure Rate from the\nsystem. This emphasis on Throughput in Equation (2) probably seems more\ncomfortable to us as it reflects the usual perspective of a knowledge work\nprocess. Typically, in our context, we care about the rate at which we are\nfinishing our work (even though, as we shall soon see, we should care just\nas much about the rate at which we start work). What is nice to know is that\nLittle’s Law can morph to match this required perspective. At first glance, this change may not otherwise seem all that significant. However, this transformation from the perspective of arrivals to the\nperspective of departures has a profound impact in terms of how we think\nabout and apply the law.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nshould consider is lowering WIP. It feels uncomfortable, but it is true. In\norder to get stuff done faster, you need to work on less (again, on average). What Dr. Little demonstrated is that the three flow metrics are all\nessentially three sides of the same coin (if a coin could have three sides). By\nchanging one of them, you will almost certainly affect one or both of the\nother two. In other words, Little’s Law reveals what levers that we can pull\nwhen undertaking process improvement. Further, as we are about to see,\nLittle’s Law will suggest the specific interventions that we should explore\nwhen our process is not performing the way we think it should. At the risk of repeating myself, what I am talking about here is simple,\n\nincontrovertible mathematical fact. A change in one metric almost always\nresults in a change in the others. Most companies that I talk to that complain\nof poor predictability are almost always ignorant of the negative implication\nof too much WIP on Cycle Time or Throughput. Ignore this correlation at\nyour own peril. It is all about the Assumptions\nThis is all straightforward enough so far, right? Well, unfortunately, it is not. Remember I said at the outset that Little’s Law is deceptively simple? Here\nis where things get more complicated. It is easy to see from a purely mathematical perspective that Equation\n(1) is logically equivalent to Equation (2). But it is more important to focus\non the difference between the two. As I mentioned earlier, Equation (1) is\nexpressly stated in terms of the Arrival Rate to the system whereas\nEquation (2) is expressly stated in terms of the Departure Rate from the\nsystem. This emphasis on Throughput in Equation (2) probably seems more\ncomfortable to us as it reflects the usual perspective of a knowledge work\nprocess. Typically, in our context, we care about the rate at which we are\nfinishing our work (even though, as we shall soon see, we should care just\nas much about the rate at which we start work). What is nice to know is that\nLittle’s Law can morph to match this required perspective. At first glance, this change may not otherwise seem all that significant. However, this transformation from the perspective of arrivals to the\nperspective of departures has a profound impact in terms of how we think\nabout and apply the law.", "tokens": 507, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 37, "segment_id": "00037", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000042"}
{"type": "chunk", "text": "Typically, in our context, we care about the rate at which we are\nfinishing our work (even though, as we shall soon see, we should care just\nas much about the rate at which we start work). What is nice to know is that\nLittle’s Law can morph to match this required perspective. At first glance, this change may not otherwise seem all that significant. However, this transformation from the perspective of arrivals to the\nperspective of departures has a profound impact in terms of how we think\nabout and apply the law. When we state Little’s Law in terms of a system’s\nThroughput then we must also immediately consider what underlying", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nTypically, in our context, we care about the rate at which we are\nfinishing our work (even though, as we shall soon see, we should care just\nas much about the rate at which we start work). What is nice to know is that\nLittle’s Law can morph to match this required perspective. At first glance, this change may not otherwise seem all that significant. However, this transformation from the perspective of arrivals to the\nperspective of departures has a profound impact in terms of how we think\nabout and apply the law. When we state Little’s Law in terms of a system’s\nThroughput then we must also immediately consider what underlying", "tokens": 137, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 37, "segment_id": "00037", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000043"}
{"type": "chunk", "text": "assumptions must be in place in order for the departure-oriented law to be\nvalid. Earlier when I first introduced Equation (1) I had stated that there was\nreally only one assumption that needed to be in place for it to work. Well, in\nthe interest of completeness, technically there were three. For Equation (1)\nwe need:\n\n1. A steady state (i.e., that the underlying stochastic processes are\n\nstationary)\n\n2. An arbitrarily long period of time under observation (to guarantee the\n\nstationarity of the underlying stochastic processes)\n\n3. That the calculation be performed using consistent units (e.g., if wait\n\ntime is stated in days, then Arrival Rate must also be stated in terms of\ndays). By the way, the point here is to not give you an advanced degree in\n\nstatistics or queuing theory. Do not worry if you do not know what\n“stochastic” or “stationary” means. You do not need to. As I have just said, I\nmention these things for completeness only. When we shift perspective to look at Little’s Law from the perspective\n\nof Throughput rather than from the perspective of Arrival Rate, however,\nwe also need to change the assumptions necessary for the law to be valid. This point is so important, I want to place it in its own callout:\n\nLooking at Little’s Law from the perspective of Throughput rather than from the\nperspective of Arrival Rate necessitates a change in the assumptions required for the\nlaw to be valid. When applying the Throughput form of Little’s Law (Equation (2)),\n\nthere are two basic cases to consider. Each case is going to require its own\nassumption to be valid. The first case is if the total amount of WIP in our process is ever\nallowed to go to zero. If so, then Little’s Law is exact between any two time\ninstances where total process WIP is zero. Yes, I did say exact. Further, only\none additional assumption (other than a start and end with zero WIP) is\nneeded for the law to work in this case. All we require is that everything\nthat enters the system eventually exits. No other assumptions about stable", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nassumptions must be in place in order for the departure-oriented law to be\nvalid. Earlier when I first introduced Equation (1) I had stated that there was\nreally only one assumption that needed to be in place for it to work. Well, in\nthe interest of completeness, technically there were three. For Equation (1)\nwe need:\n\n1. A steady state (i.e., that the underlying stochastic processes are\n\nstationary)\n\n2. An arbitrarily long period of time under observation (to guarantee the\n\nstationarity of the underlying stochastic processes)\n\n3. That the calculation be performed using consistent units (e.g., if wait\n\ntime is stated in days, then Arrival Rate must also be stated in terms of\ndays). By the way, the point here is to not give you an advanced degree in\n\nstatistics or queuing theory. Do not worry if you do not know what\n“stochastic” or “stationary” means. You do not need to. As I have just said, I\nmention these things for completeness only. When we shift perspective to look at Little’s Law from the perspective\n\nof Throughput rather than from the perspective of Arrival Rate, however,\nwe also need to change the assumptions necessary for the law to be valid. This point is so important, I want to place it in its own callout:\n\nLooking at Little’s Law from the perspective of Throughput rather than from the\nperspective of Arrival Rate necessitates a change in the assumptions required for the\nlaw to be valid. When applying the Throughput form of Little’s Law (Equation (2)),\n\nthere are two basic cases to consider. Each case is going to require its own\nassumption to be valid. The first case is if the total amount of WIP in our process is ever\nallowed to go to zero. If so, then Little’s Law is exact between any two time\ninstances where total process WIP is zero. Yes, I did say exact. Further, only\none additional assumption (other than a start and end with zero WIP) is\nneeded for the law to work in this case. All we require is that everything\nthat enters the system eventually exits. No other assumptions about stable", "tokens": 455, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 38, "segment_id": "00038", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000044"}
{"type": "chunk", "text": "systems or no other assumptions about the length of the time period. Nothing. Reflect on this result for second and see if you can think of any\ncircumstance where you start a time period with zero WIP and end the time\nperiod with zero WIP. Two examples immediately come to my mind. An\nideal software “project” would start with zero WIP and end with zero WIP. If that is the case, then at the end of the project, using Little’s Law we could\nexactly determine the average of any of the three basic metrics of flow\nassuming we collected data on the other two. Another good example would\nbe any Scrum sprint. If you are doing canonical Scrum, then, by definition\nyou start each sprint with zero WIP and you end each sprint with zero WIP\n(remember, we are talking textbook Scrum here---I know practice usually\nfalls far short of prescription). If so, then just as in the previous example,\nyou could use Little’s Law to calculate an average of any of the three basic\nmetrics of flow assuming that you have collected the data for the other two. Unfortunately, though, most of us do not live in a world where we ever\n\nrun out of WIP. Some examples for this might be: we work on multiple\nprojects at a time or there is never a clean break between when one project\nstarts and another finishes, we are forced to do maintenance requests and\nproduction support in addition to project work, we never finish all the work\nthat we had started at the beginning of sprints, etc. Which brings us to the second case: when WIP never goes to zero. In\nthis case we have to be much more careful about the assumptions that are\nrequired for a valid application of Little’s Law. When WIP never goes to zero, then the assumptions about our process\nthat are necessary to make Little’s Law (in the form of Equation (2)) work\nare:\n\n1. The average input or Arrival Rate (λ) should equal the average output\n\nor Departure Rate (Throughput). 2. All work that is started will eventually be completed and exit the\n\nsystem. 3. The amount of WIP should be roughly the same at the beginning and at\n\nthe end of the time interval chosen for the calculation. 4. The average age of the WIP is neither increasing nor decreasing. 5. Cycle Time, WIP, and Throughput must all be measured using\n\nconsistent units.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nsystems or no other assumptions about the length of the time period. Nothing. Reflect on this result for second and see if you can think of any\ncircumstance where you start a time period with zero WIP and end the time\nperiod with zero WIP. Two examples immediately come to my mind. An\nideal software “project” would start with zero WIP and end with zero WIP. If that is the case, then at the end of the project, using Little’s Law we could\nexactly determine the average of any of the three basic metrics of flow\nassuming we collected data on the other two. Another good example would\nbe any Scrum sprint. If you are doing canonical Scrum, then, by definition\nyou start each sprint with zero WIP and you end each sprint with zero WIP\n(remember, we are talking textbook Scrum here---I know practice usually\nfalls far short of prescription). If so, then just as in the previous example,\nyou could use Little’s Law to calculate an average of any of the three basic\nmetrics of flow assuming that you have collected the data for the other two. Unfortunately, though, most of us do not live in a world where we ever\n\nrun out of WIP. Some examples for this might be: we work on multiple\nprojects at a time or there is never a clean break between when one project\nstarts and another finishes, we are forced to do maintenance requests and\nproduction support in addition to project work, we never finish all the work\nthat we had started at the beginning of sprints, etc. Which brings us to the second case: when WIP never goes to zero. In\nthis case we have to be much more careful about the assumptions that are\nrequired for a valid application of Little’s Law. When WIP never goes to zero, then the assumptions about our process\nthat are necessary to make Little’s Law (in the form of Equation (2)) work\nare:\n\n1. The average input or Arrival Rate (λ) should equal the average output\n\nor Departure Rate (Throughput). 2. All work that is started will eventually be completed and exit the\n\nsystem. 3. The amount of WIP should be roughly the same at the beginning and at\n\nthe end of the time interval chosen for the calculation. 4. The average age of the WIP is neither increasing nor decreasing. 5. Cycle Time, WIP, and Throughput must all be measured using\n\nconsistent units.", "tokens": 516, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 39, "segment_id": "00039", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000045"}
{"type": "chunk", "text": "As a quick aside, even if the assumptions do not hold for the entire\n\ntime period under consideration, Little’s Law can still be used as an\nestimation. However, the “goodness” of the estimation depends on how\nbadly the assumptions have been violated. The first two assumptions (#1 and #2) comprise a notion known as\nConservation of Flow. I will spend a lot of time talking about this principle\nin Chapter 7 and Chapter 8. The second two assumptions (#3 and #4) speak\nto the notion of system stability. I will also spend a lot of time talking about\none way to recognize unstable systems in Chapter 9. The last assumption (#5) is necessary for the math (and any\n\ncorresponding analysis) to come out correctly (you will notice this is the\nsame assumption necessary when stating the law in terms of arrivals). The\nnecessity for using consistent units when performing a Little’s Law\ncalculation should be intuitively obvious, but it is fairly easy to get tripped\nup over this. When we say “consistent” units what we are really saying is,\nfor example, if we are measuring average Cycle Time using the unit of time\n“day”, then the average Throughput must be in the form of the number of\nitems per that same unit of time (day), and the average WIP must be the\naverage amount of items for one unit of time (day). As another example, if\nyou want to measure average Throughput in terms of items per week (i.e.,\nthe unit of time here is “week”), then average Cycle Time must be stated in\nterms of weeks, and average WIP must be the average for each week. - You\nmight think I am wasting your time by mentioning this, but you would be\nsurprised how many teams miss this point (one is immediately reminded of\nwhen NASA slammed an orbiter into the side of Mars because one team\nused metric units while another used English units---moral of the story: do\nnot do that). For example, I saw one Scrum team that was measuring their\nvelocity in terms of story points per sprint (as Scrum teams are wont to do).", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nAs a quick aside, even if the assumptions do not hold for the entire\n\ntime period under consideration, Little’s Law can still be used as an\nestimation. However, the “goodness” of the estimation depends on how\nbadly the assumptions have been violated. The first two assumptions (#1 and #2) comprise a notion known as\nConservation of Flow. I will spend a lot of time talking about this principle\nin Chapter 7 and Chapter 8. The second two assumptions (#3 and #4) speak\nto the notion of system stability. I will also spend a lot of time talking about\none way to recognize unstable systems in Chapter 9. The last assumption (#5) is necessary for the math (and any\n\ncorresponding analysis) to come out correctly (you will notice this is the\nsame assumption necessary when stating the law in terms of arrivals). The\nnecessity for using consistent units when performing a Little’s Law\ncalculation should be intuitively obvious, but it is fairly easy to get tripped\nup over this. When we say “consistent” units what we are really saying is,\nfor example, if we are measuring average Cycle Time using the unit of time\n“day”, then the average Throughput must be in the form of the number of\nitems per that same unit of time (day), and the average WIP must be the\naverage amount of items for one unit of time (day). As another example, if\nyou want to measure average Throughput in terms of items per week (i.e.,\nthe unit of time here is “week”), then average Cycle Time must be stated in\nterms of weeks, and average WIP must be the average for each week. - You\nmight think I am wasting your time by mentioning this, but you would be\nsurprised how many teams miss this point (one is immediately reminded of\nwhen NASA slammed an orbiter into the side of Mars because one team\nused metric units while another used English units---moral of the story: do\nnot do that). For example, I saw one Scrum team that was measuring their\nvelocity in terms of story points per sprint (as Scrum teams are wont to do).", "tokens": 460, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 40, "segment_id": "00040", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000046"}
{"type": "chunk", "text": "- You\nmight think I am wasting your time by mentioning this, but you would be\nsurprised how many teams miss this point (one is immediately reminded of\nwhen NASA slammed an orbiter into the side of Mars because one team\nused metric units while another used English units---moral of the story: do\nnot do that). For example, I saw one Scrum team that was measuring their\nvelocity in terms of story points per sprint (as Scrum teams are wont to do). For their Little’s Law calculation, they proceeded to plug in their velocity\nnumber for Throughput, their WIP number as total number of user stories\n(actual stories---not story points) completed in the sprint, and expected to\nget a Cycle Time number in days. You can imagine their surprise when the\nnumbers did not come out quite the way that they expected. Assumptions as Process Policies\nUnderstanding these foundational assumptions is of monumental\nimportance. Despite what many people will tell you, the true power of", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\n- You\nmight think I am wasting your time by mentioning this, but you would be\nsurprised how many teams miss this point (one is immediately reminded of\nwhen NASA slammed an orbiter into the side of Mars because one team\nused metric units while another used English units---moral of the story: do\nnot do that). For example, I saw one Scrum team that was measuring their\nvelocity in terms of story points per sprint (as Scrum teams are wont to do). For their Little’s Law calculation, they proceeded to plug in their velocity\nnumber for Throughput, their WIP number as total number of user stories\n(actual stories---not story points) completed in the sprint, and expected to\nget a Cycle Time number in days. You can imagine their surprise when the\nnumbers did not come out quite the way that they expected. Assumptions as Process Policies\nUnderstanding these foundational assumptions is of monumental\nimportance. Despite what many people will tell you, the true power of", "tokens": 208, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 40, "segment_id": "00040", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000047"}
{"type": "chunk", "text": "Little’s Law is not in performing the mathematical calculation by plugging\nnumbers into its formula. Even though I have spent so much time on it\nalready, I want you to forget about the arithmetic. In truth, most of us will\nnever need to compute Little’s Law. As I mentioned in the previous chapter,\nthe three flow metrics’ data is so easy to capture that you should never have\nto compute one of them---just go look at the data! Rather, the true power of Little’s Law lies in understanding the\nassumptions necessary for the law to work in the first place. If there are\nthree things that I want you to have taken away from this conversation\nabout Little’s Law they are:\n\n1. It is all about the assumptions. 2. It is all about the assumptions. 3. It is all about the assumptions. Every time you violate an assumption of Little’s Law your process\nbecomes less predictable. Every time. This increased unpredictability may\nmanifest itself as longer Cycle Times or more process variability or both. Or, worse still, these violations may not even immediately show up in your\ndata. The whole time you are violating Little’s Law your data may be\nshowing you a rosier picture of the world than is really occurring. The\ndanger here is that you may be basing some forecast on this overly\noptimistic view---only to find that things are much worse than they seemed. Of course, we live in the real world and there are going to be times\n\nwhen violating these assumptions is going to be unavoidable or even\nnecessary. But that is exactly why it is all the more important to understand\nthe implications when these violations occur. There are always going to be\nthings that happen to us that are outside of our control. However, the last\nthing we want to do is compound those uncontrollable events by allowing\nbad things to happen that were in our control and could have easily\nprevented. Control what you can control and then try to eliminate or\nmitigate the things you cannot. The above principles (especially the first four) are going to help us do\n\njust that. We can use these assumptions as the basis for some simple\npolicies that will govern the operation of our process. These policies will\nserve to control the things that we can control. These policies will serve to\nmake our process more predictable.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nLittle’s Law is not in performing the mathematical calculation by plugging\nnumbers into its formula. Even though I have spent so much time on it\nalready, I want you to forget about the arithmetic. In truth, most of us will\nnever need to compute Little’s Law. As I mentioned in the previous chapter,\nthe three flow metrics’ data is so easy to capture that you should never have\nto compute one of them---just go look at the data! Rather, the true power of Little’s Law lies in understanding the\nassumptions necessary for the law to work in the first place. If there are\nthree things that I want you to have taken away from this conversation\nabout Little’s Law they are:\n\n1. It is all about the assumptions. 2. It is all about the assumptions. 3. It is all about the assumptions. Every time you violate an assumption of Little’s Law your process\nbecomes less predictable. Every time. This increased unpredictability may\nmanifest itself as longer Cycle Times or more process variability or both. Or, worse still, these violations may not even immediately show up in your\ndata. The whole time you are violating Little’s Law your data may be\nshowing you a rosier picture of the world than is really occurring. The\ndanger here is that you may be basing some forecast on this overly\noptimistic view---only to find that things are much worse than they seemed. Of course, we live in the real world and there are going to be times\n\nwhen violating these assumptions is going to be unavoidable or even\nnecessary. But that is exactly why it is all the more important to understand\nthe implications when these violations occur. There are always going to be\nthings that happen to us that are outside of our control. However, the last\nthing we want to do is compound those uncontrollable events by allowing\nbad things to happen that were in our control and could have easily\nprevented. Control what you can control and then try to eliminate or\nmitigate the things you cannot. The above principles (especially the first four) are going to help us do\n\njust that. We can use these assumptions as the basis for some simple\npolicies that will govern the operation of our process. These policies will\nserve to control the things that we can control. These policies will serve to\nmake our process more predictable.", "tokens": 491, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 41, "segment_id": "00041", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000048"}
{"type": "chunk", "text": "Based on the assumptions above, some process policies might include\n\n(but certainly would not be limited to): - We will only start new work at\nabout the same rate that we finish old work. - We will make every\nreasonable effort to finish all work that is started and minimize wasted\neffort due to discarded work items (this will necessitate some notion of latebinding “commitment”). - If work becomes blocked we will do everything\nwe can do unblock that work as expeditiously as possible. - We will closely\nmonitor our policies around the order in which we pull items through our\nsystem so that some work items do not sit and age unnecessarily. The design of your process is really just the sum of all the policies you\n\nhave in place. How well your system performs or does not perform is\ndirectly attributable to those policies and to how well you adhere or do not\nadhere to them. When I talk about designing for predictability, what I am\ntalking about is giving you some clues---some insights---into appropriate\npolicies that you can build into the day to day operation of your process. These policies will serve to normalize and stabilize your system in order to\ngive your process the predictability that you are looking for. It is only from\nthis stable base that we can even hope to implement real, long-lasting\nprocess improvement. As my friend and colleague Frank Vega so often likes to say, “your\npolicies shape your data and your data shape your policies”. The policies\nthat I have mentioned here will in no small way influence the data that you\ncollect off of your process. That is a good thing, by the way. It is a good\nthing because that data in and of itself is potentially going to further suggest\nwhere our process policies are deficient. It is this virtuous cycle that I am\ntalking about when I say “actionable metrics for predictability”. Segmenting WIP\nI mentioned in Chapter 2 that it is possible to segment your WIP into\nseveral different types. For example it might be useful to think of your WIP\nnot as just generic work items, but categorize it into types like “user\nstories”, “production defects”, “maintenance request”, etc. This is a\nperfectly valid approach and actually may be desirable in most\ncircumstances.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nBased on the assumptions above, some process policies might include\n\n(but certainly would not be limited to): - We will only start new work at\nabout the same rate that we finish old work. - We will make every\nreasonable effort to finish all work that is started and minimize wasted\neffort due to discarded work items (this will necessitate some notion of latebinding “commitment”). - If work becomes blocked we will do everything\nwe can do unblock that work as expeditiously as possible. - We will closely\nmonitor our policies around the order in which we pull items through our\nsystem so that some work items do not sit and age unnecessarily. The design of your process is really just the sum of all the policies you\n\nhave in place. How well your system performs or does not perform is\ndirectly attributable to those policies and to how well you adhere or do not\nadhere to them. When I talk about designing for predictability, what I am\ntalking about is giving you some clues---some insights---into appropriate\npolicies that you can build into the day to day operation of your process. These policies will serve to normalize and stabilize your system in order to\ngive your process the predictability that you are looking for. It is only from\nthis stable base that we can even hope to implement real, long-lasting\nprocess improvement. As my friend and colleague Frank Vega so often likes to say, “your\npolicies shape your data and your data shape your policies”. The policies\nthat I have mentioned here will in no small way influence the data that you\ncollect off of your process. That is a good thing, by the way. It is a good\nthing because that data in and of itself is potentially going to further suggest\nwhere our process policies are deficient. It is this virtuous cycle that I am\ntalking about when I say “actionable metrics for predictability”. Segmenting WIP\nI mentioned in Chapter 2 that it is possible to segment your WIP into\nseveral different types. For example it might be useful to think of your WIP\nnot as just generic work items, but categorize it into types like “user\nstories”, “production defects”, “maintenance request”, etc. This is a\nperfectly valid approach and actually may be desirable in most\ncircumstances.", "tokens": 484, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 42, "segment_id": "00042", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000049"}
{"type": "chunk", "text": "It is this virtuous cycle that I am\ntalking about when I say “actionable metrics for predictability”. Segmenting WIP\nI mentioned in Chapter 2 that it is possible to segment your WIP into\nseveral different types. For example it might be useful to think of your WIP\nnot as just generic work items, but categorize it into types like “user\nstories”, “production defects”, “maintenance request”, etc. This is a\nperfectly valid approach and actually may be desirable in most\ncircumstances. The good news is that if you choose to segment your WIP in\nsuch a manner then Little’s Law will apply to both the overall WIP in the\nsystem as well as to each type or groups of types.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nIt is this virtuous cycle that I am\ntalking about when I say “actionable metrics for predictability”. Segmenting WIP\nI mentioned in Chapter 2 that it is possible to segment your WIP into\nseveral different types. For example it might be useful to think of your WIP\nnot as just generic work items, but categorize it into types like “user\nstories”, “production defects”, “maintenance request”, etc. This is a\nperfectly valid approach and actually may be desirable in most\ncircumstances. The good news is that if you choose to segment your WIP in\nsuch a manner then Little’s Law will apply to both the overall WIP in the\nsystem as well as to each type or groups of types.", "tokens": 158, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 42, "segment_id": "00042", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000050"}
{"type": "chunk", "text": "For example, we might want to use Little’s Law to analyze all work\nflowing through our system, or we may want to use it to just look at our\nwork items that are of type “user story”. We might want to investigate how\nbadly our production defects are violating the assumptions of the law. Or\nmaybe it is our maintenance requests grouped together with defects that are\nthe culprit. In most cases this type of segmentation is very useful and could\nprovide a more sophisticated approach to analyzing process performance. For those of you thinking ahead and for those of you familiar with\nKanban systems, you will notice that I have purposefully not used the term\n“Class of Service” here. Not to spoil the punchline, but, yes, you can use\nLittle’s Law if you choose to segment your WIP along different Classes of\nService. This tactic has a particular significance when it comes to process\npredictability (spoiler alert: it is usually bad) which is why I have devoted a\nwhole chapter (Chapter 13) to Class of Service later. Kanban Systems\nFrom a WIP perspective, it may seem that running a Kanban system\nguarantees Little’s Law’s assumptions are taken care of. There are several\nreasons why that may not be the case:\n\n1. It is possible that changing WIP limits may have no effect on total\n\naverage WIP (e.g., decreasing or increasing a WIP limit after a clear\nsystemic bottleneck). This may be one reason you do not get the\n“forecasted” behavior you might expect from Little’s Law. 2. Setting a WIP limit is not necessarily the same as limiting Work In\n\nProgress. I cannot tell you how many teams I come across that set WIP\nLimits but then routinely violate them. And violate them egregiously. 3. Average WIP over a time period is highly dependent on pull policies in\nplace. E.g., are as many items as possible pulled in order to satisfy\nWIP limits at all times? The point here is that if you are using a Kanban system, you cannot\njust simply add up all the WIP Limits on your board and think that you have\ncalculated WIP for your process (as discussed previously in Chapter 2). You\nare going to have actually track physical WIP. Fortunately, I am going to\nshow you a very easy way to do that in the next chapter!", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nFor example, we might want to use Little’s Law to analyze all work\nflowing through our system, or we may want to use it to just look at our\nwork items that are of type “user story”. We might want to investigate how\nbadly our production defects are violating the assumptions of the law. Or\nmaybe it is our maintenance requests grouped together with defects that are\nthe culprit. In most cases this type of segmentation is very useful and could\nprovide a more sophisticated approach to analyzing process performance. For those of you thinking ahead and for those of you familiar with\nKanban systems, you will notice that I have purposefully not used the term\n“Class of Service” here. Not to spoil the punchline, but, yes, you can use\nLittle’s Law if you choose to segment your WIP along different Classes of\nService. This tactic has a particular significance when it comes to process\npredictability (spoiler alert: it is usually bad) which is why I have devoted a\nwhole chapter (Chapter 13) to Class of Service later. Kanban Systems\nFrom a WIP perspective, it may seem that running a Kanban system\nguarantees Little’s Law’s assumptions are taken care of. There are several\nreasons why that may not be the case:\n\n1. It is possible that changing WIP limits may have no effect on total\n\naverage WIP (e.g., decreasing or increasing a WIP limit after a clear\nsystemic bottleneck). This may be one reason you do not get the\n“forecasted” behavior you might expect from Little’s Law. 2. Setting a WIP limit is not necessarily the same as limiting Work In\n\nProgress. I cannot tell you how many teams I come across that set WIP\nLimits but then routinely violate them. And violate them egregiously. 3. Average WIP over a time period is highly dependent on pull policies in\nplace. E.g., are as many items as possible pulled in order to satisfy\nWIP limits at all times? The point here is that if you are using a Kanban system, you cannot\njust simply add up all the WIP Limits on your board and think that you have\ncalculated WIP for your process (as discussed previously in Chapter 2). You\nare going to have actually track physical WIP. Fortunately, I am going to\nshow you a very easy way to do that in the next chapter!", "tokens": 508, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 43, "segment_id": "00043", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000051"}
{"type": "chunk", "text": "Lastly, most people think that Little’s Law is the single greatest reason\n\nto implement a Kanban-style Agile process. While I would not strictly\ndisagree with that statement, I would offer a better way of stating it. I would\nsay that Little’s Law is the single greatest reason to move to a more WIPlimited, pull-based, continuous flow process. The thing is, once we do that,\nwe can then start to use Little’s Law as our guide for process predictability. Size Does Not Matter\nI have one last topic I want to cover before wrapping up. Notice how in the\nassumptions for Little’s Law I made no mention a requirement for all work\nitems to be of the same size. That is because no such requirement exists. Most people assume that an application of Little’s Law specifically---and\nlimiting WIP in general---necessitates that all work items be of the same\nsize. That is simply not true. The precise reasons why would fill up a\nchapter in its own right, so I am going to limit my comments to two brief\npoints. First, work items size does not matter because for Little’s Law we are\n\ndealing with relationships among averages. We do not necessarily care\nabout each item individually, we care about what all items look like on\naverage. Second, and more importantly, the variability in work item size is\nprobably not the variability that is killing your predictability. Your bigger\npredictability problems are usually too much WIP, the frequency with\nwhich you violate Little’s Law’s assumptions, etc. Generally those are\neasier problems to fix than trying to arbitrarily make all work items the\nsame size. Even if you were in a context where size did matter, it would be\nmore about right-sizing your work and not same-sizing your work (but\nmore on that in Chapter 12). Forecasting\nAs this is a book about predictability, my guess is that you were expecting\nme to say that once you understand Little’s Law all you need to do is to\nplug in the numbers and out will pop the forecasting result that you are\nlooking for (à la Newton’s F = ma or Einstein’s E=mc2). However, nothing\ncould be further from the truth.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nLastly, most people think that Little’s Law is the single greatest reason\n\nto implement a Kanban-style Agile process. While I would not strictly\ndisagree with that statement, I would offer a better way of stating it. I would\nsay that Little’s Law is the single greatest reason to move to a more WIPlimited, pull-based, continuous flow process. The thing is, once we do that,\nwe can then start to use Little’s Law as our guide for process predictability. Size Does Not Matter\nI have one last topic I want to cover before wrapping up. Notice how in the\nassumptions for Little’s Law I made no mention a requirement for all work\nitems to be of the same size. That is because no such requirement exists. Most people assume that an application of Little’s Law specifically---and\nlimiting WIP in general---necessitates that all work items be of the same\nsize. That is simply not true. The precise reasons why would fill up a\nchapter in its own right, so I am going to limit my comments to two brief\npoints. First, work items size does not matter because for Little’s Law we are\n\ndealing with relationships among averages. We do not necessarily care\nabout each item individually, we care about what all items look like on\naverage. Second, and more importantly, the variability in work item size is\nprobably not the variability that is killing your predictability. Your bigger\npredictability problems are usually too much WIP, the frequency with\nwhich you violate Little’s Law’s assumptions, etc. Generally those are\neasier problems to fix than trying to arbitrarily make all work items the\nsame size. Even if you were in a context where size did matter, it would be\nmore about right-sizing your work and not same-sizing your work (but\nmore on that in Chapter 12). Forecasting\nAs this is a book about predictability, my guess is that you were expecting\nme to say that once you understand Little’s Law all you need to do is to\nplug in the numbers and out will pop the forecasting result that you are\nlooking for (à la Newton’s F = ma or Einstein’s E=mc2). However, nothing\ncould be further from the truth.", "tokens": 469, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 44, "segment_id": "00044", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000052"}
{"type": "chunk", "text": "The first thing that you need to know about Little’s Law is that it is\nconcerned with looking backward over a time period that has completed. It\nis not about looking forward; that is, is not meant to be used to make\ndeterministic predictions. As Dr. Little himself says about the law, “This is\nnot all bad. It just says that we are in the measurement business, not the\nforecasting business”. This point requires a little more discussion as it is usually where\npeople get hung up. The “law” part of Little’s Law specifies an exact\nrelationship between average WIP, average Cycle Time, and average\nThroughput, and this “law” part only applies only when you are looking\nback over historical data. The law is not about---and was never designed for\n---making deterministic forecasts about the future. For example, let’s\nassume a team that historically has had an average WIP of 20 work items,\nan average Cycle Time of 5 days, and an average Throughput of 4 items per\nday. You cannot say that you are going to increase average WIP to 40, keep\naverage Cycle Time constant at 5 days and magically Throughput will\nincrease to 8 items per day---even if you add staff to the keep the WIP to\nstaff ratio the same in the two instances. You cannot assume that Little’s\nLaw will make that prediction. It will not. All Little’s Law will say is that\nan increase in average WIP will result in a change to one or both of average\nCycle Time and average Throughput. It will further say that those changes\nwill manifest themselves in ways such that the relationship among all three\nmetrics will still obey that law. But what it does not say is that you can\ndeterministically predict what those changes will be. You have to wait until\nthe end of the time interval you are interested in and look back to apply the\nlaw. But that restriction is not fatal. The proper application of Little’s Law\n\nin our world is to understand the assumptions of the law and to develop\nprocess policies that match those assumptions. If the process we operate\nconforms---or mostly conforms---to all of the assumptions of the law then\nwe get to a world where we can start to trust the data that we are collecting\noff of our system. It is at this point that our process is probabilistically\npredictable.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nThe first thing that you need to know about Little’s Law is that it is\nconcerned with looking backward over a time period that has completed. It\nis not about looking forward; that is, is not meant to be used to make\ndeterministic predictions. As Dr. Little himself says about the law, “This is\nnot all bad. It just says that we are in the measurement business, not the\nforecasting business”. This point requires a little more discussion as it is usually where\npeople get hung up. The “law” part of Little’s Law specifies an exact\nrelationship between average WIP, average Cycle Time, and average\nThroughput, and this “law” part only applies only when you are looking\nback over historical data. The law is not about---and was never designed for\n---making deterministic forecasts about the future. For example, let’s\nassume a team that historically has had an average WIP of 20 work items,\nan average Cycle Time of 5 days, and an average Throughput of 4 items per\nday. You cannot say that you are going to increase average WIP to 40, keep\naverage Cycle Time constant at 5 days and magically Throughput will\nincrease to 8 items per day---even if you add staff to the keep the WIP to\nstaff ratio the same in the two instances. You cannot assume that Little’s\nLaw will make that prediction. It will not. All Little’s Law will say is that\nan increase in average WIP will result in a change to one or both of average\nCycle Time and average Throughput. It will further say that those changes\nwill manifest themselves in ways such that the relationship among all three\nmetrics will still obey that law. But what it does not say is that you can\ndeterministically predict what those changes will be. You have to wait until\nthe end of the time interval you are interested in and look back to apply the\nlaw. But that restriction is not fatal. The proper application of Little’s Law\n\nin our world is to understand the assumptions of the law and to develop\nprocess policies that match those assumptions. If the process we operate\nconforms---or mostly conforms---to all of the assumptions of the law then\nwe get to a world where we can start to trust the data that we are collecting\noff of our system. It is at this point that our process is probabilistically\npredictable.", "tokens": 508, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 45, "segment_id": "00045", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000053"}
{"type": "chunk", "text": "You have to wait until\nthe end of the time interval you are interested in and look back to apply the\nlaw. But that restriction is not fatal. The proper application of Little’s Law\n\nin our world is to understand the assumptions of the law and to develop\nprocess policies that match those assumptions. If the process we operate\nconforms---or mostly conforms---to all of the assumptions of the law then\nwe get to a world where we can start to trust the data that we are collecting\noff of our system. It is at this point that our process is probabilistically\npredictable. Once there we can start to use something like Monte Carlo\nsimulation on our historical data to make forecasts and, more importantly,\nwe can have some confidence in the results we get by using that method. There are other, more fundamental reasons why you do not want to use\n\nLittle’s Law to make forecasts. For one thing, I have hopefully by now", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nYou have to wait until\nthe end of the time interval you are interested in and look back to apply the\nlaw. But that restriction is not fatal. The proper application of Little’s Law\n\nin our world is to understand the assumptions of the law and to develop\nprocess policies that match those assumptions. If the process we operate\nconforms---or mostly conforms---to all of the assumptions of the law then\nwe get to a world where we can start to trust the data that we are collecting\noff of our system. It is at this point that our process is probabilistically\npredictable. Once there we can start to use something like Monte Carlo\nsimulation on our historical data to make forecasts and, more importantly,\nwe can have some confidence in the results we get by using that method. There are other, more fundamental reasons why you do not want to use\n\nLittle’s Law to make forecasts. For one thing, I have hopefully by now", "tokens": 194, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 45, "segment_id": "00045", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000054"}
{"type": "chunk", "text": "beaten home the point that Little’s Law is a relationship of averages. I\nmention this again because even if you could use Little’s Law as a\nforecasting tool (which you cannot), you would not want to as you would\nbe producing a forecast based on averages. There are all kinds of reasons\nwhy you should not forecast based on averages---too many to go into here. It turns out we can do better than averages, anyway, when collecting metrics\ndata and there are going to be much better tools at our disposal when we are\nready to do forecasting. Luckily for you, I will discuss some of those tools\nin Chapter 14 and Chapter 15 (I have just mentioned one of them in the\nprevious paragraph). Having said all that, though, there is no reason why you cannot use the\n\nlaw for quick, back-of-the-envelope type estimations about the future. Of\ncourse you can do that. I would not, however, make any commitments, staff\nhiring or firing decisions, or project cost calculations based on this type of\ncalculation alone. I would further say that it is negligent for someone to\neven suggest to do so. But this simple computation might be useful as a\nquick gut-check to decide if something like a project is worth any further\nexploration. Remember that being predictable is not completely about making\n\nforecasts. The bigger part of predictability is operating a system that\nbehaves in a way that we expect it to. By designing and operating a system\nthat follows the assumptions set forth by the Little’s Law, we will get just\nthat: a process that behaves the way we expect it to. That means we will\nhave controlled the things that we can control and that the interventions that\nwe take to make things better will result in outcomes more closely aligned\nwith our expectations. Conclusion\nI know I have said it before, but I need to say it again: Little’s Law is not\nabout understanding the mathematics of queuing theory. It is about\nunderstanding the assumptions that need to be in place in order for the law\nto work. We can use those assumptions as a guide, or blueprint, or model\nfor our own process policies. Whenever your process policies are in\nviolation of the assumptions of Little’s Law then you know that you have at\nleast diminished---or possibly eliminated---your chance of being\npredictable.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nbeaten home the point that Little’s Law is a relationship of averages. I\nmention this again because even if you could use Little’s Law as a\nforecasting tool (which you cannot), you would not want to as you would\nbe producing a forecast based on averages. There are all kinds of reasons\nwhy you should not forecast based on averages---too many to go into here. It turns out we can do better than averages, anyway, when collecting metrics\ndata and there are going to be much better tools at our disposal when we are\nready to do forecasting. Luckily for you, I will discuss some of those tools\nin Chapter 14 and Chapter 15 (I have just mentioned one of them in the\nprevious paragraph). Having said all that, though, there is no reason why you cannot use the\n\nlaw for quick, back-of-the-envelope type estimations about the future. Of\ncourse you can do that. I would not, however, make any commitments, staff\nhiring or firing decisions, or project cost calculations based on this type of\ncalculation alone. I would further say that it is negligent for someone to\neven suggest to do so. But this simple computation might be useful as a\nquick gut-check to decide if something like a project is worth any further\nexploration. Remember that being predictable is not completely about making\n\nforecasts. The bigger part of predictability is operating a system that\nbehaves in a way that we expect it to. By designing and operating a system\nthat follows the assumptions set forth by the Little’s Law, we will get just\nthat: a process that behaves the way we expect it to. That means we will\nhave controlled the things that we can control and that the interventions that\nwe take to make things better will result in outcomes more closely aligned\nwith our expectations. Conclusion\nI know I have said it before, but I need to say it again: Little’s Law is not\nabout understanding the mathematics of queuing theory. It is about\nunderstanding the assumptions that need to be in place in order for the law\nto work. We can use those assumptions as a guide, or blueprint, or model\nfor our own process policies. Whenever your process policies are in\nviolation of the assumptions of Little’s Law then you know that you have at\nleast diminished---or possibly eliminated---your chance of being\npredictable.", "tokens": 496, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 46, "segment_id": "00046", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000055"}
{"type": "chunk", "text": "As you operate your process think about the times and reasons why\nwork flows in at a faster rate than work flows out. Think about why items\nage unnecessarily due to blockages or poor pull policies. Think about why\nwork is abandoned when only partially complete (and how you account for\nthat abandonment). Think about how these occurrences are violating the\nassumptions Little’s Law and how they are ultimately affecting your ability\nto be predictable. But more importantly, think about how your\nunderstanding of Little’s Law should result in behavior changes for you and\nyour team. When violations of Little’s Law occur, it is usually because of\nsomething you did or chose (intentionally or not) not to do. Remember, you\nhave much more control over your process than you think you do. Now that we have an understanding of Little’s Law and the basic\n\nmetrics of flow, it is time to turn our attention to how these concepts are\nvisualized through the use of flow analytics. As we are about to see, it is the\nquantitative and qualitative interpretation of these unique analytics that will\nmake our process truly predictable, and will make the flow metrics truly\nactionable. Key Learnings and Takeaways\n\nLittle’s Law relates the basic metrics of flow in an elegant,\nfundamental equation. Little’s Law is a relationship of averages. Do not get distracted with the math of Little’s Law---the significance\nof the law does not necessarily come from plugging numbers into the\nequation. When stating it in terms of Equation #2, for contexts with continuous\nWIP, there are five assumptions necessary for Little’s Law to work,\nthey are:\n\nThe average input or Arrival Rate (λ) should equal the average\nThroughput (Departure Rate). All work that is started will eventually be completed and exit the\nsystem. The amount of WIP should be roughly the same at the beginning\nand at the end of the time interval chosen for the calculation. The average age of the WIP is neither increasing nor decreasing.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nAs you operate your process think about the times and reasons why\nwork flows in at a faster rate than work flows out. Think about why items\nage unnecessarily due to blockages or poor pull policies. Think about why\nwork is abandoned when only partially complete (and how you account for\nthat abandonment). Think about how these occurrences are violating the\nassumptions Little’s Law and how they are ultimately affecting your ability\nto be predictable. But more importantly, think about how your\nunderstanding of Little’s Law should result in behavior changes for you and\nyour team. When violations of Little’s Law occur, it is usually because of\nsomething you did or chose (intentionally or not) not to do. Remember, you\nhave much more control over your process than you think you do. Now that we have an understanding of Little’s Law and the basic\n\nmetrics of flow, it is time to turn our attention to how these concepts are\nvisualized through the use of flow analytics. As we are about to see, it is the\nquantitative and qualitative interpretation of these unique analytics that will\nmake our process truly predictable, and will make the flow metrics truly\nactionable. Key Learnings and Takeaways\n\nLittle’s Law relates the basic metrics of flow in an elegant,\nfundamental equation. Little’s Law is a relationship of averages. Do not get distracted with the math of Little’s Law---the significance\nof the law does not necessarily come from plugging numbers into the\nequation. When stating it in terms of Equation #2, for contexts with continuous\nWIP, there are five assumptions necessary for Little’s Law to work,\nthey are:\n\nThe average input or Arrival Rate (λ) should equal the average\nThroughput (Departure Rate). All work that is started will eventually be completed and exit the\nsystem. The amount of WIP should be roughly the same at the beginning\nand at the end of the time interval chosen for the calculation. The average age of the WIP is neither increasing nor decreasing.", "tokens": 418, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 47, "segment_id": "00047", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000056"}
{"type": "chunk", "text": "Cycle Time, WIP, and Throughput must all be measured using\nconsistent units. Use these assumptions as a guide for your process policies. The more\nyou violate these assumptions, the less chance you have of being\npredictable. Even if the assumptions do not hold for the entire time period under\nconsideration, Little’s Law can still be used as an estimation. However,\nthe “goodness” of the estimation depends on how badly the\nassumptions have been violated. Little’s Law is not for forecasting. To do forecasting we will need\nother tools. If someone tells you that you can forecast with Little’s\nLaw or shows you an example of how to do it, you have my\npermission to slap them (I put that in to see if you were still reading). If you segment your WIP into different types, then Little’s Law can be\napplied to each of the different type segments.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law\n\nCycle Time, WIP, and Throughput must all be measured using\nconsistent units. Use these assumptions as a guide for your process policies. The more\nyou violate these assumptions, the less chance you have of being\npredictable. Even if the assumptions do not hold for the entire time period under\nconsideration, Little’s Law can still be used as an estimation. However,\nthe “goodness” of the estimation depends on how badly the\nassumptions have been violated. Little’s Law is not for forecasting. To do forecasting we will need\nother tools. If someone tells you that you can forecast with Little’s\nLaw or shows you an example of how to do it, you have my\npermission to slap them (I put that in to see if you were still reading). If you segment your WIP into different types, then Little’s Law can be\napplied to each of the different type segments.", "tokens": 189, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 48, "segment_id": "00048", "chapter_num": "3", "chapter_title": "Introduction to Little’s Law", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 3: Introduction to Little’s Law", "chunk_id": "00000057"}
{"type": "chunk", "text": "Chapter 4 - Introduction to CFDs\n\nOver the next three chapters I will go into a fair amount of detail about what\na Cumulative Flow Diagram (CFD) is, what information it can provide, and\nhow to interpret the results. You might be tempted to skip this section if you\nbelieve you are already familiar with CFDs. I would ask that you do not. I\nsay this because much of what has been published about CFDs’ application\nto knowledge work is at best misleading and at worst completely wrong. This chapter aims to clear up some of the prevailing myths and\nmisconceptions about these truly incredible charts. In order to clear up these\nmyths, I need to introduce CFDs much differently than they are normally\npresented. My hope is to arm you with information you need to take full\nadvantage of one of the most effective analytic tools at your disposal. What makes a CFD a CFD? The very first thing to know about Cumulative Flow Diagrams is that they\nare all about arrivals and departures. In fact, when researching this book, the\nvery first reference that I could find to a CFD appeared in the 1960s and that\narticle actually labeled the chart as a “Cumulative Arrival and Departures\nDiagram”. I am not entirely sure when the name got changed to Cumulative\nFlow Diagram. However, as I have demonstrated in the previous chapters,\nthe concepts of arrivals and departures are central to the idea of flow, so the\nname change makes perfect sense. As its name suggests, therefore, a Cumulative Flow Diagram is an\nexcellent way to visualize the flow of work through a process. CFDs are\namong the least known, and therefore one of the least understood charts in\nall of Agile analytics; yet, they represent one of the most powerful process\nperformance gauges available to us. They are a powerful tool for a couple of\nreasons. First, these charts offer a concise, coherent visualization of the three\nmetrics of flow that I introduced in Chapter 2. Second, they offer massive\namounts of information at just a glance, or by just doing some very simple\ncalculations. Visualizing flow via a CFD gives us both quantitative and\nqualitative insight into problems---or potential problems---in our process.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nChapter 4 - Introduction to CFDs\n\nOver the next three chapters I will go into a fair amount of detail about what\na Cumulative Flow Diagram (CFD) is, what information it can provide, and\nhow to interpret the results. You might be tempted to skip this section if you\nbelieve you are already familiar with CFDs. I would ask that you do not. I\nsay this because much of what has been published about CFDs’ application\nto knowledge work is at best misleading and at worst completely wrong. This chapter aims to clear up some of the prevailing myths and\nmisconceptions about these truly incredible charts. In order to clear up these\nmyths, I need to introduce CFDs much differently than they are normally\npresented. My hope is to arm you with information you need to take full\nadvantage of one of the most effective analytic tools at your disposal. What makes a CFD a CFD? The very first thing to know about Cumulative Flow Diagrams is that they\nare all about arrivals and departures. In fact, when researching this book, the\nvery first reference that I could find to a CFD appeared in the 1960s and that\narticle actually labeled the chart as a “Cumulative Arrival and Departures\nDiagram”. I am not entirely sure when the name got changed to Cumulative\nFlow Diagram. However, as I have demonstrated in the previous chapters,\nthe concepts of arrivals and departures are central to the idea of flow, so the\nname change makes perfect sense. As its name suggests, therefore, a Cumulative Flow Diagram is an\nexcellent way to visualize the flow of work through a process. CFDs are\namong the least known, and therefore one of the least understood charts in\nall of Agile analytics; yet, they represent one of the most powerful process\nperformance gauges available to us. They are a powerful tool for a couple of\nreasons. First, these charts offer a concise, coherent visualization of the three\nmetrics of flow that I introduced in Chapter 2. Second, they offer massive\namounts of information at just a glance, or by just doing some very simple\ncalculations. Visualizing flow via a CFD gives us both quantitative and\nqualitative insight into problems---or potential problems---in our process.", "tokens": 485, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 50, "segment_id": "00050", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000058"}
{"type": "chunk", "text": "Gaining an understanding of actual process performance is one of the\nnecessary first steps for introducing overall system predictability. In order to gain this insight, however, we have to be very precise in\nterms how we define exactly what a CFD is, and---more importantly---how\nto construct one. In a point that I will hammer over and over in this and the\nnext two chapters, an improperly constructed CFD can lead to improper\nconclusions about process problems. Worse, improperly constructed CFDs\ncan lead to team or management apathy amid claims that the charts are just\nnot very useful. So, without any further ado, let’s get to it. If you have never seen a Cumulative Flow Diagram before, then here is\n\nyour chance:\n\nFigure 4.1: A Basic CFD\n\nIt may not look like much to you right now, but as I just mentioned this\n\nchart is actually communicating a lot of information. To get you oriented with what you are looking at, I first want to spend\nsome time going over the anatomy of a CFD. Once you have got that under\nyour belt, then we can move on to what this graph is actually telling us. The first thing to note about a CFD is that across the bottom (the Xaxis) is some representation of a progression of time. It could be said that the\nX-axis represents a timeline for our process. The tick marks on the X-axis\nrepresents our choice of labels for that timeline. When labeling the X-axis,", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nGaining an understanding of actual process performance is one of the\nnecessary first steps for introducing overall system predictability. In order to gain this insight, however, we have to be very precise in\nterms how we define exactly what a CFD is, and---more importantly---how\nto construct one. In a point that I will hammer over and over in this and the\nnext two chapters, an improperly constructed CFD can lead to improper\nconclusions about process problems. Worse, improperly constructed CFDs\ncan lead to team or management apathy amid claims that the charts are just\nnot very useful. So, without any further ado, let’s get to it. If you have never seen a Cumulative Flow Diagram before, then here is\n\nyour chance:\n\nFigure 4.1: A Basic CFD\n\nIt may not look like much to you right now, but as I just mentioned this\n\nchart is actually communicating a lot of information. To get you oriented with what you are looking at, I first want to spend\nsome time going over the anatomy of a CFD. Once you have got that under\nyour belt, then we can move on to what this graph is actually telling us. The first thing to note about a CFD is that across the bottom (the Xaxis) is some representation of a progression of time. It could be said that the\nX-axis represents a timeline for our process. The tick marks on the X-axis\nrepresents our choice of labels for that timeline. When labeling the X-axis,", "tokens": 315, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 51, "segment_id": "00051", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000059"}
{"type": "chunk", "text": "you can choose whatever frequency of labels you want. In this particular\nCFD, we have chosen to label every month. However you can choose\nwhatever label is best for your specific needs. You can choose to label every\ntwo weeks, every month, every day, etc. A very important point here is that these labels can be very different\nthan the reporting interval that you choose to build your CFD. The reporting\ninterval is the frequency that you choose to add data to your chart. Just as\nwith the labels, your reporting interval is up to you. You can choose to report\non your process data every day, every week, every month, etc. Just note that\nwhatever reporting interval that you choose will change the shape of your\ndiagram (choosing a different reporting interval may certainly be the tweak\nyou want to make in order to get a clearer picture of what’s going on in the\nCFD). Further note that the reporting interval and the labels need not be of\nthe same frequency. On the above graph, the reporting interval is every day,\nyet you can see that we have only labeled the timeline at every month. Lastly, I should point out that in Figure 4.1 I have chosen to show the\n\ntimeline progression from left to right. This is not a requirement, it is only a\npreference. I could have easily shown time progression from right to left. The vast majority of CFDs that you will come across (unless your name is\nFrank), however, will show the progression of time from left to right. Thus,\nfor the rest of this chapter (and this book), I will show all CFD time\nprogressions from left to right. Further, know that all properties of CFDs that\nI am about to describe assume a CFD with a time progression from left to\nright. If across the bottom is a progression of time, then up the side (the Yaxis) is a cumulative count of items in the process. To build our CFD, at each\nreporting interval we are going to calculate the total number of items at each\nstep in our process and plot them on our graph (how to properly “count”\nitems will be explained a little later in this chapter). Just as with labels and\nreporting intervals, you can choose whatever scale you want for the work\nitem axis.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nyou can choose whatever frequency of labels you want. In this particular\nCFD, we have chosen to label every month. However you can choose\nwhatever label is best for your specific needs. You can choose to label every\ntwo weeks, every month, every day, etc. A very important point here is that these labels can be very different\nthan the reporting interval that you choose to build your CFD. The reporting\ninterval is the frequency that you choose to add data to your chart. Just as\nwith the labels, your reporting interval is up to you. You can choose to report\non your process data every day, every week, every month, etc. Just note that\nwhatever reporting interval that you choose will change the shape of your\ndiagram (choosing a different reporting interval may certainly be the tweak\nyou want to make in order to get a clearer picture of what’s going on in the\nCFD). Further note that the reporting interval and the labels need not be of\nthe same frequency. On the above graph, the reporting interval is every day,\nyet you can see that we have only labeled the timeline at every month. Lastly, I should point out that in Figure 4.1 I have chosen to show the\n\ntimeline progression from left to right. This is not a requirement, it is only a\npreference. I could have easily shown time progression from right to left. The vast majority of CFDs that you will come across (unless your name is\nFrank), however, will show the progression of time from left to right. Thus,\nfor the rest of this chapter (and this book), I will show all CFD time\nprogressions from left to right. Further, know that all properties of CFDs that\nI am about to describe assume a CFD with a time progression from left to\nright. If across the bottom is a progression of time, then up the side (the Yaxis) is a cumulative count of items in the process. To build our CFD, at each\nreporting interval we are going to calculate the total number of items at each\nstep in our process and plot them on our graph (how to properly “count”\nitems will be explained a little later in this chapter). Just as with labels and\nreporting intervals, you can choose whatever scale you want for the work\nitem axis.", "tokens": 487, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 52, "segment_id": "00052", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000060"}
{"type": "chunk", "text": "If across the bottom is a progression of time, then up the side (the Yaxis) is a cumulative count of items in the process. To build our CFD, at each\nreporting interval we are going to calculate the total number of items at each\nstep in our process and plot them on our graph (how to properly “count”\nitems will be explained a little later in this chapter). Just as with labels and\nreporting intervals, you can choose whatever scale you want for the work\nitem axis. Choosing different scales will cause the picture to change, but,\nagain, that may just be the adjustment you need in order to “sharpen” your\nchart’s picture. As you plot items at each reporting interval, then over time “bands”\n\nwill emerge on your chart. Those bands will correspond to each of the\nworkflow steps in your process, as in in Figure 4.2.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nIf across the bottom is a progression of time, then up the side (the Yaxis) is a cumulative count of items in the process. To build our CFD, at each\nreporting interval we are going to calculate the total number of items at each\nstep in our process and plot them on our graph (how to properly “count”\nitems will be explained a little later in this chapter). Just as with labels and\nreporting intervals, you can choose whatever scale you want for the work\nitem axis. Choosing different scales will cause the picture to change, but,\nagain, that may just be the adjustment you need in order to “sharpen” your\nchart’s picture. As you plot items at each reporting interval, then over time “bands”\n\nwill emerge on your chart. Those bands will correspond to each of the\nworkflow steps in your process, as in in Figure 4.2.", "tokens": 187, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 52, "segment_id": "00052", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000061"}
{"type": "chunk", "text": "Figure 4.2: Anatomy of a CFD\nA quick note about what I mean by “bands” on a CFD versus what I\nmean by “lines” on a CFD. By “band” I mean each different colored section\non the graph. By “line” I mean the demarcation boundary of any band. Any\nband on a CFD is always going to be bounded by two lines: a top line and a\nbottom line. The bottom line of a given band will be the same as the top line\nof the succeeding band---should such a subsequent band exist. The chart in\nFigure 4.2, for example, has six bands corresponding to each of the process\nstates and it has seven lines that mark the boundaries. For clarification,\ntechnically, the bottom line of the “Done” band in Figure 4.2 is the line that\nruns along the bottom of the chart at the X-axis. For the purposes of CFD\ndefinition, though, this line can be ignored. Note: unless otherwise specified, when I say “top line of a CFD” I\nmean the top line of the top-most band. When I say “bottom line of a CFD” I\nmean the top line of the bottom-most band. This is illustrated in Figure 4.3:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nFigure 4.2: Anatomy of a CFD\nA quick note about what I mean by “bands” on a CFD versus what I\nmean by “lines” on a CFD. By “band” I mean each different colored section\non the graph. By “line” I mean the demarcation boundary of any band. Any\nband on a CFD is always going to be bounded by two lines: a top line and a\nbottom line. The bottom line of a given band will be the same as the top line\nof the succeeding band---should such a subsequent band exist. The chart in\nFigure 4.2, for example, has six bands corresponding to each of the process\nstates and it has seven lines that mark the boundaries. For clarification,\ntechnically, the bottom line of the “Done” band in Figure 4.2 is the line that\nruns along the bottom of the chart at the X-axis. For the purposes of CFD\ndefinition, though, this line can be ignored. Note: unless otherwise specified, when I say “top line of a CFD” I\nmean the top line of the top-most band. When I say “bottom line of a CFD” I\nmean the top line of the bottom-most band. This is illustrated in Figure 4.3:", "tokens": 276, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 53, "segment_id": "00053", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000062"}
{"type": "chunk", "text": "Figure 4.3: The Top and Bottom Line on a CFD\nI began this section by pointing out that the most important thing to\nremember about CFDs is that they are fundamentally about process arrivals\nand departures. Any chart that does not model or graph these arrivals and\ndepartures properly or any chart that includes extraneous information not\nconsidered an arrival or departure cannot be properly called a Cumulative\nFlow Diagram. This brings us to the first of several fundamental properties\nof CFDs:\n\nCFD Property #1: The top line of a Cumulative Flow Diagram always represents the\ncumulative arrivals to a process. The bottom line on a CFD always represents the\ncumulative departures from a process. When I say “always” I mean “always”. Any chart that contains\n\nadditional outside lines that do not represent process arrivals and departures\nis not a CFD. Also note the use of the word “cumulative” (this is a\nCumulative Flow Diagram, after all). Any chart that does not account for\ncumulative arrivals and departures properly is not a CFD (more on this\nlater). It is important to remember---as mentioned in Chapter 2---that the\ndefinition of the boundaries of your process is essentially up to you. However, once chosen, those boundaries will be represented by the lines on\nyour graph as defined above. You can have as many bands that represent as", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nFigure 4.3: The Top and Bottom Line on a CFD\nI began this section by pointing out that the most important thing to\nremember about CFDs is that they are fundamentally about process arrivals\nand departures. Any chart that does not model or graph these arrivals and\ndepartures properly or any chart that includes extraneous information not\nconsidered an arrival or departure cannot be properly called a Cumulative\nFlow Diagram. This brings us to the first of several fundamental properties\nof CFDs:\n\nCFD Property #1: The top line of a Cumulative Flow Diagram always represents the\ncumulative arrivals to a process. The bottom line on a CFD always represents the\ncumulative departures from a process. When I say “always” I mean “always”. Any chart that contains\n\nadditional outside lines that do not represent process arrivals and departures\nis not a CFD. Also note the use of the word “cumulative” (this is a\nCumulative Flow Diagram, after all). Any chart that does not account for\ncumulative arrivals and departures properly is not a CFD (more on this\nlater). It is important to remember---as mentioned in Chapter 2---that the\ndefinition of the boundaries of your process is essentially up to you. However, once chosen, those boundaries will be represented by the lines on\nyour graph as defined above. You can have as many bands that represent as", "tokens": 296, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 54, "segment_id": "00054", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000063"}
{"type": "chunk", "text": "many workflow steps as you want in between your two boundaries. As we\nwill see, it can be very advantageous and strongly recommended---but by no\nmeans necessary---to represent those additional states on your diagram. If\nyou do choose to include those additional states, then the top and bottom line\nof the band at each workflow step represents that state’s arrivals and\ndepartures, respectively. For example, let’s say I have a process that looks like:\n\nFigure 4.4: Example Process\nThose of you familiar with Kanban may recognize this as a Kanban\nboard, but the following discussion is equally applicable to a more Scrum or\nXP style of process that has columns as simple as “To Do”, “Doing”, and\n“Done” (how Kanban can be used to model a Scrum or XP process is well\nbeyond the scope of this book; however, the principles discussed here apply\nregardless of the particular methodology that has been chosen). In this example, arrivals to the process are denoted by the “Analysis\nActive” column, and departures from the process are denoted by the “Done”\ncolumn. A simple CFD that models only the overall cumulative arrivals and\ndepartures in this process might look like:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nmany workflow steps as you want in between your two boundaries. As we\nwill see, it can be very advantageous and strongly recommended---but by no\nmeans necessary---to represent those additional states on your diagram. If\nyou do choose to include those additional states, then the top and bottom line\nof the band at each workflow step represents that state’s arrivals and\ndepartures, respectively. For example, let’s say I have a process that looks like:\n\nFigure 4.4: Example Process\nThose of you familiar with Kanban may recognize this as a Kanban\nboard, but the following discussion is equally applicable to a more Scrum or\nXP style of process that has columns as simple as “To Do”, “Doing”, and\n“Done” (how Kanban can be used to model a Scrum or XP process is well\nbeyond the scope of this book; however, the principles discussed here apply\nregardless of the particular methodology that has been chosen). In this example, arrivals to the process are denoted by the “Analysis\nActive” column, and departures from the process are denoted by the “Done”\ncolumn. A simple CFD that models only the overall cumulative arrivals and\ndepartures in this process might look like:", "tokens": 259, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 55, "segment_id": "00055", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000064"}
{"type": "chunk", "text": "Figure 4.5: Total Process Arrivals and Departures Only on a CFD\n\nNotice that there are only two bands on this diagram. As always, the top\n\nline of the top band represents the cumulative arrivals to the “Analysis”\ncolumn and the top line of the bottom band represents the cumulative\ndepartures to the “Done” column. Figure 4.5 is a perfectly valid CFD for the\nprocess shown in Figure 4.4. One question that you may want to keep in the\nback of your mind as you go through this discussion is: what do you think\nthe advantages or disadvantages of visualizing your flow as only two lines\nand bands as shown in Figure 4.5? If we wanted a little more detail about our process, we could easily\ninclude in the above diagram the cumulative arrivals and departures for each\nof the intermediate workflow steps between “Analysis Active” and “Done”. If we were interested in doing so, then our CFD would morph into the\ndiagram depicted in Figure 4.6:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nFigure 4.5: Total Process Arrivals and Departures Only on a CFD\n\nNotice that there are only two bands on this diagram. As always, the top\n\nline of the top band represents the cumulative arrivals to the “Analysis”\ncolumn and the top line of the bottom band represents the cumulative\ndepartures to the “Done” column. Figure 4.5 is a perfectly valid CFD for the\nprocess shown in Figure 4.4. One question that you may want to keep in the\nback of your mind as you go through this discussion is: what do you think\nthe advantages or disadvantages of visualizing your flow as only two lines\nand bands as shown in Figure 4.5? If we wanted a little more detail about our process, we could easily\ninclude in the above diagram the cumulative arrivals and departures for each\nof the intermediate workflow steps between “Analysis Active” and “Done”. If we were interested in doing so, then our CFD would morph into the\ndiagram depicted in Figure 4.6:", "tokens": 218, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 56, "segment_id": "00056", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000065"}
{"type": "chunk", "text": "Figure 4.6: A Basic CFD\nThe several lines in Figure 4.6 now correspond to the cumulative\n\narrivals and departures at each step in the workflow. One quick thing before I proceed: you will notice that in this picture I\n\nhave shown the queuing states or “Done” columns for Analysis and\nDevelopment rather than just showing the Analysis and Development steps\neach as their own layer on the CFD. I have become a big fan of this\napproach as I believe this has the potential to give us greater insight into\nflow problems. For example, in the above chart we will potentially want to\npay particular attention to the bands that represent the “Analysis Done” and\n“Development Done” columns. A widening of these layers could hint at\nsomething going wrong in our process---but I am getting a little ahead of\nmyself here. The final thing to know about CFDs is they are intrinsically linked with\n\nLittle’s Law. In fact, Dr. Little has used CFDs in several of his publications\nwhen explaining his eponymous law. I spent so much time in the last chapter\ndiscussing Little’s Law’s assumptions because many times a violation of one\nof those assumptions will clearly show up on a CFD. That is the good news. The bad news is that many times an assumption violation will not clearly\nreveal itself on a CFD. This is why it is so important to know the\nassumptions behind the law and be able to map them to the context in which\nthe data was collected. If you understand the assumptions then you will be", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nFigure 4.6: A Basic CFD\nThe several lines in Figure 4.6 now correspond to the cumulative\n\narrivals and departures at each step in the workflow. One quick thing before I proceed: you will notice that in this picture I\n\nhave shown the queuing states or “Done” columns for Analysis and\nDevelopment rather than just showing the Analysis and Development steps\neach as their own layer on the CFD. I have become a big fan of this\napproach as I believe this has the potential to give us greater insight into\nflow problems. For example, in the above chart we will potentially want to\npay particular attention to the bands that represent the “Analysis Done” and\n“Development Done” columns. A widening of these layers could hint at\nsomething going wrong in our process---but I am getting a little ahead of\nmyself here. The final thing to know about CFDs is they are intrinsically linked with\n\nLittle’s Law. In fact, Dr. Little has used CFDs in several of his publications\nwhen explaining his eponymous law. I spent so much time in the last chapter\ndiscussing Little’s Law’s assumptions because many times a violation of one\nof those assumptions will clearly show up on a CFD. That is the good news. The bad news is that many times an assumption violation will not clearly\nreveal itself on a CFD. This is why it is so important to know the\nassumptions behind the law and be able to map them to the context in which\nthe data was collected. If you understand the assumptions then you will be", "tokens": 336, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 57, "segment_id": "00057", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000066"}
{"type": "chunk", "text": "able to make the necessary process adjustments for improved predictability. The last bit of good news is that I am going to spend the next several\nchapters explaining exactly how to make those adjustments. Constructing a CFD\nThe next step in learning how a CFD can help us is to understand how to\nconstruct one. To start, most people will tell you that to create a CFD, all you\nneed to do is physically count all work items in progress at each step of your\nprocess and then just plot those counts on your chart at regular reporting\nintervals. I call this approach “building a chart based on counts”. Not to put\ntoo fine a point on it, but building a chart just by counting items in progress\nis, in a word, dubious. To explain why, I would like to explore an example that might illustrate\nthe point better. For this example, I am going to use the same metaphor that\nDr. Little himself has used in several of his publications. Suppose that the system we wish to model is that of a supermarket. This\n\nparticular shop may have set hours that it opens and closes each day, or it\nmay be---as is the case with more and more American shops---open twentyfour hours a day and seven days a week. At various times throughout its\nhours of operation, it will have customers who enter and leave the shop. Some customers will make purchases while others will leave empty-handed. Having this image in mind, let’s explore two very important facts about\n\nour shop example:\n\n1. Given its physical structure, it is very obvious to determine when\n\ncustomers have entered the shop and when customers have left the\nshop. Another way of saying this is that our shop has a very clear point\nat which customers are said to have arrived to the shop, and there is a\nvery clear point at which customers are said to have departed the shop. 2. Every customer who enters the shop ultimately departs the shop. There\nare no customers who magically disappear. Even in the case of the\ncontinuously open shop, customers must inevitably and eventually\nleave. This fact is true regardless of how long customers spend in the\nshop or regardless of whether they made a purchase or not. Going forward, let’s assume we are dealing with a shop that is\ncontinuously open and that we are tracking hourly arrivals and departures", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nable to make the necessary process adjustments for improved predictability. The last bit of good news is that I am going to spend the next several\nchapters explaining exactly how to make those adjustments. Constructing a CFD\nThe next step in learning how a CFD can help us is to understand how to\nconstruct one. To start, most people will tell you that to create a CFD, all you\nneed to do is physically count all work items in progress at each step of your\nprocess and then just plot those counts on your chart at regular reporting\nintervals. I call this approach “building a chart based on counts”. Not to put\ntoo fine a point on it, but building a chart just by counting items in progress\nis, in a word, dubious. To explain why, I would like to explore an example that might illustrate\nthe point better. For this example, I am going to use the same metaphor that\nDr. Little himself has used in several of his publications. Suppose that the system we wish to model is that of a supermarket. This\n\nparticular shop may have set hours that it opens and closes each day, or it\nmay be---as is the case with more and more American shops---open twentyfour hours a day and seven days a week. At various times throughout its\nhours of operation, it will have customers who enter and leave the shop. Some customers will make purchases while others will leave empty-handed. Having this image in mind, let’s explore two very important facts about\n\nour shop example:\n\n1. Given its physical structure, it is very obvious to determine when\n\ncustomers have entered the shop and when customers have left the\nshop. Another way of saying this is that our shop has a very clear point\nat which customers are said to have arrived to the shop, and there is a\nvery clear point at which customers are said to have departed the shop. 2. Every customer who enters the shop ultimately departs the shop. There\nare no customers who magically disappear. Even in the case of the\ncontinuously open shop, customers must inevitably and eventually\nleave. This fact is true regardless of how long customers spend in the\nshop or regardless of whether they made a purchase or not. Going forward, let’s assume we are dealing with a shop that is\ncontinuously open and that we are tracking hourly arrivals and departures", "tokens": 489, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 58, "segment_id": "00058", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000067"}
{"type": "chunk", "text": "(the “open-close” scenario will be discussed later). In this example, how might we visualize the flow of customers on a\nCFD? Well, as I have just stated, a CFD is all about arrivals and departures,\nso the first thing we need to ask ourselves: how do we determine if someone\nhas arrived or departed our shop? One of the reasons I chose this particular\nexample is because answering that question in this scenario is actually very\neasy. An arriving customer is anyone who enters the shop from the outside,\nand a departing customer is anyone who leaves the shop from the inside. To\ncalculate these arrivals and departures, we could easily install turnstiles at all\ndoors and count the number of people who enter and exit over time. These\nturnstiles would not track how long each individual spent in the shop, nor\nwould they be able to tell us if a departing individual made a purchase or\nnot. They would, however, increment an arrival count for each customer who\nentered the shop (went from the outside in) and increment a departure’s\ncount for each customer who exited (went from the inside out). Every hour\nwe could go and read those counts off the turnstiles and plot them our graph. If we were tracking those counts in a spreadsheet, the data might look like\nFigure 4.7:\n\nFigure 4.7: Cumulative Count of Arrivals and Departures for the Shop Example\n\nIf using a spreadsheet, this data could easily be converted into an Area\nChart. That Area Chart, in this case, would be a CFD. Using the data from\nabove, our Cumulative Flow Diagram for this example might look like\nFigure 4.8:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\n(the “open-close” scenario will be discussed later). In this example, how might we visualize the flow of customers on a\nCFD? Well, as I have just stated, a CFD is all about arrivals and departures,\nso the first thing we need to ask ourselves: how do we determine if someone\nhas arrived or departed our shop? One of the reasons I chose this particular\nexample is because answering that question in this scenario is actually very\neasy. An arriving customer is anyone who enters the shop from the outside,\nand a departing customer is anyone who leaves the shop from the inside. To\ncalculate these arrivals and departures, we could easily install turnstiles at all\ndoors and count the number of people who enter and exit over time. These\nturnstiles would not track how long each individual spent in the shop, nor\nwould they be able to tell us if a departing individual made a purchase or\nnot. They would, however, increment an arrival count for each customer who\nentered the shop (went from the outside in) and increment a departure’s\ncount for each customer who exited (went from the inside out). Every hour\nwe could go and read those counts off the turnstiles and plot them our graph. If we were tracking those counts in a spreadsheet, the data might look like\nFigure 4.7:\n\nFigure 4.7: Cumulative Count of Arrivals and Departures for the Shop Example\n\nIf using a spreadsheet, this data could easily be converted into an Area\nChart. That Area Chart, in this case, would be a CFD. Using the data from\nabove, our Cumulative Flow Diagram for this example might look like\nFigure 4.8:", "tokens": 355, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 59, "segment_id": "00059", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000068"}
{"type": "chunk", "text": "Figure 4.8: Excel CFD for Shop Example\nLet’s say now that we want to add a process step that is “checkout”. Let’s further say our shop has a single queue that feeds all cashiers. We\ncould then install one turnstile that all customers go through to get to the\ncheckout queue and count arrivals as before. Additionally, let’s say that after\ncompleting their purchase, all customers must exit the shop through the\noverall shop departures turnstile. Our data might now look like Figure 4.9:\n\nFigure 4.9: Adding a Checkout Step to the Shop Example\n\nAnd our CFD would now look like Figure 4.10:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nFigure 4.8: Excel CFD for Shop Example\nLet’s say now that we want to add a process step that is “checkout”. Let’s further say our shop has a single queue that feeds all cashiers. We\ncould then install one turnstile that all customers go through to get to the\ncheckout queue and count arrivals as before. Additionally, let’s say that after\ncompleting their purchase, all customers must exit the shop through the\noverall shop departures turnstile. Our data might now look like Figure 4.9:\n\nFigure 4.9: Adding a Checkout Step to the Shop Example\n\nAnd our CFD would now look like Figure 4.10:", "tokens": 143, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 60, "segment_id": "00060", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000069"}
{"type": "chunk", "text": "Figure 4.10: Adding Checkout Line to Shop CFD in Excel\nThis example is straightforward enough so far, but it gets very tricky\nwhen we start consider some special cases. For instance, how do we account\nfor those customers who enter the shop but then immediately turn around\nand leave for any number of reasons: maybe they forgot their shopping list,\nmaybe they got a call and need to go outside for better reception or privacy,\netc.? Do we really want to count those customers as having “arrived” and\n“departed” the shop? Maybe. Maybe not. Similarly, what about those\ncustomers who enter the checkout queue but leave immediately because they\nrealize that they failed to pick up an item, because they picked up the wrong\nitems, or because they decide that they do not want to make any purchase\nafter all? Do we really want to count those customers as having “arrived”\nand “departed” the checkout queue? The skeptics out there might be thinking that the answer to this problem\nis easy. In these special cases, simply decrement the arrival count. However,\nif this decrementing of arrival count happens across the reporting interval,\nthe net effect is that the lines on our CFD will go down. That is to say, if our\nreporting interval is every hour on the hour, and four customers arrive at\n9:59am (and we increment our arrival count), but they then leave at 10:01am\nfor one of the special cases above (and we decide to decrement our arrival\ncount) then the data in our spreadsheet will look like Figure 4.11:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nFigure 4.10: Adding Checkout Line to Shop CFD in Excel\nThis example is straightforward enough so far, but it gets very tricky\nwhen we start consider some special cases. For instance, how do we account\nfor those customers who enter the shop but then immediately turn around\nand leave for any number of reasons: maybe they forgot their shopping list,\nmaybe they got a call and need to go outside for better reception or privacy,\netc.? Do we really want to count those customers as having “arrived” and\n“departed” the shop? Maybe. Maybe not. Similarly, what about those\ncustomers who enter the checkout queue but leave immediately because they\nrealize that they failed to pick up an item, because they picked up the wrong\nitems, or because they decide that they do not want to make any purchase\nafter all? Do we really want to count those customers as having “arrived”\nand “departed” the checkout queue? The skeptics out there might be thinking that the answer to this problem\nis easy. In these special cases, simply decrement the arrival count. However,\nif this decrementing of arrival count happens across the reporting interval,\nthe net effect is that the lines on our CFD will go down. That is to say, if our\nreporting interval is every hour on the hour, and four customers arrive at\n9:59am (and we increment our arrival count), but they then leave at 10:01am\nfor one of the special cases above (and we decide to decrement our arrival\ncount) then the data in our spreadsheet will look like Figure 4.11:", "tokens": 337, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 61, "segment_id": "00061", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000070"}
{"type": "chunk", "text": "Figure 4.11: Data for Non-Standard Departures\n\nAnd our CFD will look like Figure 4.12:\n\nFigure 4.12: Excel CFD for Non-Standard Departures\n\nThe difference between Figure 4.9 and Figure 4.11 is subtle but\nimportant. Note that the “Entered Shop” line in Figure 4.11 actually goes\ndown. You might be thinking “No problem. We have modeled exactly what\nhappened.” But did we? I would argue that we did not. That customer\nphysically arrived to our shop and then left. If we first increment then\nsubsequently decrement our arrival count then we have a possibility of a\nnegative arrival rate (which, by the way, violates the whole principle of a\nCumulative Flow Diagram). But in the real world it is not possible to have a\nnegative arrival rate. Arrivals are binary: either something has arrived or it", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nFigure 4.11: Data for Non-Standard Departures\n\nAnd our CFD will look like Figure 4.12:\n\nFigure 4.12: Excel CFD for Non-Standard Departures\n\nThe difference between Figure 4.9 and Figure 4.11 is subtle but\nimportant. Note that the “Entered Shop” line in Figure 4.11 actually goes\ndown. You might be thinking “No problem. We have modeled exactly what\nhappened.” But did we? I would argue that we did not. That customer\nphysically arrived to our shop and then left. If we first increment then\nsubsequently decrement our arrival count then we have a possibility of a\nnegative arrival rate (which, by the way, violates the whole principle of a\nCumulative Flow Diagram). But in the real world it is not possible to have a\nnegative arrival rate. Arrivals are binary: either something has arrived or it", "tokens": 195, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 62, "segment_id": "00062", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000071"}
{"type": "chunk", "text": "has not. To handle the case of a non-standard departure, we essentially have\ntwo choices: (1) count a customer as having arrived and then departed; or (2)\nnot count a customer as having arrived at all---i.e., it was a mistake to ever\nhave incremented our arrival count in the first place. This is where building a CFD based on counts breaks down and why it\n\nis very difficult---and not at all recommended---to build a CFD just by\ncounting items. So if we cannot use counts, what do we use to create a CFD? The best\napproach would be to give each individual customer a timestamp for when\nthey entered the shop, for when they entered the checkout queue, and for\nwhen they departed the shop. An example of this data might be what is\nshown in Figure 4.13:\n\nFigure 4.13: Timestamps for Customers\n\nIf a customer now exits the shop for any reason other than a “normal”\n\none then we could reflect that in our data in one of two ways. First, we could\nchoose to enter a departure timestamp and then “tag” that departure with a\nspecial reason. This would give us an opportunity to filter out that “bad” data\nif we choose to do so when building our CFD (this tag and filter strategy\ncould be employed for other work item types as well, but more on that later). This particular approach is potentially best for customers who leave a queue\nand we do not expect them to return. A spreadsheet that shows this approach\nmight look like Figure 4.14:\n\nFigure 4.14: “Tagging” a customer with an Exception Reason\nSecond, we could choose to simply delete the arrival timestamp as if\nthe customer never entered the particular downstream queue. This strategy\nwould be an acknowledgement that it was a mistake to ever have counted the", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nhas not. To handle the case of a non-standard departure, we essentially have\ntwo choices: (1) count a customer as having arrived and then departed; or (2)\nnot count a customer as having arrived at all---i.e., it was a mistake to ever\nhave incremented our arrival count in the first place. This is where building a CFD based on counts breaks down and why it\n\nis very difficult---and not at all recommended---to build a CFD just by\ncounting items. So if we cannot use counts, what do we use to create a CFD? The best\napproach would be to give each individual customer a timestamp for when\nthey entered the shop, for when they entered the checkout queue, and for\nwhen they departed the shop. An example of this data might be what is\nshown in Figure 4.13:\n\nFigure 4.13: Timestamps for Customers\n\nIf a customer now exits the shop for any reason other than a “normal”\n\none then we could reflect that in our data in one of two ways. First, we could\nchoose to enter a departure timestamp and then “tag” that departure with a\nspecial reason. This would give us an opportunity to filter out that “bad” data\nif we choose to do so when building our CFD (this tag and filter strategy\ncould be employed for other work item types as well, but more on that later). This particular approach is potentially best for customers who leave a queue\nand we do not expect them to return. A spreadsheet that shows this approach\nmight look like Figure 4.14:\n\nFigure 4.14: “Tagging” a customer with an Exception Reason\nSecond, we could choose to simply delete the arrival timestamp as if\nthe customer never entered the particular downstream queue. This strategy\nwould be an acknowledgement that it was a mistake to ever have counted the", "tokens": 390, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 63, "segment_id": "00063", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000072"}
{"type": "chunk", "text": "arrival in the first place. This case might be a better solution for items that\nwe expect to return to the queue at a later date (e.g., the situation where a\ncustomer leaves the checkout queue to go pick up additional items but who\nwill ultimately return to checkout). When building a proper CFD, either of these approaches is valid. This\n\nbrings us to the second fundamental principle of CFDs:\n\nCFD Property #2: Due to its cumulative nature, no line on a CFD can ever decrease (go\ndown). You can immediately spot that a CFD has not been constructed properly\n\nif you see lines on the chart that go down. A properly constructed CFD\nalways has lines that are either increasing (going up) or are flat. Not to\nbelabor the point, but this non-decreasing effect is precisely why these charts\nare called Cumulative Flow Diagrams. I hope you see how this example very closely parallels the types of\n\ndecisions that we make every day in our knowledge work process. A\ncustomer who enters a shop but then abruptly leaves is akin to an item that\narrives to the Analysis Active column of the board shown in Figure 4.4 but\nthen gets taken off the board for whatever reason (de-prioritized, de-scoped,\netc.). In this case it might be best to simply remove the timestamp that had\nbeen given to the item when it was placed in the Analysis Active column and\nproceed as if it had never arrived. A customer who enters the checkout queue but then leaves for whatever\n\nreason is akin to an item that has made it to the Test column in Figure 4.3,\nbut then it is determined the item should not be in Test. If the reason it\nshould not be in test is because it is so broken that it cannot even be tested,\nthen the item should be moved back to an appropriate prior step\n(Development, Analysis, etc.) and the timestamp for the Test column should\nbe erased. If the item should not be in Test because it is determined that the\nitem is no longer needed, then it should be moved directly to Done, given a\ndeparture timestamp and potentially flagged as---for example---“no longer\nneeded”.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\narrival in the first place. This case might be a better solution for items that\nwe expect to return to the queue at a later date (e.g., the situation where a\ncustomer leaves the checkout queue to go pick up additional items but who\nwill ultimately return to checkout). When building a proper CFD, either of these approaches is valid. This\n\nbrings us to the second fundamental principle of CFDs:\n\nCFD Property #2: Due to its cumulative nature, no line on a CFD can ever decrease (go\ndown). You can immediately spot that a CFD has not been constructed properly\n\nif you see lines on the chart that go down. A properly constructed CFD\nalways has lines that are either increasing (going up) or are flat. Not to\nbelabor the point, but this non-decreasing effect is precisely why these charts\nare called Cumulative Flow Diagrams. I hope you see how this example very closely parallels the types of\n\ndecisions that we make every day in our knowledge work process. A\ncustomer who enters a shop but then abruptly leaves is akin to an item that\narrives to the Analysis Active column of the board shown in Figure 4.4 but\nthen gets taken off the board for whatever reason (de-prioritized, de-scoped,\netc.). In this case it might be best to simply remove the timestamp that had\nbeen given to the item when it was placed in the Analysis Active column and\nproceed as if it had never arrived. A customer who enters the checkout queue but then leaves for whatever\n\nreason is akin to an item that has made it to the Test column in Figure 4.3,\nbut then it is determined the item should not be in Test. If the reason it\nshould not be in test is because it is so broken that it cannot even be tested,\nthen the item should be moved back to an appropriate prior step\n(Development, Analysis, etc.) and the timestamp for the Test column should\nbe erased. If the item should not be in Test because it is determined that the\nitem is no longer needed, then it should be moved directly to Done, given a\ndeparture timestamp and potentially flagged as---for example---“no longer\nneeded”.", "tokens": 462, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 64, "segment_id": "00064", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000073"}
{"type": "chunk", "text": "If the reason it\nshould not be in test is because it is so broken that it cannot even be tested,\nthen the item should be moved back to an appropriate prior step\n(Development, Analysis, etc.) and the timestamp for the Test column should\nbe erased. If the item should not be in Test because it is determined that the\nitem is no longer needed, then it should be moved directly to Done, given a\ndeparture timestamp and potentially flagged as---for example---“no longer\nneeded”. (By the way, the normal discovery of defects in the test column, to\nme, does not normally constitute an egregious enough offense to cause the\nitem to be moved back to the development column.)\n\nThus, in knowledge work, in order to properly construct a CFD, what\nwe really need to do is track the date that a particular item enters each step of", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nIf the reason it\nshould not be in test is because it is so broken that it cannot even be tested,\nthen the item should be moved back to an appropriate prior step\n(Development, Analysis, etc.) and the timestamp for the Test column should\nbe erased. If the item should not be in Test because it is determined that the\nitem is no longer needed, then it should be moved directly to Done, given a\ndeparture timestamp and potentially flagged as---for example---“no longer\nneeded”. (By the way, the normal discovery of defects in the test column, to\nme, does not normally constitute an egregious enough offense to cause the\nitem to be moved back to the development column.)\n\nThus, in knowledge work, in order to properly construct a CFD, what\nwe really need to do is track the date that a particular item enters each step of", "tokens": 179, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 64, "segment_id": "00064", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000074"}
{"type": "chunk", "text": "our work flow. An example of what that data might look like is shown in\nFigure 4.15:\n\nFigure 4.15: Example Data for building a CFD\nAs mentioned previously, it is rather straight forward to turn this data\n\ninto a format we can use to build a CFD. The added bonus of using this\nformat is that by collecting dates this way, we now have all the data we will\nneed to calculate all the metrics and analytics to be discussed in the rest of\nthis book. I cannot stress this particular point enough: by collecting data in\nthis way, not only are we assured of being able to build a correct CFD, but\nwe also get all the data we need to build an array of other very useful charts\n---i.e., the analytics we need to help us along the path toward predictability. I have mentioned several times now that you should not create a CFD\n\nfrom counting work items in progress at each step in your workflow at every\nreporting interval. Why do I make that statement when probably every other\nreference you have read about CFDs says that you should create your charts\nfrom item counts? The only time you can use counts to create a CFD is if your data\n\nsatisfies both of the following conditions:\n\n1. You never have items that move backward in your workflow\n2. You never have items that are just completely removed from your\n\nprocess before they are completed (presumably never to be heard from\nagain)\n\nI do not know about you, but I happen to live in the real world and in\n\nevery process I have ever been a part of, I have had at least one---if not both\n---of these things happen and usually on multiple occasions. Let’s take point #2 first. I hope it is easy to imagine that if all you are\n\ndoing is tracking counts, and items are simply removed from the process (by", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nour work flow. An example of what that data might look like is shown in\nFigure 4.15:\n\nFigure 4.15: Example Data for building a CFD\nAs mentioned previously, it is rather straight forward to turn this data\n\ninto a format we can use to build a CFD. The added bonus of using this\nformat is that by collecting dates this way, we now have all the data we will\nneed to calculate all the metrics and analytics to be discussed in the rest of\nthis book. I cannot stress this particular point enough: by collecting data in\nthis way, not only are we assured of being able to build a correct CFD, but\nwe also get all the data we need to build an array of other very useful charts\n---i.e., the analytics we need to help us along the path toward predictability. I have mentioned several times now that you should not create a CFD\n\nfrom counting work items in progress at each step in your workflow at every\nreporting interval. Why do I make that statement when probably every other\nreference you have read about CFDs says that you should create your charts\nfrom item counts? The only time you can use counts to create a CFD is if your data\n\nsatisfies both of the following conditions:\n\n1. You never have items that move backward in your workflow\n2. You never have items that are just completely removed from your\n\nprocess before they are completed (presumably never to be heard from\nagain)\n\nI do not know about you, but I happen to live in the real world and in\n\nevery process I have ever been a part of, I have had at least one---if not both\n---of these things happen and usually on multiple occasions. Let’s take point #2 first. I hope it is easy to imagine that if all you are\n\ndoing is tracking counts, and items are simply removed from the process (by", "tokens": 397, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 65, "segment_id": "00065", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000075"}
{"type": "chunk", "text": "any other means than going to your Done state) then it is quite possible to\nhave lines that go down (decrease) on your CFD. This situation quite\nobviously violates CFD Property #2. You could easily remedy this problem\nby making sure that every item that exits the process gets counted as part of\nthe items in your “Done” state. This solution is perfectly legitimate and,\nfurther, I would recommend you do this regardless of how you collect your\ndata (it might be further beneficial to tag these items that do not complete\n“correctly” with some metadata). Which brings us to point #1. If you will remember, this is exactly the\nsituation that I outlined in the shop metaphor section, so I will refer you to\nthat section for the more detailed discussion of backward flow. Very quickly,\nthough, remember that items that move backward---if not accounted for\nproperly---can cause the lines on our CFD to go down, which, again, violates\nProperty #2 of CFDs. Lastly, and I really cannot stress this point enough, to do any more\nserious analysis of your flow, you are going to need to capture date data as\nopposed to counts anyway (to measure things like Cycle Time and to build\nsome of the other analytics that we will discuss in later chapters). So since\nyou can create a CFD from dates, why not just use those? Another thing that you have probably noticed by now that none of the\n\nCFD examples I have shown have a line labelled “backlog”. There are some\nvery good reasons for that. For example, why cannot I have a picture that\nlooks like Figure 4.16:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nany other means than going to your Done state) then it is quite possible to\nhave lines that go down (decrease) on your CFD. This situation quite\nobviously violates CFD Property #2. You could easily remedy this problem\nby making sure that every item that exits the process gets counted as part of\nthe items in your “Done” state. This solution is perfectly legitimate and,\nfurther, I would recommend you do this regardless of how you collect your\ndata (it might be further beneficial to tag these items that do not complete\n“correctly” with some metadata). Which brings us to point #1. If you will remember, this is exactly the\nsituation that I outlined in the shop metaphor section, so I will refer you to\nthat section for the more detailed discussion of backward flow. Very quickly,\nthough, remember that items that move backward---if not accounted for\nproperly---can cause the lines on our CFD to go down, which, again, violates\nProperty #2 of CFDs. Lastly, and I really cannot stress this point enough, to do any more\nserious analysis of your flow, you are going to need to capture date data as\nopposed to counts anyway (to measure things like Cycle Time and to build\nsome of the other analytics that we will discuss in later chapters). So since\nyou can create a CFD from dates, why not just use those? Another thing that you have probably noticed by now that none of the\n\nCFD examples I have shown have a line labelled “backlog”. There are some\nvery good reasons for that. For example, why cannot I have a picture that\nlooks like Figure 4.16:", "tokens": 353, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 66, "segment_id": "00066", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000076"}
{"type": "chunk", "text": "Figure 4.16: Showing a Backlog on a Chart\nFor the most part, any diagram that shows a backlog is not a CFD. To\n\nexplain why, I would first like to describe my problem with the word\n“backlog” itself. I am not trying to denigrate any particular process here, but,\n\nunfortunately, the word backlog is so prevalent nowadays that its use carries\nwith it connotations that are counter-productive. Whether or not those\nconnotations are correct is a different debate; the point here is to just\nacknowledge that they exist. It has been my experience that people immediately assume two things\n\nwhen using the term backlog:\n\n1. That items placed in a backlog are somehow committed to (or that they\n\notherwise inherently have value), and,\n\n2. That items placed in a backlog are somehow prioritized. A backlog, therefore, is merely a convenient container for these\ncandidate ideas. Commitment does not happen until a team actually has\ncapacity, and prioritization does not happen until at the time of commitment\n(see Chapter 8 for how just-in-time commitment and prioritization work). To be clear, you could definitely have a CFD that looks like Figure\n4.16, but then it would be subject to all the properties of a CFD that I have\noutlined in this chapter. If you do not want to signal that items in your", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nFigure 4.16: Showing a Backlog on a Chart\nFor the most part, any diagram that shows a backlog is not a CFD. To\n\nexplain why, I would first like to describe my problem with the word\n“backlog” itself. I am not trying to denigrate any particular process here, but,\n\nunfortunately, the word backlog is so prevalent nowadays that its use carries\nwith it connotations that are counter-productive. Whether or not those\nconnotations are correct is a different debate; the point here is to just\nacknowledge that they exist. It has been my experience that people immediately assume two things\n\nwhen using the term backlog:\n\n1. That items placed in a backlog are somehow committed to (or that they\n\notherwise inherently have value), and,\n\n2. That items placed in a backlog are somehow prioritized. A backlog, therefore, is merely a convenient container for these\ncandidate ideas. Commitment does not happen until a team actually has\ncapacity, and prioritization does not happen until at the time of commitment\n(see Chapter 8 for how just-in-time commitment and prioritization work). To be clear, you could definitely have a CFD that looks like Figure\n4.16, but then it would be subject to all the properties of a CFD that I have\noutlined in this chapter. If you do not want to signal that items in your", "tokens": 287, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 67, "segment_id": "00067", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000077"}
{"type": "chunk", "text": "backlog have been committed to, then do not include a backlog band on your\nchart. If you do want communicate that backlog items have been committed\nto, then, by all means, display the backlog. That decision, as we are about to\nsee, could have serious ramifications for your Cycle Time calculation. I am not saying that a chart that shows a backlog is not useful---far\nfrom it. However, for the most part, a diagram that has a backlog on it is not\na CFD. But, you may ask, “How then are we to do projections of when we\nwill be done?” First, if you would like to do projections on a graph, then\nwhat you want is a something other than a CFD. Second, if you are truly\nserious about projections, then what you really should be doing is some type\nof probabilistic modeling like Monte-Carlo simulation. Projections, BurnUps, Release Planning, and Monte-Carlo simulation will all be covered in\nChapter 14 and Chapter 15. Conclusion\nMapping cumulative arrivals and departures to a process over time is one of\nthe best tools you have at your disposal to visualize flow. Observing flow in\nthis way allows us to discern an impressive amount of useful information\nregarding the health of our process. To suitably construct a CFD, therefore, we must account for arrivals\nand departures appropriately. One of the best ways to ensure that arrivals and\ndepartures are displayed correctly is to make sure that we capture the date\nthat items enter each step of our workflow (as illustrated in Figure 4.14). Those dates can then easily and accurately be converted into the data we\nneed to build a proper CFD. Now that you know what CFDs are all about and how to construct\nthem, it is time to get on to understanding what these graphs are telling us. Key Learnings and Takeaways\n\nCFDs demonstrate the cumulative arrivals and departures to a process\nover time, and, as such, are one of the best tools available for\nvisualizing flow. This type of visualization communicates a lot of quantitative and\nqualitative information at a glance. The anatomy of a CFD is:\n\nThe X-axis represents the process timeline.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nbacklog have been committed to, then do not include a backlog band on your\nchart. If you do want communicate that backlog items have been committed\nto, then, by all means, display the backlog. That decision, as we are about to\nsee, could have serious ramifications for your Cycle Time calculation. I am not saying that a chart that shows a backlog is not useful---far\nfrom it. However, for the most part, a diagram that has a backlog on it is not\na CFD. But, you may ask, “How then are we to do projections of when we\nwill be done?” First, if you would like to do projections on a graph, then\nwhat you want is a something other than a CFD. Second, if you are truly\nserious about projections, then what you really should be doing is some type\nof probabilistic modeling like Monte-Carlo simulation. Projections, BurnUps, Release Planning, and Monte-Carlo simulation will all be covered in\nChapter 14 and Chapter 15. Conclusion\nMapping cumulative arrivals and departures to a process over time is one of\nthe best tools you have at your disposal to visualize flow. Observing flow in\nthis way allows us to discern an impressive amount of useful information\nregarding the health of our process. To suitably construct a CFD, therefore, we must account for arrivals\nand departures appropriately. One of the best ways to ensure that arrivals and\ndepartures are displayed correctly is to make sure that we capture the date\nthat items enter each step of our workflow (as illustrated in Figure 4.14). Those dates can then easily and accurately be converted into the data we\nneed to build a proper CFD. Now that you know what CFDs are all about and how to construct\nthem, it is time to get on to understanding what these graphs are telling us. Key Learnings and Takeaways\n\nCFDs demonstrate the cumulative arrivals and departures to a process\nover time, and, as such, are one of the best tools available for\nvisualizing flow. This type of visualization communicates a lot of quantitative and\nqualitative information at a glance. The anatomy of a CFD is:\n\nThe X-axis represents the process timeline.", "tokens": 465, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 68, "segment_id": "00068", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000078"}
{"type": "chunk", "text": "The Y-axis represents the cumulative count of items in the process\nat each reporting interval. The labels and reporting intervals on the chart are at the sole\ndiscretion of the graph’s creator. Understanding the correct way to construct a CFD is essential to\nknowing how to interpret it. CFD Property #1 is that the top line of a Cumulative Flow Diagram\nalways represents the cumulative arrivals to a process. The bottom line\non a CFD always represents the cumulative departures from a process. CFD Property #2 is that due to its cumulative nature, no line on a CFD\ncan ever decrease (go down). The best way to capture data for a CFD is to track the date at which an\nitem enters each step of your process workflow. You are going to need\nthose data points for other analysis anyway, so you might as well\ncollect those from the start. Three easy ways to spot if a CFD has not been constructed properly:\n\nIf any line on the chart slopes downward on any part of the graph. If something that sounds like a “backlog” has been graphed\n(remember, a visualized backlog may not necessarily be bad---but\nit usually is!). If some type of projection has been plotted.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs\n\nThe Y-axis represents the cumulative count of items in the process\nat each reporting interval. The labels and reporting intervals on the chart are at the sole\ndiscretion of the graph’s creator. Understanding the correct way to construct a CFD is essential to\nknowing how to interpret it. CFD Property #1 is that the top line of a Cumulative Flow Diagram\nalways represents the cumulative arrivals to a process. The bottom line\non a CFD always represents the cumulative departures from a process. CFD Property #2 is that due to its cumulative nature, no line on a CFD\ncan ever decrease (go down). The best way to capture data for a CFD is to track the date at which an\nitem enters each step of your process workflow. You are going to need\nthose data points for other analysis anyway, so you might as well\ncollect those from the start. Three easy ways to spot if a CFD has not been constructed properly:\n\nIf any line on the chart slopes downward on any part of the graph. If something that sounds like a “backlog” has been graphed\n(remember, a visualized backlog may not necessarily be bad---but\nit usually is!). If some type of projection has been plotted.", "tokens": 257, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 69, "segment_id": "00069", "chapter_num": "4", "chapter_title": "Introduction to CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 4: Introduction to CFDs", "chunk_id": "00000079"}
{"type": "chunk", "text": "Chapter 5 - Flow Metrics and CFDs\n\nThe reason I was so pedantic about how to correctly collect data to build\nCFDs in the previous chapter is because only with a properly constructed\nCFD can we accurately perform the analysis techniques that we need for\npredictability. Those techniques are precisely what I plan to present in this\nchapter and the next. We begin our discussion with some quantitative\nanalysis. Work In Progress\nSince the top line of a CFD represents the cumulative arrivals of items to\nour process, and the bottom line of a CFD represents the cumulative\ndepartures of items from our system, then the vertical difference between\nthose two lines at any reporting interval represents the total Work In\nProgress in the system. As you have probably figured out, this principle can\neasily be extended such that we can measure the Work In Progress between\nany two points in the system at any point in time. That is to say, we can\nquickly measure the Work In Progress in the Analysis Active step, in the\nDevelopment Done step, or the total Work In Progress between Analysis\nDone and Test (just to name a few examples). Thus, our next fundamental\nprinciple of CFDs is:\n\nCFD Property #3: The vertical distance between any two lines on a CFD is the total\namount of work that is in progress between the two workflow steps represented by the\ntwo chosen lines. Figure 5.1 shows the total WIP as 90 work items on September 1:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\nChapter 5 - Flow Metrics and CFDs\n\nThe reason I was so pedantic about how to correctly collect data to build\nCFDs in the previous chapter is because only with a properly constructed\nCFD can we accurately perform the analysis techniques that we need for\npredictability. Those techniques are precisely what I plan to present in this\nchapter and the next. We begin our discussion with some quantitative\nanalysis. Work In Progress\nSince the top line of a CFD represents the cumulative arrivals of items to\nour process, and the bottom line of a CFD represents the cumulative\ndepartures of items from our system, then the vertical difference between\nthose two lines at any reporting interval represents the total Work In\nProgress in the system. As you have probably figured out, this principle can\neasily be extended such that we can measure the Work In Progress between\nany two points in the system at any point in time. That is to say, we can\nquickly measure the Work In Progress in the Analysis Active step, in the\nDevelopment Done step, or the total Work In Progress between Analysis\nDone and Test (just to name a few examples). Thus, our next fundamental\nprinciple of CFDs is:\n\nCFD Property #3: The vertical distance between any two lines on a CFD is the total\namount of work that is in progress between the two workflow steps represented by the\ntwo chosen lines. Figure 5.1 shows the total WIP as 90 work items on September 1:", "tokens": 313, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 70, "segment_id": "00070", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000080"}
{"type": "chunk", "text": "Figure 5.1: Reading Total Work In Progress off of a CFD\n\nIn this example, we got to the number 90 by subtracting the number of\nwork items (or y-value) of the bottom line of the CFD on September 1 from\nthe number of work items of the top line on September 1. Specifically, the\nbottom line on the chart shows a value of 200 work items on September 1. The top line shows a value of 290 work items on September 1. Subtracting\nthe bottom line number of work items from the top line number of work\nitems (290 -- 200) gives us a total WIP of 90 work items. Reading WIP off of each step in the workflow is accomplished in\n\nmuch the same way as shown in Figure 5.2:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\nFigure 5.1: Reading Total Work In Progress off of a CFD\n\nIn this example, we got to the number 90 by subtracting the number of\nwork items (or y-value) of the bottom line of the CFD on September 1 from\nthe number of work items of the top line on September 1. Specifically, the\nbottom line on the chart shows a value of 200 work items on September 1. The top line shows a value of 290 work items on September 1. Subtracting\nthe bottom line number of work items from the top line number of work\nitems (290 -- 200) gives us a total WIP of 90 work items. Reading WIP off of each step in the workflow is accomplished in\n\nmuch the same way as shown in Figure 5.2:", "tokens": 172, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 71, "segment_id": "00071", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000081"}
{"type": "chunk", "text": "Figure 5.2: Reading WIP at Each Step of the Workflow\nThe calculation of these numbers was performed in exactly the same\n\nway as the total WIP calculation; i.e., by subtracting the y-value of the\nbottom line of a given band from the y-value of the top line of a given band. Approximate Average Cycle Time\nContinuing the same example, the horizontal difference between the top\nline of a CFD and bottom line of a CFD at any point along the graph is your\nprocess’s Approximate Average Cycle Time. To approximately calculate\nhow long---on average---it took for items to complete at a particular\nreporting interval, we choose the point on the bottom line of the CFD that\ncorresponds with the date that we are interested in, and then we draw a\nhorizontal line backward until it intersects the top line of the CFD. We then\nlook to see what date corresponds with that top line intersection and\nsubtract it from the date we just got from the bottom line. This subtraction\nwill give you the Approximate Average Cycle Time for the items that\nfinished on the bottom line date of interest. This leads us to the next fundamental property of CFDs:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\nFigure 5.2: Reading WIP at Each Step of the Workflow\nThe calculation of these numbers was performed in exactly the same\n\nway as the total WIP calculation; i.e., by subtracting the y-value of the\nbottom line of a given band from the y-value of the top line of a given band. Approximate Average Cycle Time\nContinuing the same example, the horizontal difference between the top\nline of a CFD and bottom line of a CFD at any point along the graph is your\nprocess’s Approximate Average Cycle Time. To approximately calculate\nhow long---on average---it took for items to complete at a particular\nreporting interval, we choose the point on the bottom line of the CFD that\ncorresponds with the date that we are interested in, and then we draw a\nhorizontal line backward until it intersects the top line of the CFD. We then\nlook to see what date corresponds with that top line intersection and\nsubtract it from the date we just got from the bottom line. This subtraction\nwill give you the Approximate Average Cycle Time for the items that\nfinished on the bottom line date of interest. This leads us to the next fundamental property of CFDs:", "tokens": 253, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 72, "segment_id": "00072", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000082"}
{"type": "chunk", "text": "CFD Property #4: The horizontal distance between any two lines on a CFD represents\nthe Approximate Average Cycle Time for items that finished between the two\nworkflow steps represented by the chosen two lines. Continuing on from the previous example, let’s say we want to know\nwhat the Approximate Average Cycle Time was for items that finished on\nSeptember 1st. In this case our calculation would look like Figure 5.3:\n\nFigure 5.3: Overall Process Approximate Average Cycle Time Calculation\n\nIn this example, to calculate the Approximate Average Cycle Time for\nstories that finished on September 1 (which is this example is 24 days), you\nperform the following steps. (Please note that in this case the reporting\ninterval is days. These steps would be the same for whatever time unit you\nchoose to report your data; e.g., weeks, months, etc.):\n\n1. Start with date you are interested in on the bottom line of the graph. In\n\nthis case, that date is September 1. 2. Draw a horizontal line backward from that point on the bottom line\n\nuntil the line intersects a point on the top line of the CFD. 3. Read the date value of the top line of the CFD at that intersection\n\npoint. In this case that date is August 9. 4. Subtract top line date from the bottom line date. In this case,\n\nSeptember 1 minus August 9 is 23 days.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\nCFD Property #4: The horizontal distance between any two lines on a CFD represents\nthe Approximate Average Cycle Time for items that finished between the two\nworkflow steps represented by the chosen two lines. Continuing on from the previous example, let’s say we want to know\nwhat the Approximate Average Cycle Time was for items that finished on\nSeptember 1st. In this case our calculation would look like Figure 5.3:\n\nFigure 5.3: Overall Process Approximate Average Cycle Time Calculation\n\nIn this example, to calculate the Approximate Average Cycle Time for\nstories that finished on September 1 (which is this example is 24 days), you\nperform the following steps. (Please note that in this case the reporting\ninterval is days. These steps would be the same for whatever time unit you\nchoose to report your data; e.g., weeks, months, etc.):\n\n1. Start with date you are interested in on the bottom line of the graph. In\n\nthis case, that date is September 1. 2. Draw a horizontal line backward from that point on the bottom line\n\nuntil the line intersects a point on the top line of the CFD. 3. Read the date value of the top line of the CFD at that intersection\n\npoint. In this case that date is August 9. 4. Subtract top line date from the bottom line date. In this case,\n\nSeptember 1 minus August 9 is 23 days.", "tokens": 305, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 73, "segment_id": "00073", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000083"}
{"type": "chunk", "text": "5. Add 1 to the result. In this case, 23 plus 1 is 24 days. Why add one day in Step #5? I always advise the addition of one “time\nunit” (in this case that time unit is days) because I would argue the shortest\namount of time that an item can take to complete is one unit. For example,\nif a given work item starts and completes on the same day (e.g., September\n1), what is its Cycle Time? If we were just to subtract September 1 from\nSeptember 1 we would get a Cycle Time of zero days. I think that result is\nmisleading. After all, zero days suggests that no time whatsoever was spent\ncompleting that item. That is not reflective of reality which is why one day\nneeds to be added. Further, the addition of one day makes the calculation\nmore inclusive. For example, if a work item starts on September 1 and\nfinishes on September 2, what is its Cycle Time? If all we did is subtract\nthose two dates, we would get a Cycle Time of one day. But I would\nsuggest that since time was spent on that item on both September 1 and\nSeptember 2 that the more representative Cycle Time is two days. Which\nmeans that we would again need to add one day to our calculation. You\nmight disagree with this advice for your own particular situation. And that\nis ok (as long as you are consistent in your calculations). You will just want\nto note, though, that all Cycle Time calculations in this book follow the\n“addition of one time unit” rule. Getting back to our original discussion, the fact that you can draw a\n\nhorizontal line on a CFD and subtract two dates to come up with an\nApproximate Average Cycle time should be amazing to you for a couple of\nreasons. The first is that to normally calculate an average you simply add up\na whole bunch of values and then divide by the total number of values that\nyou have added up. However, in this case all we are doing is subtracting\ntwo dates to come up with an average. Seems strange that that would work,\nbut it does.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\n5. Add 1 to the result. In this case, 23 plus 1 is 24 days. Why add one day in Step #5? I always advise the addition of one “time\nunit” (in this case that time unit is days) because I would argue the shortest\namount of time that an item can take to complete is one unit. For example,\nif a given work item starts and completes on the same day (e.g., September\n1), what is its Cycle Time? If we were just to subtract September 1 from\nSeptember 1 we would get a Cycle Time of zero days. I think that result is\nmisleading. After all, zero days suggests that no time whatsoever was spent\ncompleting that item. That is not reflective of reality which is why one day\nneeds to be added. Further, the addition of one day makes the calculation\nmore inclusive. For example, if a work item starts on September 1 and\nfinishes on September 2, what is its Cycle Time? If all we did is subtract\nthose two dates, we would get a Cycle Time of one day. But I would\nsuggest that since time was spent on that item on both September 1 and\nSeptember 2 that the more representative Cycle Time is two days. Which\nmeans that we would again need to add one day to our calculation. You\nmight disagree with this advice for your own particular situation. And that\nis ok (as long as you are consistent in your calculations). You will just want\nto note, though, that all Cycle Time calculations in this book follow the\n“addition of one time unit” rule. Getting back to our original discussion, the fact that you can draw a\n\nhorizontal line on a CFD and subtract two dates to come up with an\nApproximate Average Cycle time should be amazing to you for a couple of\nreasons. The first is that to normally calculate an average you simply add up\na whole bunch of values and then divide by the total number of values that\nyou have added up. However, in this case all we are doing is subtracting\ntwo dates to come up with an average. Seems strange that that would work,\nbut it does.", "tokens": 461, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 74, "segment_id": "00074", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000084"}
{"type": "chunk", "text": "Getting back to our original discussion, the fact that you can draw a\n\nhorizontal line on a CFD and subtract two dates to come up with an\nApproximate Average Cycle time should be amazing to you for a couple of\nreasons. The first is that to normally calculate an average you simply add up\na whole bunch of values and then divide by the total number of values that\nyou have added up. However, in this case all we are doing is subtracting\ntwo dates to come up with an average. Seems strange that that would work,\nbut it does. The second reason that this result is remarkable, is that the items that\n\nstarted in the Analysis Active column (the first column on the board) are not\nnecessarily the stories that have finished in the Done column (the last\ncolumn on the board), yet this calculation will still yield an Approximate\nAverage Cycle Time. Interestingly enough, how good an approximation this\ncalculation is will depend on how well we are adhering to the assumptions\nthat make Little’s Law work.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\nGetting back to our original discussion, the fact that you can draw a\n\nhorizontal line on a CFD and subtract two dates to come up with an\nApproximate Average Cycle time should be amazing to you for a couple of\nreasons. The first is that to normally calculate an average you simply add up\na whole bunch of values and then divide by the total number of values that\nyou have added up. However, in this case all we are doing is subtracting\ntwo dates to come up with an average. Seems strange that that would work,\nbut it does. The second reason that this result is remarkable, is that the items that\n\nstarted in the Analysis Active column (the first column on the board) are not\nnecessarily the stories that have finished in the Done column (the last\ncolumn on the board), yet this calculation will still yield an Approximate\nAverage Cycle Time. Interestingly enough, how good an approximation this\ncalculation is will depend on how well we are adhering to the assumptions\nthat make Little’s Law work.", "tokens": 215, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 74, "segment_id": "00074", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000085"}
{"type": "chunk", "text": "As with the Work In Progress calculation, this property can also be\nextended to handle the calculation between any two arbitrary points on your\nchart. That means we can draw horizontal lines to calculate the\nApproximate Average Cycle Time through Analysis Active, or through Test,\nor the Approximate Average Cycle Time from Analysis Done through\nDevelopment Done (again, to name a few examples). Pictorially, some of\nthese examples would look like Figure 5.5:\n\nFigure 5.5: Approximate Average Cycle Times at Each Step in the Workflow\nNote that this calculation is only valid for items that have finished. That is to say, this horizontal line that you draw to make this calculation\nmust begin at the top line of the bottom band at the reporting interval that\nyou are interested in and be drawn “backward” until it intersects the top\nline. Starting at the top line and drawing a line “forward” could cause you\nto never intersect the top line of the bottom-most band. The implication\nhere is that CFDs are only good at exploring what already has happened in\nyour process. This point is so important that I am going to call it out as its\nown property of CFDs:\n\nCFD Property #5: The data displayed on a CFD depicts only what has happened for a\ngiven process. Any chart that shows any type of projection is not a CFD.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\nAs with the Work In Progress calculation, this property can also be\nextended to handle the calculation between any two arbitrary points on your\nchart. That means we can draw horizontal lines to calculate the\nApproximate Average Cycle Time through Analysis Active, or through Test,\nor the Approximate Average Cycle Time from Analysis Done through\nDevelopment Done (again, to name a few examples). Pictorially, some of\nthese examples would look like Figure 5.5:\n\nFigure 5.5: Approximate Average Cycle Times at Each Step in the Workflow\nNote that this calculation is only valid for items that have finished. That is to say, this horizontal line that you draw to make this calculation\nmust begin at the top line of the bottom band at the reporting interval that\nyou are interested in and be drawn “backward” until it intersects the top\nline. Starting at the top line and drawing a line “forward” could cause you\nto never intersect the top line of the bottom-most band. The implication\nhere is that CFDs are only good at exploring what already has happened in\nyour process. This point is so important that I am going to call it out as its\nown property of CFDs:\n\nCFD Property #5: The data displayed on a CFD depicts only what has happened for a\ngiven process. Any chart that shows any type of projection is not a CFD.", "tokens": 288, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 75, "segment_id": "00075", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000086"}
{"type": "chunk", "text": "Again, I am not saying here that projections are not important---far\nfrom it. All I am saying is that projections forward about what will or could\nhappen in your process will require a completely different chart---and more\nprobably a completely different approach (like Monte Carlo Simulation). Just know that we cannot use CFDs for that forecasting purpose or that, if\nyou do, you cannot call the resulting projection graph a CFD. I will spend\nmuch more time on projections later in the book (Chapter 14 and Chapter\n15). As you have probably noticed, I have gone through great pains to\n\nstress the fact that this horizontal line calculation only gives us an\nApproximate Average Cycle Time. I am being so pedantic about this\nbecause there is a lot of misinformation or disinformation about CFDs out\nthere. If you were to go out and do some research on Cumulative Flow\nDiagrams, you will probably find that many people will tell you that doing\nthis horizontal line calculation will give you an exact Cycle Time. It does\nnot. The reason is because the items that start on the top line of your\nCumulative Flow Diagram (at the beginning of your horizontal line) are not\nnecessarily the items that finish at the bottom line of your Cumulative Flow\nDiagram (at the end of your horizontal line). Therefore, it would be\nimpossible to calculate an exact Cycle Time for those items using just the\ndiagram alone. Further, some people will tell you that this horizontal line\ncalculation will lead to an exact average Cycle Time. This statement is also\npotentially incorrect. Unless we go in and look at the data that was used to\ngenerate the chart, or we have an understanding of some of the policies that\nhave been put in place to generate the diagram the best we can say is that\nthis horizontal calculation will lead to an Approximate Average Cycle Time. However, this approximation can be very good. In Chapters 5-7, I will\nexplain some policies that you can put in place within your own team, or\nyour own project, such that this calculation will give you an excellent\napproximation. There is another great (potentially most important) reason to\n\nunderstand why this horizontal line represents only an Approximate\nAverage Cycle Time.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\nAgain, I am not saying here that projections are not important---far\nfrom it. All I am saying is that projections forward about what will or could\nhappen in your process will require a completely different chart---and more\nprobably a completely different approach (like Monte Carlo Simulation). Just know that we cannot use CFDs for that forecasting purpose or that, if\nyou do, you cannot call the resulting projection graph a CFD. I will spend\nmuch more time on projections later in the book (Chapter 14 and Chapter\n15). As you have probably noticed, I have gone through great pains to\n\nstress the fact that this horizontal line calculation only gives us an\nApproximate Average Cycle Time. I am being so pedantic about this\nbecause there is a lot of misinformation or disinformation about CFDs out\nthere. If you were to go out and do some research on Cumulative Flow\nDiagrams, you will probably find that many people will tell you that doing\nthis horizontal line calculation will give you an exact Cycle Time. It does\nnot. The reason is because the items that start on the top line of your\nCumulative Flow Diagram (at the beginning of your horizontal line) are not\nnecessarily the items that finish at the bottom line of your Cumulative Flow\nDiagram (at the end of your horizontal line). Therefore, it would be\nimpossible to calculate an exact Cycle Time for those items using just the\ndiagram alone. Further, some people will tell you that this horizontal line\ncalculation will lead to an exact average Cycle Time. This statement is also\npotentially incorrect. Unless we go in and look at the data that was used to\ngenerate the chart, or we have an understanding of some of the policies that\nhave been put in place to generate the diagram the best we can say is that\nthis horizontal calculation will lead to an Approximate Average Cycle Time. However, this approximation can be very good. In Chapters 5-7, I will\nexplain some policies that you can put in place within your own team, or\nyour own project, such that this calculation will give you an excellent\napproximation. There is another great (potentially most important) reason to\n\nunderstand why this horizontal line represents only an Approximate\nAverage Cycle Time.", "tokens": 475, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 76, "segment_id": "00076", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000087"}
{"type": "chunk", "text": "However, this approximation can be very good. In Chapters 5-7, I will\nexplain some policies that you can put in place within your own team, or\nyour own project, such that this calculation will give you an excellent\napproximation. There is another great (potentially most important) reason to\n\nunderstand why this horizontal line represents only an Approximate\nAverage Cycle Time. It turns out the comparison of the Approximate\nAverage Cycle Time off of your CFD with the exact average Cycle Time\nfrom your real data can give you tremendous insight as to the health of your\nprocess. We will get into the specifics of that calculation and analysis in\nChapter 9.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\nHowever, this approximation can be very good. In Chapters 5-7, I will\nexplain some policies that you can put in place within your own team, or\nyour own project, such that this calculation will give you an excellent\napproximation. There is another great (potentially most important) reason to\n\nunderstand why this horizontal line represents only an Approximate\nAverage Cycle Time. It turns out the comparison of the Approximate\nAverage Cycle Time off of your CFD with the exact average Cycle Time\nfrom your real data can give you tremendous insight as to the health of your\nprocess. We will get into the specifics of that calculation and analysis in\nChapter 9.", "tokens": 141, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 76, "segment_id": "00076", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000088"}
{"type": "chunk", "text": "Average Throughput\nIf the bottom line of your CFD represents the departures from your process,\nthen the slope of that line between any two points (reporting intervals) is\nyour exact average Throughput between those two points. This slope\ncalculation is the very same “rise over run” calculation that you may\nremember from your previous mathematics training (it is ok if you do not\nremember as I have included an example of this calculation in the\ndiscussion after Figure 5.6). Furthermore, just to be clear, this is indeed an\nexact average Throughput calculation, not an approximate average as in the\nCycle Time calculation above. Likewise, if the slope of the bottom line of the CFD is your average\n\nThroughput, then the slope of the top-most line is your average arrival rate. The slope of that top line represents how fast work is coming into our\nsystem, while the slope of the bottom line represents how fast work leaving\nour system. This leads to the last of our fundamental properties of Cumulative\n\nFlow Diagrams:\n\nCFD Property #6: The slope of any line between any two reporting intervals on a CFD\nrepresents the exact Average Arrival Rate of the process state represented by the\nsucceeding band. As you have probably already guessed, Property #6 is a direct result of\n\nProperty #1, but it is so important that I wanted to call it out on its own. One important corollary to this property is that the slope of any line also\nrepresents the exact average Throughput (or Departure Rate or Completion\nRate) for the preceding workflow step. To visualize this result, let’s continue to look at the same example that\nwe used in the WIP and Cycle Time sections (Figure 5.1). To calculate the\nThroughput of the overall process, we simply compute the slope of the\nbottom line of the CFD (the top line of the Done state in Figure 5.6). Likewise, to calculate the arrival rate we use the same slope calculation for\nAnalysis Active line. Both situations are shown in Figure 5.6:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\nAverage Throughput\nIf the bottom line of your CFD represents the departures from your process,\nthen the slope of that line between any two points (reporting intervals) is\nyour exact average Throughput between those two points. This slope\ncalculation is the very same “rise over run” calculation that you may\nremember from your previous mathematics training (it is ok if you do not\nremember as I have included an example of this calculation in the\ndiscussion after Figure 5.6). Furthermore, just to be clear, this is indeed an\nexact average Throughput calculation, not an approximate average as in the\nCycle Time calculation above. Likewise, if the slope of the bottom line of the CFD is your average\n\nThroughput, then the slope of the top-most line is your average arrival rate. The slope of that top line represents how fast work is coming into our\nsystem, while the slope of the bottom line represents how fast work leaving\nour system. This leads to the last of our fundamental properties of Cumulative\n\nFlow Diagrams:\n\nCFD Property #6: The slope of any line between any two reporting intervals on a CFD\nrepresents the exact Average Arrival Rate of the process state represented by the\nsucceeding band. As you have probably already guessed, Property #6 is a direct result of\n\nProperty #1, but it is so important that I wanted to call it out on its own. One important corollary to this property is that the slope of any line also\nrepresents the exact average Throughput (or Departure Rate or Completion\nRate) for the preceding workflow step. To visualize this result, let’s continue to look at the same example that\nwe used in the WIP and Cycle Time sections (Figure 5.1). To calculate the\nThroughput of the overall process, we simply compute the slope of the\nbottom line of the CFD (the top line of the Done state in Figure 5.6). Likewise, to calculate the arrival rate we use the same slope calculation for\nAnalysis Active line. Both situations are shown in Figure 5.6:", "tokens": 437, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 77, "segment_id": "00077", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000089"}
{"type": "chunk", "text": "Figure 5.6: Arrival Rate and Departure Rate on a CFD\nTo calculate Average Throughput you will first need to ascertain the\ndate range you are interested in. In this example (Figure 5.6) that date range\nis June 21 -- November 16. The number of days in that range is our “run”,\nor, in this case, November 16 minus June 21 equals 148 days. Second, we\nneed to figure the “rise” of our bottom line work item data over that date\nrange. The number of items on the bottom line at June 21 is zero and the\nnumber of items on the bottom line at Nov 16 is 517. Subtracting those two\nnumbers gives us our “rise”, or in this case 517 -- 0 = 517. To calculate\nAverage Throughput, then, you simply divide the rise by the run. In this\ncase, our Average Throughput is 517 divided by 148 which equals 3.49\nitems per day. You can perform the exact same calculation for Average\nArrival rate by substituting the data for the top line of the CFD into your\nrise over run formula. Just as with WIP and Cycle Time, we can perform the slope\n\ncalculations to get the Average Arrival or Average Departure rate for any\nstep of the workflow as shown in Figure 5.7:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\nFigure 5.6: Arrival Rate and Departure Rate on a CFD\nTo calculate Average Throughput you will first need to ascertain the\ndate range you are interested in. In this example (Figure 5.6) that date range\nis June 21 -- November 16. The number of days in that range is our “run”,\nor, in this case, November 16 minus June 21 equals 148 days. Second, we\nneed to figure the “rise” of our bottom line work item data over that date\nrange. The number of items on the bottom line at June 21 is zero and the\nnumber of items on the bottom line at Nov 16 is 517. Subtracting those two\nnumbers gives us our “rise”, or in this case 517 -- 0 = 517. To calculate\nAverage Throughput, then, you simply divide the rise by the run. In this\ncase, our Average Throughput is 517 divided by 148 which equals 3.49\nitems per day. You can perform the exact same calculation for Average\nArrival rate by substituting the data for the top line of the CFD into your\nrise over run formula. Just as with WIP and Cycle Time, we can perform the slope\n\ncalculations to get the Average Arrival or Average Departure rate for any\nstep of the workflow as shown in Figure 5.7:", "tokens": 294, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 78, "segment_id": "00078", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000090"}
{"type": "chunk", "text": "Figure 5.8: The Three Basic Metrics of Flow on a CFD\n\nNumerically, these calculations look like Figure 5.9:\n\nFigure 5.9: Numerical Representations of the Metrics of Flow\n\nAs I mentioned in Chapter 2, it is possible to segment WIP into several\n\nconstituent types (as also mentioned in Chapter 3 on Little’s Law). CFDs\nare no different. As you may have guessed by now, when we collect our\nflow data, we can either look at that dataset as a whole in a CFD, or we can", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\nFigure 5.8: The Three Basic Metrics of Flow on a CFD\n\nNumerically, these calculations look like Figure 5.9:\n\nFigure 5.9: Numerical Representations of the Metrics of Flow\n\nAs I mentioned in Chapter 2, it is possible to segment WIP into several\n\nconstituent types (as also mentioned in Chapter 3 on Little’s Law). CFDs\nare no different. As you may have guessed by now, when we collect our\nflow data, we can either look at that dataset as a whole in a CFD, or we can", "tokens": 123, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 80, "segment_id": "00080", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000091"}
{"type": "chunk", "text": "construct a CFD based on only one or more of the subtypes. For example,\nwe can look at a single CFD that shows just the data for the user story type,\nor we can build a CFD based on just defects, or we can generate a CFD that\ncombines both user stories and maintenance---to just name a few. This\nproperty of CFDs will open up all kinds of avenues of analysis for you. For\nexample, at the portfolio level, you may want to look at data combined\nacross all teams, or you may just want to filter based on an individual team. Or maybe you want to filter by release. At the team level, you might want to\nfilter by some other custom field that is particularly relevant to your context\n(as in the “bad data” example from above). All of these activities are\nperfectly ok and I would challenge you to think about what data attributes\nyou might want to collect and then filter on when analyzing your CFDs. CFDs offer a concise way to simultaneously visualize the three basic\n\nmetrics of flow: WIP, Cycle Time, and Throughput (albeit sometimes in the\nform of averages or approximate averages). You can only be guaranteed to\ncalculate these metrics, however, if your graph obeys all six properties of a\nCFD:\n\nCFD Property #1 is that the top line of a Cumulative Flow Diagram always represents\nthe cumulative arrivals to a process. The bottom line on a CFD always represents the\ncumulative departures from a process. CFD Property #2 is that due to its cumulative nature, no line on a CFD can ever\ndecrease (go down). CFD Property #3 is that the vertical distance between any two lines on a CFD is the\ntotal amount of work that is in progress between the two workflow steps represented by\nthe two chosen lines. CFD Property #4 is that the horizontal distance between any two lines on a CFD\nrepresents the Approximate Average Cycle Time for items that finished between the two\nworkflow steps represented by the chosen two lines. CFD Property #5 is that the data displayed on a CFD depicts only what has happened\nfor a given process. Any chart that shows any type of projection is not a CFD.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\nconstruct a CFD based on only one or more of the subtypes. For example,\nwe can look at a single CFD that shows just the data for the user story type,\nor we can build a CFD based on just defects, or we can generate a CFD that\ncombines both user stories and maintenance---to just name a few. This\nproperty of CFDs will open up all kinds of avenues of analysis for you. For\nexample, at the portfolio level, you may want to look at data combined\nacross all teams, or you may just want to filter based on an individual team. Or maybe you want to filter by release. At the team level, you might want to\nfilter by some other custom field that is particularly relevant to your context\n(as in the “bad data” example from above). All of these activities are\nperfectly ok and I would challenge you to think about what data attributes\nyou might want to collect and then filter on when analyzing your CFDs. CFDs offer a concise way to simultaneously visualize the three basic\n\nmetrics of flow: WIP, Cycle Time, and Throughput (albeit sometimes in the\nform of averages or approximate averages). You can only be guaranteed to\ncalculate these metrics, however, if your graph obeys all six properties of a\nCFD:\n\nCFD Property #1 is that the top line of a Cumulative Flow Diagram always represents\nthe cumulative arrivals to a process. The bottom line on a CFD always represents the\ncumulative departures from a process. CFD Property #2 is that due to its cumulative nature, no line on a CFD can ever\ndecrease (go down). CFD Property #3 is that the vertical distance between any two lines on a CFD is the\ntotal amount of work that is in progress between the two workflow steps represented by\nthe two chosen lines. CFD Property #4 is that the horizontal distance between any two lines on a CFD\nrepresents the Approximate Average Cycle Time for items that finished between the two\nworkflow steps represented by the chosen two lines. CFD Property #5 is that the data displayed on a CFD depicts only what has happened\nfor a given process. Any chart that shows any type of projection is not a CFD.", "tokens": 474, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 81, "segment_id": "00081", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000092"}
{"type": "chunk", "text": "CFD Property #3 is that the vertical distance between any two lines on a CFD is the\ntotal amount of work that is in progress between the two workflow steps represented by\nthe two chosen lines. CFD Property #4 is that the horizontal distance between any two lines on a CFD\nrepresents the Approximate Average Cycle Time for items that finished between the two\nworkflow steps represented by the chosen two lines. CFD Property #5 is that the data displayed on a CFD depicts only what has happened\nfor a given process. Any chart that shows any type of projection is not a CFD. CFD Property #6 is that the slope of any line between any two reporting intervals on a\nCFD represents the exact Average Arrival Rate of the process state represented by the\nsucceeding band. With a strong quantitative understanding of CFDs, we move now to a\nmore qualitative analysis---which is really where the predictability rubber\nhits the road.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\nCFD Property #3 is that the vertical distance between any two lines on a CFD is the\ntotal amount of work that is in progress between the two workflow steps represented by\nthe two chosen lines. CFD Property #4 is that the horizontal distance between any two lines on a CFD\nrepresents the Approximate Average Cycle Time for items that finished between the two\nworkflow steps represented by the chosen two lines. CFD Property #5 is that the data displayed on a CFD depicts only what has happened\nfor a given process. Any chart that shows any type of projection is not a CFD. CFD Property #6 is that the slope of any line between any two reporting intervals on a\nCFD represents the exact Average Arrival Rate of the process state represented by the\nsucceeding band. With a strong quantitative understanding of CFDs, we move now to a\nmore qualitative analysis---which is really where the predictability rubber\nhits the road.", "tokens": 199, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 81, "segment_id": "00081", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000093"}
{"type": "chunk", "text": "Key Learnings and Takeaways\n\nCFD Property #3: The vertical distance between any two lines on a\nCFD is the total amount of work that is in progress between the two\nworkflow steps represented by the two chosen lines. CFD Property #4: The horizontal distance between any two lines on a\nCFD represents the Approximate Average Cycle Time for items that\nfinished between the two workflow steps represented by the chosen\ntwo lines. CFD Property #5: The data displayed on a CFD depicts only what has\nhappened for a given process. Any chart that shows any type of\nprojection is not a CFD. CFD Property #6: The slope of any line between any two reporting\nintervals on a CFD represents the exact Average Arrival Rate of the\nprocess state represented by the succeeding band. A CFD is only a CFD if it obeys all six properties because only by\nfollowing all of these properties can you be guaranteed to derive the\ncorrect quantitative metrics of flow off of your graph. Consider building CFDs that show both “Active” and “Done” states\nwithin workflow steps. For example, if your “Development” workflow\nstep if further segmented into “Active” and “Done”, then think about\nshowing both of those sub columns on your CFD. Some common myths about CFDs:\n\nIt is always correct to build a CFD from work item count data at\neach reporting interval. A horizontal line represents an exact Cycle Time or an exact\naverage Cycle Time. It is always ok to represent a traditional backlog on a CFD. It is possible to make a qualitative assessment of a CFD without\nunderstanding its context.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs\n\nKey Learnings and Takeaways\n\nCFD Property #3: The vertical distance between any two lines on a\nCFD is the total amount of work that is in progress between the two\nworkflow steps represented by the two chosen lines. CFD Property #4: The horizontal distance between any two lines on a\nCFD represents the Approximate Average Cycle Time for items that\nfinished between the two workflow steps represented by the chosen\ntwo lines. CFD Property #5: The data displayed on a CFD depicts only what has\nhappened for a given process. Any chart that shows any type of\nprojection is not a CFD. CFD Property #6: The slope of any line between any two reporting\nintervals on a CFD represents the exact Average Arrival Rate of the\nprocess state represented by the succeeding band. A CFD is only a CFD if it obeys all six properties because only by\nfollowing all of these properties can you be guaranteed to derive the\ncorrect quantitative metrics of flow off of your graph. Consider building CFDs that show both “Active” and “Done” states\nwithin workflow steps. For example, if your “Development” workflow\nstep if further segmented into “Active” and “Done”, then think about\nshowing both of those sub columns on your CFD. Some common myths about CFDs:\n\nIt is always correct to build a CFD from work item count data at\neach reporting interval. A horizontal line represents an exact Cycle Time or an exact\naverage Cycle Time. It is always ok to represent a traditional backlog on a CFD. It is possible to make a qualitative assessment of a CFD without\nunderstanding its context.", "tokens": 349, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 82, "segment_id": "00082", "chapter_num": "5", "chapter_title": "Flow Metrics and CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 5: Flow Metrics and CFDs", "chunk_id": "00000094"}
{"type": "chunk", "text": "Chapter 6 - Interpreting CFDs\n\nNow that you have a good grasp of how to do basic quantitative analysis on\na CFD, you will see that you have already built an intuition around how to\nspot qualitative flow problems without doing any computations. An\nexploration of how to interpret a Cumulative Flow Diagram is what this\nchapter is all about. First, though, some words of warning. The most important thing to\n\nremember about any qualitative analysis of CFDs is that the diagrams\nthemselves are very context specific. If you look at a CFD without\nunderstanding the context in which it was created, then all you are doing is\nlooking at a picture. Just like any visualization, a CFD is not going to tell\nyou exactly what is wrong with your process or exactly how to fix it, but it\nis going to shine a light or a magnifying glass on the places to investigate. To that point, you will be tempted to jump to snap judgments the next\ntime you see a Cumulative Flow Diagram. Do not. This is the trap that most\nknowledge work blog posts and other publications on CFDs fall into. Be\nbetter than that! The reason we visualize flow on a CFD is not so that we\ncan draw superficial conclusions about what is wrong with a given process. Rather, the reason we visualize flow via a CFD is so that we can begin to\nask the right questions sooner. CFDs are not going to do our jobs for us. They do not replace thinking. One last thing: it may seem strange, but doing any qualitative analysis\n\non CFDs really requires sound knowledge of how to do quantitative\nanalysis on CFDs. If you have skipped ahead to this chapter because you\nassumed you knew CFDs, you may want to go back and read both Chapter\n4 and Chapter 5. Keeping all that in mind, let’s take a look at some common CFDs\npatterns and explore what questions we might ask when we see these shapes\nemerge. Mismatched Arrivals and Departures\nLet’s say we had a CFD that looked like:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs\n\nChapter 6 - Interpreting CFDs\n\nNow that you have a good grasp of how to do basic quantitative analysis on\na CFD, you will see that you have already built an intuition around how to\nspot qualitative flow problems without doing any computations. An\nexploration of how to interpret a Cumulative Flow Diagram is what this\nchapter is all about. First, though, some words of warning. The most important thing to\n\nremember about any qualitative analysis of CFDs is that the diagrams\nthemselves are very context specific. If you look at a CFD without\nunderstanding the context in which it was created, then all you are doing is\nlooking at a picture. Just like any visualization, a CFD is not going to tell\nyou exactly what is wrong with your process or exactly how to fix it, but it\nis going to shine a light or a magnifying glass on the places to investigate. To that point, you will be tempted to jump to snap judgments the next\ntime you see a Cumulative Flow Diagram. Do not. This is the trap that most\nknowledge work blog posts and other publications on CFDs fall into. Be\nbetter than that! The reason we visualize flow on a CFD is not so that we\ncan draw superficial conclusions about what is wrong with a given process. Rather, the reason we visualize flow via a CFD is so that we can begin to\nask the right questions sooner. CFDs are not going to do our jobs for us. They do not replace thinking. One last thing: it may seem strange, but doing any qualitative analysis\n\non CFDs really requires sound knowledge of how to do quantitative\nanalysis on CFDs. If you have skipped ahead to this chapter because you\nassumed you knew CFDs, you may want to go back and read both Chapter\n4 and Chapter 5. Keeping all that in mind, let’s take a look at some common CFDs\npatterns and explore what questions we might ask when we see these shapes\nemerge. Mismatched Arrivals and Departures\nLet’s say we had a CFD that looked like:", "tokens": 447, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 83, "segment_id": "00083", "chapter_num": "6", "chapter_title": "Interpreting CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs", "chunk_id": "00000095"}
{"type": "chunk", "text": "Figure 6.1: Mismatched Arrivals and Departures\n\nIn this picture the slope of the top-most line is steeper than the slope of\nthe bottom-most line. This is a classic pattern that develops whenever items\narrive to our process faster than they depart. Most companies that I visit that\nstruggle with predictability have a CFD that looks something like this. Why is this so bad? Any time that we have items that arrive to our\nprocess faster than items depart from our process means that WIP will grow\nover time. In Chapter 3 on Little’s Law, we learned that an increase in WIP\nwill almost certainly lead to an increase in Cycle Time (recall from that\nchapter that having arrival rate equal departure rate---on average---is one of\nthe key assumptions for Little’s Law to work). It is impossible to be\npredictable in a world where WIP constantly increases and Cycle Times\nelongate. By definition, a process that exhibits a shape similar to Figure 6.1 is\nunstable. Process stability is fundamental to process predictability. So much\nso that I will devote all of the next chapter (Chapter 7) to explaining some\ncauses and some remedies whenever the arrivals to your process exceed\ndepartures. Flat Lines\nAnother pattern that I look for on a CFD is whenever any lines that flatten\nout over long periods of time (remember that lines can never go down!).", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs\n\nFigure 6.1: Mismatched Arrivals and Departures\n\nIn this picture the slope of the top-most line is steeper than the slope of\nthe bottom-most line. This is a classic pattern that develops whenever items\narrive to our process faster than they depart. Most companies that I visit that\nstruggle with predictability have a CFD that looks something like this. Why is this so bad? Any time that we have items that arrive to our\nprocess faster than items depart from our process means that WIP will grow\nover time. In Chapter 3 on Little’s Law, we learned that an increase in WIP\nwill almost certainly lead to an increase in Cycle Time (recall from that\nchapter that having arrival rate equal departure rate---on average---is one of\nthe key assumptions for Little’s Law to work). It is impossible to be\npredictable in a world where WIP constantly increases and Cycle Times\nelongate. By definition, a process that exhibits a shape similar to Figure 6.1 is\nunstable. Process stability is fundamental to process predictability. So much\nso that I will devote all of the next chapter (Chapter 7) to explaining some\ncauses and some remedies whenever the arrivals to your process exceed\ndepartures. Flat Lines\nAnother pattern that I look for on a CFD is whenever any lines that flatten\nout over long periods of time (remember that lines can never go down!).", "tokens": 300, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 84, "segment_id": "00084", "chapter_num": "6", "chapter_title": "Interpreting CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs", "chunk_id": "00000096"}
{"type": "chunk", "text": "Figure 6.2 shows an example of this:\n\nFigure 6.2: Flat Throughput Sections on a CFD\nDepending on your perspective, these lines could represent either\nperiods of zero arrivals or periods of zero departures. Usually you will be\nconcerned about these flat lines as periods of zero departures. The reason\nwhy is because zero departures means nothing is getting done. In other\nwords, no value is being delivered to the customer (or to a downstream\nstep). There are all kinds of circumstances that could cause this pattern to\nemerge. Maybe there is a period of several public holidays where most of\nthe staff is out (the two weeks around Christmas and New Year’s in the U.S. is a good example). Maybe the team is blocked by some external event such\nas the whole test environment being down such that testing cannot\ncomplete. Whatever the reason, think about what this zero Throughput is doing to\n\nyour predictability. If a horizontal line represents an Approximate Average\nCycle Time on your CFD, what do you think is happening to that\napproximation during periods of long, flat Throughput? What happens\nwhen we plug in a zero for average Throughput in Little’s Law, but average\nWIP is non-zero? What does that do to Cycle Time? The point here is that an emergent flat line on a CFD should trigger\nsome type of urgent conversation and that conversation should be about", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs\n\nFigure 6.2 shows an example of this:\n\nFigure 6.2: Flat Throughput Sections on a CFD\nDepending on your perspective, these lines could represent either\nperiods of zero arrivals or periods of zero departures. Usually you will be\nconcerned about these flat lines as periods of zero departures. The reason\nwhy is because zero departures means nothing is getting done. In other\nwords, no value is being delivered to the customer (or to a downstream\nstep). There are all kinds of circumstances that could cause this pattern to\nemerge. Maybe there is a period of several public holidays where most of\nthe staff is out (the two weeks around Christmas and New Year’s in the U.S. is a good example). Maybe the team is blocked by some external event such\nas the whole test environment being down such that testing cannot\ncomplete. Whatever the reason, think about what this zero Throughput is doing to\n\nyour predictability. If a horizontal line represents an Approximate Average\nCycle Time on your CFD, what do you think is happening to that\napproximation during periods of long, flat Throughput? What happens\nwhen we plug in a zero for average Throughput in Little’s Law, but average\nWIP is non-zero? What does that do to Cycle Time? The point here is that an emergent flat line on a CFD should trigger\nsome type of urgent conversation and that conversation should be about", "tokens": 301, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 85, "segment_id": "00085", "chapter_num": "6", "chapter_title": "Interpreting CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs", "chunk_id": "00000097"}
{"type": "chunk", "text": "answering at least two questions. The first question is “Why isn’t anything\ngetting done?” The second question is “What can we do to get things\nflowing again?”\n\nStair Steps\nA batch transfer in your process will manifest itself as “stair steps” on your\nCFD. By stair steps I mean a flat period on a line (as discussed above)\nimmediately followed by a jump up in arrival rate as illustrated in Figure\n6.3:\n\nFigure 6.3: Batch on a CFD\n\nFor example, if your team has a reporting interval of every day on your\n\nCFD, but---for whatever reason---you wait five days to replenish the input\ncolumn on your board. What you will see on your chart is five straight days\nof a flat input line followed by an immediate increase when the column is\nreplenished. Similarly, what if the bottom line of your CFD represents a\ndeployment to production, but you only do that deployment every three\nmonths? What is that going to look like on your CFD? Some references you may have read suggest that these stair steps are\ncaused by a regular cadence---but they do not have to be. Any batch transfer\n---whether due to a regular cadence or not---will cause these stair steps to\nform. If due to a regular cadence, then the stair steps will be of roughly\nuniform size and shape. Non-regular batch transfer will usually have a more", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs\n\nanswering at least two questions. The first question is “Why isn’t anything\ngetting done?” The second question is “What can we do to get things\nflowing again?”\n\nStair Steps\nA batch transfer in your process will manifest itself as “stair steps” on your\nCFD. By stair steps I mean a flat period on a line (as discussed above)\nimmediately followed by a jump up in arrival rate as illustrated in Figure\n6.3:\n\nFigure 6.3: Batch on a CFD\n\nFor example, if your team has a reporting interval of every day on your\n\nCFD, but---for whatever reason---you wait five days to replenish the input\ncolumn on your board. What you will see on your chart is five straight days\nof a flat input line followed by an immediate increase when the column is\nreplenished. Similarly, what if the bottom line of your CFD represents a\ndeployment to production, but you only do that deployment every three\nmonths? What is that going to look like on your CFD? Some references you may have read suggest that these stair steps are\ncaused by a regular cadence---but they do not have to be. Any batch transfer\n---whether due to a regular cadence or not---will cause these stair steps to\nform. If due to a regular cadence, then the stair steps will be of roughly\nuniform size and shape. Non-regular batch transfer will usually have a more", "tokens": 307, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 86, "segment_id": "00086", "chapter_num": "6", "chapter_title": "Interpreting CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs", "chunk_id": "00000098"}
{"type": "chunk", "text": "uneven appearance to the steps. Both of those situations are shown in\nFigure 6.3. It is important to note here, that batch in and of itself is not necessarily\n\na bad thing. What you will need to do when you see stair steps appear on\nyour Cumulative Flow Diagram is to have a think about how batch is\naffecting (positively or negatively) the predictability of your system. Can\nthose periods of batch be reduced? Eliminated? Should they be? What\nwould it take to do that? What would the impact to Cycle Time be? Bulging Bands\nThis is the one that most teams go after first. Any time that you see a\n“bulging” band in a CFD, it clearly signals an explosion of WIP in that\nparticular workflow step. An example of this is shown in Figure 6.4:\n\nFigure 6.4: Bulging Bands on a CFD\nWe know that large WIP is bad because it almost always results in\nlonger Cycle Times and poorer predictability. The obvious question we\nneed to ask is, “what is causing our increased WIP”? As always, that answer\nwill depend on your specific situation. Maybe the team is simply ignoring\nWIP limits and starting new work arbitrarily. Maybe several key team\nmembers have gone on holiday for extended periods of time. Maybe work\nis progressing slowly due to poor requirements or poor design. Any of these", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs\n\nuneven appearance to the steps. Both of those situations are shown in\nFigure 6.3. It is important to note here, that batch in and of itself is not necessarily\n\na bad thing. What you will need to do when you see stair steps appear on\nyour Cumulative Flow Diagram is to have a think about how batch is\naffecting (positively or negatively) the predictability of your system. Can\nthose periods of batch be reduced? Eliminated? Should they be? What\nwould it take to do that? What would the impact to Cycle Time be? Bulging Bands\nThis is the one that most teams go after first. Any time that you see a\n“bulging” band in a CFD, it clearly signals an explosion of WIP in that\nparticular workflow step. An example of this is shown in Figure 6.4:\n\nFigure 6.4: Bulging Bands on a CFD\nWe know that large WIP is bad because it almost always results in\nlonger Cycle Times and poorer predictability. The obvious question we\nneed to ask is, “what is causing our increased WIP”? As always, that answer\nwill depend on your specific situation. Maybe the team is simply ignoring\nWIP limits and starting new work arbitrarily. Maybe several key team\nmembers have gone on holiday for extended periods of time. Maybe work\nis progressing slowly due to poor requirements or poor design. Any of these", "tokens": 301, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 87, "segment_id": "00087", "chapter_num": "6", "chapter_title": "Interpreting CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs", "chunk_id": "00000099"}
{"type": "chunk", "text": "and more might explain any of the bulging bands in Figure 6.4. What are\nsome of the causes for a pile up of work at your job? One thing to look out for in these situations, though, is that the cause\n\nof the increased WIP may not necessarily be found in the workflow step\nwhere the bulge appears. It could be due to a “push” from a previous step,\nor it could be cause by some blockage in one or more downstream steps. Do\nnot be lulled into thinking the problem is always in the obvious place. Additionally, remember earlier when I suggested that you should\nconsider separating your workflow steps into “Active” and “Done” and then\nyou should graph each of those sub-steps on your CFD? One reason I\nrecommend that approach is because those “Done” sub-steps are clearly\nqueuing columns---i.e., they are columns where no value add work is\nhappening; work is just sitting there waiting to be pulled. I mention this\nnow because while a bulging band in general is bad, a bulging band in a\nqueuing step can be especially bad. Ideally, the bands on the CFDs that\nrepresent the queuing states should be as thin as possible (I just told you\nwhy). Whenever those bands are constantly thick or whenever they bulge,\nthen that pattern is suggesting something is going wrong with our process. Disappearing Bands\nBands that disappear altogether on a Cumulative Flow Diagram could be\ntelling us one of several things. The first possibility is that the reporting\ninterval that we have chosen is too big. Consider, for example, that we\nchoose a reporting period of every week for our chart. Let’s further say that\nthe work in our Test column flows through very quickly (e.g., in a day or\ntwo). In this case it is very likely that on any given reporting interval there\nwill be zero Work In Progress in the test column such that the test band on\nthe CFD will not show up. An example of bands disappearing is depicted in\nFigure 6.5:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs\n\nand more might explain any of the bulging bands in Figure 6.4. What are\nsome of the causes for a pile up of work at your job? One thing to look out for in these situations, though, is that the cause\n\nof the increased WIP may not necessarily be found in the workflow step\nwhere the bulge appears. It could be due to a “push” from a previous step,\nor it could be cause by some blockage in one or more downstream steps. Do\nnot be lulled into thinking the problem is always in the obvious place. Additionally, remember earlier when I suggested that you should\nconsider separating your workflow steps into “Active” and “Done” and then\nyou should graph each of those sub-steps on your CFD? One reason I\nrecommend that approach is because those “Done” sub-steps are clearly\nqueuing columns---i.e., they are columns where no value add work is\nhappening; work is just sitting there waiting to be pulled. I mention this\nnow because while a bulging band in general is bad, a bulging band in a\nqueuing step can be especially bad. Ideally, the bands on the CFDs that\nrepresent the queuing states should be as thin as possible (I just told you\nwhy). Whenever those bands are constantly thick or whenever they bulge,\nthen that pattern is suggesting something is going wrong with our process. Disappearing Bands\nBands that disappear altogether on a Cumulative Flow Diagram could be\ntelling us one of several things. The first possibility is that the reporting\ninterval that we have chosen is too big. Consider, for example, that we\nchoose a reporting period of every week for our chart. Let’s further say that\nthe work in our Test column flows through very quickly (e.g., in a day or\ntwo). In this case it is very likely that on any given reporting interval there\nwill be zero Work In Progress in the test column such that the test band on\nthe CFD will not show up. An example of bands disappearing is depicted in\nFigure 6.5:", "tokens": 441, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 88, "segment_id": "00088", "chapter_num": "6", "chapter_title": "Interpreting CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs", "chunk_id": "00000100"}
{"type": "chunk", "text": "Figure 6.5: Disappearing Bands on a CFD\nA second cause for a disappearing band may be that some upstream\n\nvariability in our process is causing downstream steps to be starved. Another possibility, is that the team frequently decides to skip a certain\n\nstep in the workflow altogether resulting in that step not having any Work\nIn Progress at any given time. For example, it could be near the end of a\nrelease and the team has decided to skip the Test step in the workflow,\ndeciding instead to push work directly from Development into production. It would be up to you to decide given your particular context whether this is\ngood or bad. While obviously an exaggerated case, in this instance the Test\nband on the CFD would completely disappear---much like what is shown in\nFigure 6.5. The S-Curve\nRemember in the last chapter when I talked about the special case of Little’s\nLaw when system WIP is allowed to go to zero? I gave two classic\nexamples of when this might happen. First, a project usually begins with\nzero WIP and (ideally) ends with zero WIP. At a more granular level, an\nideal Scrum sprint starts with zero WIP and ends with zero WIP. I mention these examples again as the typical pattern that emerges on\n\nCFD between any two time instances of zero WIP is something called an\n“S-curve”. An S-curve is characterized by a flat beginning section, followed", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs\n\nFigure 6.5: Disappearing Bands on a CFD\nA second cause for a disappearing band may be that some upstream\n\nvariability in our process is causing downstream steps to be starved. Another possibility, is that the team frequently decides to skip a certain\n\nstep in the workflow altogether resulting in that step not having any Work\nIn Progress at any given time. For example, it could be near the end of a\nrelease and the team has decided to skip the Test step in the workflow,\ndeciding instead to push work directly from Development into production. It would be up to you to decide given your particular context whether this is\ngood or bad. While obviously an exaggerated case, in this instance the Test\nband on the CFD would completely disappear---much like what is shown in\nFigure 6.5. The S-Curve\nRemember in the last chapter when I talked about the special case of Little’s\nLaw when system WIP is allowed to go to zero? I gave two classic\nexamples of when this might happen. First, a project usually begins with\nzero WIP and (ideally) ends with zero WIP. At a more granular level, an\nideal Scrum sprint starts with zero WIP and ends with zero WIP. I mention these examples again as the typical pattern that emerges on\n\nCFD between any two time instances of zero WIP is something called an\n“S-curve”. An S-curve is characterized by a flat beginning section, followed", "tokens": 309, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 89, "segment_id": "00089", "chapter_num": "6", "chapter_title": "Interpreting CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs", "chunk_id": "00000101"}
{"type": "chunk", "text": "by a steep middle section, and finishing again with a flat end period. This\nflat, then steep, then flat pattern is what gives the graph its distinctive “S”\nshape as in Figure 6.6:\n\nFigure 6.6: An S-Curve on a CFD\nThe phenomena that causes this “S” pattern to emerge is beyond the\n\nscope of this section, but know that, as I have just stated, it usually happens\nbetween any two time instances when WIP is allowed to go to zero. The\nreason I mention this now is think about what this S-curve does from a\npredictability standpoint. In this context, do you think it is always easy to\nmatch arrival and departure rates? Is it even possible? Take it a step further. From a predictability perspective, do you think\n\nthat it is optimal to manage projects this way (remember, I am talking about\npredictability here, not necessarily about how accounting or finance sees the\nworld)? Do you think it is predicatively optimal to multiply this effect\nseveral times during the course of a project by breaking it up into several\nzero WIP-bounded sprints? How might we become more predictable day to\nday, week to week, month to month by never allowing WIP to go to zero? For example, in Figure 6.6 how do you think the team is doing at\nmatching arrivals to departures at both the beginning and end of this time\nperiod? Whether reasonable or not, what we can say is that those flat spots\nadd inefficiencies and kill predictability. Is there a better way to manage\nwork such that we do not have those start-stops and flat lines?", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs\n\nby a steep middle section, and finishing again with a flat end period. This\nflat, then steep, then flat pattern is what gives the graph its distinctive “S”\nshape as in Figure 6.6:\n\nFigure 6.6: An S-Curve on a CFD\nThe phenomena that causes this “S” pattern to emerge is beyond the\n\nscope of this section, but know that, as I have just stated, it usually happens\nbetween any two time instances when WIP is allowed to go to zero. The\nreason I mention this now is think about what this S-curve does from a\npredictability standpoint. In this context, do you think it is always easy to\nmatch arrival and departure rates? Is it even possible? Take it a step further. From a predictability perspective, do you think\n\nthat it is optimal to manage projects this way (remember, I am talking about\npredictability here, not necessarily about how accounting or finance sees the\nworld)? Do you think it is predicatively optimal to multiply this effect\nseveral times during the course of a project by breaking it up into several\nzero WIP-bounded sprints? How might we become more predictable day to\nday, week to week, month to month by never allowing WIP to go to zero? For example, in Figure 6.6 how do you think the team is doing at\nmatching arrivals to departures at both the beginning and end of this time\nperiod? Whether reasonable or not, what we can say is that those flat spots\nadd inefficiencies and kill predictability. Is there a better way to manage\nwork such that we do not have those start-stops and flat lines?", "tokens": 351, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 90, "segment_id": "00090", "chapter_num": "6", "chapter_title": "Interpreting CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs", "chunk_id": "00000102"}
{"type": "chunk", "text": "Just something to think about... A Boring CFD\nSuppose you have a CFD like Figure 6.7:\n\nFigure 6.7: A “Good-Looking” CFD\n\nEverything looks rather good, right? If it truly is, then it is time to start\n\nasking questions about other process improvement actions we might take. For example, is it possible to get the lines even closer together by reducing\nWIP and thus improving Cycle Time? What can we do to make the\nThroughput line steeper? The thing is, it is possible to get a very pretty CFD picture but still\n\nhave a very dysfunctional process underneath. The best example of this is\nthe accumulation of Flow Debt. But that topic is so important that it\ndeserves its own chapter as well (see Chapter 9). You may have noticed that I have not explicitly mentioned anything\nabout using CFDs to spot bottlenecks in your process. That omission was\non purpose. It is because I am dubious about that approach. This may\nsurprise you as if you have read anything about CFDs, you have probably\nread how useful they are to spot bottlenecks. I do not agree with this\nlanguage. I believe that the best you can do by just looking at a CFD is to\npose some questions about some variability that may be occurring. It is\nimpossible to spot a systemic bottleneck. This may seem like a subtle", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs\n\nJust something to think about... A Boring CFD\nSuppose you have a CFD like Figure 6.7:\n\nFigure 6.7: A “Good-Looking” CFD\n\nEverything looks rather good, right? If it truly is, then it is time to start\n\nasking questions about other process improvement actions we might take. For example, is it possible to get the lines even closer together by reducing\nWIP and thus improving Cycle Time? What can we do to make the\nThroughput line steeper? The thing is, it is possible to get a very pretty CFD picture but still\n\nhave a very dysfunctional process underneath. The best example of this is\nthe accumulation of Flow Debt. But that topic is so important that it\ndeserves its own chapter as well (see Chapter 9). You may have noticed that I have not explicitly mentioned anything\nabout using CFDs to spot bottlenecks in your process. That omission was\non purpose. It is because I am dubious about that approach. This may\nsurprise you as if you have read anything about CFDs, you have probably\nread how useful they are to spot bottlenecks. I do not agree with this\nlanguage. I believe that the best you can do by just looking at a CFD is to\npose some questions about some variability that may be occurring. It is\nimpossible to spot a systemic bottleneck. This may seem like a subtle", "tokens": 300, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 91, "segment_id": "00091", "chapter_num": "6", "chapter_title": "Interpreting CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs", "chunk_id": "00000103"}
{"type": "chunk", "text": "distinction to you, but I prefer Deming’s and Shewhart’s language of\nvariability to that of Goldratt’s language of the Theory of Constraints. I\nthink you will get much more bang for the buck thinking about knowledge\nwork in this way. I feel so strongly about this that I a chapter to this\ndiscussion later (Chapter 13). Conclusion\nA discussion of all possible patterns that could emerge on a CFD would be a\nwhole book in itself (hmmm...good idea). What I have given you here are\nsome of the more common things you will come across. I am hoping you\nwill use these examples along with your quantitative analysis knowledge to\ndiscover the right questions to ask sooner. Remember that the point of CFD\nanalysis is not just about looking at a pretty picture. The point is to look at\nthe graph in the context in which it was generated and have a discussion\nabout what the patterns mean to overall process performance and\npredictability. Thus, the real purpose for analyzing a CFD is to learn. You\nlearn by asking questions. “What’s going on with our flow?” “Is it a good\nthing or bad thing?” “If good, how can we keep doing it?” “If bad, what\ninterventions can we take to make things better?” A CFD not only gets you\nasking the right questions sooner, but will also suggest the right actions to\ntake for increased predictability. I started my discussion of CFDs by saying that not only is most of the\n\ninformation out there in the Agile-o-sphere incorrect concerning these\ncharts, but also that all tools that I have come across (at the time of this\nwriting) generate these graphs incorrectly (save the one which I will discuss\nin a minute). So what are you to do? One option is to capture the data manually as I have outlined here and\ngenerate the chart yourself using something like Excel. This is a reasonable\napproach and one that many teams utilize. The problem with Excel is it is\nnot a very dynamic or interactive way to analyze the data. It also becomes\ncumbersome as your dataset gets very large. The second option is to use the ActionableAgileTM Analytics tool. This\ntool was built for the sole purpose of the advanced analysis of these metrics\nof flow.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs\n\ndistinction to you, but I prefer Deming’s and Shewhart’s language of\nvariability to that of Goldratt’s language of the Theory of Constraints. I\nthink you will get much more bang for the buck thinking about knowledge\nwork in this way. I feel so strongly about this that I a chapter to this\ndiscussion later (Chapter 13). Conclusion\nA discussion of all possible patterns that could emerge on a CFD would be a\nwhole book in itself (hmmm...good idea). What I have given you here are\nsome of the more common things you will come across. I am hoping you\nwill use these examples along with your quantitative analysis knowledge to\ndiscover the right questions to ask sooner. Remember that the point of CFD\nanalysis is not just about looking at a pretty picture. The point is to look at\nthe graph in the context in which it was generated and have a discussion\nabout what the patterns mean to overall process performance and\npredictability. Thus, the real purpose for analyzing a CFD is to learn. You\nlearn by asking questions. “What’s going on with our flow?” “Is it a good\nthing or bad thing?” “If good, how can we keep doing it?” “If bad, what\ninterventions can we take to make things better?” A CFD not only gets you\nasking the right questions sooner, but will also suggest the right actions to\ntake for increased predictability. I started my discussion of CFDs by saying that not only is most of the\n\ninformation out there in the Agile-o-sphere incorrect concerning these\ncharts, but also that all tools that I have come across (at the time of this\nwriting) generate these graphs incorrectly (save the one which I will discuss\nin a minute). So what are you to do? One option is to capture the data manually as I have outlined here and\ngenerate the chart yourself using something like Excel. This is a reasonable\napproach and one that many teams utilize. The problem with Excel is it is\nnot a very dynamic or interactive way to analyze the data. It also becomes\ncumbersome as your dataset gets very large. The second option is to use the ActionableAgileTM Analytics tool. This\ntool was built for the sole purpose of the advanced analysis of these metrics\nof flow.", "tokens": 485, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 92, "segment_id": "00092", "chapter_num": "6", "chapter_title": "Interpreting CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs", "chunk_id": "00000104"}
{"type": "chunk", "text": "So what are you to do? One option is to capture the data manually as I have outlined here and\ngenerate the chart yourself using something like Excel. This is a reasonable\napproach and one that many teams utilize. The problem with Excel is it is\nnot a very dynamic or interactive way to analyze the data. It also becomes\ncumbersome as your dataset gets very large. The second option is to use the ActionableAgileTM Analytics tool. This\ntool was built for the sole purpose of the advanced analysis of these metrics\nof flow. At the risk of putting forth a shameless plug, the\nActionableAgileTM Analytics tool was created by my company, so you can\nbe sure that any and all charts that are created by it are generated correctly", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs\n\nSo what are you to do? One option is to capture the data manually as I have outlined here and\ngenerate the chart yourself using something like Excel. This is a reasonable\napproach and one that many teams utilize. The problem with Excel is it is\nnot a very dynamic or interactive way to analyze the data. It also becomes\ncumbersome as your dataset gets very large. The second option is to use the ActionableAgileTM Analytics tool. This\ntool was built for the sole purpose of the advanced analysis of these metrics\nof flow. At the risk of putting forth a shameless plug, the\nActionableAgileTM Analytics tool was created by my company, so you can\nbe sure that any and all charts that are created by it are generated correctly", "tokens": 158, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 92, "segment_id": "00092", "chapter_num": "6", "chapter_title": "Interpreting CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs", "chunk_id": "00000105"}
{"type": "chunk", "text": "(the ActionableAgileTM Analytics tool is also great tool for generating\nCycle Time Scatterplots---I will discuss Scatterplots in Chapters 10-12). There is a lot of chatter out there about the uselessness of Cumulative\nFlow Diagrams. Those discussions are disappointing because a lot of these\ncomments come from well-known persons within the industry. Obviously, I\nam biased so all I want to suggest is that after reading this chapter (and this\nbook) you will make your own mind up about the utility of CFDs. I am\nhoping to have persuaded you otherwise by the time you finish. The last thing to note is that the predictive power of your CFDs\ndepends almost entirely on how well your process obeys the assumptions\nbehind Little’s Law (Chapter 3). This point is so important, that the next\nthree chapters will explain how to spot violations of Little’s Law on your\ncharts and what you can do to correct them. Key Learnings and Takeaways\n\nOn your CFD, does arrival rate match departure rate? Are there any bulges in the workflow step bands? Do any bands disappear? Are there any long periods of flat lines? Are there stair steps? Is there an S-curve? Think about improvements to consider if everything looks good on\nyour CFD.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs\n\n(the ActionableAgileTM Analytics tool is also great tool for generating\nCycle Time Scatterplots---I will discuss Scatterplots in Chapters 10-12). There is a lot of chatter out there about the uselessness of Cumulative\nFlow Diagrams. Those discussions are disappointing because a lot of these\ncomments come from well-known persons within the industry. Obviously, I\nam biased so all I want to suggest is that after reading this chapter (and this\nbook) you will make your own mind up about the utility of CFDs. I am\nhoping to have persuaded you otherwise by the time you finish. The last thing to note is that the predictive power of your CFDs\ndepends almost entirely on how well your process obeys the assumptions\nbehind Little’s Law (Chapter 3). This point is so important, that the next\nthree chapters will explain how to spot violations of Little’s Law on your\ncharts and what you can do to correct them. Key Learnings and Takeaways\n\nOn your CFD, does arrival rate match departure rate? Are there any bulges in the workflow step bands? Do any bands disappear? Are there any long periods of flat lines? Are there stair steps? Is there an S-curve? Think about improvements to consider if everything looks good on\nyour CFD.", "tokens": 272, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 93, "segment_id": "00093", "chapter_num": "6", "chapter_title": "Interpreting CFDs", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 6: Interpreting CFDs", "chunk_id": "00000106"}
{"type": "chunk", "text": "Chapter 7 - Conservation of Flow Part I\n\nImagine, for a second, an airport where the rate at which planes landed far\nexceeded the rate at which planes took off. Very little further imagination is\nneeded to come to the conclusion that, in this scenario, the total number of\nplanes situated at the airport would dramatically increase over time. It would\nnot be too long before all the available gates at the airport became occupied\nand that air traffic control (ATC) would be forced to find creative places to\npark the extra aircraft. If the situation continued, sooner or later all\nreasonable space at the airport would fill up, including utilizing any space\navailable on active runways. As soon as runways were occupied, no new\nplanes would be able to land nor would any planes scheduled for departure\nbe able to take off. Obviously, in the real world, air traffic control does everything it can to\n\navoid this nightmare scenario. It is for this precise reason why if a certain\nairport---let’s say Chicago’s O’Hare (ORD)---is experiencing weather or\nsome other reduction of capacity, that ATC slows down planes in the air\nheaded to ORD or they put a ground stop on all other airports that have\naircraft scheduled to travel to ORD. Anyone who travels with any amount of\nregularity has probably experienced an incident like this. You can bet that\nATC is closely monitoring and managing the rate at which planes take off at\nany given airport and they are doing everything they can to match that take\noff rate to the pace at which planes land. You do not have to think too long to come up with many similar\nexamples. The principle remains the same: any time you try to shove items\ninto a system at a faster rate than items can exit the system, you are met with\ndisastrous consequences. This principle seems immediately obvious and\nintuitive. Yet, for whatever reason, we constantly ignore this rule when we\nmanage knowledge work. It is exactly this phenomenon that Little’s Law\nassumption #1 is trying to address. Remember from Chapter 3 that:\n\nLittle’s Law Assumption #1: The average input or Arrival Rate of a process should\nequal the average output or Departure Rate.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\nChapter 7 - Conservation of Flow Part I\n\nImagine, for a second, an airport where the rate at which planes landed far\nexceeded the rate at which planes took off. Very little further imagination is\nneeded to come to the conclusion that, in this scenario, the total number of\nplanes situated at the airport would dramatically increase over time. It would\nnot be too long before all the available gates at the airport became occupied\nand that air traffic control (ATC) would be forced to find creative places to\npark the extra aircraft. If the situation continued, sooner or later all\nreasonable space at the airport would fill up, including utilizing any space\navailable on active runways. As soon as runways were occupied, no new\nplanes would be able to land nor would any planes scheduled for departure\nbe able to take off. Obviously, in the real world, air traffic control does everything it can to\n\navoid this nightmare scenario. It is for this precise reason why if a certain\nairport---let’s say Chicago’s O’Hare (ORD)---is experiencing weather or\nsome other reduction of capacity, that ATC slows down planes in the air\nheaded to ORD or they put a ground stop on all other airports that have\naircraft scheduled to travel to ORD. Anyone who travels with any amount of\nregularity has probably experienced an incident like this. You can bet that\nATC is closely monitoring and managing the rate at which planes take off at\nany given airport and they are doing everything they can to match that take\noff rate to the pace at which planes land. You do not have to think too long to come up with many similar\nexamples. The principle remains the same: any time you try to shove items\ninto a system at a faster rate than items can exit the system, you are met with\ndisastrous consequences. This principle seems immediately obvious and\nintuitive. Yet, for whatever reason, we constantly ignore this rule when we\nmanage knowledge work. It is exactly this phenomenon that Little’s Law\nassumption #1 is trying to address. Remember from Chapter 3 that:\n\nLittle’s Law Assumption #1: The average input or Arrival Rate of a process should\nequal the average output or Departure Rate.", "tokens": 466, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 94, "segment_id": "00094", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000107"}
{"type": "chunk", "text": "Stated in more layman’s terms, Little’s Law demands that we only start\n\nwork at about the same rate at which we finish old work (on average). Assumption #1 constitutes the first part of a principle known of the\nConservation of Flow (CoF). Any time that flow is not conserved,\npredictability suffers. Defining Arrivals\nTo understand if flow is not being conserved in your process, you first need\nto clearly define an arrival point, and clearly define departure point. I refer\nyou once again to Figure 2.1 (the queuing system diagram from Chapter 2). To apply CoF to predictability, we must design a system that clearly mimics\nwhat is going on in that diagram. Let’s consider arrivals first. That is, we need to establish an explicit and\nobvious entry point where teams can pull in new work such that it is counted\nas WIP. This entry point usually takes the form of a WIP-limited column on\nthe front of your process, and you will normally see this column labeled as\n“Input” or “Ready” or “To Do” or the like (more on how to set the WIP limit\non this column a little later in this chapter). An example of what this column\nmight look like is shown in Figure 7.1:\n\nFigure 7.1: Arrivals into a Kanban System\n\nIn Figure 7.1, items that have been placed onto the “Ready” column are\n\nsaid to have arrived into the process. This column represents a clear,", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\nStated in more layman’s terms, Little’s Law demands that we only start\n\nwork at about the same rate at which we finish old work (on average). Assumption #1 constitutes the first part of a principle known of the\nConservation of Flow (CoF). Any time that flow is not conserved,\npredictability suffers. Defining Arrivals\nTo understand if flow is not being conserved in your process, you first need\nto clearly define an arrival point, and clearly define departure point. I refer\nyou once again to Figure 2.1 (the queuing system diagram from Chapter 2). To apply CoF to predictability, we must design a system that clearly mimics\nwhat is going on in that diagram. Let’s consider arrivals first. That is, we need to establish an explicit and\nobvious entry point where teams can pull in new work such that it is counted\nas WIP. This entry point usually takes the form of a WIP-limited column on\nthe front of your process, and you will normally see this column labeled as\n“Input” or “Ready” or “To Do” or the like (more on how to set the WIP limit\non this column a little later in this chapter). An example of what this column\nmight look like is shown in Figure 7.1:\n\nFigure 7.1: Arrivals into a Kanban System\n\nIn Figure 7.1, items that have been placed onto the “Ready” column are\n\nsaid to have arrived into the process. This column represents a clear,", "tokens": 327, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 95, "segment_id": "00095", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000108"}
{"type": "chunk", "text": "unambiguous signal to the world that the team has accepted work. Please note that this arrivals column is very different from a more\ntraditional backlog. It is not meant to be an ever-expanding repository for all\ncandidate customer requests. The WIP Limit on this column represents the\nreal-time capacity of the system to take on new work, and serves to force us\nto only pull in new work in a just-in-time manner. This is one of the reasons\nwhy---as I stated in Chapter 5---that this Ready column would be displayed\non a CFD while the backlog would not. We implicitly stated a couple of policies here, so let’s make those\npolicies explicit. First, we have said that work items are only considered to\nhave arrived into our system once they are placed onto our “arrivals” column\n(the “Ready” column in Figure 7.1). Second, this arrivals column will have a\nWIP limit on it and that we will only pull new work into the system when\nthat WIP limit signals that we have capacity to do so. And third, since work\ncan only arrive via this first column, the downstream steps of our process\ncan only consider pulling work from there. Since what we are ultimately looking for is an understanding of the rate\n\nof arrivals into the system, then measuring that rate now simply becomes a\nmatter of counting the number of new work items placed onto that arrivals\ncolumn per unit time. The unit or interval of time you choose is completely\nup to you (day, week, every two weeks), but one thing you must keep in\nmind is that the unit of time you choose to measure the Arrival Rate must\nmatch the unit of time that you choose to measure your Departure Rate (I\nwill discuss Departure Rate shortly). Thus, if you measure Arrival Rate in\nweeks, then you should also measure the Departure Rate in weeks. A very subtle but very important point to note here is that choosing the\nsame interval of time to measure arrivals and departures does not mean that\nthe cadence of arrivals and departures must be the same. For example, your\nteam could choose to deploy to production at a cadence of every two weeks,\nbut could also choose to replenish the input column every week. Not only is\nstaggering cadences like that perfectly acceptable, it might be optimal given\nyour specific context. However, it makes comparing Arrival Rates and\nDeparture Rates slightly more complicated.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\nunambiguous signal to the world that the team has accepted work. Please note that this arrivals column is very different from a more\ntraditional backlog. It is not meant to be an ever-expanding repository for all\ncandidate customer requests. The WIP Limit on this column represents the\nreal-time capacity of the system to take on new work, and serves to force us\nto only pull in new work in a just-in-time manner. This is one of the reasons\nwhy---as I stated in Chapter 5---that this Ready column would be displayed\non a CFD while the backlog would not. We implicitly stated a couple of policies here, so let’s make those\npolicies explicit. First, we have said that work items are only considered to\nhave arrived into our system once they are placed onto our “arrivals” column\n(the “Ready” column in Figure 7.1). Second, this arrivals column will have a\nWIP limit on it and that we will only pull new work into the system when\nthat WIP limit signals that we have capacity to do so. And third, since work\ncan only arrive via this first column, the downstream steps of our process\ncan only consider pulling work from there. Since what we are ultimately looking for is an understanding of the rate\n\nof arrivals into the system, then measuring that rate now simply becomes a\nmatter of counting the number of new work items placed onto that arrivals\ncolumn per unit time. The unit or interval of time you choose is completely\nup to you (day, week, every two weeks), but one thing you must keep in\nmind is that the unit of time you choose to measure the Arrival Rate must\nmatch the unit of time that you choose to measure your Departure Rate (I\nwill discuss Departure Rate shortly). Thus, if you measure Arrival Rate in\nweeks, then you should also measure the Departure Rate in weeks. A very subtle but very important point to note here is that choosing the\nsame interval of time to measure arrivals and departures does not mean that\nthe cadence of arrivals and departures must be the same. For example, your\nteam could choose to deploy to production at a cadence of every two weeks,\nbut could also choose to replenish the input column every week. Not only is\nstaggering cadences like that perfectly acceptable, it might be optimal given\nyour specific context. However, it makes comparing Arrival Rates and\nDeparture Rates slightly more complicated.", "tokens": 512, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 96, "segment_id": "00096", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000109"}
{"type": "chunk", "text": "A very subtle but very important point to note here is that choosing the\nsame interval of time to measure arrivals and departures does not mean that\nthe cadence of arrivals and departures must be the same. For example, your\nteam could choose to deploy to production at a cadence of every two weeks,\nbut could also choose to replenish the input column every week. Not only is\nstaggering cadences like that perfectly acceptable, it might be optimal given\nyour specific context. However, it makes comparing Arrival Rates and\nDeparture Rates slightly more complicated. If your Throughput data is in\nterms of two week intervals and your arrival data is in terms of one week\nintervals, then you will have to do some conversion to get them to the same\nunit of time. Whether you choose to convert Throughput data from two week\nperiods to one week periods or whether you choose to convert arrival data", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\nA very subtle but very important point to note here is that choosing the\nsame interval of time to measure arrivals and departures does not mean that\nthe cadence of arrivals and departures must be the same. For example, your\nteam could choose to deploy to production at a cadence of every two weeks,\nbut could also choose to replenish the input column every week. Not only is\nstaggering cadences like that perfectly acceptable, it might be optimal given\nyour specific context. However, it makes comparing Arrival Rates and\nDeparture Rates slightly more complicated. If your Throughput data is in\nterms of two week intervals and your arrival data is in terms of one week\nintervals, then you will have to do some conversion to get them to the same\nunit of time. Whether you choose to convert Throughput data from two week\nperiods to one week periods or whether you choose to convert arrival data", "tokens": 189, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 96, "segment_id": "00096", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000110"}
{"type": "chunk", "text": "from one week to two week periods is completely up to you. Just know that\nwhatever unit of time you choose for your reporting must be consistent\nacross all metrics. It will be an interesting and important exercise for you to\nfigure out the optimal reporting interval for your specific context. Defining Departures\nIn a similar fashion, we are going to need to establish a clear, unambiguous\ndeparture point for our system. Items that pass this point do not necessarily\nhave to be visualized---though most teams do choose to dedicate space on\ntheir board for departures---but they do need to be counted. If the departure\ncolumn is visualized, then you will normally see it with the title “Done” or\n“Deployed” or the like. Typically speaking, if a team chooses to represent\nthe departures column on their board, then it will not have a WIP Limit on it. Regardless of the visualization employed, it is important to define the exact\npoint of the system where work departs, (hopefully) never to return. For\nexample, this could be the point where we deploy code to production or the\npoint at which we hand an item off to a downstream team (see Figure 7.2). Figure 7.2: Items that have departed from the system\n\nIn Figure 7.2, the demarcation line between “in our process” and “not in\n\nour process” is the line that separates the “Test” column from the\n“Deployed” column. More importantly, the expectation here is that the team\nhas put in place a set of policies for what it means for items to move from", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\nfrom one week to two week periods is completely up to you. Just know that\nwhatever unit of time you choose for your reporting must be consistent\nacross all metrics. It will be an interesting and important exercise for you to\nfigure out the optimal reporting interval for your specific context. Defining Departures\nIn a similar fashion, we are going to need to establish a clear, unambiguous\ndeparture point for our system. Items that pass this point do not necessarily\nhave to be visualized---though most teams do choose to dedicate space on\ntheir board for departures---but they do need to be counted. If the departure\ncolumn is visualized, then you will normally see it with the title “Done” or\n“Deployed” or the like. Typically speaking, if a team chooses to represent\nthe departures column on their board, then it will not have a WIP Limit on it. Regardless of the visualization employed, it is important to define the exact\npoint of the system where work departs, (hopefully) never to return. For\nexample, this could be the point where we deploy code to production or the\npoint at which we hand an item off to a downstream team (see Figure 7.2). Figure 7.2: Items that have departed from the system\n\nIn Figure 7.2, the demarcation line between “in our process” and “not in\n\nour process” is the line that separates the “Test” column from the\n“Deployed” column. More importantly, the expectation here is that the team\nhas put in place a set of policies for what it means for items to move from", "tokens": 342, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 97, "segment_id": "00097", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000111"}
{"type": "chunk", "text": "Test to Deployed, and that once those items are in Deployed, they no longer\ncount against the capacity of the team; i.e., they no longer count as WIP. Measuring the rate of departures from the system is exactly the same as\n\nmeasuring the rate of arrivals. We simply count the number of work items\nplaced into Deployed (that have “crossed the line” so to speak) per unit of\ntime. Again, the unit or interval of time is not important, only that you match\nyour departures interval to your arrivals interval as discussed above. Once you have tracked your Arrival and Departure Rates for an\n\narbitrarily long period of time (though the amount of time needed for “good”\ndata might be much shorter than you think---perhaps as little as a few\nweeks), then you can average those two rates and compare them. If those\ntwo averages come out to be the same, then you are in good shape. My\nguess, though, is that your two average rates will be different. I am going to\ndiscuss what that difference means and some actions to take to correct them\nin a minute, but first I would like to talk about a better method for\nperforming the above analysis. Arrivals and Departures on a CFD\nThere is a much better way to visualize whether the Average Arrival Rate\nequals the Average Departure Rate for your system. This better method is to\nperform the preceding analysis using a Cumulative Flow Diagram. Let’s suppose we are running a Kanban board that looks like the one in\n\nFigure 7.3:\n\nFigure 7.3: Example Kanban Board\n\nNote that this particular team has chosen to name their arrivals column\n\n“Input”, and that they have limited that column to five work items in\nprogress at a time. Note also that the team has chosen to display the", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\nTest to Deployed, and that once those items are in Deployed, they no longer\ncount against the capacity of the team; i.e., they no longer count as WIP. Measuring the rate of departures from the system is exactly the same as\n\nmeasuring the rate of arrivals. We simply count the number of work items\nplaced into Deployed (that have “crossed the line” so to speak) per unit of\ntime. Again, the unit or interval of time is not important, only that you match\nyour departures interval to your arrivals interval as discussed above. Once you have tracked your Arrival and Departure Rates for an\n\narbitrarily long period of time (though the amount of time needed for “good”\ndata might be much shorter than you think---perhaps as little as a few\nweeks), then you can average those two rates and compare them. If those\ntwo averages come out to be the same, then you are in good shape. My\nguess, though, is that your two average rates will be different. I am going to\ndiscuss what that difference means and some actions to take to correct them\nin a minute, but first I would like to talk about a better method for\nperforming the above analysis. Arrivals and Departures on a CFD\nThere is a much better way to visualize whether the Average Arrival Rate\nequals the Average Departure Rate for your system. This better method is to\nperform the preceding analysis using a Cumulative Flow Diagram. Let’s suppose we are running a Kanban board that looks like the one in\n\nFigure 7.3:\n\nFigure 7.3: Example Kanban Board\n\nNote that this particular team has chosen to name their arrivals column\n\n“Input”, and that they have limited that column to five work items in\nprogress at a time. Note also that the team has chosen to display the", "tokens": 390, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 98, "segment_id": "00098", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000112"}
{"type": "chunk", "text": "departures column and that they have labelled that column “Done”. This\ndepartures column is WIP unlimited and the implication is that they have put\nin place explicit policies for what it means for items to be moved from\n“Test” to “Done”. So what might a CFD look like for a board like this? It might look like\n\nthe one shown in Figure 7.4:\n\nFigure 7.4: An Example CFD\n\nFrom Chapter 4, we know that each layer of this CFD represents a step\n\nin the workflow of the Kanban board shown in Figure 7.3. We also know\nthat the slope of the top line of the topmost layer represents the Arrival Rate\nof the process and the slope of the top line of the bottommost band\nrepresents the Departure Rate (or Throughput). You can see from Figure 7.4\nthat those rates have been calculated to be 3.72 items per day and 2.74 items\nper day for the Arrival and Departure Rates, respectively. This calculation\ntells us that items are arriving to the process faster than items are leaving the\nprocess at about the rate of one item per day. What might the implications of\nthis situation be? The nice thing about CFDs, however, is that we need not necessarily\n\nperform this quantitative analysis to see that something is going wrong with\nour system. CFDs are such a powerful visualization technique that we can\nquite quickly do a qualitative assessment of the health of our system.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\ndepartures column and that they have labelled that column “Done”. This\ndepartures column is WIP unlimited and the implication is that they have put\nin place explicit policies for what it means for items to be moved from\n“Test” to “Done”. So what might a CFD look like for a board like this? It might look like\n\nthe one shown in Figure 7.4:\n\nFigure 7.4: An Example CFD\n\nFrom Chapter 4, we know that each layer of this CFD represents a step\n\nin the workflow of the Kanban board shown in Figure 7.3. We also know\nthat the slope of the top line of the topmost layer represents the Arrival Rate\nof the process and the slope of the top line of the bottommost band\nrepresents the Departure Rate (or Throughput). You can see from Figure 7.4\nthat those rates have been calculated to be 3.72 items per day and 2.74 items\nper day for the Arrival and Departure Rates, respectively. This calculation\ntells us that items are arriving to the process faster than items are leaving the\nprocess at about the rate of one item per day. What might the implications of\nthis situation be? The nice thing about CFDs, however, is that we need not necessarily\n\nperform this quantitative analysis to see that something is going wrong with\nour system. CFDs are such a powerful visualization technique that we can\nquite quickly do a qualitative assessment of the health of our system.", "tokens": 319, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 99, "segment_id": "00099", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000113"}
{"type": "chunk", "text": "For example, imagine you had CFD that looked like the one in Figure\n\n7.5:\n\nFigure 7.5: Quick Qualitative Assessment of CFD\n\nIt would not take you long to figure out that there was something wrong\n\nwith your process. In this picture it is quite obvious---without doing any\nquantitative analysis---that work is arriving into your system at a much faster\nrate than work is departing from you system. A few paragraphs ago I asked\nyou to think about the implication of this particular situation. To answer that\nquestion we need to reexamine how WIP and Cycle Time are visualized on\nCFDs. From Chapter 5, we know that WIP is the vertical distance between\narrivals and departures and that Approximate Average Cycle Time is the\nhorizontal distance between arrivals and departures. These properties are\nsummed up in Figure 7.6:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\nFor example, imagine you had CFD that looked like the one in Figure\n\n7.5:\n\nFigure 7.5: Quick Qualitative Assessment of CFD\n\nIt would not take you long to figure out that there was something wrong\n\nwith your process. In this picture it is quite obvious---without doing any\nquantitative analysis---that work is arriving into your system at a much faster\nrate than work is departing from you system. A few paragraphs ago I asked\nyou to think about the implication of this particular situation. To answer that\nquestion we need to reexamine how WIP and Cycle Time are visualized on\nCFDs. From Chapter 5, we know that WIP is the vertical distance between\narrivals and departures and that Approximate Average Cycle Time is the\nhorizontal distance between arrivals and departures. These properties are\nsummed up in Figure 7.6:", "tokens": 186, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 100, "segment_id": "00100", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000114"}
{"type": "chunk", "text": "Figure 7.6: Flow Metrics on a CFD\nBut look what was going on earlier on in this diagram. When the\nArrival Rate and Departure Rate lines were much closer together, you can\nsee that WIP was much smaller and Approximate Average Cycle Times were\nmuch shorter. As arrivals continued to outpace departures---as the arrival\nline diverged from the departure line---the amount of WIP in the system got\nlarger and larger and the Approximate Average Cycle Times got longer and\nlonger (as shown in Figure 7.7).", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\nFigure 7.6: Flow Metrics on a CFD\nBut look what was going on earlier on in this diagram. When the\nArrival Rate and Departure Rate lines were much closer together, you can\nsee that WIP was much smaller and Approximate Average Cycle Times were\nmuch shorter. As arrivals continued to outpace departures---as the arrival\nline diverged from the departure line---the amount of WIP in the system got\nlarger and larger and the Approximate Average Cycle Times got longer and\nlonger (as shown in Figure 7.7).", "tokens": 120, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 101, "segment_id": "00101", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000115"}
{"type": "chunk", "text": "Figure 7.7: The Implication of Arrivals faster than Departures\n\nIn a situation like this, you have almost no chance at predictability. The\nactionable intervention suggested by a CFD that looks like Figure 5.5 is that\nwe must get arrivals to match departures. So how exactly do we get arrivals to match departures? The first thing\n\nwe would do is to calculate the average Throughput off of the diagram. Let’s\nsay, for argument’s sake, that we deploy items off our process at a cadence\nof once per week. Let’s additionally say that the average Departure Rate of\nthose deployed items comes out to five items per week (note here that we are\nchoosing “week” as our unit of time). That number, five, gives us a clue as to\nwhat the WIP limit should be on our arrivals column. Since we are finishing\nfive old items per week, that means we only want to start five new items per\nweek. The implication here being that we would want to set a WIP Limit of\nfive on the arrivals column (depending on the variability of our system, we\nmight want to make that WIP Limit a little larger---say six or so---to make\nsure that our system is never starved for work). An important subtlety here is\nthat the WIP Limit of five on the arrivals column assumes that you are\nreplenishing the arrivals column at the same cadence as which you are", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\nFigure 7.7: The Implication of Arrivals faster than Departures\n\nIn a situation like this, you have almost no chance at predictability. The\nactionable intervention suggested by a CFD that looks like Figure 5.5 is that\nwe must get arrivals to match departures. So how exactly do we get arrivals to match departures? The first thing\n\nwe would do is to calculate the average Throughput off of the diagram. Let’s\nsay, for argument’s sake, that we deploy items off our process at a cadence\nof once per week. Let’s additionally say that the average Departure Rate of\nthose deployed items comes out to five items per week (note here that we are\nchoosing “week” as our unit of time). That number, five, gives us a clue as to\nwhat the WIP limit should be on our arrivals column. Since we are finishing\nfive old items per week, that means we only want to start five new items per\nweek. The implication here being that we would want to set a WIP Limit of\nfive on the arrivals column (depending on the variability of our system, we\nmight want to make that WIP Limit a little larger---say six or so---to make\nsure that our system is never starved for work). An important subtlety here is\nthat the WIP Limit of five on the arrivals column assumes that you are\nreplenishing the arrivals column at the same cadence as which you are", "tokens": 311, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 102, "segment_id": "00102", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000116"}
{"type": "chunk", "text": "deploying; i.e., once per week. But remember from before, that this need not\nbe the case. If you wanted to replenish the input column once a day, then you\nwould need to divide the original Arrival Rate number, five, by the number\nof times per week that you would do the replenishment (in this case five). Since five divided by five is one, then your new WIP limit on the arrivals\ncolumn would be one. Properly setting the WIP limit on the arrivals column will allow you to\n\nmatch the average Arrival Rate of items into your system with the average\nDeparture Rate of items out of your system. When we do this, we will get a\nCFD that looks something like Figure 7.8:\n\nFigure 7.8: Average Arrival Rate equals Average Departure Rate\nIt should be immediately obvious from looking at the CFD in Figure\n7.8 that the situation here is much better than that illustrated in Figure 7.5. As we will see in a subsequent chapter, having a pretty CFD is not a\nguarantee of a healthy system, but it is certainly a pretty decent start. By the way, any time you expressly limit WIP throughout your\nworkflow, and, more importantly, any time you honor the WIP limit(s) you\nhave set, you will get a picture that looks like Figure 7.8. What I am saying\nis that you must operate a constant WIP style of pull system. Setting a WIP", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\ndeploying; i.e., once per week. But remember from before, that this need not\nbe the case. If you wanted to replenish the input column once a day, then you\nwould need to divide the original Arrival Rate number, five, by the number\nof times per week that you would do the replenishment (in this case five). Since five divided by five is one, then your new WIP limit on the arrivals\ncolumn would be one. Properly setting the WIP limit on the arrivals column will allow you to\n\nmatch the average Arrival Rate of items into your system with the average\nDeparture Rate of items out of your system. When we do this, we will get a\nCFD that looks something like Figure 7.8:\n\nFigure 7.8: Average Arrival Rate equals Average Departure Rate\nIt should be immediately obvious from looking at the CFD in Figure\n7.8 that the situation here is much better than that illustrated in Figure 7.5. As we will see in a subsequent chapter, having a pretty CFD is not a\nguarantee of a healthy system, but it is certainly a pretty decent start. By the way, any time you expressly limit WIP throughout your\nworkflow, and, more importantly, any time you honor the WIP limit(s) you\nhave set, you will get a picture that looks like Figure 7.8. What I am saying\nis that you must operate a constant WIP style of pull system. Setting a WIP", "tokens": 315, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 103, "segment_id": "00103", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000117"}
{"type": "chunk", "text": "limit on the arrivals column is a necessary---but not sufficient---means to\nbalancing arrivals and departures. For example, imagine that we have no\nexplicit limit on our Test column but that we do have a WIP limit on the\narrivals column. As work gets pulled (pushed, really) into Test because of\nthe lack of a WIP limit, then that action will ultimately cause a pull of work\nfrom the arrivals column. Work getting pulled from the arrivals column will\nsignal to the world that there is capacity to start new work and thus the\narrivals column will be replenished even though no work has been\ncompleted. I hope it is easy to see that in this scenario how we can have\nitems that arrive to our system faster than items that depart our system. So\ndo not think your work is done by just limiting WIP at the front of your\nprocess. You must make sure that a constant amount of WIP (on average) is\nmaintained throughout the whole process. Remember, the further you stray\naway from this principle, the less predictable you will be. Limiting WIP on the arrivals column in the manner described here is\n\none way to ensure that not too much work is started and just queuing at the\nbeginning of your process. I have said it before, and I will say it again: delay\nis the enemy of flow. This approach will ensure a proper balance between\nhaving enough work to start such that your process is not starved and not\nhaving too much work such that work begins but just sits. By the way, once we get a picture that looks like Figure 7.8, we will\n\nhave taken the first---and probably most important---step to balance the\ndemand on your system against the supply that your team can offer. We are\nnow very far down the path to true process predictability. Most Kanban boards have an explicit arrivals column at the front of the\n\nprocess, but this is by no means a requirement. It is completely reasonable\nthat your particular work context allows your team to pull new work items in\nan immediate, ad hoc manner. That is to say, you need no coordination with\nany external stakeholder to prioritize items or you have a proxy for those\nstakeholders embedded with your team. In this case the arrivals column\n(e.g., the “To Do” or “Input” or “Ready” column) may be superfluous.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\nlimit on the arrivals column is a necessary---but not sufficient---means to\nbalancing arrivals and departures. For example, imagine that we have no\nexplicit limit on our Test column but that we do have a WIP limit on the\narrivals column. As work gets pulled (pushed, really) into Test because of\nthe lack of a WIP limit, then that action will ultimately cause a pull of work\nfrom the arrivals column. Work getting pulled from the arrivals column will\nsignal to the world that there is capacity to start new work and thus the\narrivals column will be replenished even though no work has been\ncompleted. I hope it is easy to see that in this scenario how we can have\nitems that arrive to our system faster than items that depart our system. So\ndo not think your work is done by just limiting WIP at the front of your\nprocess. You must make sure that a constant amount of WIP (on average) is\nmaintained throughout the whole process. Remember, the further you stray\naway from this principle, the less predictable you will be. Limiting WIP on the arrivals column in the manner described here is\n\none way to ensure that not too much work is started and just queuing at the\nbeginning of your process. I have said it before, and I will say it again: delay\nis the enemy of flow. This approach will ensure a proper balance between\nhaving enough work to start such that your process is not starved and not\nhaving too much work such that work begins but just sits. By the way, once we get a picture that looks like Figure 7.8, we will\n\nhave taken the first---and probably most important---step to balance the\ndemand on your system against the supply that your team can offer. We are\nnow very far down the path to true process predictability. Most Kanban boards have an explicit arrivals column at the front of the\n\nprocess, but this is by no means a requirement. It is completely reasonable\nthat your particular work context allows your team to pull new work items in\nan immediate, ad hoc manner. That is to say, you need no coordination with\nany external stakeholder to prioritize items or you have a proxy for those\nstakeholders embedded with your team. In this case the arrivals column\n(e.g., the “To Do” or “Input” or “Ready” column) may be superfluous.", "tokens": 508, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 104, "segment_id": "00104", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000118"}
{"type": "chunk", "text": "Most Kanban boards have an explicit arrivals column at the front of the\n\nprocess, but this is by no means a requirement. It is completely reasonable\nthat your particular work context allows your team to pull new work items in\nan immediate, ad hoc manner. That is to say, you need no coordination with\nany external stakeholder to prioritize items or you have a proxy for those\nstakeholders embedded with your team. In this case the arrivals column\n(e.g., the “To Do” or “Input” or “Ready” column) may be superfluous. This\nsituation is perfectly ok. As I just mentioned, the way to match arrivals to\ndepartures in this context would be to make sure that a constant amount of\nWIP is maintained through the process at all times. Constant WIP could be\nmaintained either by expressly limiting Work In Progress at each step of\nyour work flow or by setting one global limit for the whole process (or some", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\nMost Kanban boards have an explicit arrivals column at the front of the\n\nprocess, but this is by no means a requirement. It is completely reasonable\nthat your particular work context allows your team to pull new work items in\nan immediate, ad hoc manner. That is to say, you need no coordination with\nany external stakeholder to prioritize items or you have a proxy for those\nstakeholders embedded with your team. In this case the arrivals column\n(e.g., the “To Do” or “Input” or “Ready” column) may be superfluous. This\nsituation is perfectly ok. As I just mentioned, the way to match arrivals to\ndepartures in this context would be to make sure that a constant amount of\nWIP is maintained through the process at all times. Constant WIP could be\nmaintained either by expressly limiting Work In Progress at each step of\nyour work flow or by setting one global limit for the whole process (or some", "tokens": 201, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 104, "segment_id": "00104", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000119"}
{"type": "chunk", "text": "mixture of both). The point I am making here is that it does not really matter\nhow you limit WIP throughout the whole system just as long as you do. It should be said, though, that even in this particular situation a team\ncould benefit from an arrivals column for many of reasons. Just know that an\nexplicit arrivals column is neither prescribed nor required for predictable\nprocess design. Conclusion\nWhen you have a picture that looks like Figure 7.5 then your process is, by\ndefinition, unpredictable. The direct consequence of an Arrival Rate that\nexceeds a Departure Rate is a steady---if not dramatic---increase in WIP. Little’s Law tells us that an increase in WIP will be matched by an increase\nin Cycle Time. The implication here is that if WIP grows unbounded, then\nCycle Time will also essentially grow unbounded. If your Cycle Time is\never-increasing, then it becomes impossible to answer the question, “how\nlong before this work item will done?”\n\nIn this chapter, I have purposefully not made any mention of how teams\n\nchoose what particular items go on to the arrivals column at replenishment\ntime. Nor have I made any mention of the order in which items should be\npulled through the system once they have been placed on that column. These\nare very important questions and deserve ample consideration. The reason I\nhave left those questions unanswered---for now---is that this chapter is\nsimply about the mechanics of the first necessary step you need to take in\norder to stabilize your system and thus have any hope of predictability. Little’s Law assumption #1 states that the average Arrival Rate to a system\nmust equal the average Departure Rate of the system. I have shown you how\nto do that here. The answers to the replenishment and pull order questions\nwill be addressed in the coming chapters. I would argue that the arrivals column is one of---if not the most---\nimportant columns for your process design. In this chapter we have explored\ntwo very important reasons why this might be so:\n\n1. The arrivals column acts as the throttle by which we constrain the\n\namount of work that can arrive to our system at any given time. It is the\nmechanism by which we match the rate of arrivals in our process to the\nrate of departures. The matching of these rates is what is going to yield\nprocess predictability. And,", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\nmixture of both). The point I am making here is that it does not really matter\nhow you limit WIP throughout the whole system just as long as you do. It should be said, though, that even in this particular situation a team\ncould benefit from an arrivals column for many of reasons. Just know that an\nexplicit arrivals column is neither prescribed nor required for predictable\nprocess design. Conclusion\nWhen you have a picture that looks like Figure 7.5 then your process is, by\ndefinition, unpredictable. The direct consequence of an Arrival Rate that\nexceeds a Departure Rate is a steady---if not dramatic---increase in WIP. Little’s Law tells us that an increase in WIP will be matched by an increase\nin Cycle Time. The implication here is that if WIP grows unbounded, then\nCycle Time will also essentially grow unbounded. If your Cycle Time is\never-increasing, then it becomes impossible to answer the question, “how\nlong before this work item will done?”\n\nIn this chapter, I have purposefully not made any mention of how teams\n\nchoose what particular items go on to the arrivals column at replenishment\ntime. Nor have I made any mention of the order in which items should be\npulled through the system once they have been placed on that column. These\nare very important questions and deserve ample consideration. The reason I\nhave left those questions unanswered---for now---is that this chapter is\nsimply about the mechanics of the first necessary step you need to take in\norder to stabilize your system and thus have any hope of predictability. Little’s Law assumption #1 states that the average Arrival Rate to a system\nmust equal the average Departure Rate of the system. I have shown you how\nto do that here. The answers to the replenishment and pull order questions\nwill be addressed in the coming chapters. I would argue that the arrivals column is one of---if not the most---\nimportant columns for your process design. In this chapter we have explored\ntwo very important reasons why this might be so:\n\n1. The arrivals column acts as the throttle by which we constrain the\n\namount of work that can arrive to our system at any given time. It is the\nmechanism by which we match the rate of arrivals in our process to the\nrate of departures. The matching of these rates is what is going to yield\nprocess predictability. And,", "tokens": 502, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 105, "segment_id": "00105", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000120"}
{"type": "chunk", "text": "2. The arrivals column acts as our “commitment” point to start new work. The implication being that when new work is committed to, we expect\nit will flow completely through the process and depart the system. It is\nonly when work departs our system that customer value can truly be\nrecognized and our predictability be assessed. In the real world, work item Cycle Times are not allowed to grow ad\n\ninfinitum. Projects get cancelled and features get abandoned when they take\ntoo long to complete. This compounds the problem from a predictability\nperspective because not only is your Cycle Time not predictable, but now\nyou cannot even be certain if a certain item that is started will ever finish. Items that start but never finish is yet another a violation of an assumption of\nLittle’s Law (do you remember which one?) that carries its own impacts on\npredictability. An exploration of that violation is where we will go next. Key Learnings and Takeaways\n\nLittle’s Law assumption #1 says that the average input or Arrival Rate\nof a process should equal the average output or Departure Rate. Any predictable process needs a clear, unambiguous point at which it\nconsiders items to have “arrived”. Any predictable process needs a clear, unambiguous point at which it\nconsiders items to have “departed”. One of the best ways to visualize whether arrivals and departures are\nbalanced is to visualize them via a CFD. To balance arrivals and departures is going to require limiting WIP not\nonly at the arrivals column but also through the whole process. Once arrivals and departures are balanced, you have taken the\nnecessary first (emphasis on first) step toward process predictability. Pretty CFD pictures could still mask underlying process problems.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I\n\n2. The arrivals column acts as our “commitment” point to start new work. The implication being that when new work is committed to, we expect\nit will flow completely through the process and depart the system. It is\nonly when work departs our system that customer value can truly be\nrecognized and our predictability be assessed. In the real world, work item Cycle Times are not allowed to grow ad\n\ninfinitum. Projects get cancelled and features get abandoned when they take\ntoo long to complete. This compounds the problem from a predictability\nperspective because not only is your Cycle Time not predictable, but now\nyou cannot even be certain if a certain item that is started will ever finish. Items that start but never finish is yet another a violation of an assumption of\nLittle’s Law (do you remember which one?) that carries its own impacts on\npredictability. An exploration of that violation is where we will go next. Key Learnings and Takeaways\n\nLittle’s Law assumption #1 says that the average input or Arrival Rate\nof a process should equal the average output or Departure Rate. Any predictable process needs a clear, unambiguous point at which it\nconsiders items to have “arrived”. Any predictable process needs a clear, unambiguous point at which it\nconsiders items to have “departed”. One of the best ways to visualize whether arrivals and departures are\nbalanced is to visualize them via a CFD. To balance arrivals and departures is going to require limiting WIP not\nonly at the arrivals column but also through the whole process. Once arrivals and departures are balanced, you have taken the\nnecessary first (emphasis on first) step toward process predictability. Pretty CFD pictures could still mask underlying process problems.", "tokens": 362, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 106, "segment_id": "00106", "chapter_num": "7", "chapter_title": "Conservation of Flow Part I", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 7: Conservation of Flow Part I", "chunk_id": "00000121"}
{"type": "chunk", "text": "Chapter 8 - Conservation of Flow Part II\n\nI have never been skydiving, but I get the general gist. First, you pack a\nbunch of nylon into a little bag and strap that bag to your back. Then, you\nhop onto an airplane and fly up to a specified altitude. Finally, assuming you\nare insane, you jump out. Other than the immediate commencement of a real-time experiment of\n\nNewton’s Second Law of Motion, a very important thing happened to you\nonce you jumped out of that airplane. Once outside the plane, you made a\nvery real commitment to fall back down to the ground. Up until the moment\nof stepping off the plane, you had every opportunity to not make that\ncommitment. You could have checked your parachute and found it was not\npacked properly. The plane could have not taken off due to bad weather. You\ncould have decided not to jump because you were too scared. Any number of\nfactors could have contributed to you not making that commitment. Also notice that this commitment happened at the last responsible\n\n(possible) moment. Your jumping out of that airplane was a clear and\nunambiguous signal that you intended to fall back to earth. Which brings us to my last point. Once outside the plane, you had every\n\nexpectation that you were going to make it all the way down to the ground. The instant that you jumped it would take nothing short of an act of God to\nnot get you back down to earth. Whether you knew it or not, what you had just experienced in this\n\nsituation was a perfect example of the second part of the Conservation of\nFlow (CoF). In the previous chapter, we discussed the first part of CoF,\nwhich also happened to be one of the necessary assumptions for Little’s Law\nto work. In this chapter we will discuss the second part of CoF, which, as it\nso happens, is also one of the foundational assumptions of Little’s Law:\n\nLittle’s Law Assumption #2: All work that is started will eventually be completed and\nexit (depart) the system.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II\n\nChapter 8 - Conservation of Flow Part II\n\nI have never been skydiving, but I get the general gist. First, you pack a\nbunch of nylon into a little bag and strap that bag to your back. Then, you\nhop onto an airplane and fly up to a specified altitude. Finally, assuming you\nare insane, you jump out. Other than the immediate commencement of a real-time experiment of\n\nNewton’s Second Law of Motion, a very important thing happened to you\nonce you jumped out of that airplane. Once outside the plane, you made a\nvery real commitment to fall back down to the ground. Up until the moment\nof stepping off the plane, you had every opportunity to not make that\ncommitment. You could have checked your parachute and found it was not\npacked properly. The plane could have not taken off due to bad weather. You\ncould have decided not to jump because you were too scared. Any number of\nfactors could have contributed to you not making that commitment. Also notice that this commitment happened at the last responsible\n\n(possible) moment. Your jumping out of that airplane was a clear and\nunambiguous signal that you intended to fall back to earth. Which brings us to my last point. Once outside the plane, you had every\n\nexpectation that you were going to make it all the way down to the ground. The instant that you jumped it would take nothing short of an act of God to\nnot get you back down to earth. Whether you knew it or not, what you had just experienced in this\n\nsituation was a perfect example of the second part of the Conservation of\nFlow (CoF). In the previous chapter, we discussed the first part of CoF,\nwhich also happened to be one of the necessary assumptions for Little’s Law\nto work. In this chapter we will discuss the second part of CoF, which, as it\nso happens, is also one of the foundational assumptions of Little’s Law:\n\nLittle’s Law Assumption #2: All work that is started will eventually be completed and\nexit (depart) the system.", "tokens": 434, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 107, "segment_id": "00107", "chapter_num": "8", "chapter_title": "Conservation of Flow Part II", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II", "chunk_id": "00000122"}
{"type": "chunk", "text": "The great benefit of implementing a pull system is that it is very easy to\n\ndefine what it means for work to have “started”. A subtle side benefit that I\nhave not talked much about until now is that pull systems also allow for us\nto perform just-in-time prioritizations and just-in-time commitments. It turns\nout that just-in-time prioritizations and just-in-time commitments are going\nto help us conserve flow. Just-in-time Prioritization\nI cannot tell you how many teams I have watched waste so much time,\ngrooming, pruning, and re-prioritizing their backlogs. The truth is that the\neffort spent to maintain a backlog is waste. It is waste because the truth is\nthat much of what goes into a backlog will never get worked on anyway. Why spend time prioritizing items that you have no clue nor confidence if or\nwhen they will ever get worked? Worse, when you are ready to start new\nwork, new requirements will have shown up, or you will have gained new\ninformation, or both, which will require a whole reprioritization effort and\nwill have rendered the previous prioritization activities moot. Enter the concept of just-in-time prioritization. In a pull system, a\nprioritization conversation only happens when there is a clear indication that\nthe team has capacity to do new work. For example, let’s look at a Kanban board (Figure 8.1) not unlike the\n\none we discussed in the previous chapter:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II\n\nThe great benefit of implementing a pull system is that it is very easy to\n\ndefine what it means for work to have “started”. A subtle side benefit that I\nhave not talked much about until now is that pull systems also allow for us\nto perform just-in-time prioritizations and just-in-time commitments. It turns\nout that just-in-time prioritizations and just-in-time commitments are going\nto help us conserve flow. Just-in-time Prioritization\nI cannot tell you how many teams I have watched waste so much time,\ngrooming, pruning, and re-prioritizing their backlogs. The truth is that the\neffort spent to maintain a backlog is waste. It is waste because the truth is\nthat much of what goes into a backlog will never get worked on anyway. Why spend time prioritizing items that you have no clue nor confidence if or\nwhen they will ever get worked? Worse, when you are ready to start new\nwork, new requirements will have shown up, or you will have gained new\ninformation, or both, which will require a whole reprioritization effort and\nwill have rendered the previous prioritization activities moot. Enter the concept of just-in-time prioritization. In a pull system, a\nprioritization conversation only happens when there is a clear indication that\nthe team has capacity to do new work. For example, let’s look at a Kanban board (Figure 8.1) not unlike the\n\none we discussed in the previous chapter:", "tokens": 310, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 108, "segment_id": "00108", "chapter_num": "8", "chapter_title": "Conservation of Flow Part II", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II", "chunk_id": "00000123"}
{"type": "chunk", "text": "Figure 8.1: Just-in-time Prioritization\n\nNotice that in Figure 8.1 the “Ready” or arrivals column has a Work In\nProgress limit of six. That means that the capacity of this process is such that\na maximum of six new items can be started at any given time. What should\nthis team do when they try to decide how many items to work on next? As\nthey look at the board, they will see that there are already four items in the\nReady column. Since the column already has four items in it, and since the\nWIP limit on the column is six, this means that the process is unambiguously\nsignaling that the team only has capacity to start work on two new items. The prioritization conversation (i.e., which items should they choose) should\nthen be focused only on “what are the next two most important items that we\nshould start at this time?” Any discussion beyond deciding on just those two\nitems is waste (e.g., having a conversation, say, about prioritizing the top ten\nitems). Why? Because by the next time the team meets to replenish the\nReady column, there will have been several things about the business\nenvironment that could have changed: business needs, customer feedback,\nregulatory concerns, etc. These changing factors will constantly feed new\nrequirements the team’s way and these continuously changing business", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II\n\nFigure 8.1: Just-in-time Prioritization\n\nNotice that in Figure 8.1 the “Ready” or arrivals column has a Work In\nProgress limit of six. That means that the capacity of this process is such that\na maximum of six new items can be started at any given time. What should\nthis team do when they try to decide how many items to work on next? As\nthey look at the board, they will see that there are already four items in the\nReady column. Since the column already has four items in it, and since the\nWIP limit on the column is six, this means that the process is unambiguously\nsignaling that the team only has capacity to start work on two new items. The prioritization conversation (i.e., which items should they choose) should\nthen be focused only on “what are the next two most important items that we\nshould start at this time?” Any discussion beyond deciding on just those two\nitems is waste (e.g., having a conversation, say, about prioritizing the top ten\nitems). Why? Because by the next time the team meets to replenish the\nReady column, there will have been several things about the business\nenvironment that could have changed: business needs, customer feedback,\nregulatory concerns, etc. These changing factors will constantly feed new\nrequirements the team’s way and these continuously changing business", "tokens": 290, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 109, "segment_id": "00109", "chapter_num": "8", "chapter_title": "Conservation of Flow Part II", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II", "chunk_id": "00000124"}
{"type": "chunk", "text": "needs means that the best strategy for prioritizing new work is in a just-intime manner. This just-in-time prioritization concept is true even if you are running\n\nwhat you assume to be a stable project. As you finish some project\nrequirements, you will have gained knowledge about the problem domain. You will have gained that knowledge both through your own analysis and\ndevelopment efforts, but also through the feedback you get from regularly\nscheduled reviews with your customers. This newfound knowledge is bound\nto result in changes in your to your backlog---which, again, would warrant a\njust-in-time approach to the prioritization of work. Just-in-time Commitment\nOnce prioritized and placed on the Kanban board, there is also an explicit\nunderstanding that the new work items are now committed to. In a pull\nsystem, work is not “committed to” when it is placed in the backlog! It is\nonly committed to in a just-in-time manner as determined by the team’s\nexplicit capacity. But what do I mean by the word “commitment”? First, I mean\n\ncommitment with a small “c”. There should be no severe penalty for missing\na commitment. No one should get fired. No one should lose their bonus or be\ndenied a pay raise. But make no mistake. I do mean commitment. Once\nagreed to, I do mean that the team should do everything in its power to meet\nits commitments. Second, commitment means that there is an expectation that, once\nstarted, an item will flow all the way through the process until completion. In other words, there is a commitment that flow will be conserved. Lastly, commitment means communicating to our customers a Cycle\n\nTime range and probability for the committed-to item. Remember that once\nwe commit to start work, the customer’s first question will be “When is it\ngoing to be done?” This point of commitment is when we answer that\nquestion. Allow me to further explain the three aspects of commitment by way of\nexample. The placement of a work item in the Ready column means that the\nitem has been both prioritized and committed to. This commitment means\nthat all reasonable effort will be undertaken to make sure the item will flow\nall the way through the process to completion (just like in the sky diving\nexample). It also means that a communication will be made to our customers", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II\n\nneeds means that the best strategy for prioritizing new work is in a just-intime manner. This just-in-time prioritization concept is true even if you are running\n\nwhat you assume to be a stable project. As you finish some project\nrequirements, you will have gained knowledge about the problem domain. You will have gained that knowledge both through your own analysis and\ndevelopment efforts, but also through the feedback you get from regularly\nscheduled reviews with your customers. This newfound knowledge is bound\nto result in changes in your to your backlog---which, again, would warrant a\njust-in-time approach to the prioritization of work. Just-in-time Commitment\nOnce prioritized and placed on the Kanban board, there is also an explicit\nunderstanding that the new work items are now committed to. In a pull\nsystem, work is not “committed to” when it is placed in the backlog! It is\nonly committed to in a just-in-time manner as determined by the team’s\nexplicit capacity. But what do I mean by the word “commitment”? First, I mean\n\ncommitment with a small “c”. There should be no severe penalty for missing\na commitment. No one should get fired. No one should lose their bonus or be\ndenied a pay raise. But make no mistake. I do mean commitment. Once\nagreed to, I do mean that the team should do everything in its power to meet\nits commitments. Second, commitment means that there is an expectation that, once\nstarted, an item will flow all the way through the process until completion. In other words, there is a commitment that flow will be conserved. Lastly, commitment means communicating to our customers a Cycle\n\nTime range and probability for the committed-to item. Remember that once\nwe commit to start work, the customer’s first question will be “When is it\ngoing to be done?” This point of commitment is when we answer that\nquestion. Allow me to further explain the three aspects of commitment by way of\nexample. The placement of a work item in the Ready column means that the\nitem has been both prioritized and committed to. This commitment means\nthat all reasonable effort will be undertaken to make sure the item will flow\nall the way through the process to completion (just like in the sky diving\nexample). It also means that a communication will be made to our customers", "tokens": 490, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 110, "segment_id": "00110", "chapter_num": "8", "chapter_title": "Conservation of Flow Part II", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II", "chunk_id": "00000125"}
{"type": "chunk", "text": "regarding how long it should reasonably take that particular item to\ncomplete. That communication should take the form of “we expect this item\nto flow all the way through the process and exit in 14 days or less with an\n85% probability of success”. Many of you will recognize this as the\nlanguage of “Service Level Agreements” or SLAs in Kanban. More on just\nwhat exactly SLAs are and how to set them for your process can be found in\nChapter 12. Not to get too off-topic here, but I hope this dispels another common\n\nmyth I hear about flow-based systems, and in particular, Kanban. I often\nhear, “Kanban cannot work because there are no commitments”. Nothing\ncould be further from the truth. It is just that the approach to commitments is\nvery different than, say, Scrum. Scrum commitments are made at the sprint\nlevel. At the beginning of a sprint, a team commits to getting some number\nof stories finished by the end of the sprint. That commitment is based more\non upfront estimation and planning. In a flow-based approach, teams commit\nat the individual work item level. Once an item is pulled into the process a\ncommitment is made as to when that item should be done. That commitment\nis based more on measurement and observation rather than planning and\nestimation. The point here is not to denigrate Scrum, but to get you to think\nabout---especially if you are using a method like Scrum---how you might\nincorporate more flow-based principles into your current process. Exceptions to Conservation of Flow\nAs with all of these “rules”, there are always exceptions. There might be---\nand probably are---perfectly good reasons to discard work that is only\npartially completed. Maybe we have gained some knowledge that makes\ncontinuing to work on these particular items unnecessary, duplicative, or\notherwise wasteful. Well, obviously, in those circumstances it makes perfect\nsense to abandon that work. When this happens, though, we should\nchallenge ourselves with the following questions: “Why did that happen?”\n“Was there something that we could have done further upstream in our\nprocess to help avoid this situation?”\n\nBut, potentially more importantly, when these exceptions occur it is\nabsolutely necessary to account for them properly in your data.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II\n\nregarding how long it should reasonably take that particular item to\ncomplete. That communication should take the form of “we expect this item\nto flow all the way through the process and exit in 14 days or less with an\n85% probability of success”. Many of you will recognize this as the\nlanguage of “Service Level Agreements” or SLAs in Kanban. More on just\nwhat exactly SLAs are and how to set them for your process can be found in\nChapter 12. Not to get too off-topic here, but I hope this dispels another common\n\nmyth I hear about flow-based systems, and in particular, Kanban. I often\nhear, “Kanban cannot work because there are no commitments”. Nothing\ncould be further from the truth. It is just that the approach to commitments is\nvery different than, say, Scrum. Scrum commitments are made at the sprint\nlevel. At the beginning of a sprint, a team commits to getting some number\nof stories finished by the end of the sprint. That commitment is based more\non upfront estimation and planning. In a flow-based approach, teams commit\nat the individual work item level. Once an item is pulled into the process a\ncommitment is made as to when that item should be done. That commitment\nis based more on measurement and observation rather than planning and\nestimation. The point here is not to denigrate Scrum, but to get you to think\nabout---especially if you are using a method like Scrum---how you might\nincorporate more flow-based principles into your current process. Exceptions to Conservation of Flow\nAs with all of these “rules”, there are always exceptions. There might be---\nand probably are---perfectly good reasons to discard work that is only\npartially completed. Maybe we have gained some knowledge that makes\ncontinuing to work on these particular items unnecessary, duplicative, or\notherwise wasteful. Well, obviously, in those circumstances it makes perfect\nsense to abandon that work. When this happens, though, we should\nchallenge ourselves with the following questions: “Why did that happen?”\n“Was there something that we could have done further upstream in our\nprocess to help avoid this situation?”\n\nBut, potentially more importantly, when these exceptions occur it is\nabsolutely necessary to account for them properly in your data.", "tokens": 489, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 111, "segment_id": "00111", "chapter_num": "8", "chapter_title": "Conservation of Flow Part II", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II", "chunk_id": "00000126"}
{"type": "chunk", "text": "Maybe we have gained some knowledge that makes\ncontinuing to work on these particular items unnecessary, duplicative, or\notherwise wasteful. Well, obviously, in those circumstances it makes perfect\nsense to abandon that work. When this happens, though, we should\nchallenge ourselves with the following questions: “Why did that happen?”\n“Was there something that we could have done further upstream in our\nprocess to help avoid this situation?”\n\nBut, potentially more importantly, when these exceptions occur it is\nabsolutely necessary to account for them properly in your data. Instead of\njust removing (or deleting) an item from your board never to be tracked\nagain, it is probably best to mark that item as “finished” (whatever that\nmeans in your context), mark the date it was done, and then tag it with some", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II\n\nMaybe we have gained some knowledge that makes\ncontinuing to work on these particular items unnecessary, duplicative, or\notherwise wasteful. Well, obviously, in those circumstances it makes perfect\nsense to abandon that work. When this happens, though, we should\nchallenge ourselves with the following questions: “Why did that happen?”\n“Was there something that we could have done further upstream in our\nprocess to help avoid this situation?”\n\nBut, potentially more importantly, when these exceptions occur it is\nabsolutely necessary to account for them properly in your data. Instead of\njust removing (or deleting) an item from your board never to be tracked\nagain, it is probably best to mark that item as “finished” (whatever that\nmeans in your context), mark the date it was done, and then tag it with some", "tokens": 169, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 111, "segment_id": "00111", "chapter_num": "8", "chapter_title": "Conservation of Flow Part II", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II", "chunk_id": "00000127"}
{"type": "chunk", "text": "attribute like “abandoned” or “discarded”. In that way, we will be able to\nfilter on that attribute later. You’ll remember that I have spoken many times\nbefore about segmenting WIP based on different types. Well, one of those\ntypes might be work that has completed normally or not. For example, let’s say we have a board that looks like Figure 8.1. Let’s\n\nfurther say that we start some work item and get it all the way to the\n“Development” column before we decide we do not need this particular\nfunctionality. In this case, the item should immediately be moved to the\n“Deployed” column, the current date should be captured, and the item\nshould be tagged as “abandoned”---or with whatever other descriptor you\nchoose to use. Annotating an item in this way gives us several options when we go to\ngenerate our analytics later. You can imagine that we may want to generate\nseveral different views of a CFD for our exception cases. We may want to\nsee all data together, we may want to only see items that have finished\nnormally, or we may want to just see those items that were abandoned. Further, by accounting for these abandoned work items in this way, not only\nhave we not violated the principle of the CoF, but we can also guarantee that\nwe will be able to generate a valid CFD for all of those views. A violation of the principle of conservation of flow should be treated as\n\nan opportunity for learning. Hopefully, your new-found understanding of\nthis principle helps you to more readily recognize these learning\nopportunities and is yet another tool for you in your toolbox of continuous\nprocess improvement for predictability. Conditioning Flow and Predictability\nI just mentioned that part of the definition of commitment is that a team\nshould do everything in its power to assure that once started an item\ncompletes and it completes in the timeframe that has been communicated to\nthe customer. “Everything in its power” means first choosing a Cycle Time\nrange and probability that is achievable. It also means doing what we can to\nchoose items that have the best chance of meeting that goal. This idea of\nselecting items for success is a concept that I like to refer to as\n“Conditioning Flow”. Let me give you a few examples. Let’s say that we are operating a\n\nprocess that is currently overloaded in Test.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II\n\nattribute like “abandoned” or “discarded”. In that way, we will be able to\nfilter on that attribute later. You’ll remember that I have spoken many times\nbefore about segmenting WIP based on different types. Well, one of those\ntypes might be work that has completed normally or not. For example, let’s say we have a board that looks like Figure 8.1. Let’s\n\nfurther say that we start some work item and get it all the way to the\n“Development” column before we decide we do not need this particular\nfunctionality. In this case, the item should immediately be moved to the\n“Deployed” column, the current date should be captured, and the item\nshould be tagged as “abandoned”---or with whatever other descriptor you\nchoose to use. Annotating an item in this way gives us several options when we go to\ngenerate our analytics later. You can imagine that we may want to generate\nseveral different views of a CFD for our exception cases. We may want to\nsee all data together, we may want to only see items that have finished\nnormally, or we may want to just see those items that were abandoned. Further, by accounting for these abandoned work items in this way, not only\nhave we not violated the principle of the CoF, but we can also guarantee that\nwe will be able to generate a valid CFD for all of those views. A violation of the principle of conservation of flow should be treated as\n\nan opportunity for learning. Hopefully, your new-found understanding of\nthis principle helps you to more readily recognize these learning\nopportunities and is yet another tool for you in your toolbox of continuous\nprocess improvement for predictability. Conditioning Flow and Predictability\nI just mentioned that part of the definition of commitment is that a team\nshould do everything in its power to assure that once started an item\ncompletes and it completes in the timeframe that has been communicated to\nthe customer. “Everything in its power” means first choosing a Cycle Time\nrange and probability that is achievable. It also means doing what we can to\nchoose items that have the best chance of meeting that goal. This idea of\nselecting items for success is a concept that I like to refer to as\n“Conditioning Flow”. Let me give you a few examples. Let’s say that we are operating a\n\nprocess that is currently overloaded in Test.", "tokens": 507, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 112, "segment_id": "00112", "chapter_num": "8", "chapter_title": "Conservation of Flow Part II", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II", "chunk_id": "00000128"}
{"type": "chunk", "text": "“Everything in its power” means first choosing a Cycle Time\nrange and probability that is achievable. It also means doing what we can to\nchoose items that have the best chance of meeting that goal. This idea of\nselecting items for success is a concept that I like to refer to as\n“Conditioning Flow”. Let me give you a few examples. Let’s say that we are operating a\n\nprocess that is currently overloaded in Test. Let’s further say that the next\nhighest priority item that we wish to pull in off the backlog (though it has", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II\n\n“Everything in its power” means first choosing a Cycle Time\nrange and probability that is achievable. It also means doing what we can to\nchoose items that have the best chance of meeting that goal. This idea of\nselecting items for success is a concept that I like to refer to as\n“Conditioning Flow”. Let me give you a few examples. Let’s say that we are operating a\n\nprocess that is currently overloaded in Test. Let’s further say that the next\nhighest priority item that we wish to pull in off the backlog (though it has", "tokens": 115, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 112, "segment_id": "00112", "chapter_num": "8", "chapter_title": "Conservation of Flow Part II", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II", "chunk_id": "00000129"}
{"type": "chunk", "text": "not been pulled in yet!) has a large amount of testing effort associated with\nit. But the second highest priority item has little to no testing effort\nassociated with it. All other things being equal, we should probably pull the\nsecond priority in preference to the first priority. That is the concept of\nconditioning flow. There are several other examples of this. Let’s say the next highest\npriority to be pulled off the backlog requires a specific resource, but we\nknow that that particular resource is going to be going on vacation for\nseveral weeks starting in two days. Obviously it wouldn’t make sense to pull\nthat item in, work on it for two days, and then block it while our expert is on\nvacation. One last example might be that the team is in disagreement about\n\nwhether the next priority item is of the right size to come into the system\n(right-sizing of work items will be discussed in Chapter 12). That\ndisagreement probably stems from some uncertainty around the work item\nso maybe what the team decides to do is spike the story and pull that spike in\nfirst (by “spike” I mean a work item---user story---that is used to drive out\nrisk and uncertainty in another work item). Remember, we have control over a lot of these decisions. Making the\n\nbest choices in these circumstances is usually the difference between\nwhether our process is predictable or not. Conversations around conditioning\nflow are among the most important as they speak to what items are\ncommitted to next. Because we are talking about commitments and\npredictability here, we want to make sure that we are setting ourselves up for\nsuccess from the very first pull transaction. We want to do what we can to\ncondition our flow. Conclusion\nWhether you realized it or not before now, every time you started a piece of\nwork (be it a project, a feature, or story) but then later abandoned it you\nviolated the principle of Conservation of Flow and thus impaired your\npredictability. If work flows only part way through the system and gets\nkicked out or discarded---for whatever reason---then any effort that was\nexpended on the eliminated item immediately becomes waste. Taken to its\nlogical conclusion, you can understand why a team might want to conserve\nflow as much as possible. If work is constantly started but never finished, if\nthis partially completed work is constantly discarded in favor of starting new", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II\n\nnot been pulled in yet!) has a large amount of testing effort associated with\nit. But the second highest priority item has little to no testing effort\nassociated with it. All other things being equal, we should probably pull the\nsecond priority in preference to the first priority. That is the concept of\nconditioning flow. There are several other examples of this. Let’s say the next highest\npriority to be pulled off the backlog requires a specific resource, but we\nknow that that particular resource is going to be going on vacation for\nseveral weeks starting in two days. Obviously it wouldn’t make sense to pull\nthat item in, work on it for two days, and then block it while our expert is on\nvacation. One last example might be that the team is in disagreement about\n\nwhether the next priority item is of the right size to come into the system\n(right-sizing of work items will be discussed in Chapter 12). That\ndisagreement probably stems from some uncertainty around the work item\nso maybe what the team decides to do is spike the story and pull that spike in\nfirst (by “spike” I mean a work item---user story---that is used to drive out\nrisk and uncertainty in another work item). Remember, we have control over a lot of these decisions. Making the\n\nbest choices in these circumstances is usually the difference between\nwhether our process is predictable or not. Conversations around conditioning\nflow are among the most important as they speak to what items are\ncommitted to next. Because we are talking about commitments and\npredictability here, we want to make sure that we are setting ourselves up for\nsuccess from the very first pull transaction. We want to do what we can to\ncondition our flow. Conclusion\nWhether you realized it or not before now, every time you started a piece of\nwork (be it a project, a feature, or story) but then later abandoned it you\nviolated the principle of Conservation of Flow and thus impaired your\npredictability. If work flows only part way through the system and gets\nkicked out or discarded---for whatever reason---then any effort that was\nexpended on the eliminated item immediately becomes waste. Taken to its\nlogical conclusion, you can understand why a team might want to conserve\nflow as much as possible. If work is constantly started but never finished, if\nthis partially completed work is constantly discarded in favor of starting new", "tokens": 500, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 113, "segment_id": "00113", "chapter_num": "8", "chapter_title": "Conservation of Flow Part II", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II", "chunk_id": "00000130"}
{"type": "chunk", "text": "work, then the Cycle Time metrics are going be skewed, and the system you\nare operating becomes infinitely unpredictable. Of course, we live in the real world and these things are going to\nhappen. Some might argue---and I certainly would not debate them if they\ndid---that it is even more waste to continue to work on an item once we have\ngained information that the item is no longer necessary. By all means trash\nthat work in those instances. However, just remember to account for that\naction appropriately in your data. Taking the time to do the proper\naccounting will pay huge predictability dividends later. The idea of matching the arrival rate of your system to its departure\nrate, and the idea of making sure that flow is conserved for all items that\nenter your system go a long way to stabilize what would otherwise be\nconsidered an unstable system. When we have taken these steps we can now\nstart to have some confidence that the metrics we are collecting off of our\nsystem are more reflective of a team’s true capability. However, doing these\ntwo things alone still does not guarantee that our system is completely\nstable. It is this underlying sense of system stability that we need in order to\nreach one of our ultimate goals---a goal that I keep harping on throughout\nthis text: predictability. For the final piece of our stabilization problem, we must borrow some\n\nideas from someone who---like most great thinkers---was not truly\nappreciated in his time. Key Learnings and Takeaways\n\nLittle’s Law assumption #2 says that all work that is started will\neventually be completed and exit the process. The concept that no work gets lost or does not ever exit the process is\nthe second half of a concept known as the Conservation of Flow. To set ourselves up properly so as not to violate CoF we need to\nimplement a just-in-time prioritization and just-in-time commitment\nstrategy (these strategies are direct consequences of putting in place a\npull system). In knowledge work, commitment means two things:\n\nThat once committed to, work will flow all the way through our\nprocess to completion.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II\n\nwork, then the Cycle Time metrics are going be skewed, and the system you\nare operating becomes infinitely unpredictable. Of course, we live in the real world and these things are going to\nhappen. Some might argue---and I certainly would not debate them if they\ndid---that it is even more waste to continue to work on an item once we have\ngained information that the item is no longer necessary. By all means trash\nthat work in those instances. However, just remember to account for that\naction appropriately in your data. Taking the time to do the proper\naccounting will pay huge predictability dividends later. The idea of matching the arrival rate of your system to its departure\nrate, and the idea of making sure that flow is conserved for all items that\nenter your system go a long way to stabilize what would otherwise be\nconsidered an unstable system. When we have taken these steps we can now\nstart to have some confidence that the metrics we are collecting off of our\nsystem are more reflective of a team’s true capability. However, doing these\ntwo things alone still does not guarantee that our system is completely\nstable. It is this underlying sense of system stability that we need in order to\nreach one of our ultimate goals---a goal that I keep harping on throughout\nthis text: predictability. For the final piece of our stabilization problem, we must borrow some\n\nideas from someone who---like most great thinkers---was not truly\nappreciated in his time. Key Learnings and Takeaways\n\nLittle’s Law assumption #2 says that all work that is started will\neventually be completed and exit the process. The concept that no work gets lost or does not ever exit the process is\nthe second half of a concept known as the Conservation of Flow. To set ourselves up properly so as not to violate CoF we need to\nimplement a just-in-time prioritization and just-in-time commitment\nstrategy (these strategies are direct consequences of putting in place a\npull system). In knowledge work, commitment means two things:\n\nThat once committed to, work will flow all the way through our\nprocess to completion.", "tokens": 443, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 114, "segment_id": "00114", "chapter_num": "8", "chapter_title": "Conservation of Flow Part II", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II", "chunk_id": "00000131"}
{"type": "chunk", "text": "That part of the commitment is a communication of an expected\nCycle Time range and probability for a given item to complete. To not violate the Conservation of Flow, we need to account properly\nfor items that have started but later get abandoned. Another benefit of accounting properly for abandoned items is that we\ncan later filter our analytics on that data and help guarantee that the\ncharts are built correctly. Conditioning flow means being smart about what items to pull in next\nbased on contextual information that we currently have.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II\n\nThat part of the commitment is a communication of an expected\nCycle Time range and probability for a given item to complete. To not violate the Conservation of Flow, we need to account properly\nfor items that have started but later get abandoned. Another benefit of accounting properly for abandoned items is that we\ncan later filter our analytics on that data and help guarantee that the\ncharts are built correctly. Conditioning flow means being smart about what items to pull in next\nbased on contextual information that we currently have.", "tokens": 101, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 115, "segment_id": "00115", "chapter_num": "8", "chapter_title": "Conservation of Flow Part II", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 8: Conservation of Flow Part II", "chunk_id": "00000132"}
{"type": "chunk", "text": "Chapter 9 - Flow Debt\n\nHyman Minski may be the best economist that you have never heard of. Among other things, he is known for his work on classifying debtors based\non the types of financing they used when taking on their debt. Minski’s\ntheory was that borrowers could be categorized into one of three groups:\nhedge, speculative, and Ponzi. Hedge borrowers are those who can service\nboth the principal and interest on their debt. Speculative borrowers can only\npay the interest on their debt. And Ponzi borrowers have to constantly issue\nnew debt in order to service the old. Why am I telling you all this? To answer that question we must return\n\nto our old friend, the CFD. Specifically, recall CFD Property #4:\n\nCFD Property #4: The horizontal distance between any two lines on a CFD represents\nthe Approximate Average Cycle Time for items that finished between the two workflow\nsteps represented by the chosen two lines. When you first read that, I am sure that most of you were thinking (and\n\nmaybe still are) that being able to calculate only an Approximate Average\nCycle Time was absolutely worthless. After all, why would you ever waste\ntime measuring an Approximate Average Cycle Time from a CFD when you\ncan just go and directly compute an exact Average Cycle Time from the\nchart’s real, underlying data? While those are good questions, I would argue that knowing the CFD’s\nApproximate Average Cycle Time is extremely valuable. To understand why,\nwe must revisit Little’s Law Assumption #4:\n\nLittle’s Law Assumption #4: For the time period under consideration, the average age of\nWIP should neither be increasing nor decreasing. The Approximate Average Cycle Time as predicted by the CFD can be\ncompared to the exact Average Cycle Time as calculated from the very data\nused to build the CFD to begin with. The comparison of these two numbers", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt\n\nChapter 9 - Flow Debt\n\nHyman Minski may be the best economist that you have never heard of. Among other things, he is known for his work on classifying debtors based\non the types of financing they used when taking on their debt. Minski’s\ntheory was that borrowers could be categorized into one of three groups:\nhedge, speculative, and Ponzi. Hedge borrowers are those who can service\nboth the principal and interest on their debt. Speculative borrowers can only\npay the interest on their debt. And Ponzi borrowers have to constantly issue\nnew debt in order to service the old. Why am I telling you all this? To answer that question we must return\n\nto our old friend, the CFD. Specifically, recall CFD Property #4:\n\nCFD Property #4: The horizontal distance between any two lines on a CFD represents\nthe Approximate Average Cycle Time for items that finished between the two workflow\nsteps represented by the chosen two lines. When you first read that, I am sure that most of you were thinking (and\n\nmaybe still are) that being able to calculate only an Approximate Average\nCycle Time was absolutely worthless. After all, why would you ever waste\ntime measuring an Approximate Average Cycle Time from a CFD when you\ncan just go and directly compute an exact Average Cycle Time from the\nchart’s real, underlying data? While those are good questions, I would argue that knowing the CFD’s\nApproximate Average Cycle Time is extremely valuable. To understand why,\nwe must revisit Little’s Law Assumption #4:\n\nLittle’s Law Assumption #4: For the time period under consideration, the average age of\nWIP should neither be increasing nor decreasing. The Approximate Average Cycle Time as predicted by the CFD can be\ncompared to the exact Average Cycle Time as calculated from the very data\nused to build the CFD to begin with. The comparison of these two numbers", "tokens": 402, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 116, "segment_id": "00116", "chapter_num": "9", "chapter_title": "Flow Debt", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt", "chunk_id": "00000133"}
{"type": "chunk", "text": "will tell us if we can expect our exact Average Cycle Time to grow, decline,\nor stay the same over time. If our exact Average Cycle Time is either\ngrowing or declining then we have a violation of Little’s Law assumption #4\nwhich means that our predictability is in jeopardy. So what are the scenarios we need to consider when comparing\n\nApproximate Average Cycle Time to exact Average Cycle Time? It turns out\nthere are three. Those scenarios are:\n\n1. The Approximate Average Cycle Time is greater than your actual\n\nAverage Cycle Time. 2. The Approximate Average Cycle Time is less than your actual Average\n\nCycle Time. 3. The Approximate Average Cycle Time is roughly equal to your actual\n\nCycle Time. It may sound trite, but an easy way to remember which of these is best\nis “scenario three is where you want to be.” But it is because both scenarios\none and two put predictability at risk that we will begin our discussion with\nthose. Approximate Average Greater Than Actual Average\nIf the Approximate Average Cycle Time is greater than the exact Average\nCycle Time, then you can conclude that your process is incurring what I\nwould call “Flow Debt”. Flow Debt is when Cycle Time is artificially reduced for some items of Work In\nProgress by “borrowing” Cycle Time from other items of work in progress. To explain, a smaller exact Average Cycle Time calculation when\ncompared to the approximate average would tell you that you have (either\nexplicitly or implicitly) favored the faster completion of some work items\nover the regular completion of others. You were not able to conjure that\nshortened Cycle Time out of thin air (we are not like the Fed who can just\nprint money). This new ability to complete some items faster than they\nnormally would have finished must have come from somewhere. What you\ndid---whether you knew it or not---was to borrow Cycle Time from other", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt\n\nwill tell us if we can expect our exact Average Cycle Time to grow, decline,\nor stay the same over time. If our exact Average Cycle Time is either\ngrowing or declining then we have a violation of Little’s Law assumption #4\nwhich means that our predictability is in jeopardy. So what are the scenarios we need to consider when comparing\n\nApproximate Average Cycle Time to exact Average Cycle Time? It turns out\nthere are three. Those scenarios are:\n\n1. The Approximate Average Cycle Time is greater than your actual\n\nAverage Cycle Time. 2. The Approximate Average Cycle Time is less than your actual Average\n\nCycle Time. 3. The Approximate Average Cycle Time is roughly equal to your actual\n\nCycle Time. It may sound trite, but an easy way to remember which of these is best\nis “scenario three is where you want to be.” But it is because both scenarios\none and two put predictability at risk that we will begin our discussion with\nthose. Approximate Average Greater Than Actual Average\nIf the Approximate Average Cycle Time is greater than the exact Average\nCycle Time, then you can conclude that your process is incurring what I\nwould call “Flow Debt”. Flow Debt is when Cycle Time is artificially reduced for some items of Work In\nProgress by “borrowing” Cycle Time from other items of work in progress. To explain, a smaller exact Average Cycle Time calculation when\ncompared to the approximate average would tell you that you have (either\nexplicitly or implicitly) favored the faster completion of some work items\nover the regular completion of others. You were not able to conjure that\nshortened Cycle Time out of thin air (we are not like the Fed who can just\nprint money). This new ability to complete some items faster than they\nnormally would have finished must have come from somewhere. What you\ndid---whether you knew it or not---was to borrow Cycle Time from other", "tokens": 400, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 117, "segment_id": "00117", "chapter_num": "9", "chapter_title": "Flow Debt", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt", "chunk_id": "00000134"}
{"type": "chunk", "text": "work items that were already in progress. What you did was to create Flow\nDebt. This debt was used to pay for the expedited completion of the\npreferential work. One great example of a process taking on Flow Debt is when a system\n\nhas been designed with an expedite lane. A simple example of what an\nexpedite lane looks like on a Kanban board is shown in Figure 9.1:\n\nFigure 9.1: Expedite Lane Example\nWhen used, most expedite lanes have an extremely low WIP limit on\n\nthem (often set to one). Policies are also usually put in place such that items\nin expedite lanes can violate WIP limits at each step in the workflow. Further, most systems are designed such that when an expedite item is\nintroduced, it is pulled immediately for work---it is allowed to “jump the\nqueue” ahead of other work that is also ready to be pulled. If no resources\nare available to immediately pull the expedited entity, then many teams will\nblock other items to free up team members to go act on the expedited work. Given these normal policies, you can see why it is so important to be\nextremely conservative when setting the WIP limit on an expedite lane", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt\n\nwork items that were already in progress. What you did was to create Flow\nDebt. This debt was used to pay for the expedited completion of the\npreferential work. One great example of a process taking on Flow Debt is when a system\n\nhas been designed with an expedite lane. A simple example of what an\nexpedite lane looks like on a Kanban board is shown in Figure 9.1:\n\nFigure 9.1: Expedite Lane Example\nWhen used, most expedite lanes have an extremely low WIP limit on\n\nthem (often set to one). Policies are also usually put in place such that items\nin expedite lanes can violate WIP limits at each step in the workflow. Further, most systems are designed such that when an expedite item is\nintroduced, it is pulled immediately for work---it is allowed to “jump the\nqueue” ahead of other work that is also ready to be pulled. If no resources\nare available to immediately pull the expedited entity, then many teams will\nblock other items to free up team members to go act on the expedited work. Given these normal policies, you can see why it is so important to be\nextremely conservative when setting the WIP limit on an expedite lane", "tokens": 262, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 118, "segment_id": "00118", "chapter_num": "9", "chapter_title": "Flow Debt", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt", "chunk_id": "00000135"}
{"type": "chunk", "text": "(more information about expedited items, pull policies, and their effect on\npredictability, please see Chapter 13). Looking at Figure 9.1, you will notice that the WIP Limit for the\nexpedite lane is indeed set to one. This means that only one work item can\nbe in progress in that whole lane at any given time (but that work item can\nbe anywhere in the lane: Ready, Design, Development, or Test). As you can\nalso see, the expedite WIP limit has been adhered to and that the expedite\nitem is in the Development column. Let’s assume for a minute that no\ndevelopers were available when this item was pulled into the Development\nstep. What might happen is that the team would choose to block one (or\nmore) of those other three items in progress in order to free up resources to\ngo work on the expedited ticket. The team has chosen to take the time that\nwas to be allocated for work that was already in progress and apply that time\nto the expedited item. What has happened is that the team has chosen to\nartificially age one item (or more) in order to shorten the Cycle Time of\nanother. This is a classic example of the creation of Flow Debt. The problem is that this debt must be repaid (think the Mafia here and\n\nnot the U.S. Government). The payment of this debt will come in one of two\nways:\n\n1. The work items that were “passed over” in deference to the expedited\nitems will eventually themselves complete (in accordance with the\nprinciple of Conservation of Flow). When they do complete their Cycle\nTimes will be much longer than they normally would have been\nbecause they were forced to artificially age. Thus, debt repayment\ncomes in the form of longer Cycle Times for items already in progress. The resulting consequence is that you can have no confidence in the\n“average” Cycle Time you thought you were capable of because the\nmetrics you had collected did not include this debt. You can have no\nconfidence in this average because the accumulation of debt has made it\ninvalid; or,\n\n2. The work items that were “passed over” will be eventually kicked out\n\nof the system because they are no longer considered valuable (in\nviolation of Conservation of Flow); i.e., the window of time to realize\ntheir value has passed.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt\n\n(more information about expedited items, pull policies, and their effect on\npredictability, please see Chapter 13). Looking at Figure 9.1, you will notice that the WIP Limit for the\nexpedite lane is indeed set to one. This means that only one work item can\nbe in progress in that whole lane at any given time (but that work item can\nbe anywhere in the lane: Ready, Design, Development, or Test). As you can\nalso see, the expedite WIP limit has been adhered to and that the expedite\nitem is in the Development column. Let’s assume for a minute that no\ndevelopers were available when this item was pulled into the Development\nstep. What might happen is that the team would choose to block one (or\nmore) of those other three items in progress in order to free up resources to\ngo work on the expedited ticket. The team has chosen to take the time that\nwas to be allocated for work that was already in progress and apply that time\nto the expedited item. What has happened is that the team has chosen to\nartificially age one item (or more) in order to shorten the Cycle Time of\nanother. This is a classic example of the creation of Flow Debt. The problem is that this debt must be repaid (think the Mafia here and\n\nnot the U.S. Government). The payment of this debt will come in one of two\nways:\n\n1. The work items that were “passed over” in deference to the expedited\nitems will eventually themselves complete (in accordance with the\nprinciple of Conservation of Flow). When they do complete their Cycle\nTimes will be much longer than they normally would have been\nbecause they were forced to artificially age. Thus, debt repayment\ncomes in the form of longer Cycle Times for items already in progress. The resulting consequence is that you can have no confidence in the\n“average” Cycle Time you thought you were capable of because the\nmetrics you had collected did not include this debt. You can have no\nconfidence in this average because the accumulation of debt has made it\ninvalid; or,\n\n2. The work items that were “passed over” will be eventually kicked out\n\nof the system because they are no longer considered valuable (in\nviolation of Conservation of Flow); i.e., the window of time to realize\ntheir value has passed.", "tokens": 498, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 119, "segment_id": "00119", "chapter_num": "9", "chapter_title": "Flow Debt", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt", "chunk_id": "00000136"}
{"type": "chunk", "text": "The resulting consequence is that you can have no confidence in the\n“average” Cycle Time you thought you were capable of because the\nmetrics you had collected did not include this debt. You can have no\nconfidence in this average because the accumulation of debt has made it\ninvalid; or,\n\n2. The work items that were “passed over” will be eventually kicked out\n\nof the system because they are no longer considered valuable (in\nviolation of Conservation of Flow); i.e., the window of time to realize\ntheir value has passed. When these items are thrown out of your\nprocess, any effort or time that has been spent on progressing them\nthrough the system immediately becomes waste. Thus, the payment of\nFlow Debt is the wasted effort that could have been spent in realizing", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt\n\nThe resulting consequence is that you can have no confidence in the\n“average” Cycle Time you thought you were capable of because the\nmetrics you had collected did not include this debt. You can have no\nconfidence in this average because the accumulation of debt has made it\ninvalid; or,\n\n2. The work items that were “passed over” will be eventually kicked out\n\nof the system because they are no longer considered valuable (in\nviolation of Conservation of Flow); i.e., the window of time to realize\ntheir value has passed. When these items are thrown out of your\nprocess, any effort or time that has been spent on progressing them\nthrough the system immediately becomes waste. Thus, the payment of\nFlow Debt is the wasted effort that could have been spent in realizing", "tokens": 160, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 119, "segment_id": "00119", "chapter_num": "9", "chapter_title": "Flow Debt", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt", "chunk_id": "00000137"}
{"type": "chunk", "text": "the value of the discarded work item or in the form of wasted effort that\ncould have been spent realizing the value of something else. Either way, Flow Debt is repaid in the form of less predictability for\n\nyour process. I do not want you to conclude that all Flow Debt is bad. What you need\n\nto do is simply recognize that your system is incurring debt. The challenge\nfor you, then, is to think about how you might categorize your borrowing\ninto one of Minski’s types: Hedge, Speculative, or Ponzi. To classify what type of debtor you might be, ask yourself the\n\nfollowing questions:\n\n1. Hedge: Are expedites in your process more the exception than the rule\n(that is to say, does your board not have expedites significantly more\noften that it does have expedites)? When you do have expedited\nrequests, do you truly only ever have one item (or some WIP limited\namount of expedited items) in your process at a time? Does this time\nwith no expedited items give you an opportunity to finish work that was\notherwise blocked for previously expedited items? When you get an\nexpedited item, are you allowed to finish existing work before the\nexpedite is picked up? If the answers to these questions is yes, then you\nare probably running a properly “hedged” system. 2. Speculative: Is there always at least one item in your process and never\na time when you are not working on expedited work of some kind? Do\nyou routinely violate your expedited item WIP limit? If the answers to\nthese questions is yes, then you are probably running a speculative\nsystem and you might want to explore some options to apply more rigor\nto your expedite process. 3. Ponzi. Is all the work you do considered an expedite? Do expedited\nitems take up all of your available capacity such that you never get a\nchance to work on more “normal” items? Are your pull criteria based\nnot on explicit policies but on whomever is screaming the loudest? If\nthe answer to these questions is yes, then what you are really running is\na process Ponzi scheme. You will never be able to repay the debt you\nhave accumulated and any notion of total process predictability is gone.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt\n\nthe value of the discarded work item or in the form of wasted effort that\ncould have been spent realizing the value of something else. Either way, Flow Debt is repaid in the form of less predictability for\n\nyour process. I do not want you to conclude that all Flow Debt is bad. What you need\n\nto do is simply recognize that your system is incurring debt. The challenge\nfor you, then, is to think about how you might categorize your borrowing\ninto one of Minski’s types: Hedge, Speculative, or Ponzi. To classify what type of debtor you might be, ask yourself the\n\nfollowing questions:\n\n1. Hedge: Are expedites in your process more the exception than the rule\n(that is to say, does your board not have expedites significantly more\noften that it does have expedites)? When you do have expedited\nrequests, do you truly only ever have one item (or some WIP limited\namount of expedited items) in your process at a time? Does this time\nwith no expedited items give you an opportunity to finish work that was\notherwise blocked for previously expedited items? When you get an\nexpedited item, are you allowed to finish existing work before the\nexpedite is picked up? If the answers to these questions is yes, then you\nare probably running a properly “hedged” system. 2. Speculative: Is there always at least one item in your process and never\na time when you are not working on expedited work of some kind? Do\nyou routinely violate your expedited item WIP limit? If the answers to\nthese questions is yes, then you are probably running a speculative\nsystem and you might want to explore some options to apply more rigor\nto your expedite process. 3. Ponzi. Is all the work you do considered an expedite? Do expedited\nitems take up all of your available capacity such that you never get a\nchance to work on more “normal” items? Are your pull criteria based\nnot on explicit policies but on whomever is screaming the loudest? If\nthe answer to these questions is yes, then what you are really running is\na process Ponzi scheme. You will never be able to repay the debt you\nhave accumulated and any notion of total process predictability is gone.", "tokens": 489, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 120, "segment_id": "00120", "chapter_num": "9", "chapter_title": "Flow Debt", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt", "chunk_id": "00000138"}
{"type": "chunk", "text": "3. Ponzi. Is all the work you do considered an expedite? Do expedited\nitems take up all of your available capacity such that you never get a\nchance to work on more “normal” items? Are your pull criteria based\nnot on explicit policies but on whomever is screaming the loudest? If\nthe answer to these questions is yes, then what you are really running is\na process Ponzi scheme. You will never be able to repay the debt you\nhave accumulated and any notion of total process predictability is gone. You are fooling yourself if you continue to start “normal” work in\naddition to expedited work in this world. That normal work will almost", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt\n\n3. Ponzi. Is all the work you do considered an expedite? Do expedited\nitems take up all of your available capacity such that you never get a\nchance to work on more “normal” items? Are your pull criteria based\nnot on explicit policies but on whomever is screaming the loudest? If\nthe answer to these questions is yes, then what you are really running is\na process Ponzi scheme. You will never be able to repay the debt you\nhave accumulated and any notion of total process predictability is gone. You are fooling yourself if you continue to start “normal” work in\naddition to expedited work in this world. That normal work will almost", "tokens": 146, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 120, "segment_id": "00120", "chapter_num": "9", "chapter_title": "Flow Debt", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt", "chunk_id": "00000139"}
{"type": "chunk", "text": "never complete, or it will swapped out for other work, or it will finish\nfar too late for anyone to care. In my mind, this is the antithesis of flow. I want to make sure that you know that I am not advocating that you\nspend a lot of time on this classification nor that you become an expert in\neconomic theory. What I do want you to ask yourself is are you able to repay\nthe debt that you are taking out? How much debt is reasonable in your\ncontext? I guarantee that there are going to be some very good reasons to\ntake on “Hedge” Flow Debt from time to time (a great analogy to this in the\nreal world is when prospective homeowners take out a mortgage---assuming\nthey can be repaid, most mortgages are considered good debt). The question\nfor you becomes: are you able to service the Flow Debt that you have taken\nout? By the way, I have picked on expedite work items here, but it should be\n\nnoted that an explicit expedite lane is not the only way to incur Flow Debt. Extending the scenario from above, let’s say that you have an item in\nthe “Design Done” column. And let’s say that that item just sits there and\nnever gets pulled into “Development Doing” because you care constantly\nchoosing to pull other items in preference to it. If so, then congratulations,\nyou have Flow Debt. This particular scenario is depicted in the following diagram (Figure\n\n9.2):\n\nFigure 9.2: Ignoring an Item While it is Queuing\nAnother example of the creation of Flow Debt might be if you have\nblocked items that you ignore or do not actively work to get unblocked and\nmoving again as quickly as possible (Figure 9.3):", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt\n\nnever complete, or it will swapped out for other work, or it will finish\nfar too late for anyone to care. In my mind, this is the antithesis of flow. I want to make sure that you know that I am not advocating that you\nspend a lot of time on this classification nor that you become an expert in\neconomic theory. What I do want you to ask yourself is are you able to repay\nthe debt that you are taking out? How much debt is reasonable in your\ncontext? I guarantee that there are going to be some very good reasons to\ntake on “Hedge” Flow Debt from time to time (a great analogy to this in the\nreal world is when prospective homeowners take out a mortgage---assuming\nthey can be repaid, most mortgages are considered good debt). The question\nfor you becomes: are you able to service the Flow Debt that you have taken\nout? By the way, I have picked on expedite work items here, but it should be\n\nnoted that an explicit expedite lane is not the only way to incur Flow Debt. Extending the scenario from above, let’s say that you have an item in\nthe “Design Done” column. And let’s say that that item just sits there and\nnever gets pulled into “Development Doing” because you care constantly\nchoosing to pull other items in preference to it. If so, then congratulations,\nyou have Flow Debt. This particular scenario is depicted in the following diagram (Figure\n\n9.2):\n\nFigure 9.2: Ignoring an Item While it is Queuing\nAnother example of the creation of Flow Debt might be if you have\nblocked items that you ignore or do not actively work to get unblocked and\nmoving again as quickly as possible (Figure 9.3):", "tokens": 373, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 121, "segment_id": "00121", "chapter_num": "9", "chapter_title": "Flow Debt", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt", "chunk_id": "00000140"}
{"type": "chunk", "text": "Figure 9.3: Ignoring a Blocked Item\n\nI am sure there are other examples, but I will leave it as an exercise for\n\nthe reader to identify the types of Flow Debt in your context. By the way, the concepts in this chapter can be applied to any type of\n\ndebt that you may incur in your process (e.g., technical debt). The trick is to\nrecognize that you are creating debt and have a constructive conversation\nabout how that debt is going to be repaid. Approximate Average is Less Than Actual Average\nThis scenario is a bit less interesting than the last one. If in the above\nsituation we were talking about accumulating Flow Debt, then the case\nwhere the Approximate Average Cycle Time on your CFD is less than your\nactual Average Cycle Time means that you are paying off Flow Debt (again,\nfor the time interval under consideration). A larger actual Average Cycle Time means that those items that have---\n\nfor whatever reason---languished in progress are now finally completing. The actual average has become inflated because as the artificially aged items\ncomplete they make the actual average calculation come out “larger” than it\notherwise would have been under normal circumstances. However, paying off Flow Debt also hampers predictability. Items that\nfinish with large amounts of Flow Debt attached to them skew Cycle Time\nnumbers. An increased variability in Cycle Time means that we must\ncommunicate a larger range for the SLA of our process (see the discussion in\nthe previous chapter and in Chapter 12). A good analogy of why this might\nbe dangerous is that of a restaurant who has customers waiting to be seated. Imagine that the true wait time for customers is fifteen minutes, but because\nof variability in their seating process, the restaurant has to communicate a\ntwo hour wait time to arriving patrons. What do you think those customers\nwill do? The same thing will happen in your own process. The more your", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt\n\nFigure 9.3: Ignoring a Blocked Item\n\nI am sure there are other examples, but I will leave it as an exercise for\n\nthe reader to identify the types of Flow Debt in your context. By the way, the concepts in this chapter can be applied to any type of\n\ndebt that you may incur in your process (e.g., technical debt). The trick is to\nrecognize that you are creating debt and have a constructive conversation\nabout how that debt is going to be repaid. Approximate Average is Less Than Actual Average\nThis scenario is a bit less interesting than the last one. If in the above\nsituation we were talking about accumulating Flow Debt, then the case\nwhere the Approximate Average Cycle Time on your CFD is less than your\nactual Average Cycle Time means that you are paying off Flow Debt (again,\nfor the time interval under consideration). A larger actual Average Cycle Time means that those items that have---\n\nfor whatever reason---languished in progress are now finally completing. The actual average has become inflated because as the artificially aged items\ncomplete they make the actual average calculation come out “larger” than it\notherwise would have been under normal circumstances. However, paying off Flow Debt also hampers predictability. Items that\nfinish with large amounts of Flow Debt attached to them skew Cycle Time\nnumbers. An increased variability in Cycle Time means that we must\ncommunicate a larger range for the SLA of our process (see the discussion in\nthe previous chapter and in Chapter 12). A good analogy of why this might\nbe dangerous is that of a restaurant who has customers waiting to be seated. Imagine that the true wait time for customers is fifteen minutes, but because\nof variability in their seating process, the restaurant has to communicate a\ntwo hour wait time to arriving patrons. What do you think those customers\nwill do? The same thing will happen in your own process. The more your", "tokens": 400, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 122, "segment_id": "00122", "chapter_num": "9", "chapter_title": "Flow Debt", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt", "chunk_id": "00000141"}
{"type": "chunk", "text": "system is unpredictable, the more your customers will begin to look\nelsewhere for service. Remember that these conclusions can only be drawn assuming we are\n\nrunning an otherwise stable system (i.e., nothing about the underlying\nsystem design has changed materially). Approximate Average Roughly Equal to Actual Average\nThis case is where you want to be most of the time. If your Approximate\nAverage Cycle Time is approximately equal to your actual Average Cycle\nTime, then your process is probably performing in a fairly orderly,\npredictable manner. You are not overloaded with expedite requests, you are\nnot allowing items to stay blocked indefinitely, and you are not allowing\nitems to queue arbitrarily. In other words, you are neither accumulating nor\nrepaying Flow Debt. That is not to suggest that there are not any other areas of your process\n\nthat are unhealthy. And if you do find yourself in this situation, do not pat\nyourself on the back too quickly. A more stable system such as the one that\nyou have just engineered requires constant vigilance against the multitude of\ndestabilizing forces that present themselves every day. How Different is Different? So how different do my different average calculations need to be in order for\nme to take action? Like most questions in Kanban, the answer to this one is,\n“it depends”. The conclusions you draw and the actions you should take are\nhighly context specific. One reason this question is difficult to answer is because the\n\nApproximate Average Cycle Time calculation is just that: an approximation. Therefore, some difference between the approximate and the actual is to be\nexpected. If the difference is about 10%, then you might not get too excited. However, if the difference is 50%, then that might be a pretty good clue to\ntake action. Over time you will get a very good feel for what constitutes\n“different” in your world. Conclusion\nAre you running a process Ponzi scheme? Do you even know?", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt\n\nsystem is unpredictable, the more your customers will begin to look\nelsewhere for service. Remember that these conclusions can only be drawn assuming we are\n\nrunning an otherwise stable system (i.e., nothing about the underlying\nsystem design has changed materially). Approximate Average Roughly Equal to Actual Average\nThis case is where you want to be most of the time. If your Approximate\nAverage Cycle Time is approximately equal to your actual Average Cycle\nTime, then your process is probably performing in a fairly orderly,\npredictable manner. You are not overloaded with expedite requests, you are\nnot allowing items to stay blocked indefinitely, and you are not allowing\nitems to queue arbitrarily. In other words, you are neither accumulating nor\nrepaying Flow Debt. That is not to suggest that there are not any other areas of your process\n\nthat are unhealthy. And if you do find yourself in this situation, do not pat\nyourself on the back too quickly. A more stable system such as the one that\nyou have just engineered requires constant vigilance against the multitude of\ndestabilizing forces that present themselves every day. How Different is Different? So how different do my different average calculations need to be in order for\nme to take action? Like most questions in Kanban, the answer to this one is,\n“it depends”. The conclusions you draw and the actions you should take are\nhighly context specific. One reason this question is difficult to answer is because the\n\nApproximate Average Cycle Time calculation is just that: an approximation. Therefore, some difference between the approximate and the actual is to be\nexpected. If the difference is about 10%, then you might not get too excited. However, if the difference is 50%, then that might be a pretty good clue to\ntake action. Over time you will get a very good feel for what constitutes\n“different” in your world. Conclusion\nAre you running a process Ponzi scheme? Do you even know?", "tokens": 403, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 123, "segment_id": "00123", "chapter_num": "9", "chapter_title": "Flow Debt", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt", "chunk_id": "00000142"}
{"type": "chunk", "text": "If your process is unpredictable, one of the first places to investigate is\n\nhow much Flow Debt you are carrying. Think about what process policies\nyou can put in place to restore some stability to your system. If you believe\nyour system is not “ponz-ified”, what process policies can you institute to\nensure that your process remains stable? Lastly, I want to say that I have tried very hard to steer clear of using\nthe term “Class of Service” (CoS) in this chapter. Many of you will have\nfigured out, however, that CoS is exactly what I am talking about. I\npersonally am not a big fan of the way CoS is normally touted in our\nLean/Agile/Kanban community. To be clear, I am not a fan not because CoS\nis inherently bad, but because most teams do not know how to implement it\nproperly---nor do they understand what this improper implementation is\ndoing to their system’s predictability, performance, and/or risk management\nability. Those three goals, ironically, are usually the exact ones promoted to\njustify the use of CoS. Unfortunately, a deeper discussion of CoS and its perils will have to\n\nwait until Chapter 13. That is because I need to move on to the more\npressing need of introducing the next of our flow analytics: the Cycle Time\nScatterplot. Key Learnings and Takeaways\n\nFlow Debt is when Cycle Time is artificially reduced for some work\nitems in progress by “borrowing” Cycle Time from other work items in\nprogress. Some examples of scenarios that lead to the creation of Flow Debt are:\n\nClasses of Service\nBlockers\nOther order of pull policies in place (whether they are explicit or\nnot)\n\nComparing the Approximate Average Cycle Time for work items on a\nCFD with the exact Average Cycle Time for those work items\n(calculated from the data) can give us an idea of whether Flow Debt is\nbeing created or not. When the Approximate Average Cycle Time on your CFD is greater\nthan your actual Average Cycle Time then your process is accumulating\nFlow Debt.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt\n\nIf your process is unpredictable, one of the first places to investigate is\n\nhow much Flow Debt you are carrying. Think about what process policies\nyou can put in place to restore some stability to your system. If you believe\nyour system is not “ponz-ified”, what process policies can you institute to\nensure that your process remains stable? Lastly, I want to say that I have tried very hard to steer clear of using\nthe term “Class of Service” (CoS) in this chapter. Many of you will have\nfigured out, however, that CoS is exactly what I am talking about. I\npersonally am not a big fan of the way CoS is normally touted in our\nLean/Agile/Kanban community. To be clear, I am not a fan not because CoS\nis inherently bad, but because most teams do not know how to implement it\nproperly---nor do they understand what this improper implementation is\ndoing to their system’s predictability, performance, and/or risk management\nability. Those three goals, ironically, are usually the exact ones promoted to\njustify the use of CoS. Unfortunately, a deeper discussion of CoS and its perils will have to\n\nwait until Chapter 13. That is because I need to move on to the more\npressing need of introducing the next of our flow analytics: the Cycle Time\nScatterplot. Key Learnings and Takeaways\n\nFlow Debt is when Cycle Time is artificially reduced for some work\nitems in progress by “borrowing” Cycle Time from other work items in\nprogress. Some examples of scenarios that lead to the creation of Flow Debt are:\n\nClasses of Service\nBlockers\nOther order of pull policies in place (whether they are explicit or\nnot)\n\nComparing the Approximate Average Cycle Time for work items on a\nCFD with the exact Average Cycle Time for those work items\n(calculated from the data) can give us an idea of whether Flow Debt is\nbeing created or not. When the Approximate Average Cycle Time on your CFD is greater\nthan your actual Average Cycle Time then your process is accumulating\nFlow Debt.", "tokens": 444, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 124, "segment_id": "00124", "chapter_num": "9", "chapter_title": "Flow Debt", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt", "chunk_id": "00000143"}
{"type": "chunk", "text": "When the Approximate Average Cycle Time is less than your actual\nAverage Cycle Time then your process is paying off Flow Debt. When the Approximate Average Cycle Time is roughly equal to your\nactual Cycle Time then your process is stable from a Flow Debt\nperspective. Flow Debt leads to process unpredictability because by Little’s Law\nAssumption #2 the work items that were allowed to artificially age\neventually will need to complete and leave the system. This artificial\naging leads not only to longer overall Cycle Times, but more variability\nin your Cycle Time data.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt\n\nWhen the Approximate Average Cycle Time is less than your actual\nAverage Cycle Time then your process is paying off Flow Debt. When the Approximate Average Cycle Time is roughly equal to your\nactual Cycle Time then your process is stable from a Flow Debt\nperspective. Flow Debt leads to process unpredictability because by Little’s Law\nAssumption #2 the work items that were allowed to artificially age\neventually will need to complete and leave the system. This artificial\naging leads not only to longer overall Cycle Times, but more variability\nin your Cycle Time data.", "tokens": 115, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 125, "segment_id": "00125", "chapter_num": "9", "chapter_title": "Flow Debt", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 9: Flow Debt", "chunk_id": "00000144"}
{"type": "chunk", "text": "Chapter 10 - Introduction to Cycle Time\nScatterplots\n\nI spent a lot of time in the last several chapters talking about how\nCumulative Flow Diagrams can give you a good idea of how long it takes\nfor items to flow through your process on average. However, there are going\nto be times when doing analysis based solely on average is not going to be\ngood enough (things like forecasting a completion date come to mind, for\nexample). Not to worry because we can do much better than analysis based\non averages anyway. This is where Scatterplots come in. Scatterplots are a little less complicated than Cumulative Flow\nDiagrams but that in no way diminishes their usefulness. What diminishes\ntheir usefulness is, again, the misinformation and disinformation that has\nbeen published about them. In fact, my guess is that until now you have\nprobably not come across the term “Scatterplot” in reference to Cycle Time\nanalysis. Rather, you have probably been told that you need to look at your\nCycle Time data in something called a “Control Chart”. Not true. I will talk\nabout why Control Charts are really not all that useful in our domain a little\nlater (please note that Statistical Process Control will not be covered at all in\nthis book). For now do not get hung up on confusing terms like “Control\nChart”. There is a much simpler and better way. But before I get into the explanation about how to do basic quantitative\n\nand qualitative analysis using Scatterplots, I need to make one thing clear\nabout how to read this chapter. For this discussion I am going to focus only\non how to chart the flow metric Cycle Time on a Scatterplot. In reality you\ncan put pretty much any metric that you want to in a Scatterplot. You can put\nthings like Throughput, bugs per feature, work items per epic, etc. For the\npurposes of this chapter, however, whenever I say the word “Scatterplot”\nwithout any qualifier, what I really mean is “Cycle Time Scatterplot” (if you\nwould like a refresher on how I am choosing to define Cycle Time, then\nplease revisit Chapter 2).", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time\n\nChapter 10 - Introduction to Cycle Time\nScatterplots\n\nI spent a lot of time in the last several chapters talking about how\nCumulative Flow Diagrams can give you a good idea of how long it takes\nfor items to flow through your process on average. However, there are going\nto be times when doing analysis based solely on average is not going to be\ngood enough (things like forecasting a completion date come to mind, for\nexample). Not to worry because we can do much better than analysis based\non averages anyway. This is where Scatterplots come in. Scatterplots are a little less complicated than Cumulative Flow\nDiagrams but that in no way diminishes their usefulness. What diminishes\ntheir usefulness is, again, the misinformation and disinformation that has\nbeen published about them. In fact, my guess is that until now you have\nprobably not come across the term “Scatterplot” in reference to Cycle Time\nanalysis. Rather, you have probably been told that you need to look at your\nCycle Time data in something called a “Control Chart”. Not true. I will talk\nabout why Control Charts are really not all that useful in our domain a little\nlater (please note that Statistical Process Control will not be covered at all in\nthis book). For now do not get hung up on confusing terms like “Control\nChart”. There is a much simpler and better way. But before I get into the explanation about how to do basic quantitative\n\nand qualitative analysis using Scatterplots, I need to make one thing clear\nabout how to read this chapter. For this discussion I am going to focus only\non how to chart the flow metric Cycle Time on a Scatterplot. In reality you\ncan put pretty much any metric that you want to in a Scatterplot. You can put\nthings like Throughput, bugs per feature, work items per epic, etc. For the\npurposes of this chapter, however, whenever I say the word “Scatterplot”\nwithout any qualifier, what I really mean is “Cycle Time Scatterplot” (if you\nwould like a refresher on how I am choosing to define Cycle Time, then\nplease revisit Chapter 2).", "tokens": 452, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 127, "segment_id": "00127", "chapter_num": "10", "chapter_title": "Introduction to Cycle Time", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time", "chunk_id": "00000145"}
{"type": "chunk", "text": "What is a Cycle Time Scatterplot? Just as with the CFDs, it will first be beneficial to get a basic understanding\nof a Scatterplot’s anatomy before diving into what these charts can tell us. If you have never seen a Cycle Time Scatterplot before, then one is\n\ndisplayed in Figure 10.1 for your reference:\n\nFigure 10.1: A Basic Cycle Time Scatterplot\nAs you can see from Figure 10.1, across the bottom (the X-axis) is\nsome representation of the progression of time. Like CFDs, the X-axis\nessentially represents a timeline for our process. The tick marks on the Xaxis represents our choice of labels for that timeline. When labeling the Xaxis, you can choose whatever frequency of labels you want. In this\nparticular Scatterplot, we have chosen to label every month. However you\ncan choose whatever label is best for your specific needs. You can choose to\nlabel every two weeks, every month, every day, etc. I should point out that in Figure 10.1 I have chosen to show the timeline\n\nprogression from left to right. This is not a requirement, it is only a\npreference. I could have easily shown time progression from right to left. I,\npersonally, have never seen a Cycle Time Scatterplot that shows time\nprogression from right to left, but there is no reason why one could not be\nconstructed that way. However, for the rest of this chapter (and this book), I\nwill show all Scatterplot time progressions from left to right.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time\n\nWhat is a Cycle Time Scatterplot? Just as with the CFDs, it will first be beneficial to get a basic understanding\nof a Scatterplot’s anatomy before diving into what these charts can tell us. If you have never seen a Cycle Time Scatterplot before, then one is\n\ndisplayed in Figure 10.1 for your reference:\n\nFigure 10.1: A Basic Cycle Time Scatterplot\nAs you can see from Figure 10.1, across the bottom (the X-axis) is\nsome representation of the progression of time. Like CFDs, the X-axis\nessentially represents a timeline for our process. The tick marks on the Xaxis represents our choice of labels for that timeline. When labeling the Xaxis, you can choose whatever frequency of labels you want. In this\nparticular Scatterplot, we have chosen to label every month. However you\ncan choose whatever label is best for your specific needs. You can choose to\nlabel every two weeks, every month, every day, etc. I should point out that in Figure 10.1 I have chosen to show the timeline\n\nprogression from left to right. This is not a requirement, it is only a\npreference. I could have easily shown time progression from right to left. I,\npersonally, have never seen a Cycle Time Scatterplot that shows time\nprogression from right to left, but there is no reason why one could not be\nconstructed that way. However, for the rest of this chapter (and this book), I\nwill show all Scatterplot time progressions from left to right.", "tokens": 330, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 128, "segment_id": "00128", "chapter_num": "10", "chapter_title": "Introduction to Cycle Time", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time", "chunk_id": "00000146"}
{"type": "chunk", "text": "Up the side (the Y-axis) of your chart is going to be some representation\nof Cycle Time. Again, you can choose whatever units of Cycle Time that you\nwant for this axis. For example, you can measure Cycle Time in days,\nweeks, months, etc. To generate a Scatterplot, any time a work item completes, you find the\n\ndate that it completed across the bottom and plot a dot on the chart area\naccording to its Cycle Time. For example, let’s say a work item took seven\ndays to complete and it finished January 1, 2013. On the Scatterplot you\nwould go across the bottom to find January 1, 2013 and then go up and put it\na dot at seven days. Recall that for CFDs you could choose whatever time\nreporting interval you wanted to plot your data. In a Scatterplot, however,\nthere is really no concept of a reporting interval. A dot is always plotted on\nthe day a given work item finishes. Note that you could have several items that finish on same day with the\nsame Cycle Time. In that case, you would simply plot the several dots on top\nof one another. Hopefully whatever tool you are using to plot your\nScatterplot can handle this case, and, further, can alert you to the instances\nwhere you have several dots on top of each other. In the ActionableAgileTM\nAnalytics tool, we signify this situation by putting a little number on the dot\nto show there is more than one work item located at that point (as also\nshown in Figure 10.1). Over time as you plot more and more work item completions, a random\nset of dots will emerge on your chart. The original diagram I showed you in\nFigure 10.1 is a good example of what I am talking about. So how do we get\nuseful information off of a chart that just looks like a bunch of random dots? Percentile Lines\nThe first thing that we can do to gain a better understanding of our process’s\nCycle Time performance is to draw what I would call “standard percentile\nlines” on our Scatterplot. I should stress upfront that this standard percentile\napproach is only a starting point---you will have every opportunity to change\nthese percentiles as you get a better understanding of your context.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time\n\nUp the side (the Y-axis) of your chart is going to be some representation\nof Cycle Time. Again, you can choose whatever units of Cycle Time that you\nwant for this axis. For example, you can measure Cycle Time in days,\nweeks, months, etc. To generate a Scatterplot, any time a work item completes, you find the\n\ndate that it completed across the bottom and plot a dot on the chart area\naccording to its Cycle Time. For example, let’s say a work item took seven\ndays to complete and it finished January 1, 2013. On the Scatterplot you\nwould go across the bottom to find January 1, 2013 and then go up and put it\na dot at seven days. Recall that for CFDs you could choose whatever time\nreporting interval you wanted to plot your data. In a Scatterplot, however,\nthere is really no concept of a reporting interval. A dot is always plotted on\nthe day a given work item finishes. Note that you could have several items that finish on same day with the\nsame Cycle Time. In that case, you would simply plot the several dots on top\nof one another. Hopefully whatever tool you are using to plot your\nScatterplot can handle this case, and, further, can alert you to the instances\nwhere you have several dots on top of each other. In the ActionableAgileTM\nAnalytics tool, we signify this situation by putting a little number on the dot\nto show there is more than one work item located at that point (as also\nshown in Figure 10.1). Over time as you plot more and more work item completions, a random\nset of dots will emerge on your chart. The original diagram I showed you in\nFigure 10.1 is a good example of what I am talking about. So how do we get\nuseful information off of a chart that just looks like a bunch of random dots? Percentile Lines\nThe first thing that we can do to gain a better understanding of our process’s\nCycle Time performance is to draw what I would call “standard percentile\nlines” on our Scatterplot. I should stress upfront that this standard percentile\napproach is only a starting point---you will have every opportunity to change\nthese percentiles as you get a better understanding of your context.", "tokens": 488, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 129, "segment_id": "00129", "chapter_num": "10", "chapter_title": "Introduction to Cycle Time", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time", "chunk_id": "00000147"}
{"type": "chunk", "text": "The original diagram I showed you in\nFigure 10.1 is a good example of what I am talking about. So how do we get\nuseful information off of a chart that just looks like a bunch of random dots? Percentile Lines\nThe first thing that we can do to gain a better understanding of our process’s\nCycle Time performance is to draw what I would call “standard percentile\nlines” on our Scatterplot. I should stress upfront that this standard percentile\napproach is only a starting point---you will have every opportunity to change\nthese percentiles as you get a better understanding of your context. I would\nargue, however, that these standard percentiles represent a good enough\nplace to start for most teams. The best way to explain how to use standard percentiles on a Scatterplot\n\nis by example. I want to refer you again to the chart shown in Figure 10.1. Looking at this graph the first line that we could draw would be at the 50th", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time\n\nThe original diagram I showed you in\nFigure 10.1 is a good example of what I am talking about. So how do we get\nuseful information off of a chart that just looks like a bunch of random dots? Percentile Lines\nThe first thing that we can do to gain a better understanding of our process’s\nCycle Time performance is to draw what I would call “standard percentile\nlines” on our Scatterplot. I should stress upfront that this standard percentile\napproach is only a starting point---you will have every opportunity to change\nthese percentiles as you get a better understanding of your context. I would\nargue, however, that these standard percentiles represent a good enough\nplace to start for most teams. The best way to explain how to use standard percentiles on a Scatterplot\n\nis by example. I want to refer you again to the chart shown in Figure 10.1. Looking at this graph the first line that we could draw would be at the 50th", "tokens": 207, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 129, "segment_id": "00129", "chapter_num": "10", "chapter_title": "Introduction to Cycle Time", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time", "chunk_id": "00000148"}
{"type": "chunk", "text": "percentile of Cycle Times. The 50th percentile line is going to represent the\nvalue for a Cycle Time such that if we draw a line completely across the\nchart at that Cycle Time, 50% of the dots on the chart fall below that line and\n50% of the dots are above that line. This calculation is shown in Figure 10.2\nbelow. Figure 10.2: The 50th Percentile Line added to a Scatterplot\nIn this example the 50th percentile line occurs at twenty days. That\nmeans that 50% of the work items that have flowed through our process took\ntwenty days or less to complete. Another way of saying that is that when a\nwork item enters our process it has a 50% chance of finishing in twenty days\nor less (more on this concept a little later). The next line that might be of interest to us is the 85th percentile. Again\nthis line represents the amount of time it took for 85% of our work items to\nfinish. In Figure 10.3 you can see that the 85th percentile line occurs at 43\ndays. That means that 85% of the dots on our chart fall below that line and\n15% of the dots on our chart fall above that line. This percentile line tells us\nis that when a work item enters our process it has an 85% chance of\nfinishing in 43 days or less. This calculation is shown in Figure 10.3 below.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time\n\npercentile of Cycle Times. The 50th percentile line is going to represent the\nvalue for a Cycle Time such that if we draw a line completely across the\nchart at that Cycle Time, 50% of the dots on the chart fall below that line and\n50% of the dots are above that line. This calculation is shown in Figure 10.2\nbelow. Figure 10.2: The 50th Percentile Line added to a Scatterplot\nIn this example the 50th percentile line occurs at twenty days. That\nmeans that 50% of the work items that have flowed through our process took\ntwenty days or less to complete. Another way of saying that is that when a\nwork item enters our process it has a 50% chance of finishing in twenty days\nor less (more on this concept a little later). The next line that might be of interest to us is the 85th percentile. Again\nthis line represents the amount of time it took for 85% of our work items to\nfinish. In Figure 10.3 you can see that the 85th percentile line occurs at 43\ndays. That means that 85% of the dots on our chart fall below that line and\n15% of the dots on our chart fall above that line. This percentile line tells us\nis that when a work item enters our process it has an 85% chance of\nfinishing in 43 days or less. This calculation is shown in Figure 10.3 below.", "tokens": 315, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 130, "segment_id": "00130", "chapter_num": "10", "chapter_title": "Introduction to Cycle Time", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time", "chunk_id": "00000149"}
{"type": "chunk", "text": "Figure 10.3: The 85th Percentile Line Added to a Scatterplot\nAnother line we might want to draw is the 95th percentile line. As\n\nbefore this line represents the amount of time at which 95% of our work\nitems complete. In Figure 10.4 the 95th percentile line occurs at 63 days and\ntells us that our work items have a 95% chance of finishing in 63 days or\nless. This calculation is shown in Figure 10.4 below.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time\n\nFigure 10.3: The 85th Percentile Line Added to a Scatterplot\nAnother line we might want to draw is the 95th percentile line. As\n\nbefore this line represents the amount of time at which 95% of our work\nitems complete. In Figure 10.4 the 95th percentile line occurs at 63 days and\ntells us that our work items have a 95% chance of finishing in 63 days or\nless. This calculation is shown in Figure 10.4 below.", "tokens": 110, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 131, "segment_id": "00131", "chapter_num": "10", "chapter_title": "Introduction to Cycle Time", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time", "chunk_id": "00000150"}
{"type": "chunk", "text": "Figure 10.4: The 95th Percentile Line added to a Scatterplot\nThe 50th, 85th, and 95th percentiles are probably the most popular\n“standard” percentiles to draw. Other percentiles that you will see, though,\ncould include the 30th and 70th. Calculating those percentiles is exactly the\nsame as I have just demonstrated with the others. A Scatterplot with all of\nthese percentile lines is shown in Figure 10.5 (note the 30th percentile is 11\ndays and the 70th percentile is 32 days):", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time\n\nFigure 10.4: The 95th Percentile Line added to a Scatterplot\nThe 50th, 85th, and 95th percentiles are probably the most popular\n“standard” percentiles to draw. Other percentiles that you will see, though,\ncould include the 30th and 70th. Calculating those percentiles is exactly the\nsame as I have just demonstrated with the others. A Scatterplot with all of\nthese percentile lines is shown in Figure 10.5 (note the 30th percentile is 11\ndays and the 70th percentile is 32 days):", "tokens": 129, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 132, "segment_id": "00132", "chapter_num": "10", "chapter_title": "Introduction to Cycle Time", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time", "chunk_id": "00000151"}
{"type": "chunk", "text": "Figure 10.5: 30th, 50th, 70th, 85th, and 95th Percentile Lines all shown on a Scatterplot\nI am sure you have noticed that as we increase our level of confidence\nwe have to increase the amount of time it takes for work items to complete. This is due to the variability inherent in our process. We will spend a little\nbit of time talking about variability later in this chapter. What we will see in\nthat discussion is that no matter how hard we try to drive it out, variability\nwill always be present in our system. But that is okay. It turns out that we do\nneed a little variability in order to protect flow. However, what we are going\nto want to understand is how much of that variability is self-imposed, and\nhow much of that variability is outside of our control. The good news is that\nI will give you ways to identify each of these cases and strategies with which\nto handle them. As I mentioned earlier, drawing these standard percentile lines is a good\n\nstart, but you can see that you can easily add or subtract other percentile\nlines to your chart as you see fit. Which lines to draw is mostly going to be a\nfunction of what you want to learn from your data. Your Data is Not Normal\nMany electronic tools will draw arithmetic mean and standard deviation\nlines on their Scatterplots instead of drawing the standard percentile lines as\ndescribed above. That is to say, these tools will figure out the arithmetic\nmean of all of their Cycle Time data and then first draw that horizontal line", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time\n\nFigure 10.5: 30th, 50th, 70th, 85th, and 95th Percentile Lines all shown on a Scatterplot\nI am sure you have noticed that as we increase our level of confidence\nwe have to increase the amount of time it takes for work items to complete. This is due to the variability inherent in our process. We will spend a little\nbit of time talking about variability later in this chapter. What we will see in\nthat discussion is that no matter how hard we try to drive it out, variability\nwill always be present in our system. But that is okay. It turns out that we do\nneed a little variability in order to protect flow. However, what we are going\nto want to understand is how much of that variability is self-imposed, and\nhow much of that variability is outside of our control. The good news is that\nI will give you ways to identify each of these cases and strategies with which\nto handle them. As I mentioned earlier, drawing these standard percentile lines is a good\n\nstart, but you can see that you can easily add or subtract other percentile\nlines to your chart as you see fit. Which lines to draw is mostly going to be a\nfunction of what you want to learn from your data. Your Data is Not Normal\nMany electronic tools will draw arithmetic mean and standard deviation\nlines on their Scatterplots instead of drawing the standard percentile lines as\ndescribed above. That is to say, these tools will figure out the arithmetic\nmean of all of their Cycle Time data and then first draw that horizontal line", "tokens": 333, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 133, "segment_id": "00133", "chapter_num": "10", "chapter_title": "Introduction to Cycle Time", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time", "chunk_id": "00000152"}
{"type": "chunk", "text": "on the chart. They will then compute a standard deviation for that data and\ndraw horizontal lines corresponding to the mean plus one standard deviation\nand the mean minus one standard deviation. They might go further and draw the +2 standard deviation and -2\nstandard deviation lines as well as the +3 standard deviation and -3 standard\ndeviation lines. They will call the top standard deviation line the “Upper\nControl Limit” (UCL) and they will call the bottom standard deviation line\nthe “Lower Control Limit” (LCL). They will then call the resulting graph a\n“Control Chart”. If you are using an electronic tool to track your process\nmaybe you have seen an example of a Control Chart. You might have further heard several claims about these charts. First\nyou may have heard that on a Control Chart (as described above) 68.2% of\nthe dots fall between the plus one standard deviation line and the minus one\nstandard deviation line. They might further go on to say that over 99% of the\ndots fall between the +3 standard deviation in the -3 standard deviation line. You might have further heard that the reason you want to segment your data\nthis way is because this type of visualization will be able to tell you if your\nprocess is in control or not (hence the name Control Chart). Any dots that\nfall above the UCL or below the LCL, it is argued, signify the points in your\nprocess that are out of control. What is being called a Control Chart here is supposedly inspired by the\n\nwork of Walter A. Shewhart while employed at Bell Labs in the 1920s. Shewhart’s work was later picked up by W. Edwards Deming who became\none of the biggest proponents of the Control Chart visualization. There is only one problem. By using the method outlined above what\nthey have created is most certainly not a Control Chart---at least not in the\nShewhart tradition. What Shewhart Control Charts are and how to construct\nthem are way beyond the scope of this book, but just know that you should\nbe skeptical whenever you see someone show you something that is labeled\n“Control Chart”---as it most certainly is not.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time\n\non the chart. They will then compute a standard deviation for that data and\ndraw horizontal lines corresponding to the mean plus one standard deviation\nand the mean minus one standard deviation. They might go further and draw the +2 standard deviation and -2\nstandard deviation lines as well as the +3 standard deviation and -3 standard\ndeviation lines. They will call the top standard deviation line the “Upper\nControl Limit” (UCL) and they will call the bottom standard deviation line\nthe “Lower Control Limit” (LCL). They will then call the resulting graph a\n“Control Chart”. If you are using an electronic tool to track your process\nmaybe you have seen an example of a Control Chart. You might have further heard several claims about these charts. First\nyou may have heard that on a Control Chart (as described above) 68.2% of\nthe dots fall between the plus one standard deviation line and the minus one\nstandard deviation line. They might further go on to say that over 99% of the\ndots fall between the +3 standard deviation in the -3 standard deviation line. You might have further heard that the reason you want to segment your data\nthis way is because this type of visualization will be able to tell you if your\nprocess is in control or not (hence the name Control Chart). Any dots that\nfall above the UCL or below the LCL, it is argued, signify the points in your\nprocess that are out of control. What is being called a Control Chart here is supposedly inspired by the\n\nwork of Walter A. Shewhart while employed at Bell Labs in the 1920s. Shewhart’s work was later picked up by W. Edwards Deming who became\none of the biggest proponents of the Control Chart visualization. There is only one problem. By using the method outlined above what\nthey have created is most certainly not a Control Chart---at least not in the\nShewhart tradition. What Shewhart Control Charts are and how to construct\nthem are way beyond the scope of this book, but just know that you should\nbe skeptical whenever you see someone show you something that is labeled\n“Control Chart”---as it most certainly is not.", "tokens": 461, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 134, "segment_id": "00134", "chapter_num": "10", "chapter_title": "Introduction to Cycle Time", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time", "chunk_id": "00000153"}
{"type": "chunk", "text": "Shewhart’s work was later picked up by W. Edwards Deming who became\none of the biggest proponents of the Control Chart visualization. There is only one problem. By using the method outlined above what\nthey have created is most certainly not a Control Chart---at least not in the\nShewhart tradition. What Shewhart Control Charts are and how to construct\nthem are way beyond the scope of this book, but just know that you should\nbe skeptical whenever you see someone show you something that is labeled\n“Control Chart”---as it most certainly is not. While I am a big fan of\nShewhart’s work, I am not convinced that canonical Shewhart Control\nCharts are applicable in a knowledge work world (I am not saying they are\ndefinitely not; I am just saying I have not yet been convinced). As these things usually go, the problem is much worse than you might\n\nthink. That tools vendors’ charts are most assuredly not Control Charts\nnotwithstanding, there still remains one (at least) fatal flaw with a pseudo\nControl Chart approach. These charts---especially the calculations for the", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time\n\nShewhart’s work was later picked up by W. Edwards Deming who became\none of the biggest proponents of the Control Chart visualization. There is only one problem. By using the method outlined above what\nthey have created is most certainly not a Control Chart---at least not in the\nShewhart tradition. What Shewhart Control Charts are and how to construct\nthem are way beyond the scope of this book, but just know that you should\nbe skeptical whenever you see someone show you something that is labeled\n“Control Chart”---as it most certainly is not. While I am a big fan of\nShewhart’s work, I am not convinced that canonical Shewhart Control\nCharts are applicable in a knowledge work world (I am not saying they are\ndefinitely not; I am just saying I have not yet been convinced). As these things usually go, the problem is much worse than you might\n\nthink. That tools vendors’ charts are most assuredly not Control Charts\nnotwithstanding, there still remains one (at least) fatal flaw with a pseudo\nControl Chart approach. These charts---especially the calculations for the", "tokens": 234, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 134, "segment_id": "00134", "chapter_num": "10", "chapter_title": "Introduction to Cycle Time", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: Introduction to Cycle Time", "chunk_id": "00000154"}
{"type": "chunk", "text": "UCLs and LCLs---assume that your data is normally distributed. I can all but\nguarantee you that your Cycle Time data is not and will not be normally\ndistributed. We will talk briefly about how your data is distributed later (in\nChapter 10a), but just know that for now the conclusions based on the\nstandard deviation calculations above when applied to your non-normally\ndistributed data will be incorrect. The use of this normal distribution method is so pervasive because that\n\nis the type of statistics that that most of us are familiar with. One very\nimportant consequence of working in the knowledge work domain is that\nyou pretty much have to forget any statistics training that you may have had\nup until this point (for a great book on why we need to forget the statistics\nthat we have been taught read “The Flaw of Averages”). We do not live in a\nworld of normal distributions. But as we are about to see with Scatterplots,\nthat is not going to be a problem at all. As a quick aside, you may have also heard the name “Run Chart” in\n\nassociation with these diagrams. Again, the Scatterplots I am talking about\nhere are not Run Charts. A deep discussion of Run Charts is also beyond the\nscope of this book. I am not saying that Run Charts are not useful, by the\nway---far from it. I am just trying to be clear that this chapter’s Cycle Time\nScatterplots are most certainly not Run Charts. Getting back to standard percentiles, there are at least three reasons why\n\nI like those lines better than the dubious Control Chart tactic mentioned\nabove. First, notice that when I described how to draw the standard\npercentile lines on a Scatterplot I never made one mention of how the\nunderlying Cycle Time data might be distributed. And that is the beauty of it. To draw those lines I do not need to know how your data is distributed. In\nfact, I do not care (yet). These percentile line calculations work regardless of\nthe underlying distribution. Second, note how simple the calculations are. You just count up all the\n\ndots and multiply by percentages. Simple. You are not required to have an\nadvanced degree in statistics in order to draw these lines. Third, percentiles are not skewed by outliers.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a), but just know that for now the conclusions based on the\n\nUCLs and LCLs---assume that your data is normally distributed. I can all but\nguarantee you that your Cycle Time data is not and will not be normally\ndistributed. We will talk briefly about how your data is distributed later (in\nChapter 10a), but just know that for now the conclusions based on the\nstandard deviation calculations above when applied to your non-normally\ndistributed data will be incorrect. The use of this normal distribution method is so pervasive because that\n\nis the type of statistics that that most of us are familiar with. One very\nimportant consequence of working in the knowledge work domain is that\nyou pretty much have to forget any statistics training that you may have had\nup until this point (for a great book on why we need to forget the statistics\nthat we have been taught read “The Flaw of Averages”). We do not live in a\nworld of normal distributions. But as we are about to see with Scatterplots,\nthat is not going to be a problem at all. As a quick aside, you may have also heard the name “Run Chart” in\n\nassociation with these diagrams. Again, the Scatterplots I am talking about\nhere are not Run Charts. A deep discussion of Run Charts is also beyond the\nscope of this book. I am not saying that Run Charts are not useful, by the\nway---far from it. I am just trying to be clear that this chapter’s Cycle Time\nScatterplots are most certainly not Run Charts. Getting back to standard percentiles, there are at least three reasons why\n\nI like those lines better than the dubious Control Chart tactic mentioned\nabove. First, notice that when I described how to draw the standard\npercentile lines on a Scatterplot I never made one mention of how the\nunderlying Cycle Time data might be distributed. And that is the beauty of it. To draw those lines I do not need to know how your data is distributed. In\nfact, I do not care (yet). These percentile line calculations work regardless of\nthe underlying distribution. Second, note how simple the calculations are. You just count up all the\n\ndots and multiply by percentages. Simple. You are not required to have an\nadvanced degree in statistics in order to draw these lines. Third, percentiles are not skewed by outliers.", "tokens": 480, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 135, "segment_id": "00135", "chapter_num": "10", "chapter_title": "a), but just know that for now the conclusions based on the", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a), but just know that for now the conclusions based on the", "chunk_id": "00000155"}
{"type": "chunk", "text": "And that is the beauty of it. To draw those lines I do not need to know how your data is distributed. In\nfact, I do not care (yet). These percentile line calculations work regardless of\nthe underlying distribution. Second, note how simple the calculations are. You just count up all the\n\ndots and multiply by percentages. Simple. You are not required to have an\nadvanced degree in statistics in order to draw these lines. Third, percentiles are not skewed by outliers. One of the great\ndisadvantages of a mean and standard deviation approach (other than the\nfalse assumption of normally distributed data) is that both of those statistics\nare heavily influenced by outliers. You have probably heard the saying, “If\nBill Gates walks into a bar, then on average everyone in the bar is a\nmillionaire”. Obviously, in the Bill Gates example, average is no longer a", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a), but just know that for now the conclusions based on the\n\nAnd that is the beauty of it. To draw those lines I do not need to know how your data is distributed. In\nfact, I do not care (yet). These percentile line calculations work regardless of\nthe underlying distribution. Second, note how simple the calculations are. You just count up all the\n\ndots and multiply by percentages. Simple. You are not required to have an\nadvanced degree in statistics in order to draw these lines. Third, percentiles are not skewed by outliers. One of the great\ndisadvantages of a mean and standard deviation approach (other than the\nfalse assumption of normally distributed data) is that both of those statistics\nare heavily influenced by outliers. You have probably heard the saying, “If\nBill Gates walks into a bar, then on average everyone in the bar is a\nmillionaire”. Obviously, in the Bill Gates example, average is no longer a", "tokens": 183, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 135, "segment_id": "00135", "chapter_num": "10", "chapter_title": "a), but just know that for now the conclusions based on the", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a), but just know that for now the conclusions based on the", "chunk_id": "00000156"}
{"type": "chunk", "text": "useful statistic. The same type of phenomenon happens in our world. However, when you do get those extreme Cycle Time outliers, your\npercentile lines will not budge all that much. It is this robustness in the face\nof outliers that is why percentile lines are generally better statistics for the\nanalysis of Cycle Time. As I mentioned at the beginning of this section, chances are if you are\n\nusing an electronic tool for metrics that it will not show you a Scatterplot\nview with percentile lines overlaid. So what are you to do? You can use a\ntool like excel and generate the charts yourself. Or you can use the\nActionableAgileTM Analytics tool as it takes care of everything for you. Conclusion\nRandomness exists in all processes. One of the best ways to visualize the\nrandomness in your process is to put your Cycle Time data into a Scatterplot. As with CFDs, a Cycle Time Scatterplot can yield vast amounts of\nquantitative information (the qualitative side of Scatterplots will be\ndiscussed in Chapter 11). I mentioned at the beginning of this chapter that Cycle Time\nScatterplots are a great way to visualize Cycle Time data that goes far\nbeyond simple analysis by average. I hope that you are convinced of that\nnow. I have only scratched the surface so far with regard to the quantitative\n\nanalysis of Scatterplots, but this should be enough to get you started. It is\nenough, in fact, to allow us to switch gears and look at how qualitative\nanalysis of these charts might work. However, before we get into the details of how to interpret Scatterplots,\n\nI would like to take a short detour to discuss how to view the shape of your\nCycle Time data. Key Learnings and Takeaways\n\nScatterplots are one of the best analytics for visualizing Cycle Time\ndata. This type of visualization communicates a lot of quantitative and\nqualitative information at a glance. The anatomy of a Scatterplot is:\n\nThe X-axis represents the process timeline.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a), but just know that for now the conclusions based on the\n\nuseful statistic. The same type of phenomenon happens in our world. However, when you do get those extreme Cycle Time outliers, your\npercentile lines will not budge all that much. It is this robustness in the face\nof outliers that is why percentile lines are generally better statistics for the\nanalysis of Cycle Time. As I mentioned at the beginning of this section, chances are if you are\n\nusing an electronic tool for metrics that it will not show you a Scatterplot\nview with percentile lines overlaid. So what are you to do? You can use a\ntool like excel and generate the charts yourself. Or you can use the\nActionableAgileTM Analytics tool as it takes care of everything for you. Conclusion\nRandomness exists in all processes. One of the best ways to visualize the\nrandomness in your process is to put your Cycle Time data into a Scatterplot. As with CFDs, a Cycle Time Scatterplot can yield vast amounts of\nquantitative information (the qualitative side of Scatterplots will be\ndiscussed in Chapter 11). I mentioned at the beginning of this chapter that Cycle Time\nScatterplots are a great way to visualize Cycle Time data that goes far\nbeyond simple analysis by average. I hope that you are convinced of that\nnow. I have only scratched the surface so far with regard to the quantitative\n\nanalysis of Scatterplots, but this should be enough to get you started. It is\nenough, in fact, to allow us to switch gears and look at how qualitative\nanalysis of these charts might work. However, before we get into the details of how to interpret Scatterplots,\n\nI would like to take a short detour to discuss how to view the shape of your\nCycle Time data. Key Learnings and Takeaways\n\nScatterplots are one of the best analytics for visualizing Cycle Time\ndata. This type of visualization communicates a lot of quantitative and\nqualitative information at a glance. The anatomy of a Scatterplot is:\n\nThe X-axis represents the process timeline.", "tokens": 420, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 136, "segment_id": "00136", "chapter_num": "10", "chapter_title": "a), but just know that for now the conclusions based on the", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a), but just know that for now the conclusions based on the", "chunk_id": "00000157"}
{"type": "chunk", "text": "The Y-axis represents the Cycle Time for an item to complete. The labels and reporting intervals on the chart are at the sole\ndiscretion of the graph’s creator. A Cycle Time Scatterplot is not a Control Chart. It is not a Run Chart,\neither. One of the best ways to put some structure around Cycle Time\nScatterplot data is to draw percentile lines. Consider starting with the\n50th, 70th, 85th, and 95th percentiles. Percentiles have the advantages of being easy to calculate, being\nagnostic of the underlying data distribution, and not being skewed by\noutliers.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a), but just know that for now the conclusions based on the\n\nThe Y-axis represents the Cycle Time for an item to complete. The labels and reporting intervals on the chart are at the sole\ndiscretion of the graph’s creator. A Cycle Time Scatterplot is not a Control Chart. It is not a Run Chart,\neither. One of the best ways to put some structure around Cycle Time\nScatterplot data is to draw percentile lines. Consider starting with the\n50th, 70th, 85th, and 95th percentiles. Percentiles have the advantages of being easy to calculate, being\nagnostic of the underlying data distribution, and not being skewed by\noutliers.", "tokens": 129, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 137, "segment_id": "00137", "chapter_num": "10", "chapter_title": "a), but just know that for now the conclusions based on the", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a), but just know that for now the conclusions based on the", "chunk_id": "00000158"}
{"type": "chunk", "text": "Chapter 10a - Cycle Time Histograms\n\nWhile the analysis of Cycle Time Histograms is technically an advanced\ntopic, I do want to discuss them briefly in the interest of completeness. The\ngood news is that you need not master this analysis to be successful with the\npredictability concepts presented in this book. So why even mention Histograms at all? I mention them here for two\nreasons. First, Histograms are closely related to Cycle Time Scatterplots in\nthat they are really just another view of the same data shown on a\nScatterplot. And, second, a brief introduction to Histograms will be helpful\nfor other concepts I will introduce later (e.g., Classes of Service and\nForecasting). As I have done so many times previously, I need to insert a disclaimer\n\nat this point. For the purposes of this chapter whenever I say the word\n“Histogram” without any qualifier, what I really mean is “Cycle Time\nHistogram”. Further, this chapter is not meant to represent an exhaustive\ntreatment of these charts. For that I invite you to explore some of the books\nlisted in the Bibliography at the end of this book. What is a Histogram? Simply stated, a Histogram is graphical display of data that uses bars of\ndifferent heights to show the frequency of different data points within an\noverall dataset. A Histogram is very similar to a bar chart with one important\ndistinction being that a Histogram groups population elements together in\nranges. An example Histogram is shown in Figure 10a.1:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a - Cycle Time Histograms\n\nChapter 10a - Cycle Time Histograms\n\nWhile the analysis of Cycle Time Histograms is technically an advanced\ntopic, I do want to discuss them briefly in the interest of completeness. The\ngood news is that you need not master this analysis to be successful with the\npredictability concepts presented in this book. So why even mention Histograms at all? I mention them here for two\nreasons. First, Histograms are closely related to Cycle Time Scatterplots in\nthat they are really just another view of the same data shown on a\nScatterplot. And, second, a brief introduction to Histograms will be helpful\nfor other concepts I will introduce later (e.g., Classes of Service and\nForecasting). As I have done so many times previously, I need to insert a disclaimer\n\nat this point. For the purposes of this chapter whenever I say the word\n“Histogram” without any qualifier, what I really mean is “Cycle Time\nHistogram”. Further, this chapter is not meant to represent an exhaustive\ntreatment of these charts. For that I invite you to explore some of the books\nlisted in the Bibliography at the end of this book. What is a Histogram? Simply stated, a Histogram is graphical display of data that uses bars of\ndifferent heights to show the frequency of different data points within an\noverall dataset. A Histogram is very similar to a bar chart with one important\ndistinction being that a Histogram groups population elements together in\nranges. An example Histogram is shown in Figure 10a.1:", "tokens": 317, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 138, "segment_id": "00138", "chapter_num": "10", "chapter_title": "a - Cycle Time Histograms", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a - Cycle Time Histograms", "chunk_id": "00000159"}
{"type": "chunk", "text": "Figure 10a.1: An Example Cycle Time Histogram\nFigure 10a.1 shows frequency on the vertical (or Y) axis and Cycle\nTimes on the horizontal (or X) axis. The advantage of this chart is that it\ngives you an overall idea of the shape of the distribution of your underlying\ndata. Knowing this shape can give you some insight to the problem areas of\nyour process. You might be interested to know that in knowledge work, a\nHistogram that shows Cycle Time usually looks much like what is shown in\nFigure 10a.1. That is to say Histograms in our world usually have a big\nhump on the left and a long tail to the right. Why this type of shape occurs in\nknowledge work, whether it is a log-normal or a Weibull or some other\ndistribution, and what the shape is telling us are questions that have answers\nthat are beyond the scope of this introductory book. Just know that a deep\nanalysis is possible (and potentially very powerful). Constructing a Histogram\nConstructing a Histogram is rather straightforward. As I just mentioned, the\nvertical axis of this chart is frequency and the horizontal axis represents the\nranges of intervals (or bins) that you are interested in. For a given data\npopulation, you go through each element and every time a given data point\nfalls within a particular range, you increment the frequency of bin. The\nheight of the bins, therefore, represents the number of times that data points\nof your dataset occurs within that range.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a - Cycle Time Histograms\n\nFigure 10a.1: An Example Cycle Time Histogram\nFigure 10a.1 shows frequency on the vertical (or Y) axis and Cycle\nTimes on the horizontal (or X) axis. The advantage of this chart is that it\ngives you an overall idea of the shape of the distribution of your underlying\ndata. Knowing this shape can give you some insight to the problem areas of\nyour process. You might be interested to know that in knowledge work, a\nHistogram that shows Cycle Time usually looks much like what is shown in\nFigure 10a.1. That is to say Histograms in our world usually have a big\nhump on the left and a long tail to the right. Why this type of shape occurs in\nknowledge work, whether it is a log-normal or a Weibull or some other\ndistribution, and what the shape is telling us are questions that have answers\nthat are beyond the scope of this introductory book. Just know that a deep\nanalysis is possible (and potentially very powerful). Constructing a Histogram\nConstructing a Histogram is rather straightforward. As I just mentioned, the\nvertical axis of this chart is frequency and the horizontal axis represents the\nranges of intervals (or bins) that you are interested in. For a given data\npopulation, you go through each element and every time a given data point\nfalls within a particular range, you increment the frequency of bin. The\nheight of the bins, therefore, represents the number of times that data points\nof your dataset occurs within that range.", "tokens": 319, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 139, "segment_id": "00139", "chapter_num": "10", "chapter_title": "a - Cycle Time Histograms", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a - Cycle Time Histograms", "chunk_id": "00000160"}
{"type": "chunk", "text": "To illustrate, let’s consider the example of rolling four independent (but\n\nequal) six-sided dice. In this example we will add up the face value on the\ndice after each roll and plot them on a Histogram. The bins that we will use\nfor the horizontal axis will therefore be all the possible values for a given\nroll. That is, since the smallest value for a given roll is four (four times one),\nour bins will start at four. Since the highest possible value is twenty-four\n(four times six), then our bins will end at twenty-four. We will have one bin\nfor each possible value between four and twenty four. Figure 10a.2 shows\nthe Histogram after ten, one hundred, and five thousand rolls, respectively\n(please note that these Histograms were not generated with the\nActionableAgileTM Analytics tool). Figure 10a.2: Rolling Dice Histogram (10 trials, 100 trials, and 5000 trials, respectively)\nThe thing to note about Figure 10a.2 is that as the number of trials\nincreases, the shape of the distribution sharpens. In other words, more data is\nusually better than less data when it comes to visualization (but do not be\nfooled into thinking you need massive amounts of data to be successful with\na statistical approach). Just like the experiment of adding up the results of rolling four, equal,\n\nsix-sided dice produced random results that could be plotted as the\nHistograms shown in Figure 10a.2, so your process will generate random\nCycle Times that can be displayed in a similar manner. Figure 10a.1 is one\nsuch example. Again, the lesson here is that the more data you have, the\nsharper the picture you get. As I said in the introduction, a Histogram is simply another way to plot\n\nthe data contained with the Scatterplot. As such, we can place percentile\nlines on them in much the same way that was explained in Chapter 10. Figure 10a.1 shows an example of this. Having both views with the same percentiles is useful because both\nviews serve different purposes. The Scatterplot is a temporal view of data\nthat can show trends of dots over time. A Histogram is a condensed, spatial\nview based on the frequency of occurrence of Cycle Times. Looking at the", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a - Cycle Time Histograms\n\nTo illustrate, let’s consider the example of rolling four independent (but\n\nequal) six-sided dice. In this example we will add up the face value on the\ndice after each roll and plot them on a Histogram. The bins that we will use\nfor the horizontal axis will therefore be all the possible values for a given\nroll. That is, since the smallest value for a given roll is four (four times one),\nour bins will start at four. Since the highest possible value is twenty-four\n(four times six), then our bins will end at twenty-four. We will have one bin\nfor each possible value between four and twenty four. Figure 10a.2 shows\nthe Histogram after ten, one hundred, and five thousand rolls, respectively\n(please note that these Histograms were not generated with the\nActionableAgileTM Analytics tool). Figure 10a.2: Rolling Dice Histogram (10 trials, 100 trials, and 5000 trials, respectively)\nThe thing to note about Figure 10a.2 is that as the number of trials\nincreases, the shape of the distribution sharpens. In other words, more data is\nusually better than less data when it comes to visualization (but do not be\nfooled into thinking you need massive amounts of data to be successful with\na statistical approach). Just like the experiment of adding up the results of rolling four, equal,\n\nsix-sided dice produced random results that could be plotted as the\nHistograms shown in Figure 10a.2, so your process will generate random\nCycle Times that can be displayed in a similar manner. Figure 10a.1 is one\nsuch example. Again, the lesson here is that the more data you have, the\nsharper the picture you get. As I said in the introduction, a Histogram is simply another way to plot\n\nthe data contained with the Scatterplot. As such, we can place percentile\nlines on them in much the same way that was explained in Chapter 10. Figure 10a.1 shows an example of this. Having both views with the same percentiles is useful because both\nviews serve different purposes. The Scatterplot is a temporal view of data\nthat can show trends of dots over time. A Histogram is a condensed, spatial\nview based on the frequency of occurrence of Cycle Times. Looking at the", "tokens": 487, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 140, "segment_id": "00140", "chapter_num": "10", "chapter_title": "a - Cycle Time Histograms", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a - Cycle Time Histograms", "chunk_id": "00000161"}
{"type": "chunk", "text": "Scatterplot in Figure 10.1 it may not be obvious that the shape of the data is\nthat in Figure 10a.1. Likewise, looking at the Figure in 10a.1 you may not be\nable to detect any patterns of Cycle Times over a given timeline. Conclusion\nThough short, my hope is that this chapter has given you some insight as to\nwhy you might want to look at your Cycle Time data in the analytical chart\nknown as a Histogram. I took this detour as I wanted to make sure you had\nthis introduction given that I am going to leverage these charts to explain\nkey concepts in the following chapters. Now that we have checked Histograms off of our list, it is time to get\nback to the more pressing matter of how to interpret the data displayed in a\nScatterplot. Key Learnings and Takeaways\n\nA Histogram is a graphical display of data that uses bars of different\nheights to show the frequency of different data points within an overall\ndataset. The Histogram is a condensed, spatial view that shows the shape of the\nunderlying Cycle Time data while the Scatterplot is a temporal view of\ndata that can show trends of dots over time. Histograms can be used for more advanced Cycle Time analysis and\nforecast modeling techniques.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a - Cycle Time Histograms\n\nScatterplot in Figure 10.1 it may not be obvious that the shape of the data is\nthat in Figure 10a.1. Likewise, looking at the Figure in 10a.1 you may not be\nable to detect any patterns of Cycle Times over a given timeline. Conclusion\nThough short, my hope is that this chapter has given you some insight as to\nwhy you might want to look at your Cycle Time data in the analytical chart\nknown as a Histogram. I took this detour as I wanted to make sure you had\nthis introduction given that I am going to leverage these charts to explain\nkey concepts in the following chapters. Now that we have checked Histograms off of our list, it is time to get\nback to the more pressing matter of how to interpret the data displayed in a\nScatterplot. Key Learnings and Takeaways\n\nA Histogram is a graphical display of data that uses bars of different\nheights to show the frequency of different data points within an overall\ndataset. The Histogram is a condensed, spatial view that shows the shape of the\nunderlying Cycle Time data while the Scatterplot is a temporal view of\ndata that can show trends of dots over time. Histograms can be used for more advanced Cycle Time analysis and\nforecast modeling techniques.", "tokens": 268, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 141, "segment_id": "00141", "chapter_num": "10", "chapter_title": "a - Cycle Time Histograms", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 10: a - Cycle Time Histograms", "chunk_id": "00000162"}
{"type": "chunk", "text": "Chapter 11 - Interpreting Cycle Time Scatterplots\n\nOne of the great advantages of a Scatterplot is that it allows us to visually\ndetect trends in our process’s Cycle Time over time. But before we get started, I want to expressly callout the maxim that I\n\nhave repeated over and over until now:\n\nYour policies shape your data and your data shape your policies. I mention this again because as you read through the explanations of\nsome of the Scatterplot patterns that follow, you will quickly realize that\nmost of these results are due to policies that are explicitly under the team’s\ncontrol. If you see some anomalies creep into your data, then the first thing\nyou should ask yourself is “What policy (either explicit or implicit) do we\nhave in place that is causing our data to look like this?” Use that data to\nsuggest changes to process policies and then verify the change had the\nintended effect by further collecting and re-examining future data. The rest of this chapter will be devoted to taking a closer look at some\nof the trends and patterns that may appear on your Cycle Time Scatterplot. The Triangle\nA triangle-shaped pattern as shown in Figure 11.1 will appear in any\nsituation where Cycle Time increases over time.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots\n\nChapter 11 - Interpreting Cycle Time Scatterplots\n\nOne of the great advantages of a Scatterplot is that it allows us to visually\ndetect trends in our process’s Cycle Time over time. But before we get started, I want to expressly callout the maxim that I\n\nhave repeated over and over until now:\n\nYour policies shape your data and your data shape your policies. I mention this again because as you read through the explanations of\nsome of the Scatterplot patterns that follow, you will quickly realize that\nmost of these results are due to policies that are explicitly under the team’s\ncontrol. If you see some anomalies creep into your data, then the first thing\nyou should ask yourself is “What policy (either explicit or implicit) do we\nhave in place that is causing our data to look like this?” Use that data to\nsuggest changes to process policies and then verify the change had the\nintended effect by further collecting and re-examining future data. The rest of this chapter will be devoted to taking a closer look at some\nof the trends and patterns that may appear on your Cycle Time Scatterplot. The Triangle\nA triangle-shaped pattern as shown in Figure 11.1 will appear in any\nsituation where Cycle Time increases over time.", "tokens": 260, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 142, "segment_id": "00142", "chapter_num": "11", "chapter_title": "Interpreting Cycle Time Scatterplots", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots", "chunk_id": "00000163"}
{"type": "chunk", "text": "Figure 11.1: A Triangle Pattern on a Scatterplot\nNotice how the dots in the above Scatterplot (Figure 11.1) form a\npattern that looks something like a triangle. Explaining this phenomenon is\ngoing to require us to review the fundamental property of Scatterplots: dots\ndo not actually show up until a work item has finished. The items that have\nlonger Cycle Times are going to need an extended period before they appear\non the chart. That means that the longer the Cycle Time (the dot’s Ycomponent) the longer the amount of time we are going to have to wait (the\ndot’s X-component) to see that data point. There are two major cases to consider whenever you see this pattern\nemerge on your Scatterplot. The first is when arrivals exceed departures, and\nthe second is the accumulation of Flow Debt. For the first major case, let’s consider the context where a project starts\nfrom zero WIP. Whenever you start with an empty process it is going to take\ntime to “prime the pump”. Obviously, in those early stages work will be\npulled in faster than it departs---even if we are limiting WIP. We are going to\nneed time for each workflow step to fill up to its capacity and get a\npredictable flow going. Once that stable flow occurs, then the expectation is\nthat the triangle will eventually flatten out into a more predictable\narrangement.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots\n\nFigure 11.1: A Triangle Pattern on a Scatterplot\nNotice how the dots in the above Scatterplot (Figure 11.1) form a\npattern that looks something like a triangle. Explaining this phenomenon is\ngoing to require us to review the fundamental property of Scatterplots: dots\ndo not actually show up until a work item has finished. The items that have\nlonger Cycle Times are going to need an extended period before they appear\non the chart. That means that the longer the Cycle Time (the dot’s Ycomponent) the longer the amount of time we are going to have to wait (the\ndot’s X-component) to see that data point. There are two major cases to consider whenever you see this pattern\nemerge on your Scatterplot. The first is when arrivals exceed departures, and\nthe second is the accumulation of Flow Debt. For the first major case, let’s consider the context where a project starts\nfrom zero WIP. Whenever you start with an empty process it is going to take\ntime to “prime the pump”. Obviously, in those early stages work will be\npulled in faster than it departs---even if we are limiting WIP. We are going to\nneed time for each workflow step to fill up to its capacity and get a\npredictable flow going. Once that stable flow occurs, then the expectation is\nthat the triangle will eventually flatten out into a more predictable\narrangement.", "tokens": 300, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 143, "segment_id": "00143", "chapter_num": "11", "chapter_title": "Interpreting Cycle Time Scatterplots", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots", "chunk_id": "00000164"}
{"type": "chunk", "text": "Figure 11.2: Triangle Pattern that Flattens Out\n\nIn Figure 11.2 you can see how the dots form a triangle up until about\n\nthe beginning of September, but then flatten out as the process stabilizes. If you have the case where WIP never gets to zero, then a triangle will\nform whenever you have a nontrivial period of time where the top line and\nbottom line on your CFD diverge (see Figure 7.5). The pattern in Figure 11.1\ncould be due to the fact that for almost the whole project, this team did not\ncontrol WIP. As we said over and over in previous chapters, increased WIP\nleads to increased Cycle Times. Not controlling WIP will only cause Cycle\nTimes to get longer and longer and longer. The second major reason that a triangle pattern might emerge on your\n\nScatterplot is a process that is dominated by Flow Debt. Remember from\nChapter 9 that Flow Debt accrues any time that items are left to age\narbitrarily. Aging of items could be due to blocks, too much WIP (as in the\ncase above), or poor (or misunderstood) pull policies. Even if a team\nexplicitly controls WIP, Flow Debt can occur. Flow Debt can therefore easily\nexplain the emergence of a triangle. The items at the bottom of the triangle\nwere those items that were pulled preferentially through the process (for\nwhatever reason) whereas items toward the top of the triangle were left to\nage unnecessarily (again, for whatever reason). If Arrival Rate and Departure", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots\n\nFigure 11.2: Triangle Pattern that Flattens Out\n\nIn Figure 11.2 you can see how the dots form a triangle up until about\n\nthe beginning of September, but then flatten out as the process stabilizes. If you have the case where WIP never gets to zero, then a triangle will\nform whenever you have a nontrivial period of time where the top line and\nbottom line on your CFD diverge (see Figure 7.5). The pattern in Figure 11.1\ncould be due to the fact that for almost the whole project, this team did not\ncontrol WIP. As we said over and over in previous chapters, increased WIP\nleads to increased Cycle Times. Not controlling WIP will only cause Cycle\nTimes to get longer and longer and longer. The second major reason that a triangle pattern might emerge on your\n\nScatterplot is a process that is dominated by Flow Debt. Remember from\nChapter 9 that Flow Debt accrues any time that items are left to age\narbitrarily. Aging of items could be due to blocks, too much WIP (as in the\ncase above), or poor (or misunderstood) pull policies. Even if a team\nexplicitly controls WIP, Flow Debt can occur. Flow Debt can therefore easily\nexplain the emergence of a triangle. The items at the bottom of the triangle\nwere those items that were pulled preferentially through the process (for\nwhatever reason) whereas items toward the top of the triangle were left to\nage unnecessarily (again, for whatever reason). If Arrival Rate and Departure", "tokens": 331, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 144, "segment_id": "00144", "chapter_num": "11", "chapter_title": "Interpreting Cycle Time Scatterplots", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots", "chunk_id": "00000165"}
{"type": "chunk", "text": "Rate are matched, then the only way you will not see a triangle on your\nScatterplot is if you control Flow Debt. Clusters of Dots\nThe second type of pattern that might emerge is an obvious clustering of\ndots on your Scatterplot. Consider, for example, the following chart in\nFigure 11.3:\n\nFigure 11.3: Clusters on a Scatterplot\n\nNote the clusters of dots at the beginning of October 2008 (around the\n\nmiddle of Figure 11.3) and at the end of July 2009 (the lower right side of\nFigure 11.3). As with all of these analytics, the point is to get to the point\nwhere you can ask the right questions sooner. So, when we see clusters of\ndots like in Figure 8.11, we are at the very least going to want to ask “what’s\ngoing on here?” That should probably quickly be followed by “is this a good\nthing or a bad thing?” If it is bad, what can we do about it? By the way, not all clusters of very low Cycle Times are good. Look at\n\nthe cluster of dots for July 2009 again in Figure 8.11. What do you think\nmight be causing our Cycle Times to have decreased so radically? Are you\nonly thinking of good reasons? What might be some bad reasons that would\ncause this to happen? One sinister reason that I see all too often is mandatory\novertime. It stands to reason that if your normal data is based on 8 hour days\nand 5 day work weeks that moving to 12 hour days and 7 day work weeks", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots\n\nRate are matched, then the only way you will not see a triangle on your\nScatterplot is if you control Flow Debt. Clusters of Dots\nThe second type of pattern that might emerge is an obvious clustering of\ndots on your Scatterplot. Consider, for example, the following chart in\nFigure 11.3:\n\nFigure 11.3: Clusters on a Scatterplot\n\nNote the clusters of dots at the beginning of October 2008 (around the\n\nmiddle of Figure 11.3) and at the end of July 2009 (the lower right side of\nFigure 11.3). As with all of these analytics, the point is to get to the point\nwhere you can ask the right questions sooner. So, when we see clusters of\ndots like in Figure 8.11, we are at the very least going to want to ask “what’s\ngoing on here?” That should probably quickly be followed by “is this a good\nthing or a bad thing?” If it is bad, what can we do about it? By the way, not all clusters of very low Cycle Times are good. Look at\n\nthe cluster of dots for July 2009 again in Figure 8.11. What do you think\nmight be causing our Cycle Times to have decreased so radically? Are you\nonly thinking of good reasons? What might be some bad reasons that would\ncause this to happen? One sinister reason that I see all too often is mandatory\novertime. It stands to reason that if your normal data is based on 8 hour days\nand 5 day work weeks that moving to 12 hour days and 7 day work weeks", "tokens": 347, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 145, "segment_id": "00145", "chapter_num": "11", "chapter_title": "Interpreting Cycle Time Scatterplots", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots", "chunk_id": "00000166"}
{"type": "chunk", "text": "will probably make your Cycle Time look better (assuming, of course, that\nyou continue to limit WIP!). But is that a good thing? I know most managers\nwould say yes. I would say otherwise. And from a predictability perspective,\nit is terrible. Not only are long periods of mandatory overtime not\nsustainable but it also skews our data. Do you really want to be offering an\nSLA or making a forecast with mandatory overtime as one of the upfront\nassumptions that is baked in? If your answer to that question is “yes”, then\nthis book is not for you. Gaps\nGaps in the dots on your Scatterplot means that no work items finished in\nthat particular time interval. These gaps will directly correlate with the same\ntime period that a flat section appears on the bottom line of your CFD. Flat\nlines on the CFD mean nothing completed; if nothing has completed then no\ndots will show up on your Scatterplot. Further, the cause of these gaps is the\nsame reasons that CFD Throughput flattens out: public holidays, external\nblockers, batch transfer, etc. Batch transfer bears some more exploration. It is not uncommon for a\n\nScrum team to generate a Scatterplot that looks like Figure 11.4:\n\nFigure 11.4: Batch Transfer on a Scatterplot\nThe stacks of dots that you see here are at the sprint boundaries when\nthere is a mad rush to complete work items. But look at how the data thins", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots\n\nwill probably make your Cycle Time look better (assuming, of course, that\nyou continue to limit WIP!). But is that a good thing? I know most managers\nwould say yes. I would say otherwise. And from a predictability perspective,\nit is terrible. Not only are long periods of mandatory overtime not\nsustainable but it also skews our data. Do you really want to be offering an\nSLA or making a forecast with mandatory overtime as one of the upfront\nassumptions that is baked in? If your answer to that question is “yes”, then\nthis book is not for you. Gaps\nGaps in the dots on your Scatterplot means that no work items finished in\nthat particular time interval. These gaps will directly correlate with the same\ntime period that a flat section appears on the bottom line of your CFD. Flat\nlines on the CFD mean nothing completed; if nothing has completed then no\ndots will show up on your Scatterplot. Further, the cause of these gaps is the\nsame reasons that CFD Throughput flattens out: public holidays, external\nblockers, batch transfer, etc. Batch transfer bears some more exploration. It is not uncommon for a\n\nScrum team to generate a Scatterplot that looks like Figure 11.4:\n\nFigure 11.4: Batch Transfer on a Scatterplot\nThe stacks of dots that you see here are at the sprint boundaries when\nthere is a mad rush to complete work items. But look at how the data thins", "tokens": 314, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 146, "segment_id": "00146", "chapter_num": "11", "chapter_title": "Interpreting Cycle Time Scatterplots", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots", "chunk_id": "00000167"}
{"type": "chunk", "text": "out between those stacks. Is this a good thing or a bad thing? Either way,\nwhat impact is this having on our predictability? If you think it is a bad\nthing, what might you do change that? You might be surprised that I have not talked much about variation in\n\nthis chapter. The truth is that I am not going to talk all that much about\nvariation here. A full treatment of variation is well beyond the scope of this\nbook (and has already been accomplished by much greater minds than\nmine). Further, understanding variation is more of a “thinking” thing rather\nthan a “tool” thing. I believe that it is mostly impossible to classify variation\nof your data into things like “special causes” or “common causes” simply by\nlooking at a Scatterplot (at least as I have described them here). Rather, my\nonly two immediate goals are (1) to discuss some patterns that may appear\non your Scatterplot, and (2) to get you to start asking some questions about\nwhy those patterns may have emerged. Internal and External Variability\nI began this chapter by suggesting that a Scatterplot just looks like a random\ncollection of dots on a chart. The reason that Scatterplots look the way they\ndo is because of the variation that exists in your process. The first thing to\nknow about variation is that it will always exist. From a predictability\nperspective, the point is not to always try to drive variation out; rather, the\npoint will be to understand the causes of that variation in an attempt to make\nyour process more predictable. For example, take a look at Figure 11.5:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots\n\nout between those stacks. Is this a good thing or a bad thing? Either way,\nwhat impact is this having on our predictability? If you think it is a bad\nthing, what might you do change that? You might be surprised that I have not talked much about variation in\n\nthis chapter. The truth is that I am not going to talk all that much about\nvariation here. A full treatment of variation is well beyond the scope of this\nbook (and has already been accomplished by much greater minds than\nmine). Further, understanding variation is more of a “thinking” thing rather\nthan a “tool” thing. I believe that it is mostly impossible to classify variation\nof your data into things like “special causes” or “common causes” simply by\nlooking at a Scatterplot (at least as I have described them here). Rather, my\nonly two immediate goals are (1) to discuss some patterns that may appear\non your Scatterplot, and (2) to get you to start asking some questions about\nwhy those patterns may have emerged. Internal and External Variability\nI began this chapter by suggesting that a Scatterplot just looks like a random\ncollection of dots on a chart. The reason that Scatterplots look the way they\ndo is because of the variation that exists in your process. The first thing to\nknow about variation is that it will always exist. From a predictability\nperspective, the point is not to always try to drive variation out; rather, the\npoint will be to understand the causes of that variation in an attempt to make\nyour process more predictable. For example, take a look at Figure 11.5:", "tokens": 343, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 147, "segment_id": "00147", "chapter_num": "11", "chapter_title": "Interpreting Cycle Time Scatterplots", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots", "chunk_id": "00000168"}
{"type": "chunk", "text": "Figure 11.5: An Example Scatterplot\n\nAt first glance you might be inclined to dismiss those dots at the top of\n\nthe Scatterplot as outliers. You might question the value of including them\nsince they are clearly one-offs. You might even (if you did not like yourself\nvery much) do some further quantitative analysis to prove that those dots are\nnot statistically significant. And you know what, if you made those\nassertions then I probably would not argue with you too strenuously. I would\nsay, though, that while those points are outliers, they obviously happened\nand probably warrant some deeper investigation. I would also say that, while\npotentially statistically insignificant, there might be some good contextual or\nqualitative reasons to keep them in from an analysis perspective. To illustrate this point, consider what the chart in Figure 11.5 is\ncommunicating to us. The 50th percentile of Cycle Time is 20 days and the\n85th percentile is 44 days. But you can see there is a work item on this chart\nthat took 181 days! Can you think of some reasons that would have caused\nthat particular work item to take so long? Maybe the team had a\ndevelopment dependency on an external vendor or a dependency on some\nother internal development team. Maybe the team did not have a test\nenvironment immediately available to them. Maybe the customer was not\nimmediately available for sign-off. The shared theme for all of these reasons\nis that those work items took so long to complete due to reasons outside of\nthe team’s control. And that is generally what you will find as you move “up", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots\n\nFigure 11.5: An Example Scatterplot\n\nAt first glance you might be inclined to dismiss those dots at the top of\n\nthe Scatterplot as outliers. You might question the value of including them\nsince they are clearly one-offs. You might even (if you did not like yourself\nvery much) do some further quantitative analysis to prove that those dots are\nnot statistically significant. And you know what, if you made those\nassertions then I probably would not argue with you too strenuously. I would\nsay, though, that while those points are outliers, they obviously happened\nand probably warrant some deeper investigation. I would also say that, while\npotentially statistically insignificant, there might be some good contextual or\nqualitative reasons to keep them in from an analysis perspective. To illustrate this point, consider what the chart in Figure 11.5 is\ncommunicating to us. The 50th percentile of Cycle Time is 20 days and the\n85th percentile is 44 days. But you can see there is a work item on this chart\nthat took 181 days! Can you think of some reasons that would have caused\nthat particular work item to take so long? Maybe the team had a\ndevelopment dependency on an external vendor or a dependency on some\nother internal development team. Maybe the team did not have a test\nenvironment immediately available to them. Maybe the customer was not\nimmediately available for sign-off. The shared theme for all of these reasons\nis that those work items took so long to complete due to reasons outside of\nthe team’s control. And that is generally what you will find as you move “up", "tokens": 339, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 148, "segment_id": "00148", "chapter_num": "11", "chapter_title": "Interpreting Cycle Time Scatterplots", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots", "chunk_id": "00000169"}
{"type": "chunk", "text": "the stack” of dots on a Scatterplot. More often than not, those outliers will be\ncaused by circumstances that are outside of the team’s control. The opposite is also generally true. As you move “down the stack” the\n\nwork items that took less time to complete were generally due to reasons that\nwere totally under the team’s control. For example, reconsider that work\nitem that I just mentioned that took 181 days to complete. Do you really\nthink that item would have taken 181 days if it was totally under control of\nthe team that was working on it? Maybe, but probably not. Additionally,\nlook at those dots that just barely violated that 85th percentile line. Do you\nthink that there were things that the team could have done to ensure that the\nviolation did not happen? Probably (swarm or break up the item are two\nideas that come immediately to mind). I hope that you are getting a feel for the type of variability analysis that\nI am asking you to perform with these Scatterplots. Will all outliers be due to\nexternal causes? Certainly not. Maybe the team allowed an item that ended\nup being too big into the process. Maybe the team ignored an item once it\nhad been pulled. Likewise, will there be external issues hiding in the shorter\nCycle Times? Almost certainly. But at least I have shown you how to use a\nScatterplot with percentile lines to begin the conversations about how to\naddress those issues. Further, the more you adhere to the assumptions of\nLittle’s Law, the more confident we can be that the “up the stack” dots are\ndue to outliers, and the “down the stack” dots are due to team policies. Lastly, I have tried very hard not to use the language of the theory of\n\nvariation (e.g., “special cause” and “common cause”) as well as I have tried\nvery hard not to use the language of Statistical Process Control (SPC). Not\nthat I have anything against those approaches. Quite the opposite, in fact. I\nhold in very high regard the work of Shewhart and Deming. However, for\nmost people and most purposes, going down an SPC path leads to academic\ndebates about how to distinguish common cause from special cause, such as\narguing over what specific statistical technique you should use for\ndetermining the upper and lower control limits (as discussed previously).", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots\n\nthe stack” of dots on a Scatterplot. More often than not, those outliers will be\ncaused by circumstances that are outside of the team’s control. The opposite is also generally true. As you move “down the stack” the\n\nwork items that took less time to complete were generally due to reasons that\nwere totally under the team’s control. For example, reconsider that work\nitem that I just mentioned that took 181 days to complete. Do you really\nthink that item would have taken 181 days if it was totally under control of\nthe team that was working on it? Maybe, but probably not. Additionally,\nlook at those dots that just barely violated that 85th percentile line. Do you\nthink that there were things that the team could have done to ensure that the\nviolation did not happen? Probably (swarm or break up the item are two\nideas that come immediately to mind). I hope that you are getting a feel for the type of variability analysis that\nI am asking you to perform with these Scatterplots. Will all outliers be due to\nexternal causes? Certainly not. Maybe the team allowed an item that ended\nup being too big into the process. Maybe the team ignored an item once it\nhad been pulled. Likewise, will there be external issues hiding in the shorter\nCycle Times? Almost certainly. But at least I have shown you how to use a\nScatterplot with percentile lines to begin the conversations about how to\naddress those issues. Further, the more you adhere to the assumptions of\nLittle’s Law, the more confident we can be that the “up the stack” dots are\ndue to outliers, and the “down the stack” dots are due to team policies. Lastly, I have tried very hard not to use the language of the theory of\n\nvariation (e.g., “special cause” and “common cause”) as well as I have tried\nvery hard not to use the language of Statistical Process Control (SPC). Not\nthat I have anything against those approaches. Quite the opposite, in fact. I\nhold in very high regard the work of Shewhart and Deming. However, for\nmost people and most purposes, going down an SPC path leads to academic\ndebates about how to distinguish common cause from special cause, such as\narguing over what specific statistical technique you should use for\ndetermining the upper and lower control limits (as discussed previously).", "tokens": 504, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 149, "segment_id": "00149", "chapter_num": "11", "chapter_title": "Interpreting Cycle Time Scatterplots", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots", "chunk_id": "00000170"}
{"type": "chunk", "text": "Not\nthat I have anything against those approaches. Quite the opposite, in fact. I\nhold in very high regard the work of Shewhart and Deming. However, for\nmost people and most purposes, going down an SPC path leads to academic\ndebates about how to distinguish common cause from special cause, such as\narguing over what specific statistical technique you should use for\ndetermining the upper and lower control limits (as discussed previously). These types of debates only serve to cause confusion and miss the point of\nwhat we are trying to accomplish anyway. Use the Scatterplot as a powerful\nway to visualize variation. But do not think it will magically categorize that\nvariation for you. You are still going to have to inspect the dots, shapes, and\npatterns that emerge on your diagram. In other words, you are still going to\nhave to think for yourself in order to get more predictable.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots\n\nNot\nthat I have anything against those approaches. Quite the opposite, in fact. I\nhold in very high regard the work of Shewhart and Deming. However, for\nmost people and most purposes, going down an SPC path leads to academic\ndebates about how to distinguish common cause from special cause, such as\narguing over what specific statistical technique you should use for\ndetermining the upper and lower control limits (as discussed previously). These types of debates only serve to cause confusion and miss the point of\nwhat we are trying to accomplish anyway. Use the Scatterplot as a powerful\nway to visualize variation. But do not think it will magically categorize that\nvariation for you. You are still going to have to inspect the dots, shapes, and\npatterns that emerge on your diagram. In other words, you are still going to\nhave to think for yourself in order to get more predictable.", "tokens": 190, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 149, "segment_id": "00149", "chapter_num": "11", "chapter_title": "Interpreting Cycle Time Scatterplots", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots", "chunk_id": "00000171"}
{"type": "chunk", "text": "Conclusion\nAs with CFDs, the real purpose for analyzing a Cycle Time Scatterplot is to\nlearn. To learn you should ask some familiar questions. “What’s going on\nwith our Cycle Time?” “Is what’s going on a good thing or bad thing?” “If\ngood, how can we keep doing it?” “If bad, what interventions could make\nthings better?” A Scatterplot not only gets you to asking the right questions\nsooner, but will also suggest the right actions to take for increased\npredictability. There are many things that contribute to the random scattering of dots\npresent on most Scatterplots. You may have been surprised to find out that\nmost of the causes of randomness are things we do to ourselves (well, maybe\nnot so surprised had you been reading closely until now). Now that we have a decent understanding of what Scatterplots are and\n\nhow to interpret them, it is time to move on to how we might use our\nnewfound knowledge to enhance our predictability via the Service Level\nAgreement. Key Learnings and Takeaways\n\nThe policies that you have in place will greatly influence the patterns\nand trends of dots that appear on your Scatterplot. Some qualitative things to look for on Cycle Time Scatterplots:\n\nA triangle pattern that never flattens out\nClusters of dots (either high or low)\nLong periods of gaps in the data\nExtreme outliers\nDots that just cross a give percentile line", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots\n\nConclusion\nAs with CFDs, the real purpose for analyzing a Cycle Time Scatterplot is to\nlearn. To learn you should ask some familiar questions. “What’s going on\nwith our Cycle Time?” “Is what’s going on a good thing or bad thing?” “If\ngood, how can we keep doing it?” “If bad, what interventions could make\nthings better?” A Scatterplot not only gets you to asking the right questions\nsooner, but will also suggest the right actions to take for increased\npredictability. There are many things that contribute to the random scattering of dots\npresent on most Scatterplots. You may have been surprised to find out that\nmost of the causes of randomness are things we do to ourselves (well, maybe\nnot so surprised had you been reading closely until now). Now that we have a decent understanding of what Scatterplots are and\n\nhow to interpret them, it is time to move on to how we might use our\nnewfound knowledge to enhance our predictability via the Service Level\nAgreement. Key Learnings and Takeaways\n\nThe policies that you have in place will greatly influence the patterns\nand trends of dots that appear on your Scatterplot. Some qualitative things to look for on Cycle Time Scatterplots:\n\nA triangle pattern that never flattens out\nClusters of dots (either high or low)\nLong periods of gaps in the data\nExtreme outliers\nDots that just cross a give percentile line", "tokens": 297, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 150, "segment_id": "00150", "chapter_num": "11", "chapter_title": "Interpreting Cycle Time Scatterplots", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 11: Interpreting Cycle Time Scatterplots", "chunk_id": "00000172"}
{"type": "chunk", "text": "Chapter 12 - Service Level Agreements\n\nIn Chapter 10 I explained how to use percentile lines as an aid to analyzing\nScatterplot data. But what exactly are the percentile lines telling us? To answer this question, we must first revisit some principles from the\n\nprevious section. Recall that in one of the chapters on the Conservation of\nFlow (Chapter 8) I talked about the principle of just-in-time commitment. Just-in-time commitment helps us to balance the demand on the system with\nthe system’s capacity. However, there is a direct consequence of\nimplementing this methodology. The other dimension of deferred\ncommitment that does not really get talked about all that much is the\nnecessity that we must---at the time of commitment---also communicate to\nour customers a date range and confidence level for each and every\ncommitted-to work item. For example, when we pull an item into our\nprocess we might tell our customers that we expect that item to flow all the\nway through to completion in fourteen days or less with 85% confidence\nlevel. These date ranges and confidence levels are normally published as part\n\nof process visualization and are commonly known as “Service Level\nAgreements” or SLAs. Now, I personally hate the term SLA (I think Deming\nwould too). SLA sounds too much like the language of formally negotiated\ncontracts with penalties for nonconformance. That is really not what we are\ntalking about here. What we are talking about is a reasonable expectation of\nservice that a team is committing to for a particular item. A team or an\nindividual should not be punished for missing these commitments (recall that\nI talked earlier about the term commitment with a small “c”). Rather, the\nteam should take any missed SLA as an opportunity to learn. Why did we\nmiss the SLA? Is there anything we can to do prevent that happening in the\nfuture? Better nomenclature for the concept of a SLA, in my opinion, is\n“Service Level Expectation” or “Cycle Time Target”. However, as SLA is\nthe term most commonly used in our industry then I am going to adopt that\nvocabulary myself for our purposes in this chapter.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements\n\nChapter 12 - Service Level Agreements\n\nIn Chapter 10 I explained how to use percentile lines as an aid to analyzing\nScatterplot data. But what exactly are the percentile lines telling us? To answer this question, we must first revisit some principles from the\n\nprevious section. Recall that in one of the chapters on the Conservation of\nFlow (Chapter 8) I talked about the principle of just-in-time commitment. Just-in-time commitment helps us to balance the demand on the system with\nthe system’s capacity. However, there is a direct consequence of\nimplementing this methodology. The other dimension of deferred\ncommitment that does not really get talked about all that much is the\nnecessity that we must---at the time of commitment---also communicate to\nour customers a date range and confidence level for each and every\ncommitted-to work item. For example, when we pull an item into our\nprocess we might tell our customers that we expect that item to flow all the\nway through to completion in fourteen days or less with 85% confidence\nlevel. These date ranges and confidence levels are normally published as part\n\nof process visualization and are commonly known as “Service Level\nAgreements” or SLAs. Now, I personally hate the term SLA (I think Deming\nwould too). SLA sounds too much like the language of formally negotiated\ncontracts with penalties for nonconformance. That is really not what we are\ntalking about here. What we are talking about is a reasonable expectation of\nservice that a team is committing to for a particular item. A team or an\nindividual should not be punished for missing these commitments (recall that\nI talked earlier about the term commitment with a small “c”). Rather, the\nteam should take any missed SLA as an opportunity to learn. Why did we\nmiss the SLA? Is there anything we can to do prevent that happening in the\nfuture? Better nomenclature for the concept of a SLA, in my opinion, is\n“Service Level Expectation” or “Cycle Time Target”. However, as SLA is\nthe term most commonly used in our industry then I am going to adopt that\nvocabulary myself for our purposes in this chapter.", "tokens": 461, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 151, "segment_id": "00151", "chapter_num": "12", "chapter_title": "Service Level Agreements", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements", "chunk_id": "00000173"}
{"type": "chunk", "text": "The way we determine what date range and confidence level that we\n\ncan reasonably commit to is by looking at the percentile lines on our\nScatterplot. To explain, I want to refer you back to Figure 10.5. You can see in this\n\ndiagram that the 50th percentile for the Cycle Times is 20 days, the 85th\npercentile is 43 days, and the 95th percentile is 63 days. That means that any\nitem that enters our process has a 50% chance of finishing in 20 days or less,\nan 85% chance of finishing in 43 days or less, or a 95% chance of finishing\nin 63 days or less. Armed with this information we can sit down with our\ncustomers and ask them what kind of confidence level they would be most\ncomfortable with. If they are ok with us missing our commitments 50% of\nthe time, then the team would choose 20 days at 50% as its SLA. If,\nhowever, they want a greater confidence in terms of the team meeting its\ncommitments, then the team may choose to go with an SLA of 43 days at\n85%. To reiterate, the choice of a team’s SLA should be made in close\ncollaboration with their customers. While there is no hard and fast rule on this, it is been my experience\nthat most teams start out at the 85th percentile as their SLA. The goal of the\nteam then should be to first meet that SLA at least 85% of the time (true\npredictability) but then also to bring down the total number of days that the\n85th percentile represents over time. Part of process improvement is going to\nbe to shift all the percentile lines down as much as possible (but no further!). A wider spread in those lines means not only a higher number of days that\nwe must communicate for our SLA, but it also means that our process is\nsuffering from more variability. Both of those things decrease our overall\npredictability. Take the following example of Figure 12.1:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements\n\nThe way we determine what date range and confidence level that we\n\ncan reasonably commit to is by looking at the percentile lines on our\nScatterplot. To explain, I want to refer you back to Figure 10.5. You can see in this\n\ndiagram that the 50th percentile for the Cycle Times is 20 days, the 85th\npercentile is 43 days, and the 95th percentile is 63 days. That means that any\nitem that enters our process has a 50% chance of finishing in 20 days or less,\nan 85% chance of finishing in 43 days or less, or a 95% chance of finishing\nin 63 days or less. Armed with this information we can sit down with our\ncustomers and ask them what kind of confidence level they would be most\ncomfortable with. If they are ok with us missing our commitments 50% of\nthe time, then the team would choose 20 days at 50% as its SLA. If,\nhowever, they want a greater confidence in terms of the team meeting its\ncommitments, then the team may choose to go with an SLA of 43 days at\n85%. To reiterate, the choice of a team’s SLA should be made in close\ncollaboration with their customers. While there is no hard and fast rule on this, it is been my experience\nthat most teams start out at the 85th percentile as their SLA. The goal of the\nteam then should be to first meet that SLA at least 85% of the time (true\npredictability) but then also to bring down the total number of days that the\n85th percentile represents over time. Part of process improvement is going to\nbe to shift all the percentile lines down as much as possible (but no further!). A wider spread in those lines means not only a higher number of days that\nwe must communicate for our SLA, but it also means that our process is\nsuffering from more variability. Both of those things decrease our overall\npredictability. Take the following example of Figure 12.1:", "tokens": 445, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 152, "segment_id": "00152", "chapter_num": "12", "chapter_title": "Service Level Agreements", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements", "chunk_id": "00000174"}
{"type": "chunk", "text": "Figure 12.1: A Wider Spread in Percentiles\n\nIn Figure 8.6 the 50th percentile for the chart is 20 days, the 70th\npercentile is 25 days, the 85th percentile is 54 days, and the 95th percentile is\n75 days. Think for a second about what an interesting conversation this\nwould be when we present this data to our customers. At a 70% confidence,\nthe team would require a 25 day or less SLA. But to go to an 85%\nconfidence---that is just a 15% increase in confidence---the team would have\nto more than double their SLA from 25 days to 54 days! This particular\nexample is taken from a real world client of mine and, in this instance, the\ncustomer chose the 70% SLA to start out. Interestingly enough, though, the\nteam, by implementing the strategies outlined in this book, was able to shift\nall of those percentile lines down over the course of the project such that by\nthe end, the 85% percentile was now 25 days---exactly what the 70%\npercentile had been just months before. The team removed unnecessary\nvariability, and, by definition, became more predictable. I have just explained how to use standard percentiles to establish an\nSLA, but you might question, “How do I know if these standard percentiles\nare the right ones to use for my context?” Great question. The answer is that\nif you are just starting out, then those standard percentiles are most likely\ngood enough. How you might detect if you need to move to another\npercentile more suitable for your specific situation is a more advanced topic\nthat will need to wait for my next book. The point is that there is no hard and", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements\n\nFigure 12.1: A Wider Spread in Percentiles\n\nIn Figure 8.6 the 50th percentile for the chart is 20 days, the 70th\npercentile is 25 days, the 85th percentile is 54 days, and the 95th percentile is\n75 days. Think for a second about what an interesting conversation this\nwould be when we present this data to our customers. At a 70% confidence,\nthe team would require a 25 day or less SLA. But to go to an 85%\nconfidence---that is just a 15% increase in confidence---the team would have\nto more than double their SLA from 25 days to 54 days! This particular\nexample is taken from a real world client of mine and, in this instance, the\ncustomer chose the 70% SLA to start out. Interestingly enough, though, the\nteam, by implementing the strategies outlined in this book, was able to shift\nall of those percentile lines down over the course of the project such that by\nthe end, the 85% percentile was now 25 days---exactly what the 70%\npercentile had been just months before. The team removed unnecessary\nvariability, and, by definition, became more predictable. I have just explained how to use standard percentiles to establish an\nSLA, but you might question, “How do I know if these standard percentiles\nare the right ones to use for my context?” Great question. The answer is that\nif you are just starting out, then those standard percentiles are most likely\ngood enough. How you might detect if you need to move to another\npercentile more suitable for your specific situation is a more advanced topic\nthat will need to wait for my next book. The point is that there is no hard and", "tokens": 383, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 153, "segment_id": "00153", "chapter_num": "12", "chapter_title": "Service Level Agreements", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements", "chunk_id": "00000175"}
{"type": "chunk", "text": "fast rule in terms of what percentile numbers to use. All I can say is begin\nwith these standard ones and experiment from there. Another question you might ask is, “How many data points do I need\n\nbefore I can establish an SLA?” The answer to that is---as always---\ndependent on your specific context. But I can tell you it is probably less than\nyou think. As few as maybe 11 or 12. Probably no more than 30. The bigger\nquestion is in terms of quality not quantity. Instead of considering the\nnumber of dots, one question you may ask yourself is how well is your\nprocess obeying the assumptions of Little’s Law in the producing those\nCycle Times? The better you are at adhering to those assumptions, the fewer\ndata points you will need. If you consistently violate some or all of the\nassumptions, then almost no amount of data is going to provide you a\nconfidence level that you can be comfortable with. The last thing I want to say about SLAs is that there are generally three\n\nmistakes I see when they are set. Those mistakes are:\n\n1. To set an SLA independent of analyzing your Cycle Time data. 2. To allow an SLA to be set by an external manager or external\n\nmanagement group. 3. Set an SLA without collaborating with customers and/or other\n\nstakeholders. For the first point I want to say that there is nothing (necessarily) wrong\n\nwith choosing an SLA that is not supported by the data. For example, let’s\nsay your data communicates that 85th percentile is 45 days. It would\ntechnically be ok to publish an SLA of 35 days at 85%. But at least make\nthat decision in context after having reviewed what your Scatterplot is telling\nyou. The second mistake should be obvious, but it is worth reiterating. The\n\nwhole point of an SLA is not to beat a team into submission or to punish\nthem when they miss their commitments. Since it is the team who is making\nthe commitment, it should be the team that chooses what that commitment\npoint is. The only other party that should be involved in the decision to set\nan SLA should be a customer and/or other stakeholder. Which brings me to the last point. We are nothing without our\ncustomers. As stated in Chapter 1, they are the whole reason for our\nexistence.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements\n\nfast rule in terms of what percentile numbers to use. All I can say is begin\nwith these standard ones and experiment from there. Another question you might ask is, “How many data points do I need\n\nbefore I can establish an SLA?” The answer to that is---as always---\ndependent on your specific context. But I can tell you it is probably less than\nyou think. As few as maybe 11 or 12. Probably no more than 30. The bigger\nquestion is in terms of quality not quantity. Instead of considering the\nnumber of dots, one question you may ask yourself is how well is your\nprocess obeying the assumptions of Little’s Law in the producing those\nCycle Times? The better you are at adhering to those assumptions, the fewer\ndata points you will need. If you consistently violate some or all of the\nassumptions, then almost no amount of data is going to provide you a\nconfidence level that you can be comfortable with. The last thing I want to say about SLAs is that there are generally three\n\nmistakes I see when they are set. Those mistakes are:\n\n1. To set an SLA independent of analyzing your Cycle Time data. 2. To allow an SLA to be set by an external manager or external\n\nmanagement group. 3. Set an SLA without collaborating with customers and/or other\n\nstakeholders. For the first point I want to say that there is nothing (necessarily) wrong\n\nwith choosing an SLA that is not supported by the data. For example, let’s\nsay your data communicates that 85th percentile is 45 days. It would\ntechnically be ok to publish an SLA of 35 days at 85%. But at least make\nthat decision in context after having reviewed what your Scatterplot is telling\nyou. The second mistake should be obvious, but it is worth reiterating. The\n\nwhole point of an SLA is not to beat a team into submission or to punish\nthem when they miss their commitments. Since it is the team who is making\nthe commitment, it should be the team that chooses what that commitment\npoint is. The only other party that should be involved in the decision to set\nan SLA should be a customer and/or other stakeholder. Which brings me to the last point. We are nothing without our\ncustomers. As stated in Chapter 1, they are the whole reason for our\nexistence.", "tokens": 508, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 154, "segment_id": "00154", "chapter_num": "12", "chapter_title": "Service Level Agreements", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements", "chunk_id": "00000176"}
{"type": "chunk", "text": "The second mistake should be obvious, but it is worth reiterating. The\n\nwhole point of an SLA is not to beat a team into submission or to punish\nthem when they miss their commitments. Since it is the team who is making\nthe commitment, it should be the team that chooses what that commitment\npoint is. The only other party that should be involved in the decision to set\nan SLA should be a customer and/or other stakeholder. Which brings me to the last point. We are nothing without our\ncustomers. As stated in Chapter 1, they are the whole reason for our\nexistence. It is our professional obligation to design a process that works for\nthem. Therefore, our customers should have a seat at the table when", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements\n\nThe second mistake should be obvious, but it is worth reiterating. The\n\nwhole point of an SLA is not to beat a team into submission or to punish\nthem when they miss their commitments. Since it is the team who is making\nthe commitment, it should be the team that chooses what that commitment\npoint is. The only other party that should be involved in the decision to set\nan SLA should be a customer and/or other stakeholder. Which brings me to the last point. We are nothing without our\ncustomers. As stated in Chapter 1, they are the whole reason for our\nexistence. It is our professional obligation to design a process that works for\nthem. Therefore, our customers should have a seat at the table when", "tokens": 155, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 154, "segment_id": "00154", "chapter_num": "12", "chapter_title": "Service Level Agreements", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements", "chunk_id": "00000177"}
{"type": "chunk", "text": "discussing what commitment confidence level is acceptable. They may\nsurprise you. They may opt for a shorter Cycle Time SLA with a higher\nuncertainty. They may be fine with a longer Cycle Time SLA if that means\ngreater certainty. Our customers and stakeholders almost certainly have\ncontextual information that we do not that will have some bearing on our\nchoice of an SLA. Listen to them. SLAs for Different Work Item Types\nIn the chapter on Cumulative Flow Diagrams (Chapter 4), I talked about the\nstrategy of filtering on different work item types to generate different views\nof your data. The same approach is available for us to use on Cycle Time\nScatterplots. Let’s say we had a dataset that included the work item types of\nuser stories, defects, and maintenance requests. With this data we could\ngenerate a Scatterplot and corresponding percentile lines for the data that\nincluded all three work items. Or we could generate a Scatterplot that\nincluded data for just the user stories. Or one that included just the defects,\nor one for just the maintenance requests, or for some combination thereof. As with CFDs, any one of these data segmentations---and their\ncorresponding analysis---is perfectly valid. But why might we want to segment our data in this way? There are at\nleast two answers to this question. The first might be that you have tagged\nthe items that did not finish “normally” (e.g., were abandoned) and want to\nfilter your data to show only those. Displaying only the abandoned items\nwould give you a good visualization as to the time wasted on those activities. That might give rise to questions and conversations about how to minimize\nthose occurrences. The second reason for segmenting is that the Cycle Time percentiles for\n\na Scatterplot consisting of data for only the work item type of “story” are\nprobably going to be much different from the Cycle Time percentiles for a\nScatterplot consisting of data for only the work item type of “defect”. Segmenting our data this way would allow us---if we wanted---to offer\ndifferent SLAs for different work item types. For example, our SLA for user\nstories might be 14 days at 85% but for defects it might be five days at 85%. I am reluctant to discuss this SLA segmentation now, because you have\n\nto be very careful here.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements\n\ndiscussing what commitment confidence level is acceptable. They may\nsurprise you. They may opt for a shorter Cycle Time SLA with a higher\nuncertainty. They may be fine with a longer Cycle Time SLA if that means\ngreater certainty. Our customers and stakeholders almost certainly have\ncontextual information that we do not that will have some bearing on our\nchoice of an SLA. Listen to them. SLAs for Different Work Item Types\nIn the chapter on Cumulative Flow Diagrams (Chapter 4), I talked about the\nstrategy of filtering on different work item types to generate different views\nof your data. The same approach is available for us to use on Cycle Time\nScatterplots. Let’s say we had a dataset that included the work item types of\nuser stories, defects, and maintenance requests. With this data we could\ngenerate a Scatterplot and corresponding percentile lines for the data that\nincluded all three work items. Or we could generate a Scatterplot that\nincluded data for just the user stories. Or one that included just the defects,\nor one for just the maintenance requests, or for some combination thereof. As with CFDs, any one of these data segmentations---and their\ncorresponding analysis---is perfectly valid. But why might we want to segment our data in this way? There are at\nleast two answers to this question. The first might be that you have tagged\nthe items that did not finish “normally” (e.g., were abandoned) and want to\nfilter your data to show only those. Displaying only the abandoned items\nwould give you a good visualization as to the time wasted on those activities. That might give rise to questions and conversations about how to minimize\nthose occurrences. The second reason for segmenting is that the Cycle Time percentiles for\n\na Scatterplot consisting of data for only the work item type of “story” are\nprobably going to be much different from the Cycle Time percentiles for a\nScatterplot consisting of data for only the work item type of “defect”. Segmenting our data this way would allow us---if we wanted---to offer\ndifferent SLAs for different work item types. For example, our SLA for user\nstories might be 14 days at 85% but for defects it might be five days at 85%. I am reluctant to discuss this SLA segmentation now, because you have\n\nto be very careful here.", "tokens": 502, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 155, "segment_id": "00155", "chapter_num": "12", "chapter_title": "Service Level Agreements", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements", "chunk_id": "00000178"}
{"type": "chunk", "text": "Segmenting our data this way would allow us---if we wanted---to offer\ndifferent SLAs for different work item types. For example, our SLA for user\nstories might be 14 days at 85% but for defects it might be five days at 85%. I am reluctant to discuss this SLA segmentation now, because you have\n\nto be very careful here. Remember that all the assumptions of Little’s Law\nstill apply. If you are going to offer different SLAs for different work items", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements\n\nSegmenting our data this way would allow us---if we wanted---to offer\ndifferent SLAs for different work item types. For example, our SLA for user\nstories might be 14 days at 85% but for defects it might be five days at 85%. I am reluctant to discuss this SLA segmentation now, because you have\n\nto be very careful here. Remember that all the assumptions of Little’s Law\nstill apply. If you are going to offer different SLAs for different work items", "tokens": 104, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 155, "segment_id": "00155", "chapter_num": "12", "chapter_title": "Service Level Agreements", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements", "chunk_id": "00000179"}
{"type": "chunk", "text": "types, then you have to you have to ensure that all the assumptions for\nLittle’s Law for each and every subtype are adhered to. Offering different SLAs for different work item types is a fairly\nadvanced behavior. If you are just starting out with flow principles, I would\nhighly recommend just setting one global SLA for all your work items types\nand get predictable that way first. Ignore “conventional wisdom” that you\nhave to design in things like Classes of Service up front and offer different\nSLAs for those different Classes of Service immediately. To put it delicately,\nI believe this type of advice is misguided (a fuller treatment of Class of\nService and its dangers is presented in Chapter 13). If you are new to these\nmetrics, begin by applying the principles presented in this book and then\nmeasure and observe. Get predictable at an overall system level first. You\nmay find that is good enough. Only optimize for subtypes later if you really\nneed to. Right-Sizing\nOne last thing about percentiles and SLAs. Remember that in Chapter 8 I\ntalked about the concept of just-in-time commitment and about how\noperating a pull system allows us to defer commitment to the last responsible\nmoment. In that chapter I also talked about the consequence of deferring\ncommitment is that we need to do what we can to make sure that---once\ncommitted to---an item has the best possible chance of flowing through the\nsystem to completing. One of those things we need to do is to perform a\n“right size” check on the item. Before you ask, right-sizing does not mean you do a lot of upfront\nestimation and planning. Remember, this book emphasizes measurement and\nobservation over estimation and planning. The SLA we have chosen is the\nmeasurement we are looking for. In other words, the SLA will act as the\nlitmus test for whether an item is of the right size to flow through the system. For example, let’s say we have chosen an SLA of fourteen days at 85%. Before a team pulls an item into the process, a quick question should be\nasked if the team believes that this particular item can be finished in fourteen\ndays or less. The length of this conversation should be measured in seconds. Seriously, seconds. Remember, at this point we do not care if we think this\nitem is going to take exactly five days or nine days or 8.247 days.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements\n\ntypes, then you have to you have to ensure that all the assumptions for\nLittle’s Law for each and every subtype are adhered to. Offering different SLAs for different work item types is a fairly\nadvanced behavior. If you are just starting out with flow principles, I would\nhighly recommend just setting one global SLA for all your work items types\nand get predictable that way first. Ignore “conventional wisdom” that you\nhave to design in things like Classes of Service up front and offer different\nSLAs for those different Classes of Service immediately. To put it delicately,\nI believe this type of advice is misguided (a fuller treatment of Class of\nService and its dangers is presented in Chapter 13). If you are new to these\nmetrics, begin by applying the principles presented in this book and then\nmeasure and observe. Get predictable at an overall system level first. You\nmay find that is good enough. Only optimize for subtypes later if you really\nneed to. Right-Sizing\nOne last thing about percentiles and SLAs. Remember that in Chapter 8 I\ntalked about the concept of just-in-time commitment and about how\noperating a pull system allows us to defer commitment to the last responsible\nmoment. In that chapter I also talked about the consequence of deferring\ncommitment is that we need to do what we can to make sure that---once\ncommitted to---an item has the best possible chance of flowing through the\nsystem to completing. One of those things we need to do is to perform a\n“right size” check on the item. Before you ask, right-sizing does not mean you do a lot of upfront\nestimation and planning. Remember, this book emphasizes measurement and\nobservation over estimation and planning. The SLA we have chosen is the\nmeasurement we are looking for. In other words, the SLA will act as the\nlitmus test for whether an item is of the right size to flow through the system. For example, let’s say we have chosen an SLA of fourteen days at 85%. Before a team pulls an item into the process, a quick question should be\nasked if the team believes that this particular item can be finished in fourteen\ndays or less. The length of this conversation should be measured in seconds. Seriously, seconds. Remember, at this point we do not care if we think this\nitem is going to take exactly five days or nine days or 8.247 days.", "tokens": 511, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 156, "segment_id": "00156", "chapter_num": "12", "chapter_title": "Service Level Agreements", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements", "chunk_id": "00000180"}
{"type": "chunk", "text": "For example, let’s say we have chosen an SLA of fourteen days at 85%. Before a team pulls an item into the process, a quick question should be\nasked if the team believes that this particular item can be finished in fourteen\ndays or less. The length of this conversation should be measured in seconds. Seriously, seconds. Remember, at this point we do not care if we think this\nitem is going to take exactly five days or nine days or 8.247 days. We are not\ninterested in that type of precision as it is impossible to attain that upfront. We also do not care what this particular relative complexity is compared to", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements\n\nFor example, let’s say we have chosen an SLA of fourteen days at 85%. Before a team pulls an item into the process, a quick question should be\nasked if the team believes that this particular item can be finished in fourteen\ndays or less. The length of this conversation should be measured in seconds. Seriously, seconds. Remember, at this point we do not care if we think this\nitem is going to take exactly five days or nine days or 8.247 days. We are not\ninterested in that type of precision as it is impossible to attain that upfront. We also do not care what this particular relative complexity is compared to", "tokens": 134, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 156, "segment_id": "00156", "chapter_num": "12", "chapter_title": "Service Level Agreements", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements", "chunk_id": "00000181"}
{"type": "chunk", "text": "the other items. The only thing we do care about is we think we can get it\ndone in 14 days or less. If the answer to that question is yes, then the\nconversation is over and the item is pulled. If the answer is no, then maybe\nthe team goes off and thinks about how to break it up, or change the fidelity,\nor spike it to get more information. Some of you out there may be arguing that right-sizing is a form of\nestimation. I would say that you are probably right. I never said that all\nestimation goes away. All I said was that the amount and frequency with\nwhich you do estimation will change. Think about all the time you have\nwasted in your life doing estimation. Think about all the time wasting in\n“pointless” debates of whether a story is two points or three points. Using\nthese percentiles is a means to get rid of all of that. Measuring to get an SLA\nallows us to adopt a much lighter approach to estimation and planning. To\nme, this is one of the biggest reasons to gather the data in the first place. Percentiles as Intervention Triggers\nThere is still another reason to look at our Cycle Time data percentiles as\nthey pertain to SLAs. And to understand this other reason, we need to first\ntalk about life expectancy. According to a life expectancy calculator at WorldLifeExpectancy.com\n\n(at the time of this writing), a female born in the United States has a life\nexpectancy of 85.8 years at the time of her birth. If she lives to be 5 years\nold, her life expectancy goes up to 86.1 years. If she lives to be 50, her life\nexpectancy becomes 87.3 years. And if she lives to be 85 (her life\nexpectancy at the time of her birth), her new life expectancy jumps to 93! This data is summarized in the following table:\n\nFigure 12.2: Life Expectancies at Different Ages\nIt is a little known fact that the older you get, the longer your life\nexpectancy is. That is due to the fact that the older you get the more things\nyou have survived that should have killed you.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements\n\nthe other items. The only thing we do care about is we think we can get it\ndone in 14 days or less. If the answer to that question is yes, then the\nconversation is over and the item is pulled. If the answer is no, then maybe\nthe team goes off and thinks about how to break it up, or change the fidelity,\nor spike it to get more information. Some of you out there may be arguing that right-sizing is a form of\nestimation. I would say that you are probably right. I never said that all\nestimation goes away. All I said was that the amount and frequency with\nwhich you do estimation will change. Think about all the time you have\nwasted in your life doing estimation. Think about all the time wasting in\n“pointless” debates of whether a story is two points or three points. Using\nthese percentiles is a means to get rid of all of that. Measuring to get an SLA\nallows us to adopt a much lighter approach to estimation and planning. To\nme, this is one of the biggest reasons to gather the data in the first place. Percentiles as Intervention Triggers\nThere is still another reason to look at our Cycle Time data percentiles as\nthey pertain to SLAs. And to understand this other reason, we need to first\ntalk about life expectancy. According to a life expectancy calculator at WorldLifeExpectancy.com\n\n(at the time of this writing), a female born in the United States has a life\nexpectancy of 85.8 years at the time of her birth. If she lives to be 5 years\nold, her life expectancy goes up to 86.1 years. If she lives to be 50, her life\nexpectancy becomes 87.3 years. And if she lives to be 85 (her life\nexpectancy at the time of her birth), her new life expectancy jumps to 93! This data is summarized in the following table:\n\nFigure 12.2: Life Expectancies at Different Ages\nIt is a little known fact that the older you get, the longer your life\nexpectancy is. That is due to the fact that the older you get the more things\nyou have survived that should have killed you.", "tokens": 470, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 157, "segment_id": "00157", "chapter_num": "12", "chapter_title": "Service Level Agreements", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements", "chunk_id": "00000182"}
{"type": "chunk", "text": "The exact same phenomenon happens with Cycle Time. Generally\nspeaking, the older a work item gets, the greater chance it has of aging still\nmore. That is bad. Remember, delay is the enemy of flow! This is why it is so important to study the aging of work items in\nprogress. As items age (as items remain in process without completing), we\ngain information about them. We need to use this information to our\nadvantage because, as I have said many times before, the true definition of\nAgile is the ability to respond quickly to new information. To paraphrase\nDon Reinertsen, this new information should cause our tactics to change. The percentiles on our Scatterplot work as perfect checkpoints to examine\nour newfound information. We will use these checkpoints to be as proactive\nas possible to insure that work gets completed in a timely and predictable\nmanner. How does this work? Let’s talk about the 50th percentile first. And let’s\n\nassume for this discussion that our team is using an 85th percentile SLA. Once an item remains in progress to a point such that its age is the same as\nthe Cycle Time of the 50th percentile line, we can say a couple of things. First, we can say that, by definition, this item is now larger than half the\nwork items we have seen before. That might give us reason to pause. What\nhave we found out about this item that might require us to take action on it? Do we need to swarm on it? Do we need to break it up? Do we need to\nescalate the removal of a blocker? The urgency of these questions is due to\nthe second thing we can say when an item’s age reaches the 50th percentile. When we first pulled the work item into our process it had a 15% chance of\nviolating its SLA (that is the very definition of using the 85th percentile as an\nSLA). Now that the item has hit the 50th percentile, the chance of it violating\nits SLA has doubled from 15% to 30%. Remember, the older an item gets\nthe larger the probably that it will get older. Even if that does not cause\nconcern, it should at least cause conversation. This is what actionable\npredictability is all about.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements\n\nThe exact same phenomenon happens with Cycle Time. Generally\nspeaking, the older a work item gets, the greater chance it has of aging still\nmore. That is bad. Remember, delay is the enemy of flow! This is why it is so important to study the aging of work items in\nprogress. As items age (as items remain in process without completing), we\ngain information about them. We need to use this information to our\nadvantage because, as I have said many times before, the true definition of\nAgile is the ability to respond quickly to new information. To paraphrase\nDon Reinertsen, this new information should cause our tactics to change. The percentiles on our Scatterplot work as perfect checkpoints to examine\nour newfound information. We will use these checkpoints to be as proactive\nas possible to insure that work gets completed in a timely and predictable\nmanner. How does this work? Let’s talk about the 50th percentile first. And let’s\n\nassume for this discussion that our team is using an 85th percentile SLA. Once an item remains in progress to a point such that its age is the same as\nthe Cycle Time of the 50th percentile line, we can say a couple of things. First, we can say that, by definition, this item is now larger than half the\nwork items we have seen before. That might give us reason to pause. What\nhave we found out about this item that might require us to take action on it? Do we need to swarm on it? Do we need to break it up? Do we need to\nescalate the removal of a blocker? The urgency of these questions is due to\nthe second thing we can say when an item’s age reaches the 50th percentile. When we first pulled the work item into our process it had a 15% chance of\nviolating its SLA (that is the very definition of using the 85th percentile as an\nSLA). Now that the item has hit the 50th percentile, the chance of it violating\nits SLA has doubled from 15% to 30%. Remember, the older an item gets\nthe larger the probably that it will get older. Even if that does not cause\nconcern, it should at least cause conversation. This is what actionable\npredictability is all about.", "tokens": 487, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 158, "segment_id": "00158", "chapter_num": "12", "chapter_title": "Service Level Agreements", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements", "chunk_id": "00000183"}
{"type": "chunk", "text": "When we first pulled the work item into our process it had a 15% chance of\nviolating its SLA (that is the very definition of using the 85th percentile as an\nSLA). Now that the item has hit the 50th percentile, the chance of it violating\nits SLA has doubled from 15% to 30%. Remember, the older an item gets\nthe larger the probably that it will get older. Even if that does not cause\nconcern, it should at least cause conversation. This is what actionable\npredictability is all about. When an item has aged to the 70th percentile line, we know it is bigger\nthan more than two-thirds of the other items we have seen before. And now\nits chance of missing its SLA has jumped to 50%. Flip a coin. The\nconversations we were having earlier (i.e., when the item hit the 50th\npercentile line) should now become all the more urgent.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements\n\nWhen we first pulled the work item into our process it had a 15% chance of\nviolating its SLA (that is the very definition of using the 85th percentile as an\nSLA). Now that the item has hit the 50th percentile, the chance of it violating\nits SLA has doubled from 15% to 30%. Remember, the older an item gets\nthe larger the probably that it will get older. Even if that does not cause\nconcern, it should at least cause conversation. This is what actionable\npredictability is all about. When an item has aged to the 70th percentile line, we know it is bigger\nthan more than two-thirds of the other items we have seen before. And now\nits chance of missing its SLA has jumped to 50%. Flip a coin. The\nconversations we were having earlier (i.e., when the item hit the 50th\npercentile line) should now become all the more urgent.", "tokens": 206, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 158, "segment_id": "00158", "chapter_num": "12", "chapter_title": "Service Level Agreements", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements", "chunk_id": "00000184"}
{"type": "chunk", "text": "And they should continue to be urgent as that work item’s age gets\ncloser and closer to the 85th percentile. The last thing we want is for that\nitem to violate its SLA---even though we know it is going to happen 15% of\nthe time. We want to make sure that we have done everything we can to\nprevent a violation occurring. The reason for this is just because an item has\nbreached its SLA does not mean that we all of a sudden take our foot off the\ngas. We still need to finish that work. Some customer somewhere is waiting\nfor their value to be delivered. However, once we breach our SLA we are squarely in unpredictable\n\nland because now we cannot communicate to our customers when this\nparticular item will complete. For example, take a look at the figure below\n(Figure 12.3):\n\nFigure 12.3: The Danger of Breaching an SLA\n\nYou can see in this chart that the 85th percentile is 43 days. But there is\nan item in late October that took 181 days to finish (do you see that isolated\ndot right at the top of the chart?). That no man’s land between 43 days and\n181 days (and potentially beyond) is a scary place to be in. We want to do\nwhatever we can not to have items fall in there. Conclusion\nSLAs are one of the most important and yet least talked about topics in all of\nLean-Agile. SLAs not only allow teams to make commitments at the", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements\n\nAnd they should continue to be urgent as that work item’s age gets\ncloser and closer to the 85th percentile. The last thing we want is for that\nitem to violate its SLA---even though we know it is going to happen 15% of\nthe time. We want to make sure that we have done everything we can to\nprevent a violation occurring. The reason for this is just because an item has\nbreached its SLA does not mean that we all of a sudden take our foot off the\ngas. We still need to finish that work. Some customer somewhere is waiting\nfor their value to be delivered. However, once we breach our SLA we are squarely in unpredictable\n\nland because now we cannot communicate to our customers when this\nparticular item will complete. For example, take a look at the figure below\n(Figure 12.3):\n\nFigure 12.3: The Danger of Breaching an SLA\n\nYou can see in this chart that the 85th percentile is 43 days. But there is\nan item in late October that took 181 days to finish (do you see that isolated\ndot right at the top of the chart?). That no man’s land between 43 days and\n181 days (and potentially beyond) is a scary place to be in. We want to do\nwhatever we can not to have items fall in there. Conclusion\nSLAs are one of the most important and yet least talked about topics in all of\nLean-Agile. SLAs not only allow teams to make commitments at the", "tokens": 324, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 159, "segment_id": "00159", "chapter_num": "12", "chapter_title": "Service Level Agreements", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements", "chunk_id": "00000185"}
{"type": "chunk", "text": "individual work item level, but they also give us extremely useful\ninformation about when teams need to intervene to ensure the timely\ncompletion of those items. Further, if a team follows all of the principles\npresented in this book, then the SLA can be used as a substitute for many\nupfront planning and estimation activities. I began Chapter 11 by discussing how most of the reasons why we are\n\nnot predictable is due to things under our control that we do to ourselves. One of the most common things we do to ourselves that hinders our\npredictability is not pay attention to the order in which items are pulled\nthrough our process. This problem is so common that I will devote the\nentirety of the next chapter to discussing its perils. Key Learnings and Takeaways\n\nUse your Scatterplot’s percentiles to collaborate with your customers in\nchoosing a Service Level Agreement for your process (other terms for\nService Level Agreement could be Service Level Expectation or Cycle\nTime Target). As with CFDs, it is possible to segment your data by type. You might\nchoose to do this to offer different SLAs for different work item types\nin your process. SLAs allow for commitment (and estimation) at the work item level. SLAs provide a sense of urgency to items that have been committed to. You can also use Cycle Time data percentiles as a guide for “rightsizing” items that come into your process. Use this right-sizing as a\nshortcut for estimation. Comparing an item’s age to its SLA can provide useful information\nabout when to make an intervention to ensure timely completion.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements\n\nindividual work item level, but they also give us extremely useful\ninformation about when teams need to intervene to ensure the timely\ncompletion of those items. Further, if a team follows all of the principles\npresented in this book, then the SLA can be used as a substitute for many\nupfront planning and estimation activities. I began Chapter 11 by discussing how most of the reasons why we are\n\nnot predictable is due to things under our control that we do to ourselves. One of the most common things we do to ourselves that hinders our\npredictability is not pay attention to the order in which items are pulled\nthrough our process. This problem is so common that I will devote the\nentirety of the next chapter to discussing its perils. Key Learnings and Takeaways\n\nUse your Scatterplot’s percentiles to collaborate with your customers in\nchoosing a Service Level Agreement for your process (other terms for\nService Level Agreement could be Service Level Expectation or Cycle\nTime Target). As with CFDs, it is possible to segment your data by type. You might\nchoose to do this to offer different SLAs for different work item types\nin your process. SLAs allow for commitment (and estimation) at the work item level. SLAs provide a sense of urgency to items that have been committed to. You can also use Cycle Time data percentiles as a guide for “rightsizing” items that come into your process. Use this right-sizing as a\nshortcut for estimation. Comparing an item’s age to its SLA can provide useful information\nabout when to make an intervention to ensure timely completion.", "tokens": 335, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 160, "segment_id": "00160", "chapter_num": "12", "chapter_title": "Service Level Agreements", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 12: Service Level Agreements", "chunk_id": "00000186"}
{"type": "chunk", "text": "Chapter 13 - Pull Policies\n\nMost airports around the world allow access to the flight departure area if a\nperson can prove that he is a passenger who is indeed flying that day. This\nproof usually takes the form of a valid boarding pass and a valid\ngovernment-issued ID. The United States is no exception to this rule. In the U.S., the\nTransportation Security Administration (TSA) is responsible performing\npassenger checks. TSA agents are stationed right before security and\npassengers wishing to get to the departures area must first check-in with\nthese agents. Many small airports in the U.S. staff only one TSA agent to perform\n\ntraveler validation. At those small airports during busy periods, quite a long\nqueue will form in front of the sole agent. Little’s Law tells us that as more\nand more people join the queue, those people can expect to wait for longer\nand longer amounts of time to get through the checkpoint (on average). In\nthis scenario, if you are a regular passenger, do you see the problem with\npredictability? It gets worse. In an attempt to streamline the process for what are considered low-risk\n\npassengers, the TSA has introduced something called “TSA Pre-check”\n(TSA Pre). Passengers who are certified as TSA Pre do not have to go\nthrough the whole security rigmarole of taking off shoes, taking off belts,\ntaking off jackets, and removing laptops. That is great if you are TSA Pre. The problem is that you still have to go through the upfront TSA passenger\nvalidation outlined previously. However, the TSA has attempted to solve this\nproblem by establishing a different lane for TSA Pre passengers to queue in\nto get their credentials checked. So now there are two lanes for two different\ntypes of passenger: a first lane called TSA Pre (as I have just mentioned) and\na second lane that I am going to call “punter”. In the small airports,\nunfortunately, there is still usually only one upfront, credential-checking\nagent to serve both of these lines. The TSA’s policy is that whenever there is\na person standing in the TSA Pre line, that the agent should stop pulling", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nChapter 13 - Pull Policies\n\nMost airports around the world allow access to the flight departure area if a\nperson can prove that he is a passenger who is indeed flying that day. This\nproof usually takes the form of a valid boarding pass and a valid\ngovernment-issued ID. The United States is no exception to this rule. In the U.S., the\nTransportation Security Administration (TSA) is responsible performing\npassenger checks. TSA agents are stationed right before security and\npassengers wishing to get to the departures area must first check-in with\nthese agents. Many small airports in the U.S. staff only one TSA agent to perform\n\ntraveler validation. At those small airports during busy periods, quite a long\nqueue will form in front of the sole agent. Little’s Law tells us that as more\nand more people join the queue, those people can expect to wait for longer\nand longer amounts of time to get through the checkpoint (on average). In\nthis scenario, if you are a regular passenger, do you see the problem with\npredictability? It gets worse. In an attempt to streamline the process for what are considered low-risk\n\npassengers, the TSA has introduced something called “TSA Pre-check”\n(TSA Pre). Passengers who are certified as TSA Pre do not have to go\nthrough the whole security rigmarole of taking off shoes, taking off belts,\ntaking off jackets, and removing laptops. That is great if you are TSA Pre. The problem is that you still have to go through the upfront TSA passenger\nvalidation outlined previously. However, the TSA has attempted to solve this\nproblem by establishing a different lane for TSA Pre passengers to queue in\nto get their credentials checked. So now there are two lanes for two different\ntypes of passenger: a first lane called TSA Pre (as I have just mentioned) and\na second lane that I am going to call “punter”. In the small airports,\nunfortunately, there is still usually only one upfront, credential-checking\nagent to serve both of these lines. The TSA’s policy is that whenever there is\na person standing in the TSA Pre line, that the agent should stop pulling", "tokens": 450, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 162, "segment_id": "00162", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000187"}
{"type": "chunk", "text": "from the punter queue and pull from the TSA Pre queue. See a problem with\noverall predictability yet? It gets worse. In addition to a separate TSA Pre lane there is usually a separate\n“priority lane” for passengers who have qualified for elite status on an\nairline. These passengers still have to go through the same security checks as\nthe other punters, but they do not have to wait in a long line to get the\nupfront ID check. To be clear, this is technically not a TSA thing, it is\nusually an airport/airline thing. However, at those small airports, it is the\nsingle TSA agent’s usual policy to look at the TSA Pre line first. If there is\nno one there, she will look at the priority lane next and pull people from\nthere. Only if there is no one in the TSA Pre or priority queue will the agent\nstart to pull again from the punter line. See a problem yet? It gets worse. As I just mentioned, everyone who wants to get air side at an airport\n\nmust go through this upfront ID check. Everyone. This includes any and all\nairline staff: pilots, flight attendants, etc. Crew members can usually choose\nwhatever line they want to get their credentials checked (TSA Pre, Priority,\nor punter). Further, once they are in those lines, the crew are allowed to go\nstraight to the front of their chosen queue regardless of how many people are\nahead of them. At those small airports, the sole TSA agent first looks to see\nif there are any airline crew in line. If none, then they look to see if there are\nany TSA Pre passengers. If none, then they look to see if there are any\npriority passengers. If none, then they finally pull from the punter line. See a\nproblem yet? If you are in the punter line, guess what you are doing while that lone\nTSA agent pulls passengers from those higher priority queues? You got it:\nwaiting. What do you think this is doing to the predictability of the punter\nqueue? In other words, how many assumptions of Little’s Law have been\nviolated in this airport scenario? Is Little’s Law even applicable here? Class of Service\nThis airport screening example is a classic implementation of a concept\nknown as Class of Service (CoS):", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nfrom the punter queue and pull from the TSA Pre queue. See a problem with\noverall predictability yet? It gets worse. In addition to a separate TSA Pre lane there is usually a separate\n“priority lane” for passengers who have qualified for elite status on an\nairline. These passengers still have to go through the same security checks as\nthe other punters, but they do not have to wait in a long line to get the\nupfront ID check. To be clear, this is technically not a TSA thing, it is\nusually an airport/airline thing. However, at those small airports, it is the\nsingle TSA agent’s usual policy to look at the TSA Pre line first. If there is\nno one there, she will look at the priority lane next and pull people from\nthere. Only if there is no one in the TSA Pre or priority queue will the agent\nstart to pull again from the punter line. See a problem yet? It gets worse. As I just mentioned, everyone who wants to get air side at an airport\n\nmust go through this upfront ID check. Everyone. This includes any and all\nairline staff: pilots, flight attendants, etc. Crew members can usually choose\nwhatever line they want to get their credentials checked (TSA Pre, Priority,\nor punter). Further, once they are in those lines, the crew are allowed to go\nstraight to the front of their chosen queue regardless of how many people are\nahead of them. At those small airports, the sole TSA agent first looks to see\nif there are any airline crew in line. If none, then they look to see if there are\nany TSA Pre passengers. If none, then they look to see if there are any\npriority passengers. If none, then they finally pull from the punter line. See a\nproblem yet? If you are in the punter line, guess what you are doing while that lone\nTSA agent pulls passengers from those higher priority queues? You got it:\nwaiting. What do you think this is doing to the predictability of the punter\nqueue? In other words, how many assumptions of Little’s Law have been\nviolated in this airport scenario? Is Little’s Law even applicable here? Class of Service\nThis airport screening example is a classic implementation of a concept\nknown as Class of Service (CoS):", "tokens": 492, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 163, "segment_id": "00163", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000188"}
{"type": "chunk", "text": "A Class of Service is a policy or set of policies around the order in which work items are\npulled through a given process once those items are committed to (i.e., once those items\nare counted as Work In Progress). That is to say, when a resource in a process frees up, CoS are the\npolicies around how that resource determines what in-progress item to work\non next. There are three subtleties to this definition that need to be addressed\nup front. First, a Class of Service is different than a work item type (I spoke\nabout how to segment WIP into different types in Chapter 2). This point can\nbe very confusing because many a Kanban “expert” uses these two terms\ninterchangeably. They are not. At least, not necessarily. We can choose to\nsegment our work items into any number of types and there is no\nprescription as to what categories we use for those types. Some previous\nexamples I have given for work item types are user stories, defects, small\nenhancements, and the like. You could also segment work items into types\nusing the source or destination of the work. For example, we could call a\nunit of work a finance work item type, or we could say it is an external\nwebsite work item type. Or we could call a unit of work a regulatory work\nitem type or a technical debt work item type. The possibilities are endless. And, yes, one of the ways you could choose to segment types is by Class of\nService---but you do not have to. I have always thought a better way to\napply CoS is to make it a dimension of an existing type. For example, a\nwork item of type user story has an expedited CoS, a work item of type\nregulatory requirement has a fixed date CoS. But that is just personal\npreference. Just know that work item types and CoS are different. Do not let\nthe existing literature out there on this stuff confuse you. To be clear, you can have any number of types of Class of Service as\n\nwell. The most talked about ones happen to be Expedite, Fixed Date,\nStandard, and Intangible. But those are only four examples of limitless kinds\nof Class of Service. Any time that you put a policy in place (explicit or not!)\naround the order in which you pull something through a process, then you\nhave introduced a Class of Service.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nA Class of Service is a policy or set of policies around the order in which work items are\npulled through a given process once those items are committed to (i.e., once those items\nare counted as Work In Progress). That is to say, when a resource in a process frees up, CoS are the\npolicies around how that resource determines what in-progress item to work\non next. There are three subtleties to this definition that need to be addressed\nup front. First, a Class of Service is different than a work item type (I spoke\nabout how to segment WIP into different types in Chapter 2). This point can\nbe very confusing because many a Kanban “expert” uses these two terms\ninterchangeably. They are not. At least, not necessarily. We can choose to\nsegment our work items into any number of types and there is no\nprescription as to what categories we use for those types. Some previous\nexamples I have given for work item types are user stories, defects, small\nenhancements, and the like. You could also segment work items into types\nusing the source or destination of the work. For example, we could call a\nunit of work a finance work item type, or we could say it is an external\nwebsite work item type. Or we could call a unit of work a regulatory work\nitem type or a technical debt work item type. The possibilities are endless. And, yes, one of the ways you could choose to segment types is by Class of\nService---but you do not have to. I have always thought a better way to\napply CoS is to make it a dimension of an existing type. For example, a\nwork item of type user story has an expedited CoS, a work item of type\nregulatory requirement has a fixed date CoS. But that is just personal\npreference. Just know that work item types and CoS are different. Do not let\nthe existing literature out there on this stuff confuse you. To be clear, you can have any number of types of Class of Service as\n\nwell. The most talked about ones happen to be Expedite, Fixed Date,\nStandard, and Intangible. But those are only four examples of limitless kinds\nof Class of Service. Any time that you put a policy in place (explicit or not!)\naround the order in which you pull something through a process, then you\nhave introduced a Class of Service.", "tokens": 510, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 164, "segment_id": "00164", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000189"}
{"type": "chunk", "text": "But that is just personal\npreference. Just know that work item types and CoS are different. Do not let\nthe existing literature out there on this stuff confuse you. To be clear, you can have any number of types of Class of Service as\n\nwell. The most talked about ones happen to be Expedite, Fixed Date,\nStandard, and Intangible. But those are only four examples of limitless kinds\nof Class of Service. Any time that you put a policy in place (explicit or not!)\naround the order in which you pull something through a process, then you\nhave introduced a Class of Service. The second subtlety of the above definition is that CoS does not attach\nuntil a work item has been pulled into the process. I cannot stress this point\nenough. There is absolutely no point in having a discussion about whether\nwork item A is an Expedite (for example) and whether work item B is a", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nBut that is just personal\npreference. Just know that work item types and CoS are different. Do not let\nthe existing literature out there on this stuff confuse you. To be clear, you can have any number of types of Class of Service as\n\nwell. The most talked about ones happen to be Expedite, Fixed Date,\nStandard, and Intangible. But those are only four examples of limitless kinds\nof Class of Service. Any time that you put a policy in place (explicit or not!)\naround the order in which you pull something through a process, then you\nhave introduced a Class of Service. The second subtlety of the above definition is that CoS does not attach\nuntil a work item has been pulled into the process. I cannot stress this point\nenough. There is absolutely no point in having a discussion about whether\nwork item A is an Expedite (for example) and whether work item B is a", "tokens": 193, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 164, "segment_id": "00164", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000190"}
{"type": "chunk", "text": "Fixed Date while both items A and B are still in the backlog. The reason for\nthis is, as I have mentioned so many times before, is that while those items\nare still in the backlog there is no confidence that either will ever be worked\non. Additionally, it is entirely possible that once committed to, our SLA\nwould predict that we need not give any preferential pull order to that item. For example, let’s assume that it is February 1 when we pull a new item into\nour process. Let’s further say that this new item has a due date of February\n28, and that the SLA for our process is 11 days. In this case, our SLA would\npredict that this item will complete well before its due date so there would be\nno point in giving it any preferential treatment. Given both of these\nscenarios, why waste time determining the order of pull before an item is in\nthe system? That is why the decision of what CoS to use happens only at the\ntime of an item’s first pull transaction. Which brings me to the last subtlety about CoS. The order in which\n\nitems are pulled once committed to is very different from the decision\ncriteria around what item to work on next at input queue replenishment time. Again, this is a very subtle but very important distinction. The criteria for\nwhat items we pull next off the backlog are very different from the criteria\naround the order in which we pull those items once in progress. If this\nconcept is still ambiguous to you, then hopefully I will have cleared it up by\nthe end of this discussion. The Impact of Class of Service on Predictability\nIn the last chapter, I mentioned that most teams do not understand how the\nimproper implementation of pull policy---whether explicit or not---\nnegatively impacts their system’s predictability. They do not understand\nthese negative impacts because CoS has either never been properly or fully\nexplained to them. I would like to quantify these negative impacts by\nexamining a pull policy scenario that I have set up for you. In this particular example, we are going to be operating a process that\n\nlooks like Figure 13.1:", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nFixed Date while both items A and B are still in the backlog. The reason for\nthis is, as I have mentioned so many times before, is that while those items\nare still in the backlog there is no confidence that either will ever be worked\non. Additionally, it is entirely possible that once committed to, our SLA\nwould predict that we need not give any preferential pull order to that item. For example, let’s assume that it is February 1 when we pull a new item into\nour process. Let’s further say that this new item has a due date of February\n28, and that the SLA for our process is 11 days. In this case, our SLA would\npredict that this item will complete well before its due date so there would be\nno point in giving it any preferential treatment. Given both of these\nscenarios, why waste time determining the order of pull before an item is in\nthe system? That is why the decision of what CoS to use happens only at the\ntime of an item’s first pull transaction. Which brings me to the last subtlety about CoS. The order in which\n\nitems are pulled once committed to is very different from the decision\ncriteria around what item to work on next at input queue replenishment time. Again, this is a very subtle but very important distinction. The criteria for\nwhat items we pull next off the backlog are very different from the criteria\naround the order in which we pull those items once in progress. If this\nconcept is still ambiguous to you, then hopefully I will have cleared it up by\nthe end of this discussion. The Impact of Class of Service on Predictability\nIn the last chapter, I mentioned that most teams do not understand how the\nimproper implementation of pull policy---whether explicit or not---\nnegatively impacts their system’s predictability. They do not understand\nthese negative impacts because CoS has either never been properly or fully\nexplained to them. I would like to quantify these negative impacts by\nexamining a pull policy scenario that I have set up for you. In this particular example, we are going to be operating a process that\n\nlooks like Figure 13.1:", "tokens": 456, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 165, "segment_id": "00165", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000191"}
{"type": "chunk", "text": "Figure 13.1: The WIP Limited Process in our Simulation\n\nYou will notice on this board that the Specifying column has a Work In\nProgress limit of two, the Development column has a Work In Progress limit\nof two, and the Test column has a Work In Progress limit of one. Let’s\nfurther suppose that for this process we will be working through a backlog of\n50 items. In this experiment, we are going to size all of our items such that\neach one takes exactly 10 days to go through each column. That is, every\nitem in the backlog that flows through this board will take exactly 10 days in\nSpecifying, 10 days in Development and 10 days in Test. We are also going\nto introduce two Classes of Service: Standard and Expedite. I will explain\nthe pull order rules for each of these as we go through the simulation. Lastly,\nyou should know that in this experiment there will be no blocking events or\nadded scope. We will start the simulation with 50 items in the backlog and\nwe will finish the simulation with 50 items in Done. All items will be\nallowed to flow through unmolested. Or will they?", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nFigure 13.1: The WIP Limited Process in our Simulation\n\nYou will notice on this board that the Specifying column has a Work In\nProgress limit of two, the Development column has a Work In Progress limit\nof two, and the Test column has a Work In Progress limit of one. Let’s\nfurther suppose that for this process we will be working through a backlog of\n50 items. In this experiment, we are going to size all of our items such that\neach one takes exactly 10 days to go through each column. That is, every\nitem in the backlog that flows through this board will take exactly 10 days in\nSpecifying, 10 days in Development and 10 days in Test. We are also going\nto introduce two Classes of Service: Standard and Expedite. I will explain\nthe pull order rules for each of these as we go through the simulation. Lastly,\nyou should know that in this experiment there will be no blocking events or\nadded scope. We will start the simulation with 50 items in the backlog and\nwe will finish the simulation with 50 items in Done. All items will be\nallowed to flow through unmolested. Or will they?", "tokens": 249, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 166, "segment_id": "00166", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000192"}
{"type": "chunk", "text": "You will notice from the design of the board in Figure 13.1 that, at the\nend of the 20th day, two items will have completed in the Dev column but\nthere will only be space to pull one of those items into the Test column. As\nyou are about to see, the simple decision around which of those two to pull\nwill have a dramatic effect on the predictability of your system. For the first run we are going to assign only a Standard CoS for work\nitems on the board. Further, we are going to define a strict “First-In, FirstOut” (FIFO) pull order policy for those Standard class items. That is, the\ndecision around what item should be pulled next will be based solely on\nwhich item entered the board first. Before I show you the results, I would like you to try to guess what the\nexpected Cycle Time for our items will be. (Note: for these simulations I am\ngoing to consider the “expected value” for the Cycle Times to be the 85th\npercentile.) If you are ready with your guess then read on. Figure 13.2: Strict FIFO Pull Order with No Expedites\n\nFigure 13.2 shows a Histogram of the Cycle Time results. You can see\nthat after running this simulation, the 85th percentile for our Cycle Times is", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nYou will notice from the design of the board in Figure 13.1 that, at the\nend of the 20th day, two items will have completed in the Dev column but\nthere will only be space to pull one of those items into the Test column. As\nyou are about to see, the simple decision around which of those two to pull\nwill have a dramatic effect on the predictability of your system. For the first run we are going to assign only a Standard CoS for work\nitems on the board. Further, we are going to define a strict “First-In, FirstOut” (FIFO) pull order policy for those Standard class items. That is, the\ndecision around what item should be pulled next will be based solely on\nwhich item entered the board first. Before I show you the results, I would like you to try to guess what the\nexpected Cycle Time for our items will be. (Note: for these simulations I am\ngoing to consider the “expected value” for the Cycle Times to be the 85th\npercentile.) If you are ready with your guess then read on. Figure 13.2: Strict FIFO Pull Order with No Expedites\n\nFigure 13.2 shows a Histogram of the Cycle Time results. You can see\nthat after running this simulation, the 85th percentile for our Cycle Times is", "tokens": 283, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 167, "segment_id": "00167", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000193"}
{"type": "chunk", "text": "50 days. In other words, 85% of our items finished in 50 days or less. Also,\nas you look at the distribution of Cycle Times in the Histogram above, you\nwill see that we have a fairly predictable system---there is not much\nvariability going on here. But let’s see what happens when we begin to\ntweak some things. In this next round, we are going to replace our strict FIFO pull order\npolicy with a policy that says that we will choose which item to pull next\ncompletely at random. One way it may help you to think about this is when\ntwo items are finished in the Development column, we are essentially going\nto flip a coin to see which one we should pull next into the Test column. Any guess now as to what this new policy is going to do to our\n\nexpected Cycle Time? To variability? To predictability? Figure 13.3: Random Pull Order with no Expedites\nIn this case (Figure 13.3), the simple switch from FIFO queuing to\nrandom queuing has increased our 85th percentile Cycle Time from 50 days\nto 60 days---that is an increase of 20%! Did you expect that such a minor\npolicy change would have such a big Cycle Time impact? You can also see", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\n50 days. In other words, 85% of our items finished in 50 days or less. Also,\nas you look at the distribution of Cycle Times in the Histogram above, you\nwill see that we have a fairly predictable system---there is not much\nvariability going on here. But let’s see what happens when we begin to\ntweak some things. In this next round, we are going to replace our strict FIFO pull order\npolicy with a policy that says that we will choose which item to pull next\ncompletely at random. One way it may help you to think about this is when\ntwo items are finished in the Development column, we are essentially going\nto flip a coin to see which one we should pull next into the Test column. Any guess now as to what this new policy is going to do to our\n\nexpected Cycle Time? To variability? To predictability? Figure 13.3: Random Pull Order with no Expedites\nIn this case (Figure 13.3), the simple switch from FIFO queuing to\nrandom queuing has increased our 85th percentile Cycle Time from 50 days\nto 60 days---that is an increase of 20%! Did you expect that such a minor\npolicy change would have such a big Cycle Time impact? You can also see", "tokens": 271, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 168, "segment_id": "00168", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000194"}
{"type": "chunk", "text": "that the corresponding distribution (shown in Figure 13.3) is much more\nspread out reflecting the increased variability of our random decision\nmaking. Things get interesting when we start to add in some expedites. Let’s\n\nlook at that next. We are now going to go back to the pull policy where our Standard\nclass items are going to be pulled through in a strict FIFO queuing order. The twist we are going introduce, though, is that we are now going to\ninclude an Expedite Class of Service for some of the items on our board. In\nthis round we are going to choose exactly one item on the board at a time to\nhave an Expedite Class of Service. When one expedited item finishes,\nanother one will be immediately introduced. These Expedites will be\nallowed to violate WIP limits in every column. Further, whenever both an\nExpedite and Standard class item finish simultaneously, then the Expedite\nitem will always be given preference over the Standard item when it comes\nto deciding which one to pull next. Standard questions apply before proceeding: any thoughts on Cycle\n\nTime impact? Variability? Predictability?", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nthat the corresponding distribution (shown in Figure 13.3) is much more\nspread out reflecting the increased variability of our random decision\nmaking. Things get interesting when we start to add in some expedites. Let’s\n\nlook at that next. We are now going to go back to the pull policy where our Standard\nclass items are going to be pulled through in a strict FIFO queuing order. The twist we are going introduce, though, is that we are now going to\ninclude an Expedite Class of Service for some of the items on our board. In\nthis round we are going to choose exactly one item on the board at a time to\nhave an Expedite Class of Service. When one expedited item finishes,\nanother one will be immediately introduced. These Expedites will be\nallowed to violate WIP limits in every column. Further, whenever both an\nExpedite and Standard class item finish simultaneously, then the Expedite\nitem will always be given preference over the Standard item when it comes\nto deciding which one to pull next. Standard questions apply before proceeding: any thoughts on Cycle\n\nTime impact? Variability? Predictability?", "tokens": 238, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 169, "segment_id": "00169", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000195"}
{"type": "chunk", "text": "Figure 13.4: FIFO Pull Order with Always One Expedite on the Board\nAny surprises here (Figure 13.4)? Compared to the previous case (the\n\nrandom pulling case), Expected Cycle Time has increased five days from 60\ndays to 65 days. You can see the Histogram (Figure 13.4) has become much\nmore compact, but there is still a wider spread than when compared to our\nbaseline case (the strict FIFO/no expedites case), and, as I just mentioned,\noverall Cycle Times are longer. Did you expect this to be the worst case yet\nfrom a Cycle Time perspective? You can see that this is only marginally\nworse than the random queuing round---but it is still worse. That is an\ninteresting point that bears a little more emphasis. In this context,\nintroducing an Expedite CoS is worse for predictability than simply pulling\nitems at random. Hopefully you are getting a feel for just how disruptive\nexpedites can be (if you were not convinced already). But we are not done yet. There is still one permutation left to consider. In this final experiment, we are going to change our pull policies for\nStandard class items back to random from FIFO. We are going to keep the\nrule of always having one Expedite item on the board. The pull policies for", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nFigure 13.4: FIFO Pull Order with Always One Expedite on the Board\nAny surprises here (Figure 13.4)? Compared to the previous case (the\n\nrandom pulling case), Expected Cycle Time has increased five days from 60\ndays to 65 days. You can see the Histogram (Figure 13.4) has become much\nmore compact, but there is still a wider spread than when compared to our\nbaseline case (the strict FIFO/no expedites case), and, as I just mentioned,\noverall Cycle Times are longer. Did you expect this to be the worst case yet\nfrom a Cycle Time perspective? You can see that this is only marginally\nworse than the random queuing round---but it is still worse. That is an\ninteresting point that bears a little more emphasis. In this context,\nintroducing an Expedite CoS is worse for predictability than simply pulling\nitems at random. Hopefully you are getting a feel for just how disruptive\nexpedites can be (if you were not convinced already). But we are not done yet. There is still one permutation left to consider. In this final experiment, we are going to change our pull policies for\nStandard class items back to random from FIFO. We are going to keep the\nrule of always having one Expedite item on the board. The pull policies for", "tokens": 280, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 170, "segment_id": "00170", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000196"}
{"type": "chunk", "text": "the Expedites remain the same: they can violate WIP limits and will always\nget pulled in preference to Standard class items. Now what do you think will happen? Figure 13.5: Random Pull Order with Always One Expedite on the Board\nExpected Cycle Time in this scenario (Figure 13.5) has jumped to a\nsimulation-worst 100 days! The spread of our data shown by the Histogram\n(Figure 13.5) is also worrying: Cycle Times range anywhere from 40 days to\n170 days. If that is not variability, then I do not know what is. Remember, in\nthe ideal system of the first case, the range of Cycle Times were 30 to 50\ndays. Let’s look at all these results side by side (Figure 13.6):", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nthe Expedites remain the same: they can violate WIP limits and will always\nget pulled in preference to Standard class items. Now what do you think will happen? Figure 13.5: Random Pull Order with Always One Expedite on the Board\nExpected Cycle Time in this scenario (Figure 13.5) has jumped to a\nsimulation-worst 100 days! The spread of our data shown by the Histogram\n(Figure 13.5) is also worrying: Cycle Times range anywhere from 40 days to\n170 days. If that is not variability, then I do not know what is. Remember, in\nthe ideal system of the first case, the range of Cycle Times were 30 to 50\ndays. Let’s look at all these results side by side (Figure 13.6):", "tokens": 169, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 171, "segment_id": "00171", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000197"}
{"type": "chunk", "text": "Figure 13.6: CoS Results Side by Side\n\nI would like you to reflect on this result for a minute. Minor tweaks to\nprocess policies had a dramatic impact on simulation outcomes. Again, note\nthat these policies were all things that were completely under our control! All of the variability in these scenarios was of our own doing. Worse still,\nmy guess is that you have probably never even given any thought to some of\nthese policies. Do you pay attention to how you decide what order to pull\nitems through your process? Do you try to control or limit the number of\nExpedites on your board? Do you have any clue what a lack of these\nconsiderations is doing to your process predictability? Obviously in the previous example I have controlled for story size. That\nis generally not possible (nor even required nor suggested) in the real world. Differences in story size are additional variability that is going to affect the\npredictability of the process and make these Histograms look even worse. That being the case, why would we not try to mimic FIFO as closely as\npossible? Why would we not try to control pull policies that we can control? The short answer is that we should. The longer answer is that in many\n\ncontexts FIFO queuing may be impractical (leaving the business value\ndimension of pull decisions aside for a minute).", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nFigure 13.6: CoS Results Side by Side\n\nI would like you to reflect on this result for a minute. Minor tweaks to\nprocess policies had a dramatic impact on simulation outcomes. Again, note\nthat these policies were all things that were completely under our control! All of the variability in these scenarios was of our own doing. Worse still,\nmy guess is that you have probably never even given any thought to some of\nthese policies. Do you pay attention to how you decide what order to pull\nitems through your process? Do you try to control or limit the number of\nExpedites on your board? Do you have any clue what a lack of these\nconsiderations is doing to your process predictability? Obviously in the previous example I have controlled for story size. That\nis generally not possible (nor even required nor suggested) in the real world. Differences in story size are additional variability that is going to affect the\npredictability of the process and make these Histograms look even worse. That being the case, why would we not try to mimic FIFO as closely as\npossible? Why would we not try to control pull policies that we can control? The short answer is that we should. The longer answer is that in many\n\ncontexts FIFO queuing may be impractical (leaving the business value\ndimension of pull decisions aside for a minute).", "tokens": 280, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 172, "segment_id": "00172", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000198"}
{"type": "chunk", "text": "There are a couple of reasons for the impracticality of FIFO queuing. Think about a restaurant, for example. Patrons of restaurants do not flow\nthrough in a strict FIFO ordering. To illustrate, let’s say a group is seated\nfirst at Table A. Then a different group is seated second at Table B. The\ngroup at Table B does not have to wait until the first group at Table A has\nfinished before the second group is allowed to leave. That would just be\nsilly. The groups are, however, usually seated in a First In First Served\n(FIFS) order. A (mostly) FIFS scheme is much more practical in the\nknowledge work context as well and usually is the best strategy from a\npredictability perspective. Extending the restaurant example, let’s say that a group of four people\narrives to an establishment that is currently full and they need to wait for a\ntable to open up in order to be seated. Let’s further say that a group of two\npeople arrives after the group of four and this second group needs to wait as\nwell. If the first table to open up seats only two people, then it is reasonable\nthat the group of two---who arrived second---would be seated first. This\nscenario happens all the time in knowledge work. Maybe a resource frees up\nand is ready to pull an item. But he does not have the expertise to work on\nthe item that has been waiting the longest (which should be his first choice). From a practical perspective, it would be reasonable for him to pull the item\nthat has been waiting the second longest (assuming, again, that he has the\nright skills to work on that second one). But remember, even though this\nmay be the best practical decision, it may not be the best predictable\ndecision. In this scenario, what are some longer term improvements you\ncould make for better predictability? The point to all of this is that the further you stray from FIFO queuing,\n\nthe less predictable you are. That is not to say that there are not practical\nreasons why you should forfeit FIFO. And by the way, arbitrary business\nvalue reasons and fictional Cost of Delay calculations do not fall into this\npractical category. But more on that a little later.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nThere are a couple of reasons for the impracticality of FIFO queuing. Think about a restaurant, for example. Patrons of restaurants do not flow\nthrough in a strict FIFO ordering. To illustrate, let’s say a group is seated\nfirst at Table A. Then a different group is seated second at Table B. The\ngroup at Table B does not have to wait until the first group at Table A has\nfinished before the second group is allowed to leave. That would just be\nsilly. The groups are, however, usually seated in a First In First Served\n(FIFS) order. A (mostly) FIFS scheme is much more practical in the\nknowledge work context as well and usually is the best strategy from a\npredictability perspective. Extending the restaurant example, let’s say that a group of four people\narrives to an establishment that is currently full and they need to wait for a\ntable to open up in order to be seated. Let’s further say that a group of two\npeople arrives after the group of four and this second group needs to wait as\nwell. If the first table to open up seats only two people, then it is reasonable\nthat the group of two---who arrived second---would be seated first. This\nscenario happens all the time in knowledge work. Maybe a resource frees up\nand is ready to pull an item. But he does not have the expertise to work on\nthe item that has been waiting the longest (which should be his first choice). From a practical perspective, it would be reasonable for him to pull the item\nthat has been waiting the second longest (assuming, again, that he has the\nright skills to work on that second one). But remember, even though this\nmay be the best practical decision, it may not be the best predictable\ndecision. In this scenario, what are some longer term improvements you\ncould make for better predictability? The point to all of this is that the further you stray from FIFO queuing,\n\nthe less predictable you are. That is not to say that there are not practical\nreasons why you should forfeit FIFO. And by the way, arbitrary business\nvalue reasons and fictional Cost of Delay calculations do not fall into this\npractical category. But more on that a little later.", "tokens": 474, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 173, "segment_id": "00173", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000199"}
{"type": "chunk", "text": "But remember, even though this\nmay be the best practical decision, it may not be the best predictable\ndecision. In this scenario, what are some longer term improvements you\ncould make for better predictability? The point to all of this is that the further you stray from FIFO queuing,\n\nthe less predictable you are. That is not to say that there are not practical\nreasons why you should forfeit FIFO. And by the way, arbitrary business\nvalue reasons and fictional Cost of Delay calculations do not fall into this\npractical category. But more on that a little later. The most common objection I get when I explain why teams should\n\nadopt FIFO (or FIFS, or mostly FIFS) and dump expedites is that,\n“Expedites happen all the time in our context and we can’t not work on\nthem”. They might go on to say that these expedites are unpredictable in size\nand number. Not only am I sympathetic to this argument, I acknowledge that\nthis is the case for most teams at most companies.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nBut remember, even though this\nmay be the best practical decision, it may not be the best predictable\ndecision. In this scenario, what are some longer term improvements you\ncould make for better predictability? The point to all of this is that the further you stray from FIFO queuing,\n\nthe less predictable you are. That is not to say that there are not practical\nreasons why you should forfeit FIFO. And by the way, arbitrary business\nvalue reasons and fictional Cost of Delay calculations do not fall into this\npractical category. But more on that a little later. The most common objection I get when I explain why teams should\n\nadopt FIFO (or FIFS, or mostly FIFS) and dump expedites is that,\n“Expedites happen all the time in our context and we can’t not work on\nthem”. They might go on to say that these expedites are unpredictable in size\nand number. Not only am I sympathetic to this argument, I acknowledge that\nthis is the case for most teams at most companies.", "tokens": 217, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 173, "segment_id": "00173", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000200"}
{"type": "chunk", "text": "Slack\nSo what is a team to do? Why, look at FedEx, of course. Federal Express (FedEx) is an American shipping company that allows\n\nclients to send packages all over the world. For this example, though, let’s\nlimit the scope of our discussion to just the continental United States. Suffice\nit to say that FedEx knows a thing or two about flow and predictability, and\nthe company is worth studying. When a prospective customer wishes to ship a package via FedEx that\n\ncustomer has several service options to choose from. She can choose to it\nsend overnight, 2nd day air, and standard ground---to just name a few. All of\nthese service options are going to result in different CoS that FedEx uses in\norder to make sure that packages get to their destinations within the agreed\nSLA. Think about this for a second. In the U.S. there are thousands of\nlocations that FedEx will need to pick up packages from. On any given day,\nit is impossible for FedEx to proactively and deterministically know the\nexact number of packages, their respective requested CoS, their full\ndimensions, weight, etc. that will show up at any one of their locations. They\ncould have one shop that is swamped with overnight requests while another\nlocation remains relatively quiet. The magnitude of this problem is almost\nbeyond comprehension. The incredible thing is, while I have not used FedEx a lot, I can tell you\nthat every time I have needed to send a package overnight it has arrived at its\nlocation on time. How does FedEx do it? There are a lot of strategies that FedEx employs, but the one that is\nprobably most important is that at any given time FedEx has empty planes in\nthe air. Yes, I said empty planes. That way, if a location gets overwhelmed,\nor if packages get left behind because a regularly scheduled plane was full\nthen an empty plane is redirected (just-in-time it should be said) to the\nproblem spot. At any given time FedEx has “spares in the air”! A lot of people will tell you that Lean is all about waste elimination. But imagine if the FedEx CFO was hyper-focused on waste elimination for\nprocess improvement. Would that CFO ever allow empty planes to be in the\nair at any given time for any reason? Of course not.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nSlack\nSo what is a team to do? Why, look at FedEx, of course. Federal Express (FedEx) is an American shipping company that allows\n\nclients to send packages all over the world. For this example, though, let’s\nlimit the scope of our discussion to just the continental United States. Suffice\nit to say that FedEx knows a thing or two about flow and predictability, and\nthe company is worth studying. When a prospective customer wishes to ship a package via FedEx that\n\ncustomer has several service options to choose from. She can choose to it\nsend overnight, 2nd day air, and standard ground---to just name a few. All of\nthese service options are going to result in different CoS that FedEx uses in\norder to make sure that packages get to their destinations within the agreed\nSLA. Think about this for a second. In the U.S. there are thousands of\nlocations that FedEx will need to pick up packages from. On any given day,\nit is impossible for FedEx to proactively and deterministically know the\nexact number of packages, their respective requested CoS, their full\ndimensions, weight, etc. that will show up at any one of their locations. They\ncould have one shop that is swamped with overnight requests while another\nlocation remains relatively quiet. The magnitude of this problem is almost\nbeyond comprehension. The incredible thing is, while I have not used FedEx a lot, I can tell you\nthat every time I have needed to send a package overnight it has arrived at its\nlocation on time. How does FedEx do it? There are a lot of strategies that FedEx employs, but the one that is\nprobably most important is that at any given time FedEx has empty planes in\nthe air. Yes, I said empty planes. That way, if a location gets overwhelmed,\nor if packages get left behind because a regularly scheduled plane was full\nthen an empty plane is redirected (just-in-time it should be said) to the\nproblem spot. At any given time FedEx has “spares in the air”! A lot of people will tell you that Lean is all about waste elimination. But imagine if the FedEx CFO was hyper-focused on waste elimination for\nprocess improvement. Would that CFO ever allow empty planes to be in the\nair at any given time for any reason? Of course not.", "tokens": 488, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 174, "segment_id": "00174", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000201"}
{"type": "chunk", "text": "Yes, I said empty planes. That way, if a location gets overwhelmed,\nor if packages get left behind because a regularly scheduled plane was full\nthen an empty plane is redirected (just-in-time it should be said) to the\nproblem spot. At any given time FedEx has “spares in the air”! A lot of people will tell you that Lean is all about waste elimination. But imagine if the FedEx CFO was hyper-focused on waste elimination for\nprocess improvement. Would that CFO ever allow empty planes to be in the\nair at any given time for any reason? Of course not. Flying empty planes\nmeans paying pilots’ salaries, it means burning jet fuel, it means additional\nmaintenance and upkeep. Luckily for FedEx, they understand that Lean is\nnot just about waste elimination, it is about the effective, efficient, and\npredictable delivery of customer value. FedEx understands all too well the", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nYes, I said empty planes. That way, if a location gets overwhelmed,\nor if packages get left behind because a regularly scheduled plane was full\nthen an empty plane is redirected (just-in-time it should be said) to the\nproblem spot. At any given time FedEx has “spares in the air”! A lot of people will tell you that Lean is all about waste elimination. But imagine if the FedEx CFO was hyper-focused on waste elimination for\nprocess improvement. Would that CFO ever allow empty planes to be in the\nair at any given time for any reason? Of course not. Flying empty planes\nmeans paying pilots’ salaries, it means burning jet fuel, it means additional\nmaintenance and upkeep. Luckily for FedEx, they understand that Lean is\nnot just about waste elimination, it is about the effective, efficient, and\npredictable delivery of customer value. FedEx understands all too well the", "tokens": 185, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 174, "segment_id": "00174", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000202"}
{"type": "chunk", "text": "variability introduced by offering different CoS. They know that, in the face\nof that variability, if they want to deliver on their SLAs they must have\nspares in the air. They have to build slack into the system. Pretty much the\nonly way to predictably deliver in the face of variability introduced by\ndifferent CoS is to build slack into the system. There is just no way around\nit. So let’s get back to the “we have expedites that we cannot predict and\n\nthat we have to work on” argument. Armed with this information about\nvariability and slack, what do you think would happen if you went to your\nmanagement and said, “if we want to predictably deliver on all of the\nexpedites in our process (to say nothing of all of our other work), we need to\nhave some team members that sit around, do nothing, and wait for the\nexpedites to occur.” You better have your resume updated because after you\nget laughed out of the room you will be looking for a new job. “Ok, so you cannot have idle developers,” so-called CoS experts will\n\ntell you, “then what you need to do is put a strict limit on the number of\nexpedites that can be in your process at any given time.” They will further\nadvise you that the limit on expedites needs to be as small as possible---\npotentially as low as a WIP limit of one. Problem solved. Not at all. This advice ignores two further fundamental problems of CoS. For the\nfirst I will need another example. In my regular Kanban trainings I am a big\nfan of using Russell Healy’s getKanban board game. I like the game not\nbecause it shows people how to do Kanban properly, but because it does a\ngreat job of highlighting many of the errors in the advice given by so many\nKanban experts. One of those errors is the advised use of an expedite lane on\na Kanban Board (or CoS in general). Now in this game, there is a lane\ndedicated for expedited items, and, further, there is an explicit WIP limit of\none for that lane. This is the exact implementation of the strategy that I just\nexplained. So what is the problem?", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nvariability introduced by offering different CoS. They know that, in the face\nof that variability, if they want to deliver on their SLAs they must have\nspares in the air. They have to build slack into the system. Pretty much the\nonly way to predictably deliver in the face of variability introduced by\ndifferent CoS is to build slack into the system. There is just no way around\nit. So let’s get back to the “we have expedites that we cannot predict and\n\nthat we have to work on” argument. Armed with this information about\nvariability and slack, what do you think would happen if you went to your\nmanagement and said, “if we want to predictably deliver on all of the\nexpedites in our process (to say nothing of all of our other work), we need to\nhave some team members that sit around, do nothing, and wait for the\nexpedites to occur.” You better have your resume updated because after you\nget laughed out of the room you will be looking for a new job. “Ok, so you cannot have idle developers,” so-called CoS experts will\n\ntell you, “then what you need to do is put a strict limit on the number of\nexpedites that can be in your process at any given time.” They will further\nadvise you that the limit on expedites needs to be as small as possible---\npotentially as low as a WIP limit of one. Problem solved. Not at all. This advice ignores two further fundamental problems of CoS. For the\nfirst I will need another example. In my regular Kanban trainings I am a big\nfan of using Russell Healy’s getKanban board game. I like the game not\nbecause it shows people how to do Kanban properly, but because it does a\ngreat job of highlighting many of the errors in the advice given by so many\nKanban experts. One of those errors is the advised use of an expedite lane on\na Kanban Board (or CoS in general). Now in this game, there is a lane\ndedicated for expedited items, and, further, there is an explicit WIP limit of\none for that lane. This is the exact implementation of the strategy that I just\nexplained. So what is the problem?", "tokens": 487, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 175, "segment_id": "00175", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000203"}
{"type": "chunk", "text": "I like the game not\nbecause it shows people how to do Kanban properly, but because it does a\ngreat job of highlighting many of the errors in the advice given by so many\nKanban experts. One of those errors is the advised use of an expedite lane on\na Kanban Board (or CoS in general). Now in this game, there is a lane\ndedicated for expedited items, and, further, there is an explicit WIP limit of\none for that lane. This is the exact implementation of the strategy that I just\nexplained. So what is the problem? At the end of the game, I take the teams\nthrough an analysis of the data that they generated while they played the\nsimulation (using all the techniques that have been outlined in the previous\nchapters). The data usually shows them that their standard items flow\nthrough the system in about ten or eleven days at the 85th percentile. And the\nspread in the Cycle Time data of standard items is usually between three and\n15 days. The data for the expedited items’ Cycle Time show that those items\nalways take three days or less. You can see that the policies those teams used", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nI like the game not\nbecause it shows people how to do Kanban properly, but because it does a\ngreat job of highlighting many of the errors in the advice given by so many\nKanban experts. One of those errors is the advised use of an expedite lane on\na Kanban Board (or CoS in general). Now in this game, there is a lane\ndedicated for expedited items, and, further, there is an explicit WIP limit of\none for that lane. This is the exact implementation of the strategy that I just\nexplained. So what is the problem? At the end of the game, I take the teams\nthrough an analysis of the data that they generated while they played the\nsimulation (using all the techniques that have been outlined in the previous\nchapters). The data usually shows them that their standard items flow\nthrough the system in about ten or eleven days at the 85th percentile. And the\nspread in the Cycle Time data of standard items is usually between three and\n15 days. The data for the expedited items’ Cycle Time show that those items\nalways take three days or less. You can see that the policies those teams used", "tokens": 247, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 175, "segment_id": "00175", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000204"}
{"type": "chunk", "text": "to attack the expedites made them eminently predictable. You will also note\nthat those policies also contributed to the variability in the standard items,\nbut that is not what is important here. What is important here is what\nhappens when we project this to the real world. Imagine now that you are a\nproduct owner and you see that your requested item is given a standard CoS. That means that the team will request eleven days to complete it. But if your\nrequested item is given an expedited CoS, then that item gets done in three\ndays. What do you think is going to happen in the real world? That is right:\neverything becomes an expedite! Good luck trying to keep to the WIP of the\nexpedited lane limited to one. But that is not the only problem. Let’s say that you work at an\nenlightened company and that they do agree that there will only be one\nexpedited item in progress at any given time. It turns out even that is not\nenough! In the simulation example above, we limited our expedited items to\none but that still caused a sharp increase in Cycle Time variability. Why? Because there was always one expedited item in progress. If you are going to\nhave an expedited lane, and you limit that lane’s WIP to one, but there is\nalways one item in it, then, I am sorry to say, you do not have an expedited\nprocess. You have a standard process that you are calling an expedited\nprocess, and you have a substandard process which is everything else. For all practical purposes, introducing CoS is one of the worst things you can do to\npredictability. But, you might argue, the real reason to introduce CoS is to maximize\n\nbusiness value (for the purposes of this conversation, I am going to lump\ncost of delay and managing risk in with optimizing for business value). I\nmight be persuaded by this argument if I believed that it was possible to\naccurately predetermine business value. If you could do that, then you really\ndo not need to be reading this book because your life is easy. Obviously, if\nyou have a priori knowledge of business value then you would just pull\nitems in a way that maximizes that value. However, most companies I work\nwith have no clue about upfront business value. And it is not due to\ninexperience, incompetence, or lack of trying.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nto attack the expedites made them eminently predictable. You will also note\nthat those policies also contributed to the variability in the standard items,\nbut that is not what is important here. What is important here is what\nhappens when we project this to the real world. Imagine now that you are a\nproduct owner and you see that your requested item is given a standard CoS. That means that the team will request eleven days to complete it. But if your\nrequested item is given an expedited CoS, then that item gets done in three\ndays. What do you think is going to happen in the real world? That is right:\neverything becomes an expedite! Good luck trying to keep to the WIP of the\nexpedited lane limited to one. But that is not the only problem. Let’s say that you work at an\nenlightened company and that they do agree that there will only be one\nexpedited item in progress at any given time. It turns out even that is not\nenough! In the simulation example above, we limited our expedited items to\none but that still caused a sharp increase in Cycle Time variability. Why? Because there was always one expedited item in progress. If you are going to\nhave an expedited lane, and you limit that lane’s WIP to one, but there is\nalways one item in it, then, I am sorry to say, you do not have an expedited\nprocess. You have a standard process that you are calling an expedited\nprocess, and you have a substandard process which is everything else. For all practical purposes, introducing CoS is one of the worst things you can do to\npredictability. But, you might argue, the real reason to introduce CoS is to maximize\n\nbusiness value (for the purposes of this conversation, I am going to lump\ncost of delay and managing risk in with optimizing for business value). I\nmight be persuaded by this argument if I believed that it was possible to\naccurately predetermine business value. If you could do that, then you really\ndo not need to be reading this book because your life is easy. Obviously, if\nyou have a priori knowledge of business value then you would just pull\nitems in a way that maximizes that value. However, most companies I work\nwith have no clue about upfront business value. And it is not due to\ninexperience, incompetence, or lack of trying.", "tokens": 511, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 176, "segment_id": "00176", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000205"}
{"type": "chunk", "text": "I\nmight be persuaded by this argument if I believed that it was possible to\naccurately predetermine business value. If you could do that, then you really\ndo not need to be reading this book because your life is easy. Obviously, if\nyou have a priori knowledge of business value then you would just pull\nitems in a way that maximizes that value. However, most companies I work\nwith have no clue about upfront business value. And it is not due to\ninexperience, incompetence, or lack of trying. The reason most companies\ndo not know about an item’s business value upfront is because that value---in\nmost cases---is impossible to predict. As value is only determined by our\ncustomers, an item’s true value can only be known once put in the hands of", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nI\nmight be persuaded by this argument if I believed that it was possible to\naccurately predetermine business value. If you could do that, then you really\ndo not need to be reading this book because your life is easy. Obviously, if\nyou have a priori knowledge of business value then you would just pull\nitems in a way that maximizes that value. However, most companies I work\nwith have no clue about upfront business value. And it is not due to\ninexperience, incompetence, or lack of trying. The reason most companies\ndo not know about an item’s business value upfront is because that value---in\nmost cases---is impossible to predict. As value is only determined by our\ncustomers, an item’s true value can only be known once put in the hands of", "tokens": 165, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 176, "segment_id": "00176", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000206"}
{"type": "chunk", "text": "the customer. Sure, most companies will require a business case before a\nproject is started and this business case acts a proxy for business value. But,\nas you know, most business cases are anywhere from pure works of fiction\nto out and out lies. Basing pull decisions on disingenuous arguments is\nsuspect at best. Let’s put it another way. As I just mentioned, true business value can be\ndetermined only after delivery to the customer. Choices about what to work\non and when, then, are really just you placing bets on what you think the\ncustomer will find valuable. By introducing CoS and by giving preference to\nsome items in the process over other items means that you are gambling that\nthe customer will find those preferred items more valuable. The problem is\nthat when you lose that bet---and I guarantee you almost always will---you\nwill have not only lost the bet on the expedited item, but you will have also\nlost the bet for every other item in progress that you skipped over. Honestly, I am only mostly that cynical. I do believe that the business\n\nvalue of an item should be considered, but I believe it should only be\nconsidered at input queue replenishment time. After an item is placed in\nprocess then I believe the best long term strategy is to pull that item---and all\nother items---through the process as predictably as possible. After all, part of\nthe business value equation is how long it will take to get an item done. If\nyou cannot answer the question “how long?” then how much confidence can\nyou really have in your business value calculation? What about obvious high value expedites? Things like production being\n\ndown that require all hands on deck? Or a new regulatory requirement that\ncould result in massive fines for noncompliance? Obviously, those things\nwill---and should---take precedence. But, just like the FedEx example, you\nshould study the rate of occurrence for those items and adjust your process\ndesign accordingly. That will potentially mean lowering overall process WIP. That will probably mean making sure free resources look to help out with\nother items in process before pulling in new items. And so on.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nthe customer. Sure, most companies will require a business case before a\nproject is started and this business case acts a proxy for business value. But,\nas you know, most business cases are anywhere from pure works of fiction\nto out and out lies. Basing pull decisions on disingenuous arguments is\nsuspect at best. Let’s put it another way. As I just mentioned, true business value can be\ndetermined only after delivery to the customer. Choices about what to work\non and when, then, are really just you placing bets on what you think the\ncustomer will find valuable. By introducing CoS and by giving preference to\nsome items in the process over other items means that you are gambling that\nthe customer will find those preferred items more valuable. The problem is\nthat when you lose that bet---and I guarantee you almost always will---you\nwill have not only lost the bet on the expedited item, but you will have also\nlost the bet for every other item in progress that you skipped over. Honestly, I am only mostly that cynical. I do believe that the business\n\nvalue of an item should be considered, but I believe it should only be\nconsidered at input queue replenishment time. After an item is placed in\nprocess then I believe the best long term strategy is to pull that item---and all\nother items---through the process as predictably as possible. After all, part of\nthe business value equation is how long it will take to get an item done. If\nyou cannot answer the question “how long?” then how much confidence can\nyou really have in your business value calculation? What about obvious high value expedites? Things like production being\n\ndown that require all hands on deck? Or a new regulatory requirement that\ncould result in massive fines for noncompliance? Obviously, those things\nwill---and should---take precedence. But, just like the FedEx example, you\nshould study the rate of occurrence for those items and adjust your process\ndesign accordingly. That will potentially mean lowering overall process WIP. That will probably mean making sure free resources look to help out with\nother items in process before pulling in new items. And so on.", "tokens": 456, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 177, "segment_id": "00177", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000207"}
{"type": "chunk", "text": "What about obvious high value expedites? Things like production being\n\ndown that require all hands on deck? Or a new regulatory requirement that\ncould result in massive fines for noncompliance? Obviously, those things\nwill---and should---take precedence. But, just like the FedEx example, you\nshould study the rate of occurrence for those items and adjust your process\ndesign accordingly. That will potentially mean lowering overall process WIP. That will probably mean making sure free resources look to help out with\nother items in process before pulling in new items. And so on. To come full circle on our discussion about Little’s Law that was started\n\nin Chapter 3, I hope it is obvious for you to see how CoS represents a clear\nviolation of the fourth assumption of Little’s Law (and potentially the first\nand the third as well). The central thesis of this book is that every violation\nof a Little’s Law assumption represents a reduction in overall process\npredictability. CoS represents an institutionalized violation of those", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nWhat about obvious high value expedites? Things like production being\n\ndown that require all hands on deck? Or a new regulatory requirement that\ncould result in massive fines for noncompliance? Obviously, those things\nwill---and should---take precedence. But, just like the FedEx example, you\nshould study the rate of occurrence for those items and adjust your process\ndesign accordingly. That will potentially mean lowering overall process WIP. That will probably mean making sure free resources look to help out with\nother items in process before pulling in new items. And so on. To come full circle on our discussion about Little’s Law that was started\n\nin Chapter 3, I hope it is obvious for you to see how CoS represents a clear\nviolation of the fourth assumption of Little’s Law (and potentially the first\nand the third as well). The central thesis of this book is that every violation\nof a Little’s Law assumption represents a reduction in overall process\npredictability. CoS represents an institutionalized violation of those", "tokens": 211, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 177, "segment_id": "00177", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000208"}
{"type": "chunk", "text": "assumptions. How could you ever expect to be predictable when using CoS\nas your standard process policy? Conclusion\nIt is obvious that to solve the problem outlined at the beginning of this\nchapter, the TSA could simply hire more agents. At the very least you would\nwant to have a minimum of one agent per queue. This intervention would\npotentially solve the problem---or it would go a long way to alleviating it. Note that in this case, however, CoS would be eliminated. If each queue had\nits own server, then there would be no need for CoS. Wouldn’t it be great if\nall our problems could be solved by just adding more people? The reality is\nthat most companies do not have the money to keep hiring. That being the\ncase, we want to make sure that we are using the resources we do have as\nefficiently as possible. That means choosing pull policies that maximize our\nresources’ effectiveness and eliminating policies that make it harder for\nthose resources to do their jobs predictably. Although it probably sounds like it, I am not saying that CoS is\n\ninherently evil or that all CoS implementations are incorrect. I am, however,\ncoming at this from the perspective of predictability. With that consideration,\nwhat I am saying is that you need to consider all aspects of CoS before\nimplementing those policies. By definition, CoS will introduce variability\nand unpredictability into your process. The unpredictability manifests itself\n---among other things---as Flow Debt (Chapter 9). The truth is that the only\npart of your process that is more predictable with CoS is the highest priority\nclass. Overall, CoS will cause your process to actually take a predictability\nhit (see Figures 13.4 and 13.5). Are you really that confident that the upfront\nvalue decisions that you are making with CoS are worth more than all the\nnegative implications? The arguments swirling around out there about why to use CoS are very\n\nseductive. The people making those arguments are very persuasive. I am\nhoping I have at least given you something to think about before assuming\nyou should start with CoS as a default. For me, the better strategy is to consider an item’s forecasted value at\n\nqueue replenishment time. Then, once in process, pull that item through\nwhile paying attention to all the concepts outlined in this and the previous\nchapters.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nassumptions. How could you ever expect to be predictable when using CoS\nas your standard process policy? Conclusion\nIt is obvious that to solve the problem outlined at the beginning of this\nchapter, the TSA could simply hire more agents. At the very least you would\nwant to have a minimum of one agent per queue. This intervention would\npotentially solve the problem---or it would go a long way to alleviating it. Note that in this case, however, CoS would be eliminated. If each queue had\nits own server, then there would be no need for CoS. Wouldn’t it be great if\nall our problems could be solved by just adding more people? The reality is\nthat most companies do not have the money to keep hiring. That being the\ncase, we want to make sure that we are using the resources we do have as\nefficiently as possible. That means choosing pull policies that maximize our\nresources’ effectiveness and eliminating policies that make it harder for\nthose resources to do their jobs predictably. Although it probably sounds like it, I am not saying that CoS is\n\ninherently evil or that all CoS implementations are incorrect. I am, however,\ncoming at this from the perspective of predictability. With that consideration,\nwhat I am saying is that you need to consider all aspects of CoS before\nimplementing those policies. By definition, CoS will introduce variability\nand unpredictability into your process. The unpredictability manifests itself\n---among other things---as Flow Debt (Chapter 9). The truth is that the only\npart of your process that is more predictable with CoS is the highest priority\nclass. Overall, CoS will cause your process to actually take a predictability\nhit (see Figures 13.4 and 13.5). Are you really that confident that the upfront\nvalue decisions that you are making with CoS are worth more than all the\nnegative implications? The arguments swirling around out there about why to use CoS are very\n\nseductive. The people making those arguments are very persuasive. I am\nhoping I have at least given you something to think about before assuming\nyou should start with CoS as a default. For me, the better strategy is to consider an item’s forecasted value at\n\nqueue replenishment time. Then, once in process, pull that item through\nwhile paying attention to all the concepts outlined in this and the previous\nchapters.", "tokens": 507, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 178, "segment_id": "00178", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000209"}
{"type": "chunk", "text": "You have to know what you are doing before you do it. Build your\nprocess. Operate it using the policies for predictability that I have outlined\nthus far. Measure it. And then make a determination if CoS can help. Chances are you will never need CoS. Chances are you will never need Class of Service once you have a predictable process. But what else do we need to consider ourselves predictable? I implied\n\nearlier that there are essentially to dimensions to being predictable:\n\n1. Making sure your process behaves in a way it is expected to; and,\n2. Making accurate predictions about the future. Up until now we have mostly talked about point #1. It is time that we\n\nturn our attention to point #2. Key Learnings and Takeaways\n\nClass of Service is the policy or set of policies around the order in\nwhich work items are pulled through a given process once those items\nare committed to (i.e., counted as Work In Progress). Class of Service only attaches at the point of commitment. Class of Service is different from queue replenishment. Assigning a work item a Class of Service is different from assigning a\nwork item a type. Class of Service represents an institutionalized violation of some\nassumptions of Little’s Law. This violation takes the form of Flow Debt\nwhich ultimately makes your process less predictable. The only way to predictably deliver using Class of Service is to build\nslack into the system. Instead of designing Class of Service into your process up front,\nconsider other things you can do to eliminate or mitigate the need for\nthem. Only introduce CoS after you have operated your process for a while\nand are confident that CoS is necessary. Still consider policies for CoS\nthat mitigate their inevitable negative impact on flow.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies\n\nYou have to know what you are doing before you do it. Build your\nprocess. Operate it using the policies for predictability that I have outlined\nthus far. Measure it. And then make a determination if CoS can help. Chances are you will never need CoS. Chances are you will never need Class of Service once you have a predictable process. But what else do we need to consider ourselves predictable? I implied\n\nearlier that there are essentially to dimensions to being predictable:\n\n1. Making sure your process behaves in a way it is expected to; and,\n2. Making accurate predictions about the future. Up until now we have mostly talked about point #1. It is time that we\n\nturn our attention to point #2. Key Learnings and Takeaways\n\nClass of Service is the policy or set of policies around the order in\nwhich work items are pulled through a given process once those items\nare committed to (i.e., counted as Work In Progress). Class of Service only attaches at the point of commitment. Class of Service is different from queue replenishment. Assigning a work item a Class of Service is different from assigning a\nwork item a type. Class of Service represents an institutionalized violation of some\nassumptions of Little’s Law. This violation takes the form of Flow Debt\nwhich ultimately makes your process less predictable. The only way to predictably deliver using Class of Service is to build\nslack into the system. Instead of designing Class of Service into your process up front,\nconsider other things you can do to eliminate or mitigate the need for\nthem. Only introduce CoS after you have operated your process for a while\nand are confident that CoS is necessary. Still consider policies for CoS\nthat mitigate their inevitable negative impact on flow.", "tokens": 366, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 179, "segment_id": "00179", "chapter_num": "13", "chapter_title": "Pull Policies", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 13: Pull Policies", "chunk_id": "00000210"}
{"type": "chunk", "text": "Chapter 14 - Introduction to Forecasting\n\nOne of the definitions of predictability is the ability to make a quantitative\nforecast about a process’s future state. Since forecasting is a part of\npredictability, I thought I would least say a few words about it. A forecast is just a calculation about the occurrence of some future\nevent. Yes, an estimate can be thought of as a forecast. But the forecasts that\nwe are going to talk about in this chapter are going to be much more\nscientific than just some poor guy’s best guess. For the most part, we are going to be asked to make forecasts about the\n\ncompletion times for a given task, feature, project, etc., so for the purposes\nof this discussion let’s limit ourselves to time forecasts. That means that\nfrom now on whenever I use the word “forecast” on its own, I am really\nreferring to a “time forecast”. Although, it should be said, that I believe the\nprinciples I am going to talk about here are applicable to any type of\nforecast. Before we get any further, I would like to discuss is the necessary\n\ncomponents of a forecast. You should never---and I mean never---\ncommunicate a forecast that does not include at least two things: a date\nrange and a probability for that date range occurring. A forecast is a calculation about the future completion of an item or items that includes\nboth a date range and a probability. The future is full of uncertainty, and whenever uncertainty is involved\n\nthen a probabilistic approach is necessitated (think quantum physics, the\nweather, etc.). A forecast without an associated probability is deterministic,\nand, as you know, the future is anything but deterministic. With that said, let’s get to some methods that you can---and, more\nimportantly, cannot---use to develop a forecast. As this is an introduction,\nthe methods outlined here are not meant to be all inclusive nor do I flatter\nmyself to think that the treatment of the ones that I have chosen is", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting\n\nChapter 14 - Introduction to Forecasting\n\nOne of the definitions of predictability is the ability to make a quantitative\nforecast about a process’s future state. Since forecasting is a part of\npredictability, I thought I would least say a few words about it. A forecast is just a calculation about the occurrence of some future\nevent. Yes, an estimate can be thought of as a forecast. But the forecasts that\nwe are going to talk about in this chapter are going to be much more\nscientific than just some poor guy’s best guess. For the most part, we are going to be asked to make forecasts about the\n\ncompletion times for a given task, feature, project, etc., so for the purposes\nof this discussion let’s limit ourselves to time forecasts. That means that\nfrom now on whenever I use the word “forecast” on its own, I am really\nreferring to a “time forecast”. Although, it should be said, that I believe the\nprinciples I am going to talk about here are applicable to any type of\nforecast. Before we get any further, I would like to discuss is the necessary\n\ncomponents of a forecast. You should never---and I mean never---\ncommunicate a forecast that does not include at least two things: a date\nrange and a probability for that date range occurring. A forecast is a calculation about the future completion of an item or items that includes\nboth a date range and a probability. The future is full of uncertainty, and whenever uncertainty is involved\n\nthen a probabilistic approach is necessitated (think quantum physics, the\nweather, etc.). A forecast without an associated probability is deterministic,\nand, as you know, the future is anything but deterministic. With that said, let’s get to some methods that you can---and, more\nimportantly, cannot---use to develop a forecast. As this is an introduction,\nthe methods outlined here are not meant to be all inclusive nor do I flatter\nmyself to think that the treatment of the ones that I have chosen is", "tokens": 421, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 181, "segment_id": "00181", "chapter_num": "14", "chapter_title": "Introduction to Forecasting", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting", "chunk_id": "00000211"}
{"type": "chunk", "text": "exhaustive. For a richer discussion of these methods, please consult the\nreferences listed at the end of the book. Little’s Law\nAs I stated Chapter 3, using Little’s Law to calculate a quantitative forecast\nis an incorrect application of the law. Little’s Law is about examining what\nhas happened in the past. It is not about making deterministic forecasts\nabout the future. One of the reasons you cannot make deterministic\nforecasts with Little’s Law is because it is impossible to predict which of\nthe Law’s assumptions will be violated in the future and how many times\nthey will be violated. Remember, each violation of an assumption\ninvalidates the exactness of the law. Even if you could use Little’s Law for projections, you would not want\nto. The reason is because it is a relationship of averages (arithmetic means). You never want to make a forecast based on an average. Average is a\nmeaningless statistic unless you know something about the underlying\ndistribution of the data from which the average was calculated. Specifically,\nwhen we are ignorant of the distribution, then we do not know what\npercentile we are talking about when we say the word “average”. For\nexample, depending on the shape of the distribution, the mean could be\nsignificantly less than 50%, exactly 50%, or significantly more than 50%. But you will recall that with Little’s Law we do not care about the\nprobability distributions of the underlying stochastic processes. If we do not\nknow the distribution, then we cannot give a probability of where the\naverage falls. If we do not know a probability, then we cannot make a\nforecast. It is that simple. Alternatively, using Little’s Law for a gut check validation of a\n\nforecast for a qualitative determination is perfectly acceptable. But of\ncourse you would not want to make any staffing, cost, or project\ncommitments based on these back-of-the-envelope calculation type\ncalculations. But what if we do know something about the underlying distribution? That knowledge could be extremely valuable. Further, I would argue it is\nworth investing in acquiring that knowledge. Any time we have distribution\ninformation we are going to run away from Little’s Law for forecasting and\ntoward some of the better techniques that follow.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting\n\nexhaustive. For a richer discussion of these methods, please consult the\nreferences listed at the end of the book. Little’s Law\nAs I stated Chapter 3, using Little’s Law to calculate a quantitative forecast\nis an incorrect application of the law. Little’s Law is about examining what\nhas happened in the past. It is not about making deterministic forecasts\nabout the future. One of the reasons you cannot make deterministic\nforecasts with Little’s Law is because it is impossible to predict which of\nthe Law’s assumptions will be violated in the future and how many times\nthey will be violated. Remember, each violation of an assumption\ninvalidates the exactness of the law. Even if you could use Little’s Law for projections, you would not want\nto. The reason is because it is a relationship of averages (arithmetic means). You never want to make a forecast based on an average. Average is a\nmeaningless statistic unless you know something about the underlying\ndistribution of the data from which the average was calculated. Specifically,\nwhen we are ignorant of the distribution, then we do not know what\npercentile we are talking about when we say the word “average”. For\nexample, depending on the shape of the distribution, the mean could be\nsignificantly less than 50%, exactly 50%, or significantly more than 50%. But you will recall that with Little’s Law we do not care about the\nprobability distributions of the underlying stochastic processes. If we do not\nknow the distribution, then we cannot give a probability of where the\naverage falls. If we do not know a probability, then we cannot make a\nforecast. It is that simple. Alternatively, using Little’s Law for a gut check validation of a\n\nforecast for a qualitative determination is perfectly acceptable. But of\ncourse you would not want to make any staffing, cost, or project\ncommitments based on these back-of-the-envelope calculation type\ncalculations. But what if we do know something about the underlying distribution? That knowledge could be extremely valuable. Further, I would argue it is\nworth investing in acquiring that knowledge. Any time we have distribution\ninformation we are going to run away from Little’s Law for forecasting and\ntoward some of the better techniques that follow.", "tokens": 467, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 182, "segment_id": "00182", "chapter_num": "14", "chapter_title": "Introduction to Forecasting", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting", "chunk_id": "00000212"}
{"type": "chunk", "text": "Forecasts for a Single Item\nWhat if you are asked to make a forecast about the completion of a specific\nwork item, or epic or project? The answer to this question is actually very\nstraightforward. In fact, I have already told you how to do it. In order to\nmake a projection for a single work item, you will have to first collect the\nCycle Time data for the all same types of work items à la the method I\ndescribed in the Scatterplots chapter (Chapter 12). Once you have that data,\nit is a very simple exercise to answer the above question. You will just\nchoose the percentile that you want to attach to your forecast and use the\ncorresponding range. For example, look at the following Scatterplot for a\nteam’s user stories (Figure 14.1):\n\nFigure 14.1: A Sample Scatterplot\nA simple forecast that you could give using this data is that a typical\nwork item completes in 43 days or less 85% of the time. And that is it. If the\nwork items we are interested in were epics or projects, for example, then we\nwould need to capture the Cycle Time data for epics or projects and then the\napproach to come up with a forecast for those work item types is exactly the\nsame.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting\n\nForecasts for a Single Item\nWhat if you are asked to make a forecast about the completion of a specific\nwork item, or epic or project? The answer to this question is actually very\nstraightforward. In fact, I have already told you how to do it. In order to\nmake a projection for a single work item, you will have to first collect the\nCycle Time data for the all same types of work items à la the method I\ndescribed in the Scatterplots chapter (Chapter 12). Once you have that data,\nit is a very simple exercise to answer the above question. You will just\nchoose the percentile that you want to attach to your forecast and use the\ncorresponding range. For example, look at the following Scatterplot for a\nteam’s user stories (Figure 14.1):\n\nFigure 14.1: A Sample Scatterplot\nA simple forecast that you could give using this data is that a typical\nwork item completes in 43 days or less 85% of the time. And that is it. If the\nwork items we are interested in were epics or projects, for example, then we\nwould need to capture the Cycle Time data for epics or projects and then the\napproach to come up with a forecast for those work item types is exactly the\nsame.", "tokens": 275, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 183, "segment_id": "00183", "chapter_num": "14", "chapter_title": "Introduction to Forecasting", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting", "chunk_id": "00000213"}
{"type": "chunk", "text": "Straight Line Projections\nI hate to belabor this point, but any CFD with a projection on it is not a\nCFD. It is a Burn Up chart or Projection Chart or something else, but it is\nmost definitely not a CFD. To review, there are two reasons why a\nprojections on CFDs are incorrect. The first reason is because to do a\nprojection the chart must have some type of backlog displayed. But CFDs\nshould not have backlogs on them. That is mistake number one. The second\nreason is that CFDs are for looking backward, they are not for making\nprojections about the future. That is mistake number two. The fact that it is\nnot a CFD is not a bad thing because this projection view can potentially be\nvery useful (used incorrectly it can also be very bad). I should point out\nhere that because I cannot call them CFDs, the term I am going to use for\nthese types of charts is going to be either Burn Up Charts or Projection\nCharts. Many teams are tempted to just perform a straight line projection off of\nthe Throughput line on a Burn Up chart. The calculation---it is reasoned---is\nfairly simple. If a backlog has 100 items in it and the team is averaging 10\nitems per week, then it is easy to draw a trend line off the Throughput line\nand see where it intersects the backlog line as above. If you drop a line\ndown to the X-axis at the point where the two lines intersect, then, voila,\nyou have your release date. There are so many problems with this approach that I am not sure\nwhere to begin. The first, and potentially most obvious since we just talked\nabout it, is that once again this forecast is being based on an average. I have\nalready discussed several reasons why you should not do that so I will not\ngo into them here. Secondly, over time, there is going to be variability in both the\nBacklog and Average Throughput. Depending on the time horizon under\nconsideration, both the Backlog and Throughput can vary wildly (see the Scurve section below). Looking at this rather one-dimensional view of the\nworld could cause managers to either panic or be overly confident\ndepending on which way the variability pendulum swings on any given day. Thirdly, there is no date range. That is one of our requirements for a\nproper forecast.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting\n\nStraight Line Projections\nI hate to belabor this point, but any CFD with a projection on it is not a\nCFD. It is a Burn Up chart or Projection Chart or something else, but it is\nmost definitely not a CFD. To review, there are two reasons why a\nprojections on CFDs are incorrect. The first reason is because to do a\nprojection the chart must have some type of backlog displayed. But CFDs\nshould not have backlogs on them. That is mistake number one. The second\nreason is that CFDs are for looking backward, they are not for making\nprojections about the future. That is mistake number two. The fact that it is\nnot a CFD is not a bad thing because this projection view can potentially be\nvery useful (used incorrectly it can also be very bad). I should point out\nhere that because I cannot call them CFDs, the term I am going to use for\nthese types of charts is going to be either Burn Up Charts or Projection\nCharts. Many teams are tempted to just perform a straight line projection off of\nthe Throughput line on a Burn Up chart. The calculation---it is reasoned---is\nfairly simple. If a backlog has 100 items in it and the team is averaging 10\nitems per week, then it is easy to draw a trend line off the Throughput line\nand see where it intersects the backlog line as above. If you drop a line\ndown to the X-axis at the point where the two lines intersect, then, voila,\nyou have your release date. There are so many problems with this approach that I am not sure\nwhere to begin. The first, and potentially most obvious since we just talked\nabout it, is that once again this forecast is being based on an average. I have\nalready discussed several reasons why you should not do that so I will not\ngo into them here. Secondly, over time, there is going to be variability in both the\nBacklog and Average Throughput. Depending on the time horizon under\nconsideration, both the Backlog and Throughput can vary wildly (see the Scurve section below). Looking at this rather one-dimensional view of the\nworld could cause managers to either panic or be overly confident\ndepending on which way the variability pendulum swings on any given day. Thirdly, there is no date range. That is one of our requirements for a\nproper forecast.", "tokens": 511, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 184, "segment_id": "00184", "chapter_num": "14", "chapter_title": "Introduction to Forecasting", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting", "chunk_id": "00000214"}
{"type": "chunk", "text": "Secondly, over time, there is going to be variability in both the\nBacklog and Average Throughput. Depending on the time horizon under\nconsideration, both the Backlog and Throughput can vary wildly (see the Scurve section below). Looking at this rather one-dimensional view of the\nworld could cause managers to either panic or be overly confident\ndepending on which way the variability pendulum swings on any given day. Thirdly, there is no date range. That is one of our requirements for a\nproper forecast. No problem say the advocates. Let’s draw an optimistic line\nfor the backlog and a pessimistic line for the backlog. Likewise, let’s draw\nan optimistic and pessimistic line for the Throughput trend line. Now we\nhave several points of intersection for consideration that we can use for our", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting\n\nSecondly, over time, there is going to be variability in both the\nBacklog and Average Throughput. Depending on the time horizon under\nconsideration, both the Backlog and Throughput can vary wildly (see the Scurve section below). Looking at this rather one-dimensional view of the\nworld could cause managers to either panic or be overly confident\ndepending on which way the variability pendulum swings on any given day. Thirdly, there is no date range. That is one of our requirements for a\nproper forecast. No problem say the advocates. Let’s draw an optimistic line\nfor the backlog and a pessimistic line for the backlog. Likewise, let’s draw\nan optimistic and pessimistic line for the Throughput trend line. Now we\nhave several points of intersection for consideration that we can use for our", "tokens": 168, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 184, "segment_id": "00184", "chapter_num": "14", "chapter_title": "Introduction to Forecasting", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting", "chunk_id": "00000215"}
{"type": "chunk", "text": "completion date range. While I would agree that this is a much better view\nof the world, it still raises several questions. How were the optimistic and\npessimistic backlog lines determined? The same should be asked of the\nThroughput lines. But most importantly, what is the probability of hitting\nthis range? A further complication of a straight line projection is that your\ncompletion rate over the long term is potentially not a straight line. As I\nmentioned before, any time you start a project with zero WIP and end with\nzero WIP, the resulting pattern of the Throughput line on the CFD mimics\nan “S-curve”. Using a straight line to approximate an S-curve is\nproblematic at best and dangerous at worst. There are overly complicated\nmethods to approximate S-curves out there (again with no range and\nprobabilities attached), and I am not going to get into them here, but I will\nsay that the effort put into generating those forecasts would be better spent\nusing more modern forecasting methods. Just as with Little’s Law, it is probably ok to perform a straight line\n\nprojection for the purposes of a quick gut check on project status. But any\ninsight you may gain is certainly not actionable. In fact, any action\nmotivated by this strategy would probably be akin to tampering. The thing is, however, if you put in place all the predictability\nmeasures that I have talked about in this book up until now, then straight\nline projections do not necessarily give results that are that bad. If you truly\ncan keep continuous WIP, minimally violate the assumptions of Little’s\nLaw, not introduce CoS, then this type of approach might be good enough. If it is and it works for you, then, great, keep doing it. I am not going to tell\nyou otherwise. But even so, we might be able to tweak things a little bit to\ngive you more insight. If you insist on using a Burn Up to do your projections, then might I\n\nsuggest you augment your charts with the percentiles off of your\nScatterplot? The way it would work is as follows. Start with your arrival\nand departure data for a CFD. Choose a completion date for your project (or\nrelease or whatever) and extend the timescale of the X-axis out to that\ncompletion date. Draw a vertical line up from the X-axis at that specific\ndate.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting\n\ncompletion date range. While I would agree that this is a much better view\nof the world, it still raises several questions. How were the optimistic and\npessimistic backlog lines determined? The same should be asked of the\nThroughput lines. But most importantly, what is the probability of hitting\nthis range? A further complication of a straight line projection is that your\ncompletion rate over the long term is potentially not a straight line. As I\nmentioned before, any time you start a project with zero WIP and end with\nzero WIP, the resulting pattern of the Throughput line on the CFD mimics\nan “S-curve”. Using a straight line to approximate an S-curve is\nproblematic at best and dangerous at worst. There are overly complicated\nmethods to approximate S-curves out there (again with no range and\nprobabilities attached), and I am not going to get into them here, but I will\nsay that the effort put into generating those forecasts would be better spent\nusing more modern forecasting methods. Just as with Little’s Law, it is probably ok to perform a straight line\n\nprojection for the purposes of a quick gut check on project status. But any\ninsight you may gain is certainly not actionable. In fact, any action\nmotivated by this strategy would probably be akin to tampering. The thing is, however, if you put in place all the predictability\nmeasures that I have talked about in this book up until now, then straight\nline projections do not necessarily give results that are that bad. If you truly\ncan keep continuous WIP, minimally violate the assumptions of Little’s\nLaw, not introduce CoS, then this type of approach might be good enough. If it is and it works for you, then, great, keep doing it. I am not going to tell\nyou otherwise. But even so, we might be able to tweak things a little bit to\ngive you more insight. If you insist on using a Burn Up to do your projections, then might I\n\nsuggest you augment your charts with the percentiles off of your\nScatterplot? The way it would work is as follows. Start with your arrival\nand departure data for a CFD. Choose a completion date for your project (or\nrelease or whatever) and extend the timescale of the X-axis out to that\ncompletion date. Draw a vertical line up from the X-axis at that specific\ndate.", "tokens": 507, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 185, "segment_id": "00185", "chapter_num": "14", "chapter_title": "Introduction to Forecasting", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting", "chunk_id": "00000216"}
{"type": "chunk", "text": "But even so, we might be able to tweak things a little bit to\ngive you more insight. If you insist on using a Burn Up to do your projections, then might I\n\nsuggest you augment your charts with the percentiles off of your\nScatterplot? The way it would work is as follows. Start with your arrival\nand departure data for a CFD. Choose a completion date for your project (or\nrelease or whatever) and extend the timescale of the X-axis out to that\ncompletion date. Draw a vertical line up from the X-axis at that specific\ndate. From your Scatterplot locate the Cycle Time for your 85th percentile\n(or whatever percentile you feel comfortable with). Take that 85th percentile\nCycle Time and subtract it from your completion date. You can draw\nanother line at this data and mark it “85th Percentile or something.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting\n\nBut even so, we might be able to tweak things a little bit to\ngive you more insight. If you insist on using a Burn Up to do your projections, then might I\n\nsuggest you augment your charts with the percentiles off of your\nScatterplot? The way it would work is as follows. Start with your arrival\nand departure data for a CFD. Choose a completion date for your project (or\nrelease or whatever) and extend the timescale of the X-axis out to that\ncompletion date. Draw a vertical line up from the X-axis at that specific\ndate. From your Scatterplot locate the Cycle Time for your 85th percentile\n(or whatever percentile you feel comfortable with). Take that 85th percentile\nCycle Time and subtract it from your completion date. You can draw\nanother line at this data and mark it “85th Percentile or something.", "tokens": 182, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 185, "segment_id": "00185", "chapter_num": "14", "chapter_title": "Introduction to Forecasting", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting", "chunk_id": "00000217"}
{"type": "chunk", "text": "There are several advantages to this view. First, as with other\n\nprojections of this nature, you know that any items that make up the\nThroughput line before the completion date are going to be in the release. Second, you know that any item that is started before that 85th percentile\nline has a greater than 85% chance of making the release. Any item started\nafter that line has a less than 85% chance of making the release (you could\ndraw subsequent percentile lines to communicate the diminished chance of\nlate-started items of making the release). Obviously, this chart will not tell you the exact number of items that\n\nwill be in any given release (a better question to ask, by the way, is what is\nthe likelihood of getting at least X number of work items finished by a\nparticular date). But I would argue no chart out there will tell you that. Not\ndeterministically anyway. As you approach the release date, you have a\nbetter and better understanding of the probability of items making it or not. Product owners (or customers) can then use that information to help guide\nthem in the selection of what items should be started next. And that is\nprobably about as good as you are going to get with a straight line\nprojection approach. Conclusion\nIn my experience, making a forecast for a single item’s completion is very\nstraightforward. Simply use the SLA method mentioned in Chapter 12. Further, I do not recommend using Little’s Law or a straight-line\nprojection to make a forecast for a completion date. That is because both\napproaches are based on averages and neither give a probability of success. If you really want to get good at probabilistic forecasting, then you are\n\ngoing to have to use a tool like the one we are going to talk about next:\nMonte Carlo Simulation. Key Learnings and Takeaways\n\nA proper date forecast includes both a range and a probability. To forecast the completion of a single item use SLAs the method for\ncalculating them outlined in Chapter 12. Do not use Little’s Law for forecasting. Do not use averages for forecasting.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting\n\nThere are several advantages to this view. First, as with other\n\nprojections of this nature, you know that any items that make up the\nThroughput line before the completion date are going to be in the release. Second, you know that any item that is started before that 85th percentile\nline has a greater than 85% chance of making the release. Any item started\nafter that line has a less than 85% chance of making the release (you could\ndraw subsequent percentile lines to communicate the diminished chance of\nlate-started items of making the release). Obviously, this chart will not tell you the exact number of items that\n\nwill be in any given release (a better question to ask, by the way, is what is\nthe likelihood of getting at least X number of work items finished by a\nparticular date). But I would argue no chart out there will tell you that. Not\ndeterministically anyway. As you approach the release date, you have a\nbetter and better understanding of the probability of items making it or not. Product owners (or customers) can then use that information to help guide\nthem in the selection of what items should be started next. And that is\nprobably about as good as you are going to get with a straight line\nprojection approach. Conclusion\nIn my experience, making a forecast for a single item’s completion is very\nstraightforward. Simply use the SLA method mentioned in Chapter 12. Further, I do not recommend using Little’s Law or a straight-line\nprojection to make a forecast for a completion date. That is because both\napproaches are based on averages and neither give a probability of success. If you really want to get good at probabilistic forecasting, then you are\n\ngoing to have to use a tool like the one we are going to talk about next:\nMonte Carlo Simulation. Key Learnings and Takeaways\n\nA proper date forecast includes both a range and a probability. To forecast the completion of a single item use SLAs the method for\ncalculating them outlined in Chapter 12. Do not use Little’s Law for forecasting. Do not use averages for forecasting.", "tokens": 443, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 186, "segment_id": "00186", "chapter_num": "14", "chapter_title": "Introduction to Forecasting", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 14: Introduction to Forecasting", "chunk_id": "00000218"}
{"type": "chunk", "text": "Chapter 15 - Monte Carlo Method Introduction\n\nIn 1873, a Yorkshire cotton industry engineer named Joseph Jagger walked\ninto a casino in Monte Carlo. Several days later he walked out of the casino\nwith what amounted to close to over three million dollars (in today’s money)\nhaving “broke the bank”. In all truthfulness, though, during Jagger’s run the\ncasino itself never actually ran out of money (although the croupier’s bank at\nthe table did). But the story’s place in popular culture had been cemented. About seventy years later, a group of physicists working on nuclear\nfission problems at Los Alamos Laboratory in New Mexico named a method\nof using a statistical approach to solving complicated equations after a\ncasino in Monte Carlo. Coincidence? Well, not really. What did the two events have in common other than the name Monte\nCarlo? It was the recognition that a statistics could be used to solve highly\ncomplex problems. At its simplest, the Monte Carlo Method (or Monte Carlo simulation)\n\ncan be thought of as experiments with random numbers. The method is\nnormally applied to highly uncertain problems where direct computation is\ndifficult, impractical, or impossible. It has proved a useful tool in all kinds of\nfields like nuclear physics (which we just saw) oil and gas exploration,\nfinance, insurance, etc. Given the uncertainty in knowledge work it seems\nstrange that our industry has been rather late to the Monte Carlo game. One\nmight argue that it has taken the emergence of modern agile methods to get\nus to the point where would could even model the work that we do for\nsimulation. Regardless, I firmly believe that the Monte Carlo Method is the\nfuture of forecasting in knowledge work. Teams and companies that get this\nidea will survive. The others will not. To offer a glimpse of how to perform a Monte Carlo Simulation, I offer this snippet from\nWikipedia:\n\nMonte Carlo methods vary, but tend to follow a particular pattern:\n\n1. Define a domain of possible inputs. 2. Generate inputs randomly from a probability distribution over the domain. 3. Perform a deterministic computation on the inputs.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 15: Monte Carlo Method Introduction\n\nChapter 15 - Monte Carlo Method Introduction\n\nIn 1873, a Yorkshire cotton industry engineer named Joseph Jagger walked\ninto a casino in Monte Carlo. Several days later he walked out of the casino\nwith what amounted to close to over three million dollars (in today’s money)\nhaving “broke the bank”. In all truthfulness, though, during Jagger’s run the\ncasino itself never actually ran out of money (although the croupier’s bank at\nthe table did). But the story’s place in popular culture had been cemented. About seventy years later, a group of physicists working on nuclear\nfission problems at Los Alamos Laboratory in New Mexico named a method\nof using a statistical approach to solving complicated equations after a\ncasino in Monte Carlo. Coincidence? Well, not really. What did the two events have in common other than the name Monte\nCarlo? It was the recognition that a statistics could be used to solve highly\ncomplex problems. At its simplest, the Monte Carlo Method (or Monte Carlo simulation)\n\ncan be thought of as experiments with random numbers. The method is\nnormally applied to highly uncertain problems where direct computation is\ndifficult, impractical, or impossible. It has proved a useful tool in all kinds of\nfields like nuclear physics (which we just saw) oil and gas exploration,\nfinance, insurance, etc. Given the uncertainty in knowledge work it seems\nstrange that our industry has been rather late to the Monte Carlo game. One\nmight argue that it has taken the emergence of modern agile methods to get\nus to the point where would could even model the work that we do for\nsimulation. Regardless, I firmly believe that the Monte Carlo Method is the\nfuture of forecasting in knowledge work. Teams and companies that get this\nidea will survive. The others will not. To offer a glimpse of how to perform a Monte Carlo Simulation, I offer this snippet from\nWikipedia:\n\nMonte Carlo methods vary, but tend to follow a particular pattern:\n\n1. Define a domain of possible inputs. 2. Generate inputs randomly from a probability distribution over the domain. 3. Perform a deterministic computation on the inputs.", "tokens": 449, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 188, "segment_id": "00188", "chapter_num": "15", "chapter_title": "Monte Carlo Method Introduction", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 15: Monte Carlo Method Introduction", "chunk_id": "00000219"}
{"type": "chunk", "text": "4. Aggregate the results. <newline />\n\nThe intricacies and practices about how to model and simulate\nknowledge work using the Monte Carlo Method are well beyond the scope\nof this book. Anyone truly interested in applying this method to knowledge\nwork should review Troy Magennis’ work on Lean Forecasting. I am not\ngoing to reproduce all of that information here. Rather, my goal is to discuss\nwhy flow principles and flow metrics are necessary to make a Monte Carlo\napproach more actionable. Operating your process in the manner that I have\nexplained up until now is going to make it much easier for you to build more\naccurate models. More accurate models will lead to more accurate forecasts. And that is, after all, what we are all looking for. As always, for the purpose of clarity, there are a couple of things I need\nto mention first. From this point forward I am going to use the terms “Monte\nCarlo Simulation” and “The Monte Carlo Method” interchangeably (my\napologies to the purists out there). Further, I am going to categorize Monte\nCarlo Simulations into two cases: the case when you have data and the case\nwhen you do not. For the latter situation (when you do not have data), you\nare forced to choose a probability distribution for the value or values that\nyou are trying to simulate. This choice quickly gets into a philosophical\ndebate around what is the best type of probability distribution to use. As you\nmay have guessed, I have never been one to shy away from a good debate;\nhowever, I believe this one is fairly academic. That is why, for the rest of this\nchapter, I am going to focus on the case when you do have data with which\nto simulate. What Data to Use\nThis brings me to my first advice when doing Monte Carlo Simulation: if\nyou have the data, use the data. If you do not have the data, then get the data\n(mine it or measure it), and use the data. Even if you are forced to pick a\ndistribution when performing your first simulation because you have no\ndata, you should quickly do what you can to gather real data to replace the\noriginal artificial distribution in your model. I want to emphasize that by “gather real data” what I mean is to\n\nmeasure the basic metrics of flow from a process that utilizes all of the\ntechniques outlined in this book.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 15: Monte Carlo Method Introduction\n\n4. Aggregate the results. <newline />\n\nThe intricacies and practices about how to model and simulate\nknowledge work using the Monte Carlo Method are well beyond the scope\nof this book. Anyone truly interested in applying this method to knowledge\nwork should review Troy Magennis’ work on Lean Forecasting. I am not\ngoing to reproduce all of that information here. Rather, my goal is to discuss\nwhy flow principles and flow metrics are necessary to make a Monte Carlo\napproach more actionable. Operating your process in the manner that I have\nexplained up until now is going to make it much easier for you to build more\naccurate models. More accurate models will lead to more accurate forecasts. And that is, after all, what we are all looking for. As always, for the purpose of clarity, there are a couple of things I need\nto mention first. From this point forward I am going to use the terms “Monte\nCarlo Simulation” and “The Monte Carlo Method” interchangeably (my\napologies to the purists out there). Further, I am going to categorize Monte\nCarlo Simulations into two cases: the case when you have data and the case\nwhen you do not. For the latter situation (when you do not have data), you\nare forced to choose a probability distribution for the value or values that\nyou are trying to simulate. This choice quickly gets into a philosophical\ndebate around what is the best type of probability distribution to use. As you\nmay have guessed, I have never been one to shy away from a good debate;\nhowever, I believe this one is fairly academic. That is why, for the rest of this\nchapter, I am going to focus on the case when you do have data with which\nto simulate. What Data to Use\nThis brings me to my first advice when doing Monte Carlo Simulation: if\nyou have the data, use the data. If you do not have the data, then get the data\n(mine it or measure it), and use the data. Even if you are forced to pick a\ndistribution when performing your first simulation because you have no\ndata, you should quickly do what you can to gather real data to replace the\noriginal artificial distribution in your model. I want to emphasize that by “gather real data” what I mean is to\n\nmeasure the basic metrics of flow from a process that utilizes all of the\ntechniques outlined in this book.", "tokens": 505, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 189, "segment_id": "00189", "chapter_num": "15", "chapter_title": "Monte Carlo Method Introduction", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 15: Monte Carlo Method Introduction", "chunk_id": "00000220"}
{"type": "chunk", "text": "If you do not have the data, then get the data\n(mine it or measure it), and use the data. Even if you are forced to pick a\ndistribution when performing your first simulation because you have no\ndata, you should quickly do what you can to gather real data to replace the\noriginal artificial distribution in your model. I want to emphasize that by “gather real data” what I mean is to\n\nmeasure the basic metrics of flow from a process that utilizes all of the\ntechniques outlined in this book. If you have an intrinsically unstable", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 15: Monte Carlo Method Introduction\n\nIf you do not have the data, then get the data\n(mine it or measure it), and use the data. Even if you are forced to pick a\ndistribution when performing your first simulation because you have no\ndata, you should quickly do what you can to gather real data to replace the\noriginal artificial distribution in your model. I want to emphasize that by “gather real data” what I mean is to\n\nmeasure the basic metrics of flow from a process that utilizes all of the\ntechniques outlined in this book. If you have an intrinsically unstable", "tokens": 116, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 189, "segment_id": "00189", "chapter_num": "15", "chapter_title": "Monte Carlo Method Introduction", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 15: Monte Carlo Method Introduction", "chunk_id": "00000221"}
{"type": "chunk", "text": "process, then that process might not be a great candidate for Monte Carlo\nSimulation. For example, one indication that your process data might not be\nsuitable for Monte Carlo simulation is if you have a CFD that looks like\nFigure 7.5 (where arrivals far outpace your departures). In Chapter 7 I\nshowed that Figure 7.5 demonstrates a scenario where Cycle Times are\nconstantly increasing. Ever increasing Cycle Times mean that any selection\nof data from a past timeframe is a poor indication of what might happen in a\nfuture timeframe. This problem is mostly eliminated if you operate a process\nthat looks like Figure 7.8 (where arrivals match departures). However, getting to a process that produces a CFD like Figure 7.8 is\nnot necessarily good enough. Another “smell” that our data might not be\nsuitable for Monte Carlo Simulation is if we have a triangle-shaped\nScatterplot as shown in Figure 11.1. A triangle pattern on a Scatterplot is also\nthe result of an inherently unstable process. Recall that even if you have a\nCFD that looks like Figure 7.8, you still can have a Scatterplot that looks\nlike Figure 11.1. The culprit in that scenario is Flow Debt. Large\naccumulations of Flow Debt destabilize a process and make it imminently\nunpredictable. Could you throw the Cycle Time data from Figure 11.1 into a\nMonte Carlo Simulation? Yes. Would the resulting forecast be reasonable? Probably not. Your Model’s Assumptions\nThe second thing you need to you need to know about Monte Carlo\nSimulations is that you need to be keenly aware of assumptions. I am not\njust talking about the assumptions built into your model, but I am also\ntalking about the assumptions built into how whatever tool that you use (I\nam assuming you are using a tool for Monte Carlo Simulations) implements\nthose assumptions. The accuracy of your model---and I cannot emphasize\nthis enough---is going to depend on how well you match your process\npolicies (that is, the day-to-day rules around how you operate your process)\nto all assumptions in the model and simulation tool. Your model’s ability to produce an accurate forecast is going to depend on how well you\nmatch your process policies to your model’s assumptions.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 15: Monte Carlo Method Introduction\n\nprocess, then that process might not be a great candidate for Monte Carlo\nSimulation. For example, one indication that your process data might not be\nsuitable for Monte Carlo simulation is if you have a CFD that looks like\nFigure 7.5 (where arrivals far outpace your departures). In Chapter 7 I\nshowed that Figure 7.5 demonstrates a scenario where Cycle Times are\nconstantly increasing. Ever increasing Cycle Times mean that any selection\nof data from a past timeframe is a poor indication of what might happen in a\nfuture timeframe. This problem is mostly eliminated if you operate a process\nthat looks like Figure 7.8 (where arrivals match departures). However, getting to a process that produces a CFD like Figure 7.8 is\nnot necessarily good enough. Another “smell” that our data might not be\nsuitable for Monte Carlo Simulation is if we have a triangle-shaped\nScatterplot as shown in Figure 11.1. A triangle pattern on a Scatterplot is also\nthe result of an inherently unstable process. Recall that even if you have a\nCFD that looks like Figure 7.8, you still can have a Scatterplot that looks\nlike Figure 11.1. The culprit in that scenario is Flow Debt. Large\naccumulations of Flow Debt destabilize a process and make it imminently\nunpredictable. Could you throw the Cycle Time data from Figure 11.1 into a\nMonte Carlo Simulation? Yes. Would the resulting forecast be reasonable? Probably not. Your Model’s Assumptions\nThe second thing you need to you need to know about Monte Carlo\nSimulations is that you need to be keenly aware of assumptions. I am not\njust talking about the assumptions built into your model, but I am also\ntalking about the assumptions built into how whatever tool that you use (I\nam assuming you are using a tool for Monte Carlo Simulations) implements\nthose assumptions. The accuracy of your model---and I cannot emphasize\nthis enough---is going to depend on how well you match your process\npolicies (that is, the day-to-day rules around how you operate your process)\nto all assumptions in the model and simulation tool. Your model’s ability to produce an accurate forecast is going to depend on how well you\nmatch your process policies to your model’s assumptions.", "tokens": 493, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 190, "segment_id": "00190", "chapter_num": "15", "chapter_title": "Monte Carlo Method Introduction", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 15: Monte Carlo Method Introduction", "chunk_id": "00000222"}
{"type": "chunk", "text": "For example, let’s revisit the scenario that I outlined in the Class of\nService chapter (Chapter 13). In that simulation, we had a Kanban board that\nlooked like Figure 15.1:\n\nFigure 15.1: A Kanban Board Used as a Model for Monte Carlo Simulation\n\nNow let’s say that you have modeled the case where you have Standard\nitems and Expedite items and that you can only have on Expedite item on the\nboard at a time. Further, let’s say that Expedite items can violate WIP limits\nand can block other Standard items to complete. Let’s assume you have\nmodeled all of that correctly. But let’s say that you did not model any\npolicies around the order of pull between Standard items that finish at the\nsame time. Additionally, let’s say that the tool you are using defaults to a strict\n\nFIFO pull order in the absence of any other policy being modeled. Finally,\nlet’s say that your actual day-to-day process uses (without explicitly stating\nit) a purely random pull order for Standard items. To be clear, in this\nscenario, we have a mismatch between the tool which assumes strict FIFO\nand your implicit process policy that assumes a random pull order.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 15: Monte Carlo Method Introduction\n\nFor example, let’s revisit the scenario that I outlined in the Class of\nService chapter (Chapter 13). In that simulation, we had a Kanban board that\nlooked like Figure 15.1:\n\nFigure 15.1: A Kanban Board Used as a Model for Monte Carlo Simulation\n\nNow let’s say that you have modeled the case where you have Standard\nitems and Expedite items and that you can only have on Expedite item on the\nboard at a time. Further, let’s say that Expedite items can violate WIP limits\nand can block other Standard items to complete. Let’s assume you have\nmodeled all of that correctly. But let’s say that you did not model any\npolicies around the order of pull between Standard items that finish at the\nsame time. Additionally, let’s say that the tool you are using defaults to a strict\n\nFIFO pull order in the absence of any other policy being modeled. Finally,\nlet’s say that your actual day-to-day process uses (without explicitly stating\nit) a purely random pull order for Standard items. To be clear, in this\nscenario, we have a mismatch between the tool which assumes strict FIFO\nand your implicit process policy that assumes a random pull order.", "tokens": 259, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 191, "segment_id": "00191", "chapter_num": "15", "chapter_title": "Monte Carlo Method Introduction", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 15: Monte Carlo Method Introduction", "chunk_id": "00000223"}
{"type": "chunk", "text": "Do you remember what is going to happen here? Your simulation---\n\nbecause it assumed FIFO for Standard items---is going to spit out a\nforecasted Cycle Time for your Standard items of 65 days at the 85th\npercentile. However, your real-world process---because you are using\nrandom queuing---is actually going to result in Cycle Times of 100 days at\nthe 85th percentile. Due to that one missed assumption, you have overoptimistically forecast by up 35 days per item! Think about how this\nproblem gets multiplied if you have hundreds of items in your backlog. What do you think your customers are going to say if you forecast a 65-day\n85th percentile, but actually operated your process at a 100-day 85th\npercentile? Another classic example of a missed assumption is when there is an\nopen WIP spot but an item was not pulled immediately. Consider a scenario\nwhere you are operating a process that produces the following Kanban\nboard:\n\nFigure 15.2: An Example Kanban Board\nIn Figure 15.2, you can see that the Test column has a WIP limit of\nthree, but there is only one item in it. Further, you can see there are three\nitems in the Development Done column that are waiting to be pulled. Let’s\nalso say that the board has been in this state for several days. However, the\ntool that you used to model this process never allows this condition to\nhappen. That is to say that the Monte Carlo Simulation tool automatically\nand immediately pulls an item from Dev Done to Test whenever Test has\nspace under its WIP Limit. Can you see that in your real world process that\nyour items are aging longer than they were simulated to have done? That is a\nproblem.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 15: Monte Carlo Method Introduction\n\nDo you remember what is going to happen here? Your simulation---\n\nbecause it assumed FIFO for Standard items---is going to spit out a\nforecasted Cycle Time for your Standard items of 65 days at the 85th\npercentile. However, your real-world process---because you are using\nrandom queuing---is actually going to result in Cycle Times of 100 days at\nthe 85th percentile. Due to that one missed assumption, you have overoptimistically forecast by up 35 days per item! Think about how this\nproblem gets multiplied if you have hundreds of items in your backlog. What do you think your customers are going to say if you forecast a 65-day\n85th percentile, but actually operated your process at a 100-day 85th\npercentile? Another classic example of a missed assumption is when there is an\nopen WIP spot but an item was not pulled immediately. Consider a scenario\nwhere you are operating a process that produces the following Kanban\nboard:\n\nFigure 15.2: An Example Kanban Board\nIn Figure 15.2, you can see that the Test column has a WIP limit of\nthree, but there is only one item in it. Further, you can see there are three\nitems in the Development Done column that are waiting to be pulled. Let’s\nalso say that the board has been in this state for several days. However, the\ntool that you used to model this process never allows this condition to\nhappen. That is to say that the Monte Carlo Simulation tool automatically\nand immediately pulls an item from Dev Done to Test whenever Test has\nspace under its WIP Limit. Can you see that in your real world process that\nyour items are aging longer than they were simulated to have done? That is a\nproblem.", "tokens": 374, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 192, "segment_id": "00192", "chapter_num": "15", "chapter_title": "Monte Carlo Method Introduction", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 15: Monte Carlo Method Introduction", "chunk_id": "00000224"}
{"type": "chunk", "text": "The moral of the story is that you have to use the assumptions in your\n\nmodel (both explicit or implicit) as actionable interventions to take while\nyou are actually operating your process, or you have to take action to change\nthe assumptions in the model to match the real world as it unfolds. When\nyou get this right, then a Monte Carlo strategy is the going to be one of the\nmost powerful predictive tools in your arsenal. The thing to know about Monte Carlo simulation is that there is no one\n\npredicted outcome. Sampling a probability distribution will lead to\nthousands of possible outcomes that the, in turn, need to be analyzed in\nterms of the probability that they will indeed occur. Once you have obtained\na forecast using Monte Carlo, your job is not done. It is not just set it and\nforget it. You need to actively manage to the assumptions in the model or\nchange the model assumptions based on new information. Conclusion\nTo be successful in forecasting, you have to first know what constitutes the\nproper form of a forecast and then you have to understand what methods are\nyour friends in terms of developing reliable forecasts. Even the best forecasting methods, however, are going to be only as\n\ngood as the data they are based on. The first step in building a reliable\nforecast is to put in place a predictable process such that you can have\nconfidence in the data that you are collecting. A forecast put together using\nbad data (from an unstable system, for example) produces something that\neither no one will like or no one will believe (this is the GIGO principle:\nGarbage In, Garbage Out). No forecasting method is going to be a suitable\nsubstitute for either (a) common sense thinking or (b) active management\ninterventions as suggested by new information. A forecast based on sound data that has been produced by a process that\nincorporates all the policies of predictability mentioned earlier is going to be\ndefensible in the face of any challenge or criticism. At that point you have\ndone your best. Let the chips fall where they may. Key Learnings and Takeaways\n\nMonte Carlo Simulation is one of the best methods for coming up with\na reasonable forecast.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 15: Monte Carlo Method Introduction\n\nThe moral of the story is that you have to use the assumptions in your\n\nmodel (both explicit or implicit) as actionable interventions to take while\nyou are actually operating your process, or you have to take action to change\nthe assumptions in the model to match the real world as it unfolds. When\nyou get this right, then a Monte Carlo strategy is the going to be one of the\nmost powerful predictive tools in your arsenal. The thing to know about Monte Carlo simulation is that there is no one\n\npredicted outcome. Sampling a probability distribution will lead to\nthousands of possible outcomes that the, in turn, need to be analyzed in\nterms of the probability that they will indeed occur. Once you have obtained\na forecast using Monte Carlo, your job is not done. It is not just set it and\nforget it. You need to actively manage to the assumptions in the model or\nchange the model assumptions based on new information. Conclusion\nTo be successful in forecasting, you have to first know what constitutes the\nproper form of a forecast and then you have to understand what methods are\nyour friends in terms of developing reliable forecasts. Even the best forecasting methods, however, are going to be only as\n\ngood as the data they are based on. The first step in building a reliable\nforecast is to put in place a predictable process such that you can have\nconfidence in the data that you are collecting. A forecast put together using\nbad data (from an unstable system, for example) produces something that\neither no one will like or no one will believe (this is the GIGO principle:\nGarbage In, Garbage Out). No forecasting method is going to be a suitable\nsubstitute for either (a) common sense thinking or (b) active management\ninterventions as suggested by new information. A forecast based on sound data that has been produced by a process that\nincorporates all the policies of predictability mentioned earlier is going to be\ndefensible in the face of any challenge or criticism. At that point you have\ndone your best. Let the chips fall where they may. Key Learnings and Takeaways\n\nMonte Carlo Simulation is one of the best methods for coming up with\na reasonable forecast.", "tokens": 458, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 193, "segment_id": "00193", "chapter_num": "15", "chapter_title": "Monte Carlo Method Introduction", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 15: Monte Carlo Method Introduction", "chunk_id": "00000225"}
{"type": "chunk", "text": "Chapter 16 - Getting Started\n\nHopefully I have convinced you by now that if you want your process to be\npredictable then you need to adopt the flow metrics and analytics that have\nbeen presented in this book. But how do you get started? I would not be\ndoing my job if I did not give you at least some pointers on how to begin. Defining Your Process\nIt may seem obvious or trivial to you, but the very first thing you need to do\nto get started is define the boundaries of your process. As I mentioned in\nChapter 2, you must first decide on a point at which you consider work to\nhave entered (or arrived to) your process. You must then decide the point at\nwhich you consider work to have exited (departed from) your process. Starting with a definition of your process boundaries is essential as any\nwork items between these two boundaries can be considered WIP. Remember that these boundaries are independent of any sprint or\niteration definition. That is to say, if you use sprints or iterations to manage\nyour process then it is possible for work to arrive at any time during the\nsprint and it is possible for work to depart at any time during the sprint. This\nconcept may seem anathema to Scrum purists, yet the possibility remains. That means that any time work comes into your process---regardless of\nwhether it is the beginning of a sprint or not---you need to count that work\nas arrived. Likewise, if any work exits your process---regardless of whether\nit is the end of a sprint or not---you need to count that work as departed. The next thing you need to decide is which items that fall between\nthose two boundaries will count as WIP. As I also mentioned in Chapter 2,\nthe choice of items to call WIP is up to you, but make that choice and start\ntracking. As with anything, you can always tweak that decision later as you\nlearn more. Lastly, consider which of your existing policies are in direct violation\nof the assumptions of Little’s Law. Do you not explicitly control arrivals by\nmatching them to departures? Do you make sure that everything that starts\neventually completes (or at least tag and track items that do not complete", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started\n\nChapter 16 - Getting Started\n\nHopefully I have convinced you by now that if you want your process to be\npredictable then you need to adopt the flow metrics and analytics that have\nbeen presented in this book. But how do you get started? I would not be\ndoing my job if I did not give you at least some pointers on how to begin. Defining Your Process\nIt may seem obvious or trivial to you, but the very first thing you need to do\nto get started is define the boundaries of your process. As I mentioned in\nChapter 2, you must first decide on a point at which you consider work to\nhave entered (or arrived to) your process. You must then decide the point at\nwhich you consider work to have exited (departed from) your process. Starting with a definition of your process boundaries is essential as any\nwork items between these two boundaries can be considered WIP. Remember that these boundaries are independent of any sprint or\niteration definition. That is to say, if you use sprints or iterations to manage\nyour process then it is possible for work to arrive at any time during the\nsprint and it is possible for work to depart at any time during the sprint. This\nconcept may seem anathema to Scrum purists, yet the possibility remains. That means that any time work comes into your process---regardless of\nwhether it is the beginning of a sprint or not---you need to count that work\nas arrived. Likewise, if any work exits your process---regardless of whether\nit is the end of a sprint or not---you need to count that work as departed. The next thing you need to decide is which items that fall between\nthose two boundaries will count as WIP. As I also mentioned in Chapter 2,\nthe choice of items to call WIP is up to you, but make that choice and start\ntracking. As with anything, you can always tweak that decision later as you\nlearn more. Lastly, consider which of your existing policies are in direct violation\nof the assumptions of Little’s Law. Do you not explicitly control arrivals by\nmatching them to departures? Do you make sure that everything that starts\neventually completes (or at least tag and track items that do not complete", "tokens": 470, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 195, "segment_id": "00195", "chapter_num": "16", "chapter_title": "Getting Started", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started", "chunk_id": "00000226"}
{"type": "chunk", "text": "properly)? Do you let items arbitrarily age due to poor pull decisions (Class\nof Service, blockages, queuing, etc.)? If you currently operate your process\nin blatant violation of Little’s Law, then you may want to think about\nchanges to implement to get your process more aligned with that law. Remember that each violation of one of Little’s Law’s assumptions hampers\nyour ability to be predictable. Capturing Data\nOnce you have decided on your process policies, now all you have to do is\ncapture the data. This is both easier and harder than it sounds. To answer\nwhy, we must consider two cases. The first case we need to consider is if you are tracking data manually\n\n(i.e., independent of any other Agile tooling). In this case, you need to\nphysically record the date that each work item enters each step of your\nworkflow. For example, let’s say your workflow is Analysis Active,\nAnalysis Done, Development Active, Development Done, Test, Done. In\nthis process, you would need to document the day that each item entered\neach state. An excerpt of what that data might look like is shown in Figure\n16.1:\n\nFigure 16.1: Example Collected Data\nYou will remember that this approach was outlined in Chapter 4\n(including how to handle the case when items move backward in your\nprocess), and I will refer you to that Chapter for a more detailed\nexplanation. You may want to further augment your data with certain item\n\nattributes. That is to say, you may want to capture which team worked on an\nitem, what type it was (for example, user story, defect, etc.), if it finished\nnormally---to name just a few examples. The attributes you choose to", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started\n\nproperly)? Do you let items arbitrarily age due to poor pull decisions (Class\nof Service, blockages, queuing, etc.)? If you currently operate your process\nin blatant violation of Little’s Law, then you may want to think about\nchanges to implement to get your process more aligned with that law. Remember that each violation of one of Little’s Law’s assumptions hampers\nyour ability to be predictable. Capturing Data\nOnce you have decided on your process policies, now all you have to do is\ncapture the data. This is both easier and harder than it sounds. To answer\nwhy, we must consider two cases. The first case we need to consider is if you are tracking data manually\n\n(i.e., independent of any other Agile tooling). In this case, you need to\nphysically record the date that each work item enters each step of your\nworkflow. For example, let’s say your workflow is Analysis Active,\nAnalysis Done, Development Active, Development Done, Test, Done. In\nthis process, you would need to document the day that each item entered\neach state. An excerpt of what that data might look like is shown in Figure\n16.1:\n\nFigure 16.1: Example Collected Data\nYou will remember that this approach was outlined in Chapter 4\n(including how to handle the case when items move backward in your\nprocess), and I will refer you to that Chapter for a more detailed\nexplanation. You may want to further augment your data with certain item\n\nattributes. That is to say, you may want to capture which team worked on an\nitem, what type it was (for example, user story, defect, etc.), if it finished\nnormally---to name just a few examples. The attributes you choose to", "tokens": 368, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 196, "segment_id": "00196", "chapter_num": "16", "chapter_title": "Getting Started", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started", "chunk_id": "00000227"}
{"type": "chunk", "text": "decorate your data are completely up to you. The reason you will want to do\nthis, however, is those attributes will serve as filter points later. For\nexample, maybe we only want to see data from Team A. Maybe we only\nwant to see data for defects. Maybe we want to see all the items that got\ncancelled while in progress. Tagging data with appropriate attributes is a\npowerful practice that will enhance your understanding of overall process\nperformance. The second case you may need to consider is when you are using an\nelectronic Agile tool to manage your work (e.g., VersionOne®, Jira, or the\nlike). In this case we need to mine the data out of that tool so that it looks\nsomething like Figure 16.1. That is easier said than done. The problem is\nthat most Agile tools do not track data in this way. That is not necessarily\nthe fault of the tool---they were not designed with a flow metrics approach\nin mind. However, it does mean that it will require some work on your part\nto get your data in the format as shown in Figure 16.1. Luckily for us, most\nelectronic tools offer an API (or direct access via SQL) to get to the data. The algorithm needed is going to be tool-specific and is beyond the scope\nof this book, so I will not going into any detail here. Keep in mind, though,\nthat you are still going to have to handle the special cases of work flowing\nbackward, work skipping steps, work being cancelled versus closed, etc. Also remember that you will want to mine the same item metadata that I\njust mentioned (type, team, etc.) to allow us to filter the data later. Another word of caution that I need to mention about both cases is that\nyour data is only as good as your use of your Agile tracking tool---whether\nthat tool be an electronic system or a physical board. Your data is only as good as your use of your Agile tracking tool. What I mean by that is no data extraction scheme will make up for\n\nabusing either your electronic or physical board. If work items are not\nupdated in a timely manner, or blockers not captured properly, or items are\nmoved back and forth randomly, then that lack of attention to process\npolicies will be reflected in your data. You will then be forced to make the\nawkward decision to either try to fix the data or discard it altogether.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started\n\ndecorate your data are completely up to you. The reason you will want to do\nthis, however, is those attributes will serve as filter points later. For\nexample, maybe we only want to see data from Team A. Maybe we only\nwant to see data for defects. Maybe we want to see all the items that got\ncancelled while in progress. Tagging data with appropriate attributes is a\npowerful practice that will enhance your understanding of overall process\nperformance. The second case you may need to consider is when you are using an\nelectronic Agile tool to manage your work (e.g., VersionOne®, Jira, or the\nlike). In this case we need to mine the data out of that tool so that it looks\nsomething like Figure 16.1. That is easier said than done. The problem is\nthat most Agile tools do not track data in this way. That is not necessarily\nthe fault of the tool---they were not designed with a flow metrics approach\nin mind. However, it does mean that it will require some work on your part\nto get your data in the format as shown in Figure 16.1. Luckily for us, most\nelectronic tools offer an API (or direct access via SQL) to get to the data. The algorithm needed is going to be tool-specific and is beyond the scope\nof this book, so I will not going into any detail here. Keep in mind, though,\nthat you are still going to have to handle the special cases of work flowing\nbackward, work skipping steps, work being cancelled versus closed, etc. Also remember that you will want to mine the same item metadata that I\njust mentioned (type, team, etc.) to allow us to filter the data later. Another word of caution that I need to mention about both cases is that\nyour data is only as good as your use of your Agile tracking tool---whether\nthat tool be an electronic system or a physical board. Your data is only as good as your use of your Agile tracking tool. What I mean by that is no data extraction scheme will make up for\n\nabusing either your electronic or physical board. If work items are not\nupdated in a timely manner, or blockers not captured properly, or items are\nmoved back and forth randomly, then that lack of attention to process\npolicies will be reflected in your data. You will then be forced to make the\nawkward decision to either try to fix the data or discard it altogether.", "tokens": 512, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 197, "segment_id": "00197", "chapter_num": "16", "chapter_title": "Getting Started", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started", "chunk_id": "00000228"}
{"type": "chunk", "text": "Your data is only as good as your use of your Agile tracking tool. What I mean by that is no data extraction scheme will make up for\n\nabusing either your electronic or physical board. If work items are not\nupdated in a timely manner, or blockers not captured properly, or items are\nmoved back and forth randomly, then that lack of attention to process\npolicies will be reflected in your data. You will then be forced to make the\nawkward decision to either try to fix the data or discard it altogether. It is a\nmuch better strategy to make sure all team members use your Agile tracking", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started\n\nYour data is only as good as your use of your Agile tracking tool. What I mean by that is no data extraction scheme will make up for\n\nabusing either your electronic or physical board. If work items are not\nupdated in a timely manner, or blockers not captured properly, or items are\nmoved back and forth randomly, then that lack of attention to process\npolicies will be reflected in your data. You will then be forced to make the\nawkward decision to either try to fix the data or discard it altogether. It is a\nmuch better strategy to make sure all team members use your Agile tracking", "tokens": 125, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 197, "segment_id": "00197", "chapter_num": "16", "chapter_title": "Getting Started", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started", "chunk_id": "00000229"}
{"type": "chunk", "text": "tool in an agreed upon matter so that you can have confidence in any\nsubsequently collected data. How Much Data? “How much data do I need?” is one of the most common questions I get\nwhen introducing these methods to my clients. Most people assume you\nneed copious amounts of data in order to glean any useful information. That\nis not necessarily correct. While more data is generally better, the truth is\nthat less (often much less) data can be good enough. For example, Douglas Hubbard (whose book “How to Measure\nAnything” is listed in the Bibliography) advises his clients on his “Rule of\nFive”:\n\nRule of Five -- There is a 93.75% chance that the median of a population is between the\nsmallest and largest values in any random sample of five from that population. Recall from Chapter 10 that the median is the 50th percentile line on\nour Scatterplot. The Rule of Five seems remarkable but it is true (please see\nHubbard’s book for a detailed proof as to why this rule works). If you think\nof your process as a random Cycle Time number generator, then you will\nhave a very good idea of where the median of your Cycle Time data is after\nonly five items complete. While powerful, the Rule of Five only gets us to the median of our\npopulation---which is actually not a bad place to start. But how much more\ndata do we need to have confidence in the overall bounds of our process’s\nCycle Time? To answer that, let’s consider a dataset that is uniformly\ndistributed. A uniform distribution assumes that all samples from its\npopulation are equally probable. The textbook example of a uniform\ndistribution is rolling a fair, six-sided die. All numbers on the die have an\nequal chance of coming up on each throw. If you were to plot the results of\nseveral rolls, what would emerge over time is a histogram with equal-height\nbars for each number on the die. Uniform distributions are interesting to\nstudy as they have several useful properties. For example, let’s say we have\neleven samples from a uniformly distributed population. The fact that we\nknow we have a uniform distribution means that there is a 90% probability\nthat the next sample (i.e., the 12th sample) will be between the min and the", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started\n\ntool in an agreed upon matter so that you can have confidence in any\nsubsequently collected data. How Much Data? “How much data do I need?” is one of the most common questions I get\nwhen introducing these methods to my clients. Most people assume you\nneed copious amounts of data in order to glean any useful information. That\nis not necessarily correct. While more data is generally better, the truth is\nthat less (often much less) data can be good enough. For example, Douglas Hubbard (whose book “How to Measure\nAnything” is listed in the Bibliography) advises his clients on his “Rule of\nFive”:\n\nRule of Five -- There is a 93.75% chance that the median of a population is between the\nsmallest and largest values in any random sample of five from that population. Recall from Chapter 10 that the median is the 50th percentile line on\nour Scatterplot. The Rule of Five seems remarkable but it is true (please see\nHubbard’s book for a detailed proof as to why this rule works). If you think\nof your process as a random Cycle Time number generator, then you will\nhave a very good idea of where the median of your Cycle Time data is after\nonly five items complete. While powerful, the Rule of Five only gets us to the median of our\npopulation---which is actually not a bad place to start. But how much more\ndata do we need to have confidence in the overall bounds of our process’s\nCycle Time? To answer that, let’s consider a dataset that is uniformly\ndistributed. A uniform distribution assumes that all samples from its\npopulation are equally probable. The textbook example of a uniform\ndistribution is rolling a fair, six-sided die. All numbers on the die have an\nequal chance of coming up on each throw. If you were to plot the results of\nseveral rolls, what would emerge over time is a histogram with equal-height\nbars for each number on the die. Uniform distributions are interesting to\nstudy as they have several useful properties. For example, let’s say we have\neleven samples from a uniformly distributed population. The fact that we\nknow we have a uniform distribution means that there is a 90% probability\nthat the next sample (i.e., the 12th sample) will be between the min and the", "tokens": 486, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 198, "segment_id": "00198", "chapter_num": "16", "chapter_title": "Getting Started", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started", "chunk_id": "00000230"}
{"type": "chunk", "text": "max of the previous eleven samples. That means that we have a fairly good\nunderstanding of the range of our uniform distribution after having\ncollected only eleven data points. Our Cycle Times for our processes are not\ngoing to be uniformly distributed (please see Chapter 10a for more info), so\nwe are going to need more than eleven samples to gain insight to our world,\nbut not much more. I mention the Rule of Five and Uniform Distributions to give you a\n\nfeel for the greatly increased knowledge that can be gained after observing\nonly a few data points. Do not think you need to collect hundreds or\nthousands of samples over several months to have any confidence in what\nyour data is telling you. Probability is on your side here. Trust that you are\ngetting very valuable feedback with even a very small data set. Some Pitfalls to Consider\nOnce you have enough data in the correct format then it is just a matter of\ncreating the associated flow analytics. Creating CFDs, Scatterplots,\nHistograms, etc. is fairly straightforward using a tool like Microsoft’s\nExcel. All you need to do is turn the above dates into WIP counts for the\nCFD, and subtract the first date in the workflow from the last date in the\nworkflow to calculate Cycle Time for the Scatterplot and Histogram. Again,\nI would strongly caution against using guidance found on many popular\nwebsites to do this because (a) those websites do not assume you have your\ndata in the proper format, and (b) the instructions they give can lead to\nimproperly constructed analytics. While Excel may be a great tool to use when just starting out, you will\n\nno doubt quickly run into some limitations with that particular software\npackage. First and foremost, Excel offers only a static view of your data. It\ndoes not allow you to readily interact with your analytics such as\ndynamically zooming in on a particular part of the graph, easily filtering out\ndifferent types of work items, doing on the fly metrics calculations, and so\nforth. Secondly, Excel can become a bit unwieldy if managing thousands or\ntens of thousands of rows of data spread across multiple teams or\ndepartments. Still, Excel is not a bad option when starting out to make some\nquick progress. You should also know that most major Agile tools vendors include\n\nsome basic form of the analytics presented in this book.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started\n\nmax of the previous eleven samples. That means that we have a fairly good\nunderstanding of the range of our uniform distribution after having\ncollected only eleven data points. Our Cycle Times for our processes are not\ngoing to be uniformly distributed (please see Chapter 10a for more info), so\nwe are going to need more than eleven samples to gain insight to our world,\nbut not much more. I mention the Rule of Five and Uniform Distributions to give you a\n\nfeel for the greatly increased knowledge that can be gained after observing\nonly a few data points. Do not think you need to collect hundreds or\nthousands of samples over several months to have any confidence in what\nyour data is telling you. Probability is on your side here. Trust that you are\ngetting very valuable feedback with even a very small data set. Some Pitfalls to Consider\nOnce you have enough data in the correct format then it is just a matter of\ncreating the associated flow analytics. Creating CFDs, Scatterplots,\nHistograms, etc. is fairly straightforward using a tool like Microsoft’s\nExcel. All you need to do is turn the above dates into WIP counts for the\nCFD, and subtract the first date in the workflow from the last date in the\nworkflow to calculate Cycle Time for the Scatterplot and Histogram. Again,\nI would strongly caution against using guidance found on many popular\nwebsites to do this because (a) those websites do not assume you have your\ndata in the proper format, and (b) the instructions they give can lead to\nimproperly constructed analytics. While Excel may be a great tool to use when just starting out, you will\n\nno doubt quickly run into some limitations with that particular software\npackage. First and foremost, Excel offers only a static view of your data. It\ndoes not allow you to readily interact with your analytics such as\ndynamically zooming in on a particular part of the graph, easily filtering out\ndifferent types of work items, doing on the fly metrics calculations, and so\nforth. Secondly, Excel can become a bit unwieldy if managing thousands or\ntens of thousands of rows of data spread across multiple teams or\ndepartments. Still, Excel is not a bad option when starting out to make some\nquick progress. You should also know that most major Agile tools vendors include\n\nsome basic form of the analytics presented in this book.", "tokens": 496, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 199, "segment_id": "00199", "chapter_num": "16", "chapter_title": "Getting Started", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started", "chunk_id": "00000231"}
{"type": "chunk", "text": "It\ndoes not allow you to readily interact with your analytics such as\ndynamically zooming in on a particular part of the graph, easily filtering out\ndifferent types of work items, doing on the fly metrics calculations, and so\nforth. Secondly, Excel can become a bit unwieldy if managing thousands or\ntens of thousands of rows of data spread across multiple teams or\ndepartments. Still, Excel is not a bad option when starting out to make some\nquick progress. You should also know that most major Agile tools vendors include\n\nsome basic form of the analytics presented in this book. You might be\nasking yourself why you cannot just use the analytics included with your", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started\n\nIt\ndoes not allow you to readily interact with your analytics such as\ndynamically zooming in on a particular part of the graph, easily filtering out\ndifferent types of work items, doing on the fly metrics calculations, and so\nforth. Secondly, Excel can become a bit unwieldy if managing thousands or\ntens of thousands of rows of data spread across multiple teams or\ndepartments. Still, Excel is not a bad option when starting out to make some\nquick progress. You should also know that most major Agile tools vendors include\n\nsome basic form of the analytics presented in this book. You might be\nasking yourself why you cannot just use the analytics included with your", "tokens": 139, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 199, "segment_id": "00199", "chapter_num": "16", "chapter_title": "Getting Started", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started", "chunk_id": "00000232"}
{"type": "chunk", "text": "favorite tool. There are several answers to this question. And each answer\nmust be considered carefully. The first thing to consider is that while it is true that most tools ship\nwith something called a “Cumulative Flow Diagram” I have yet to see an\nelectronic tool that generates a CFD correctly (barring the one that I will\ndiscuss shortly). The telltale sign that a CFD has not been constructed\nproperly is if it has lines on it that go down. I explained why this is the case\nand introduced it as CFD Property #2 in Chapter 4, but it is worth\nreiterating here:\n\nCFD Property #2: Due to its cumulative nature, no line on a CFD can ever decrease\n(go down). Any time you see a CFD that has one or more lines go down, then you\ncan immediately tell that whoever constructed that CFD did not account for\narrivals and/or departures correctly. Not accounting for arrivals and\ndepartures properly invalidates any resultant analysis of your chart. To illustrate the point a little better, if you are currently using an\nelectronic tool for reporting, have it generate its CFD for you. If you do not\nsee any lines on the chart that go down, that is a good sign. However, as a\ntest, try to “turn off” some of the latter workflow steps (if you can) starting\nfrom the bottom up. Do you see any of the remaining lines go down now? If\nso, it is a safe bet that the overall CFD has not been built according to all of\nthe required CFD principles. The second telltale sign that a CFD is suspect is if it contains a state\n\ncalled “Backlog”. Strictly speaking, there is nothing wrong with displaying\na backlog on a CFD, but the question remains how is the tool calculating\nthe overall process approximate average Cycle Time (does it even call this\ncalculation an approximate average Cycle Time or does it lead you to\nbelieve it is an exact Cycle Time)? Again, I refer you to CFD Property #1\nfrom Chapter 4:\n\nCFD Property #1: The top line of a Cumulative Flow Diagram always represents the\ncumulative arrivals to a process. The bottom line on a CFD always represents the\ncumulative departures from a process.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started\n\nfavorite tool. There are several answers to this question. And each answer\nmust be considered carefully. The first thing to consider is that while it is true that most tools ship\nwith something called a “Cumulative Flow Diagram” I have yet to see an\nelectronic tool that generates a CFD correctly (barring the one that I will\ndiscuss shortly). The telltale sign that a CFD has not been constructed\nproperly is if it has lines on it that go down. I explained why this is the case\nand introduced it as CFD Property #2 in Chapter 4, but it is worth\nreiterating here:\n\nCFD Property #2: Due to its cumulative nature, no line on a CFD can ever decrease\n(go down). Any time you see a CFD that has one or more lines go down, then you\ncan immediately tell that whoever constructed that CFD did not account for\narrivals and/or departures correctly. Not accounting for arrivals and\ndepartures properly invalidates any resultant analysis of your chart. To illustrate the point a little better, if you are currently using an\nelectronic tool for reporting, have it generate its CFD for you. If you do not\nsee any lines on the chart that go down, that is a good sign. However, as a\ntest, try to “turn off” some of the latter workflow steps (if you can) starting\nfrom the bottom up. Do you see any of the remaining lines go down now? If\nso, it is a safe bet that the overall CFD has not been built according to all of\nthe required CFD principles. The second telltale sign that a CFD is suspect is if it contains a state\n\ncalled “Backlog”. Strictly speaking, there is nothing wrong with displaying\na backlog on a CFD, but the question remains how is the tool calculating\nthe overall process approximate average Cycle Time (does it even call this\ncalculation an approximate average Cycle Time or does it lead you to\nbelieve it is an exact Cycle Time)? Again, I refer you to CFD Property #1\nfrom Chapter 4:\n\nCFD Property #1: The top line of a Cumulative Flow Diagram always represents the\ncumulative arrivals to a process. The bottom line on a CFD always represents the\ncumulative departures from a process.", "tokens": 492, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 200, "segment_id": "00200", "chapter_num": "16", "chapter_title": "Getting Started", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started", "chunk_id": "00000233"}
{"type": "chunk", "text": "This property demands that overall process approximate average Cycle\nTime always be calculated from the top line of a CFD through to the bottom\nline of a CFD. If your chart includes a backlog and your tool’s computed\nCycle Time does not include the time spent in the backlog, then, again, you\nshould be skeptical about whether the tool is calculating flow metrics\nproperly. Another pitfall to watch out for is how your Scatterplot is generated---\n\nassuming your tool even generates a Scatterplot. Your tool may call its\nScatterplot a “Control Chart”---which it most certainly is not. As I\nmentioned in Chapter 10, why Control Charts (at least Control Charts in the\nShewhart and Deming tradition) are probably not applicable to knowledge\nwork is beyond the scope of this book. The thing you need to watch out for,\nthough, is that if your tool takes a “Control Chart” approach, it is almost\ncertainly assuming that your data is normally distributed. When looking at\nyour Agile tool’s Control Chart, look to see if displays lines that say\nsomething like “mean plus one standard deviation” or “μ + σ”. It might also\ngive you an associated percentage akin to the standard percentages that I\ndemonstrated in Chapter 10. In this case, that percentage is going to be\nbased on an assumption that your data is normally distributed---which I can\nguarantee it is not. How do I know it is not? Look at your Histogram. You\nmay remember from your statistics training that the shape of a normal\ndistribution is a bell curve. When you look at your Histogram you will see\nthat your data does not follow a bell curve pattern. Using the mean plus a standard deviation (or the mean plus any\nnumber of standard deviations) approach and then associating the result\nwith percentiles is dangerous given that your data is not normally\ndistributed. You will get calculation errors that are not insignificant and you\nwill potentially make poor decisions based on bad data. The moral of this story is that when you are starting out with this type\n\nof analysis, do not necessarily trust the data or charts that your Agile tool\ndisplays for you. Do not trust its associated calculations. It may seem\ntedious, but I would encourage you to initially track some sample data\nyourself and then compare it to what your electronic tool generates for you. You may be surprised at how different those results can be.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started\n\nThis property demands that overall process approximate average Cycle\nTime always be calculated from the top line of a CFD through to the bottom\nline of a CFD. If your chart includes a backlog and your tool’s computed\nCycle Time does not include the time spent in the backlog, then, again, you\nshould be skeptical about whether the tool is calculating flow metrics\nproperly. Another pitfall to watch out for is how your Scatterplot is generated---\n\nassuming your tool even generates a Scatterplot. Your tool may call its\nScatterplot a “Control Chart”---which it most certainly is not. As I\nmentioned in Chapter 10, why Control Charts (at least Control Charts in the\nShewhart and Deming tradition) are probably not applicable to knowledge\nwork is beyond the scope of this book. The thing you need to watch out for,\nthough, is that if your tool takes a “Control Chart” approach, it is almost\ncertainly assuming that your data is normally distributed. When looking at\nyour Agile tool’s Control Chart, look to see if displays lines that say\nsomething like “mean plus one standard deviation” or “μ + σ”. It might also\ngive you an associated percentage akin to the standard percentages that I\ndemonstrated in Chapter 10. In this case, that percentage is going to be\nbased on an assumption that your data is normally distributed---which I can\nguarantee it is not. How do I know it is not? Look at your Histogram. You\nmay remember from your statistics training that the shape of a normal\ndistribution is a bell curve. When you look at your Histogram you will see\nthat your data does not follow a bell curve pattern. Using the mean plus a standard deviation (or the mean plus any\nnumber of standard deviations) approach and then associating the result\nwith percentiles is dangerous given that your data is not normally\ndistributed. You will get calculation errors that are not insignificant and you\nwill potentially make poor decisions based on bad data. The moral of this story is that when you are starting out with this type\n\nof analysis, do not necessarily trust the data or charts that your Agile tool\ndisplays for you. Do not trust its associated calculations. It may seem\ntedious, but I would encourage you to initially track some sample data\nyourself and then compare it to what your electronic tool generates for you. You may be surprised at how different those results can be.", "tokens": 510, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 201, "segment_id": "00201", "chapter_num": "16", "chapter_title": "Getting Started", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started", "chunk_id": "00000234"}
{"type": "chunk", "text": "You will get calculation errors that are not insignificant and you\nwill potentially make poor decisions based on bad data. The moral of this story is that when you are starting out with this type\n\nof analysis, do not necessarily trust the data or charts that your Agile tool\ndisplays for you. Do not trust its associated calculations. It may seem\ntedious, but I would encourage you to initially track some sample data\nyourself and then compare it to what your electronic tool generates for you. You may be surprised at how different those results can be. And when those\nresults are different, which method will you trust more? I hope you will forgive the shameless plug, but your other option is to\n\nuse the ActionableAgileTM Analytics tool (available at", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started\n\nYou will get calculation errors that are not insignificant and you\nwill potentially make poor decisions based on bad data. The moral of this story is that when you are starting out with this type\n\nof analysis, do not necessarily trust the data or charts that your Agile tool\ndisplays for you. Do not trust its associated calculations. It may seem\ntedious, but I would encourage you to initially track some sample data\nyourself and then compare it to what your electronic tool generates for you. You may be surprised at how different those results can be. And when those\nresults are different, which method will you trust more? I hope you will forgive the shameless plug, but your other option is to\n\nuse the ActionableAgileTM Analytics tool (available at", "tokens": 156, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 201, "segment_id": "00201", "chapter_num": "16", "chapter_title": "Getting Started", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started", "chunk_id": "00000235"}
{"type": "chunk", "text": "https://actionableagile.com). That tool has been designed from the ground\nup with flow metrics and flow analytics in mind. You can be sure that if you\nget your data in the correct format (Figure 16.1) then putting that data into\nthe ActionableAgileTM Analytics tool will result in flow analytics that are\ngenerated correctly. But, again, do not take our word for it. Collect the data\nyourself and validate any results independently. Conclusion\nI am going to wrap up this book (the next chapter) by taking a look at one\nof the largest and most successful implementations of using Actionable\nAgile Metrics for Predictability. The examples from the next chapter\ncombined with an understanding of how to avoid the common pitfalls\noutlined here should have you well on your way to a predictable process. But before you read the case study, let’s take a minute to review what\n\nwe have learned so far. The steps to predictability are simple:\n\n1. Set process policies based on the assumptions of Little’s Law---\nincluding policies around how you define the boundaries of your\nprocess. a. Do not start new work at a faster rate than you finish old work. b. Do not allow items to age arbitrarily due to blockages, too much\n\nWIP or poor pull policies (Class of Service). c. Minimize the amount of work that is started but never finishes. 2. As you operate your process, collect data on the basic metrics of flow. a. Work In Progress\nb. Cycle Time\nc. Throughput\n\n3. Visualize your flow metrics in flow analytics. a. Cumulative Flow Diagrams\nb. Cycle Time Scatterplots and Histograms\n\n4. Use the analytics to take action. a. Intervene when your process goes awry\nb. Identify improvements to policies to improve performance\nc. Make forecasts", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started\n\nhttps://actionableagile.com). That tool has been designed from the ground\nup with flow metrics and flow analytics in mind. You can be sure that if you\nget your data in the correct format (Figure 16.1) then putting that data into\nthe ActionableAgileTM Analytics tool will result in flow analytics that are\ngenerated correctly. But, again, do not take our word for it. Collect the data\nyourself and validate any results independently. Conclusion\nI am going to wrap up this book (the next chapter) by taking a look at one\nof the largest and most successful implementations of using Actionable\nAgile Metrics for Predictability. The examples from the next chapter\ncombined with an understanding of how to avoid the common pitfalls\noutlined here should have you well on your way to a predictable process. But before you read the case study, let’s take a minute to review what\n\nwe have learned so far. The steps to predictability are simple:\n\n1. Set process policies based on the assumptions of Little’s Law---\nincluding policies around how you define the boundaries of your\nprocess. a. Do not start new work at a faster rate than you finish old work. b. Do not allow items to age arbitrarily due to blockages, too much\n\nWIP or poor pull policies (Class of Service). c. Minimize the amount of work that is started but never finishes. 2. As you operate your process, collect data on the basic metrics of flow. a. Work In Progress\nb. Cycle Time\nc. Throughput\n\n3. Visualize your flow metrics in flow analytics. a. Cumulative Flow Diagrams\nb. Cycle Time Scatterplots and Histograms\n\n4. Use the analytics to take action. a. Intervene when your process goes awry\nb. Identify improvements to policies to improve performance\nc. Make forecasts", "tokens": 388, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 202, "segment_id": "00202", "chapter_num": "16", "chapter_title": "Getting Started", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 16: Getting Started", "chunk_id": "00000236"}
{"type": "chunk", "text": "Chapter 17 - Actionable Agile Metrics at Siemens\nHS\n\nIn the interest of full disclosure, this case study has been previously\npublished on two different occasions. One version appeared on the InfoQ\nwebsite and the other on the Agile Alliance website. Bennet Vallet and I have\nalso presented these results at conferences all over the world. I have included\nanother slightly modified version here partly for your convenience, but\nmostly because it remains, at the time of this writing, the largest and most\nsuccessful application of using actionable metrics for predictability. If you\nwant some ideas on how to use the concepts of this book for your particular\nsituation, this case study is a great place start. Before you get started reading, however, you should know that this case\n\nstudy assumes that you are familiar with the concepts of the metrics of flow\n(Chapter 2) and their relationship via Little’s Law (Chapter 3). Further, this\ncase study assumes that you are familiar with how these metrics are\nvisualized via Cumulative Flow Diagrams (Chapter 5) and Cycle\nScatterplots (Chapter 10). Some familiarity with Kanban and its practices is\nalso useful but not required. This case study is written from the perspective of Bennet Vallet who\npartnered with me to write up his experience with Actionable Agile Metrics. Introduction\nSiemens Health Services (HS) provides sophisticated software for the\nHealthcare industry. HS had been using traditional Agile metrics (e.g., story\npoints, velocity) for several years, but never realized the transparency and\npredictability that those metrics promised. By moving to the simpler, more\nactionable metrics of flow we were able to achieve a 42% reduction in Cycle\nTime and a very significant improvement in operational efficiency. Furthermore, adopting flow has led to real improvements in quality and\ncollaboration, all of which have been sustained across multiple releases. This\ncase study describes how moving to a continuous flow model augmented\nSiemens’ agility and explains how predictability is a systemic behavior that", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens\n\nChapter 17 - Actionable Agile Metrics at Siemens\nHS\n\nIn the interest of full disclosure, this case study has been previously\npublished on two different occasions. One version appeared on the InfoQ\nwebsite and the other on the Agile Alliance website. Bennet Vallet and I have\nalso presented these results at conferences all over the world. I have included\nanother slightly modified version here partly for your convenience, but\nmostly because it remains, at the time of this writing, the largest and most\nsuccessful application of using actionable metrics for predictability. If you\nwant some ideas on how to use the concepts of this book for your particular\nsituation, this case study is a great place start. Before you get started reading, however, you should know that this case\n\nstudy assumes that you are familiar with the concepts of the metrics of flow\n(Chapter 2) and their relationship via Little’s Law (Chapter 3). Further, this\ncase study assumes that you are familiar with how these metrics are\nvisualized via Cumulative Flow Diagrams (Chapter 5) and Cycle\nScatterplots (Chapter 10). Some familiarity with Kanban and its practices is\nalso useful but not required. This case study is written from the perspective of Bennet Vallet who\npartnered with me to write up his experience with Actionable Agile Metrics. Introduction\nSiemens Health Services (HS) provides sophisticated software for the\nHealthcare industry. HS had been using traditional Agile metrics (e.g., story\npoints, velocity) for several years, but never realized the transparency and\npredictability that those metrics promised. By moving to the simpler, more\nactionable metrics of flow we were able to achieve a 42% reduction in Cycle\nTime and a very significant improvement in operational efficiency. Furthermore, adopting flow has led to real improvements in quality and\ncollaboration, all of which have been sustained across multiple releases. This\ncase study describes how moving to a continuous flow model augmented\nSiemens’ agility and explains how predictability is a systemic behavior that", "tokens": 423, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 205, "segment_id": "00205", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens", "chunk_id": "00000237"}
{"type": "chunk", "text": "one has to manage by understanding and acting in accordance with the\nassumptions of Little’s law and the impacts of resource utilization. History\nSiemens Health Services, the health IT business unit of Siemens Healthcare,\nis a global provider of enterprise healthcare information technology\nsolutions. Our customers are hospitals and large physician group practices. We also provide related services such as software installation, hosting,\nintegration, and business process outsourcing. The development organization for Siemens HS is known as Product\nLifecycle Management (PLM) and consists of approximately 50 teams based\nprimarily in Malvern, Pennsylvania, with sizable development resources\nlocated in India and Europe. In 2003 the company undertook a highly\nambitious initiative to develop Soarian®, a brand new suite of healthcare\nenterprise solutions. The healthcare domain is extremely complex, undergoing constant\nchange, restructuring, and regulation. It should be of no surprise that given\nour domain, the quality of our products is of the highest priority; in fact, one\nmight say that quality is mission critical. Furthermore, the solutions we build\nhave to scale from small and medium sized community hospitals to the\nlargest multi-facility healthcare systems in the world. We need to provide\nworld class performance and adhere to FDA, ISO, Sarbanes--Oxley, patient\nsafety, auditability, and reporting regulations. Our key business challenge is to rapidly develop functionality to\ncompete against mature systems already in the market. Our systems provide\nnew capabilities based on new technology that helps us to leapfrog the\ncompetition. In this vein, we adopted an Agile development methodology,\nand more specifically Scrum/XP practices as the key vehicles to achieve this\ngoal\n\nOur development teams transitioned to Agile in 2005. Engaging many\n\nof the most well-known experts and coaches in the community, we\nundertook an accelerated approach to absorbing and incorporating new\npractices. We saw significant improvement over our previous waterfall\nmethods almost immediately and our enthusiasm for Agile continued to\ngrow. By September 2011 we had a mature Agile development program,\nhaving adopted most Scrum and XP practices. Our Scrum teams included all\nroles (product owners, Scrum masters, business analysts, developers and", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens\n\none has to manage by understanding and acting in accordance with the\nassumptions of Little’s law and the impacts of resource utilization. History\nSiemens Health Services, the health IT business unit of Siemens Healthcare,\nis a global provider of enterprise healthcare information technology\nsolutions. Our customers are hospitals and large physician group practices. We also provide related services such as software installation, hosting,\nintegration, and business process outsourcing. The development organization for Siemens HS is known as Product\nLifecycle Management (PLM) and consists of approximately 50 teams based\nprimarily in Malvern, Pennsylvania, with sizable development resources\nlocated in India and Europe. In 2003 the company undertook a highly\nambitious initiative to develop Soarian®, a brand new suite of healthcare\nenterprise solutions. The healthcare domain is extremely complex, undergoing constant\nchange, restructuring, and regulation. It should be of no surprise that given\nour domain, the quality of our products is of the highest priority; in fact, one\nmight say that quality is mission critical. Furthermore, the solutions we build\nhave to scale from small and medium sized community hospitals to the\nlargest multi-facility healthcare systems in the world. We need to provide\nworld class performance and adhere to FDA, ISO, Sarbanes--Oxley, patient\nsafety, auditability, and reporting regulations. Our key business challenge is to rapidly develop functionality to\ncompete against mature systems already in the market. Our systems provide\nnew capabilities based on new technology that helps us to leapfrog the\ncompetition. In this vein, we adopted an Agile development methodology,\nand more specifically Scrum/XP practices as the key vehicles to achieve this\ngoal\n\nOur development teams transitioned to Agile in 2005. Engaging many\n\nof the most well-known experts and coaches in the community, we\nundertook an accelerated approach to absorbing and incorporating new\npractices. We saw significant improvement over our previous waterfall\nmethods almost immediately and our enthusiasm for Agile continued to\ngrow. By September 2011 we had a mature Agile development program,\nhaving adopted most Scrum and XP practices. Our Scrum teams included all\nroles (product owners, Scrum masters, business analysts, developers and", "tokens": 459, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 206, "segment_id": "00206", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens", "chunk_id": "00000238"}
{"type": "chunk", "text": "testers). We had a mature product backlog and ran 30-day sprints with\nformal sprint planning, reviews, and retrospectives. We were releasing large\nbatches of new features and enhancements once a year (mostly because that\nis the frequency at which we’ve always released). Practices such as CI,\nTDD, story-driven development, continuous customer interaction, pair\nprogramming, planning poker, and relative point-based estimation were for\nthe most part well integrated into our teams and process. Our experience\nshowed that Scrum and Agile practices vastly improved collaboration across\nroles, improved customer functionality, improved code quality and speed. Our Scrum process includes all analysis, development and testing of\n\nfeatures. A feature is declared “done” only once it has passed validation\ntesting in a fully integrated environment performed by a Test Engineer\nwithin each Scrum Team. Once all release features are complete, Siemens\nperforms another round of regression testing, followed by customer beta\ntesting before declaring general availability and shipping to all our\ncustomers. Despite many improvements and real benefits realized by our Agile\nadoption, our overall success was limited. We were continually challenged to\nestimate and deliver on committed release dates. Meeting regulatory\nrequirements and customer expectations requires a high degree of certainty\nand predictability. Our internal decision checkpoints and quality gates\nrequired firm commitments. Our commitment to customers, internal\nstakeholder expectations and revenue forecasts required accurate release\nscope and delivery forecasts that carry a very high premium for delay. At the program and team levels, sprint and release deadlines were\ncharacterized by schedule pressure often requiring overtime and the metrics\nwe collected were not providing the transparency needed to clearly gauge\ncompletion dates or provide actionable insight into the state of our teams. In the trenches, our teams were also challenged to plan and complete\nstories in time-boxed sprint increments. The last week of each sprint was\nalways a mad rush by teams to claim as many points as possible, resulting in\nhasty and over-burdened story testing. While velocity rates at sprint reviews\noften seemed good, reality pointed to a large number of stories blocked or\nincomplete and multiple features in progress with few, if any, features\ncompleting until end of the release. This incongruity between velocity\n(number of points completed in a sprint) and reality was primarily caused by\nteams starting too many features and/or stories. It had been common practice", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens\n\ntesters). We had a mature product backlog and ran 30-day sprints with\nformal sprint planning, reviews, and retrospectives. We were releasing large\nbatches of new features and enhancements once a year (mostly because that\nis the frequency at which we’ve always released). Practices such as CI,\nTDD, story-driven development, continuous customer interaction, pair\nprogramming, planning poker, and relative point-based estimation were for\nthe most part well integrated into our teams and process. Our experience\nshowed that Scrum and Agile practices vastly improved collaboration across\nroles, improved customer functionality, improved code quality and speed. Our Scrum process includes all analysis, development and testing of\n\nfeatures. A feature is declared “done” only once it has passed validation\ntesting in a fully integrated environment performed by a Test Engineer\nwithin each Scrum Team. Once all release features are complete, Siemens\nperforms another round of regression testing, followed by customer beta\ntesting before declaring general availability and shipping to all our\ncustomers. Despite many improvements and real benefits realized by our Agile\nadoption, our overall success was limited. We were continually challenged to\nestimate and deliver on committed release dates. Meeting regulatory\nrequirements and customer expectations requires a high degree of certainty\nand predictability. Our internal decision checkpoints and quality gates\nrequired firm commitments. Our commitment to customers, internal\nstakeholder expectations and revenue forecasts required accurate release\nscope and delivery forecasts that carry a very high premium for delay. At the program and team levels, sprint and release deadlines were\ncharacterized by schedule pressure often requiring overtime and the metrics\nwe collected were not providing the transparency needed to clearly gauge\ncompletion dates or provide actionable insight into the state of our teams. In the trenches, our teams were also challenged to plan and complete\nstories in time-boxed sprint increments. The last week of each sprint was\nalways a mad rush by teams to claim as many points as possible, resulting in\nhasty and over-burdened story testing. While velocity rates at sprint reviews\noften seemed good, reality pointed to a large number of stories blocked or\nincomplete and multiple features in progress with few, if any, features\ncompleting until end of the release. This incongruity between velocity\n(number of points completed in a sprint) and reality was primarily caused by\nteams starting too many features and/or stories. It had been common practice", "tokens": 496, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 207, "segment_id": "00207", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens", "chunk_id": "00000239"}
{"type": "chunk", "text": "to start multiple features at one time to mitigate possible risks. In addition,\nwhenever a story or feature was blocked (for a variety of reasons such as\nwaiting for a dependency from another team, waiting for customer\nvalidation, inability to test because of environmental or build break issues,\netc.), teams would simply start the next story or feature so that we could\nclaim the points which we had committed to achieve. So, while velocity\nburn-ups could look in line with expectations, multiple features were not\nbeing completed on any regular cadence, leading to bottle-necks especially\nat the end of the release as the teams strove to complete and test features. During this period we operated under the assumption that if we mastered\nAgile practices, planned better, and worked harder we would be successful. Heroic efforts were expected. In November of 2011 executive management chartered a small team of\ndirector level managers to coordinate and drive process improvement across\nthe PLM organization, with the key goal of finally realizing the\npredictability, operational efficiency, and quality gains originally promised\nby our Agile approach. After some research, the team concluded that any\nchanges had to be systemic. Other previous process improvements had\nfocused on specific functional areas such as coding or testing, and had not\nled to real improvements across the whole system or value stream. By value\nstream in this context we mean all development activities performed within\nthe Scrum Teams from “specifying to done”. By reviewing the value stream\nwith a “Lean” perspective we realized that our problems were indeed\nsystemic, caused by our predilection for large batch sizes such as large\nfeature releases. Reading Goldratt (Goldratt, 2004), and Reinertsen\n(Reinertsen, 2009) we also came to understand the impacts of large,\nsystemic queues. Coming to the understanding that the overtime, for which\nprogrammers were sacrificing their weekends, may actually have been\nelongating the release completion date was an epiphany. This path inevitably led us to learn about Kanban. We saw in Kanban a\n\nmeans of enforcing Lean and continuous improvement across the system\nwhile still maintaining our core Agile development practices. Kanban would\nmanage Work In Progress, Cycle Time, and Throughput by providing a pull\nsystem and thus reduce the negative impacts of large batches and high\ncapacity utilization.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens\n\nto start multiple features at one time to mitigate possible risks. In addition,\nwhenever a story or feature was blocked (for a variety of reasons such as\nwaiting for a dependency from another team, waiting for customer\nvalidation, inability to test because of environmental or build break issues,\netc.), teams would simply start the next story or feature so that we could\nclaim the points which we had committed to achieve. So, while velocity\nburn-ups could look in line with expectations, multiple features were not\nbeing completed on any regular cadence, leading to bottle-necks especially\nat the end of the release as the teams strove to complete and test features. During this period we operated under the assumption that if we mastered\nAgile practices, planned better, and worked harder we would be successful. Heroic efforts were expected. In November of 2011 executive management chartered a small team of\ndirector level managers to coordinate and drive process improvement across\nthe PLM organization, with the key goal of finally realizing the\npredictability, operational efficiency, and quality gains originally promised\nby our Agile approach. After some research, the team concluded that any\nchanges had to be systemic. Other previous process improvements had\nfocused on specific functional areas such as coding or testing, and had not\nled to real improvements across the whole system or value stream. By value\nstream in this context we mean all development activities performed within\nthe Scrum Teams from “specifying to done”. By reviewing the value stream\nwith a “Lean” perspective we realized that our problems were indeed\nsystemic, caused by our predilection for large batch sizes such as large\nfeature releases. Reading Goldratt (Goldratt, 2004), and Reinertsen\n(Reinertsen, 2009) we also came to understand the impacts of large,\nsystemic queues. Coming to the understanding that the overtime, for which\nprogrammers were sacrificing their weekends, may actually have been\nelongating the release completion date was an epiphany. This path inevitably led us to learn about Kanban. We saw in Kanban a\n\nmeans of enforcing Lean and continuous improvement across the system\nwhile still maintaining our core Agile development practices. Kanban would\nmanage Work In Progress, Cycle Time, and Throughput by providing a pull\nsystem and thus reduce the negative impacts of large batches and high\ncapacity utilization.", "tokens": 491, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 208, "segment_id": "00208", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens", "chunk_id": "00000240"}
{"type": "chunk", "text": "Coming to the understanding that the overtime, for which\nprogrammers were sacrificing their weekends, may actually have been\nelongating the release completion date was an epiphany. This path inevitably led us to learn about Kanban. We saw in Kanban a\n\nmeans of enforcing Lean and continuous improvement across the system\nwhile still maintaining our core Agile development practices. Kanban would\nmanage Work In Progress, Cycle Time, and Throughput by providing a pull\nsystem and thus reduce the negative impacts of large batches and high\ncapacity utilization. Furthermore, we saw in Kanban the potential for metrics\nthat were both tangible (and could be well understood by all corporate stake-", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens\n\nComing to the understanding that the overtime, for which\nprogrammers were sacrificing their weekends, may actually have been\nelongating the release completion date was an epiphany. This path inevitably led us to learn about Kanban. We saw in Kanban a\n\nmeans of enforcing Lean and continuous improvement across the system\nwhile still maintaining our core Agile development practices. Kanban would\nmanage Work In Progress, Cycle Time, and Throughput by providing a pull\nsystem and thus reduce the negative impacts of large batches and high\ncapacity utilization. Furthermore, we saw in Kanban the potential for metrics\nthat were both tangible (and could be well understood by all corporate stake-", "tokens": 136, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 208, "segment_id": "00208", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens", "chunk_id": "00000241"}
{"type": "chunk", "text": "holders) and provide individual teams and program management with data\nthat is highly transparent and actionable. We chose our revenue-cycle application as our pilot, consisting of 15\nScrum teams located in Malvern, PA., Brooklyn, N.Y., and Kolkata, India. Although each Scrum team focuses on specific business domains, the\napplication itself requires integrating all these domains into a single unitary\ncustomer solution. At this scale of systemic complexity, dependency\nmanagement, and continuous integration, a very high degree of consistency\nand cohesion across the whole program is required. With this in mind, we\ndesigned a “big-bang” approach with a high degree of policy, work-unit,\nworkflow, doneness, and metric standardization across all teams. We also\nconcluded that we needed electronic boards: large monitors displayed in\neach team room that would be accessible in real time to all our local and\noffshore developers. An electronic board would also provide an enterprise\nmanagement view across the program and a mechanism for real-time metrics\ncollection. Our initial product release using Kanban began in April 2012 and\nwas completed that December. Results from our first experience using\nKanban were far better than any of our previous releases. Our Cycle Time\nlooked predictable and defects were down significantly. Our second release began in March 2013 and finished in September of\n\nthat same year. We continue to use Kanban for our product development\ntoday. As we had hoped, learnings and experience from the first release led\nto even better results in the releases that followed. Actionable Metrics\nNow that we had decided to do Kanban at Siemens HS, we had to change the\nmetrics we used so that we could more readily align with our newfound\nemphasis on flow. The metrics of flow are very different than traditional\nScrum-style metrics. As mentioned earlier, instead of focusing on things like\nstory points and velocity, our teams now paid attention to Work In Progress\n(WIP), Cycle Time, and Throughput. The reason these flow metrics are\npreferable to traditional Agile metrics is because they are much more\nactionable and transparent. By transparent we mean that the metrics provide\na high degree of visibility into the teams’ (and programs’) progress. By\nactionable, we mean that the metrics themselves will suggest the specific\nteam interventions needed to improve the overall performance of the\nprocess.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens\n\nholders) and provide individual teams and program management with data\nthat is highly transparent and actionable. We chose our revenue-cycle application as our pilot, consisting of 15\nScrum teams located in Malvern, PA., Brooklyn, N.Y., and Kolkata, India. Although each Scrum team focuses on specific business domains, the\napplication itself requires integrating all these domains into a single unitary\ncustomer solution. At this scale of systemic complexity, dependency\nmanagement, and continuous integration, a very high degree of consistency\nand cohesion across the whole program is required. With this in mind, we\ndesigned a “big-bang” approach with a high degree of policy, work-unit,\nworkflow, doneness, and metric standardization across all teams. We also\nconcluded that we needed electronic boards: large monitors displayed in\neach team room that would be accessible in real time to all our local and\noffshore developers. An electronic board would also provide an enterprise\nmanagement view across the program and a mechanism for real-time metrics\ncollection. Our initial product release using Kanban began in April 2012 and\nwas completed that December. Results from our first experience using\nKanban were far better than any of our previous releases. Our Cycle Time\nlooked predictable and defects were down significantly. Our second release began in March 2013 and finished in September of\n\nthat same year. We continue to use Kanban for our product development\ntoday. As we had hoped, learnings and experience from the first release led\nto even better results in the releases that followed. Actionable Metrics\nNow that we had decided to do Kanban at Siemens HS, we had to change the\nmetrics we used so that we could more readily align with our newfound\nemphasis on flow. The metrics of flow are very different than traditional\nScrum-style metrics. As mentioned earlier, instead of focusing on things like\nstory points and velocity, our teams now paid attention to Work In Progress\n(WIP), Cycle Time, and Throughput. The reason these flow metrics are\npreferable to traditional Agile metrics is because they are much more\nactionable and transparent. By transparent we mean that the metrics provide\na high degree of visibility into the teams’ (and programs’) progress. By\nactionable, we mean that the metrics themselves will suggest the specific\nteam interventions needed to improve the overall performance of the\nprocess.", "tokens": 493, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 209, "segment_id": "00209", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens", "chunk_id": "00000242"}
{"type": "chunk", "text": "To understand how flow metrics might suggest improvement\n\ninterventions we must first explore some definitions. For Siemens HS, we\ndefined WIP to be any work item (e.g., user story, defect, etc.) that was\nbetween the “Specifying Active” step and the “Done” step in our workflow\n(Figure 17.1). Figure 17.1: Example Kanban Board\n\nCycle Time was defined to be the amount of total elapsed time needed\nfor a work item to get from “Specifying Active” to “Done”. Throughput was\ndefined as the number of work items that entered the “Done” step per unit of\ntime (e.g., user stories per week). We have stressed throughout this paper that predictability is of\nparamount importance to Siemens HS. So how was the organization doing\nbefore Kanban? Figure 17.2 is a Scatterplot of Cycle Times for finished stories in the\nFinancials organization for the whole release before Kanban was introduced.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens\n\nTo understand how flow metrics might suggest improvement\n\ninterventions we must first explore some definitions. For Siemens HS, we\ndefined WIP to be any work item (e.g., user story, defect, etc.) that was\nbetween the “Specifying Active” step and the “Done” step in our workflow\n(Figure 17.1). Figure 17.1: Example Kanban Board\n\nCycle Time was defined to be the amount of total elapsed time needed\nfor a work item to get from “Specifying Active” to “Done”. Throughput was\ndefined as the number of work items that entered the “Done” step per unit of\ntime (e.g., user stories per week). We have stressed throughout this paper that predictability is of\nparamount importance to Siemens HS. So how was the organization doing\nbefore Kanban? Figure 17.2 is a Scatterplot of Cycle Times for finished stories in the\nFinancials organization for the whole release before Kanban was introduced.", "tokens": 206, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 210, "segment_id": "00210", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": null, "section_title": null, "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens", "chunk_id": "00000243"}
{"type": "chunk", "text": "Figure 17.2: Cycle Times in the Release before Kanban\nWhat this Scatterplot tells us is that in this release, 50% of all stories\nfinished in 21 days or less. But remember we told you earlier that Siemens\nHS was running 30 day sprints? That means that any story that started at the\nbeginning of a sprint had little better than 50% chance of finishing within the\nsprint. Furthermore, 85% of stories were finishing in 71 days or less---that is\n2.5 sprints! What’s worse is that Figure 17.3 shows us that over the course of\nthe release the general trend of story Cycle Times was getting longer and\nlonger and longer.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nFigure 17.2: Cycle Times in the Release before Kanban\nWhat this Scatterplot tells us is that in this release, 50% of all stories\nfinished in 21 days or less. But remember we told you earlier that Siemens\nHS was running 30 day sprints? That means that any story that started at the\nbeginning of a sprint had little better than 50% chance of finishing within the\nsprint. Furthermore, 85% of stories were finishing in 71 days or less---that is\n2.5 sprints! What’s worse is that Figure 17.3 shows us that over the course of\nthe release the general trend of story Cycle Times was getting longer and\nlonger and longer.", "tokens": 153, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 211, "segment_id": "00211", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000244"}
{"type": "chunk", "text": "Figure 17.3: General Upward Trend of Cycle Times before the Introduction of Kanban\nFigure 17.3 is not a picture of a very predictable process. So what was going on here? A simplified interpretation of Little’s Law\n\ntells us that if Cycle Times are too long, then we essentially have two\noptions: decrease WIP or increase Throughput. Most managers inexplicably\nusually opt for the latter. They make teams work longer hours (stay late)\neach day. They make teams work mandatory weekends. They try and steal\nresources from other projects. Some companies may even go so far as to hire\ntemporary or permanent staff. The problem with trying to impact\nThroughput in these ways is that most organizations actually end up\nincreasing WIP faster than they increase Throughput. If we refer back to\nLittle’s Law, we know that if WIP increases faster than Throughput, then\nCycle Times will only increase. Increasing WIP faster than increasing\nThroughput only exacerbates the problem of long Cycle Times. Our choice (eventually) was the much more sensible and economical\n\none: reduce Cycle Times by limiting WIP through the use of Kanban. What\nmost people fail to realize is that limiting WIP can be as simple as making\nsure that work is not started at a faster rate than work is completed (please\nsee Figure 5.5 as an example of how mismatched arrival and departure rates\nincreases WIP in the process). Matching arrival rates to departure rates is the\nnecessary first step to stabilizing a system. Only by operating a stable system\ncould we hope to achieve our goal of predictability.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nFigure 17.3: General Upward Trend of Cycle Times before the Introduction of Kanban\nFigure 17.3 is not a picture of a very predictable process. So what was going on here? A simplified interpretation of Little’s Law\n\ntells us that if Cycle Times are too long, then we essentially have two\noptions: decrease WIP or increase Throughput. Most managers inexplicably\nusually opt for the latter. They make teams work longer hours (stay late)\neach day. They make teams work mandatory weekends. They try and steal\nresources from other projects. Some companies may even go so far as to hire\ntemporary or permanent staff. The problem with trying to impact\nThroughput in these ways is that most organizations actually end up\nincreasing WIP faster than they increase Throughput. If we refer back to\nLittle’s Law, we know that if WIP increases faster than Throughput, then\nCycle Times will only increase. Increasing WIP faster than increasing\nThroughput only exacerbates the problem of long Cycle Times. Our choice (eventually) was the much more sensible and economical\n\none: reduce Cycle Times by limiting WIP through the use of Kanban. What\nmost people fail to realize is that limiting WIP can be as simple as making\nsure that work is not started at a faster rate than work is completed (please\nsee Figure 5.5 as an example of how mismatched arrival and departure rates\nincreases WIP in the process). Matching arrival rates to departure rates is the\nnecessary first step to stabilizing a system. Only by operating a stable system\ncould we hope to achieve our goal of predictability.", "tokens": 343, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 212, "segment_id": "00212", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000245"}
{"type": "chunk", "text": "Unfortunately for us, however, the first release that we implemented\nKanban, we chose not to limit WIP right away (the argument could be made\nthat we were not actually doing “Kanban” at that point). Why? Because\nearly on in our Kanban adoption the teams and management resisted the\nimposition of WIP limits. This was not unexpected, as mandating limits on\nwork went against the grain of the then current beliefs. We therefore decided\nto delay until the third month of the release. This allowed the teams and\nmanagement to gain a better familiarity of the method and become more\namenable. The delay in implementing WIP limits cost us and in retrospect we\nshould have pushed harder to impose WIP limits from the outset. As you\nmight expect, because of the lack of WIP limits, the very same problems that\nwe saw in the previous release (pre-Kanban) started to appear: Cycle Times\nwere too long and the general trend was that they were getting longer. Taking a look at the CFD (Figure 17.4) in the first release with Kanban\nclearly shows how our teams were starting to work on items at a faster rate\nthan we were finishing them:\n\nFigure 17.4: CFD Early on in the first release with Kanban\nThis disregard for when new work should be started resulted in an\ninevitable increase in WIP which, in turn, manifested itself in longer Cycle\nTimes (as shown in Figure 17.5).", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nUnfortunately for us, however, the first release that we implemented\nKanban, we chose not to limit WIP right away (the argument could be made\nthat we were not actually doing “Kanban” at that point). Why? Because\nearly on in our Kanban adoption the teams and management resisted the\nimposition of WIP limits. This was not unexpected, as mandating limits on\nwork went against the grain of the then current beliefs. We therefore decided\nto delay until the third month of the release. This allowed the teams and\nmanagement to gain a better familiarity of the method and become more\namenable. The delay in implementing WIP limits cost us and in retrospect we\nshould have pushed harder to impose WIP limits from the outset. As you\nmight expect, because of the lack of WIP limits, the very same problems that\nwe saw in the previous release (pre-Kanban) started to appear: Cycle Times\nwere too long and the general trend was that they were getting longer. Taking a look at the CFD (Figure 17.4) in the first release with Kanban\nclearly shows how our teams were starting to work on items at a faster rate\nthan we were finishing them:\n\nFigure 17.4: CFD Early on in the first release with Kanban\nThis disregard for when new work should be started resulted in an\ninevitable increase in WIP which, in turn, manifested itself in longer Cycle\nTimes (as shown in Figure 17.5).", "tokens": 317, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 213, "segment_id": "00213", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000246"}
{"type": "chunk", "text": "Figure 17.5: Scatterplot early on in the first release with Kanban\nUpon seeing these patterns emerge, we instituted a policy of limiting\n\nWIP across all teams. Limiting WIP had the almost immediate effect of\nstabilizing the system such that Cycle Times no longer continued to grow (as\nshown in Figure 17.6). Figure 17.6: Stabilized Cycle Times after introducing WIP Limits\n\nOver the course of our first release with Kanban, the 85th percentile of\nstory Cycle Time had dropped from 71 days to 43 days. And, as you can see", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nFigure 17.5: Scatterplot early on in the first release with Kanban\nUpon seeing these patterns emerge, we instituted a policy of limiting\n\nWIP across all teams. Limiting WIP had the almost immediate effect of\nstabilizing the system such that Cycle Times no longer continued to grow (as\nshown in Figure 17.6). Figure 17.6: Stabilized Cycle Times after introducing WIP Limits\n\nOver the course of our first release with Kanban, the 85th percentile of\nstory Cycle Time had dropped from 71 days to 43 days. And, as you can see", "tokens": 128, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 214, "segment_id": "00214", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000247"}
{"type": "chunk", "text": "from comparing Figure 17.4 to Figure 17.7 (the release before Kanban, and\nthe first release using Kanban, respectively) the teams were suffering from\nmuch less variability. Less variability resulted in more predictability. In other\nwords, once we limited WIP in early September 2012 the process Cycle\nTimes did not increase indefinitely as they did the release before. They\nreached a stable state at about 41 days almost immediately, and stayed at that\nstable state for the rest of the release. This stabilization effect of limiting WIP is also powerfully\n\ndemonstrated in the CFD (Figure 17.7):\n\nFigure 17.7: CFD in the First Release with Kanban after WIP limits were introduced\nThe second release after the introduction of Kanban saw much the same\n\nresult (with regard to predictability). 85 percent of stories were finishing\nwithin 41 days and variability was still better controlled. Looking at the two\nScatterplots side by side bears this out (Figure 17.8):", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nfrom comparing Figure 17.4 to Figure 17.7 (the release before Kanban, and\nthe first release using Kanban, respectively) the teams were suffering from\nmuch less variability. Less variability resulted in more predictability. In other\nwords, once we limited WIP in early September 2012 the process Cycle\nTimes did not increase indefinitely as they did the release before. They\nreached a stable state at about 41 days almost immediately, and stayed at that\nstable state for the rest of the release. This stabilization effect of limiting WIP is also powerfully\n\ndemonstrated in the CFD (Figure 17.7):\n\nFigure 17.7: CFD in the First Release with Kanban after WIP limits were introduced\nThe second release after the introduction of Kanban saw much the same\n\nresult (with regard to predictability). 85 percent of stories were finishing\nwithin 41 days and variability was still better controlled. Looking at the two\nScatterplots side by side bears this out (Figure 17.8):", "tokens": 221, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 215, "segment_id": "00215", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000248"}
{"type": "chunk", "text": "Figure 17.8: Scatterplots of the First Release using Kanban (above) and the Second Release of\nKanban (below)\n\nHopefully it is obvious to the reader that by taking action on the metrics\nthat had been provided, we had achieved our goal of predictability. As shown\nin Figure 17.8, our first release using Kanban yielded Cycle Times of 43\ndays or less, and our second release using Kanban yielded Cycle Times of 40\ndays or less. This result is the very definition of predictability.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nFigure 17.8: Scatterplots of the First Release using Kanban (above) and the Second Release of\nKanban (below)\n\nHopefully it is obvious to the reader that by taking action on the metrics\nthat had been provided, we had achieved our goal of predictability. As shown\nin Figure 17.8, our first release using Kanban yielded Cycle Times of 43\ndays or less, and our second release using Kanban yielded Cycle Times of 40\ndays or less. This result is the very definition of predictability.", "tokens": 114, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 216, "segment_id": "00216", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000249"}
{"type": "chunk", "text": "By attaining predictable and stable Cycle Times we would now be able\n\nto use these metrics as input to future projections. How we did projections\nwill be discussed in more detail in the next section of this chapter. These shorter Cycle Times and decreased variability also led to a\n\ntremendous increase in quality (Figure 17.9):\n\nFigure 17.9: Quality Compared between Releases\nFigure 17.9 shows how Kanban both reduced the number of defects\ncreated during release development well as minimizing the gap between\ndefects created and defects resolved during the release. By managing queues,\nlimiting work-in progress and batch sizes and building a cadence through a\npull system (limited WIP) versus push system (non-limited WIP) we were\nable to expose more defects and execute more timely resolutions. On the\nother hand “pushing” a large batch of requirements and/or starting too many\nrequirements will delay discovery of defects and other issues; as defects are\nhidden in incomplete requirements and code. By understanding Little’s Law, and by looking at how the flow appears\n\nin charts like CFDs and Scatterplots, Siemens HS could see what\ninterventions were necessary to get control of their system. Namely, the\norganization was suffering from too much WIP which was, in turn, affecting\nCycle Time and quality. In taking the action to limit WIP, Siemens saw an\nimmediate decrease in Cycle Time and an immediate increase in quality. These metrics also highlighted problems within the Siemens HS\nproduct development process, and the following section of this chapter will\ndiscuss what next steps the organization is going to implement in order to\ncontinue to improve its system.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nBy attaining predictable and stable Cycle Times we would now be able\n\nto use these metrics as input to future projections. How we did projections\nwill be discussed in more detail in the next section of this chapter. These shorter Cycle Times and decreased variability also led to a\n\ntremendous increase in quality (Figure 17.9):\n\nFigure 17.9: Quality Compared between Releases\nFigure 17.9 shows how Kanban both reduced the number of defects\ncreated during release development well as minimizing the gap between\ndefects created and defects resolved during the release. By managing queues,\nlimiting work-in progress and batch sizes and building a cadence through a\npull system (limited WIP) versus push system (non-limited WIP) we were\nable to expose more defects and execute more timely resolutions. On the\nother hand “pushing” a large batch of requirements and/or starting too many\nrequirements will delay discovery of defects and other issues; as defects are\nhidden in incomplete requirements and code. By understanding Little’s Law, and by looking at how the flow appears\n\nin charts like CFDs and Scatterplots, Siemens HS could see what\ninterventions were necessary to get control of their system. Namely, the\norganization was suffering from too much WIP which was, in turn, affecting\nCycle Time and quality. In taking the action to limit WIP, Siemens saw an\nimmediate decrease in Cycle Time and an immediate increase in quality. These metrics also highlighted problems within the Siemens HS\nproduct development process, and the following section of this chapter will\ndiscuss what next steps the organization is going to implement in order to\ncontinue to improve its system.", "tokens": 349, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 217, "segment_id": "00217", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000250"}
{"type": "chunk", "text": "How Metrics Changed Everything\nApart from the improvements in predictability and quality, we also saw\nsignificant improvements in operational efficiency. We had “real-time”\ninsight into systemic blocks, variability and bottlenecks and could take\nappropriate actions quickly. In one case by analyzing Throughput (story run\nrate) and Cycle Time for each column (specifying, testing and developing),\nwe were able to clearly see where we were experiencing capacity problems. We were also able to gauge our “flow efficiency” by calculating the\npercentage of time stories were being worked on or “touched” versus\n“waiting” or “blocked”. Wait time is the time a story sits in an inactive or\ndone queue because moving to the next active state is prevented by WIP\nlimits. Blocked time is the time work on a story is impeded, including\nimpediments such as build-breaks, defects, waiting for customer validation\netc. The calculation is made by capturing time spent in the “specifying done\nand developing done” column plus any additional blocked time which we\ncall “wait time”. (Blocked or impediment data is provided directly by the\ntool we are using). Subtracting “wait time” from total Cycle Time gives us\n“touched time”. Calculating flow efficiency is simply calculating the\npercentage of total touch time over total Cycle Time. Flow efficiency\npercentage can act as a powerful Key Performance Indicator (KPI) or\nbenchmark in terms of measuring overall system efficiency. This level of transparency, broadly across the program and more deeply\n\nwithin each team enabled us to make very timely adjustments. Cumulative\nflow diagrams provided a full picture at the individual team and program\nlevels where our capacity weaknesses lay and revealed where we needed to\nmake adjustments to improve Throughput and efficiency. For example, at the\nenterprise level using the Cumulative Flow Diagram the management team\nwas able to see higher Throughput in “developing” versus “testing” across\nall teams and thus make a decision to invest in increasing test automation\nexponentially to re-balance capacity. This was actually easy to spot as the\n“developing done” state on the CFD consistently had stories queued up\nwaiting for the “testing” column WIP limits to allow them to move into\n“testing”.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nHow Metrics Changed Everything\nApart from the improvements in predictability and quality, we also saw\nsignificant improvements in operational efficiency. We had “real-time”\ninsight into systemic blocks, variability and bottlenecks and could take\nappropriate actions quickly. In one case by analyzing Throughput (story run\nrate) and Cycle Time for each column (specifying, testing and developing),\nwe were able to clearly see where we were experiencing capacity problems. We were also able to gauge our “flow efficiency” by calculating the\npercentage of time stories were being worked on or “touched” versus\n“waiting” or “blocked”. Wait time is the time a story sits in an inactive or\ndone queue because moving to the next active state is prevented by WIP\nlimits. Blocked time is the time work on a story is impeded, including\nimpediments such as build-breaks, defects, waiting for customer validation\netc. The calculation is made by capturing time spent in the “specifying done\nand developing done” column plus any additional blocked time which we\ncall “wait time”. (Blocked or impediment data is provided directly by the\ntool we are using). Subtracting “wait time” from total Cycle Time gives us\n“touched time”. Calculating flow efficiency is simply calculating the\npercentage of total touch time over total Cycle Time. Flow efficiency\npercentage can act as a powerful Key Performance Indicator (KPI) or\nbenchmark in terms of measuring overall system efficiency. This level of transparency, broadly across the program and more deeply\n\nwithin each team enabled us to make very timely adjustments. Cumulative\nflow diagrams provided a full picture at the individual team and program\nlevels where our capacity weaknesses lay and revealed where we needed to\nmake adjustments to improve Throughput and efficiency. For example, at the\nenterprise level using the Cumulative Flow Diagram the management team\nwas able to see higher Throughput in “developing” versus “testing” across\nall teams and thus make a decision to invest in increasing test automation\nexponentially to re-balance capacity. This was actually easy to spot as the\n“developing done” state on the CFD consistently had stories queued up\nwaiting for the “testing” column WIP limits to allow them to move into\n“testing”.", "tokens": 470, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 218, "segment_id": "00218", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000251"}
{"type": "chunk", "text": "For example, at the\nenterprise level using the Cumulative Flow Diagram the management team\nwas able to see higher Throughput in “developing” versus “testing” across\nall teams and thus make a decision to invest in increasing test automation\nexponentially to re-balance capacity. This was actually easy to spot as the\n“developing done” state on the CFD consistently had stories queued up\nwaiting for the “testing” column WIP limits to allow them to move into\n“testing”. At the team level the metrics would be used to manage WIP by\nadjusting WIP limits when needed to ensure flow and prevent the build-up of\nbottlenecks and used extensively in retrospectives to look at variability. By\nusing the Scatterplot, teams could clearly see stories whose Cycle Time\nexceeded normal ranges, perform root cause analysis and take steps and", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nFor example, at the\nenterprise level using the Cumulative Flow Diagram the management team\nwas able to see higher Throughput in “developing” versus “testing” across\nall teams and thus make a decision to invest in increasing test automation\nexponentially to re-balance capacity. This was actually easy to spot as the\n“developing done” state on the CFD consistently had stories queued up\nwaiting for the “testing” column WIP limits to allow them to move into\n“testing”. At the team level the metrics would be used to manage WIP by\nadjusting WIP limits when needed to ensure flow and prevent the build-up of\nbottlenecks and used extensively in retrospectives to look at variability. By\nusing the Scatterplot, teams could clearly see stories whose Cycle Time\nexceeded normal ranges, perform root cause analysis and take steps and", "tokens": 180, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 218, "segment_id": "00218", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000252"}
{"type": "chunk", "text": "actions to prevent recurrence. The CFD also allowed us to track our average\nThroughput or departure-rate (the number of stories we were completing per\nday/week etc.) and calculate an end date based on the number of stories\nremaining in the backlog -- (similar to the way one uses points and velocity,\nbut more tangible). Furthermore by controlling WIP and managing flow we\nsaw continued clean builds in our continuous integration process, leading to\nstable testing environments, and the clearing of previously persistent testing\nbottlenecks. The results from the first release using Kanban were better than\nexpected. The release completed on schedule and below budget by over\n10%. The second release was even better: along with sustained\nimprovements in Cycle Time, we also became much faster. By reducing\nCycle Time we were increasing Throughput, enabling us to complete 33%\nmore stories than we had in the previous release, with even better quality in\nterms of number of defects and first pass yield -- meaning the percentage of\nformal integration and regression tests passing the first time they are\nexecuted. In the release prior to Kanban our first pass yield percentage was\nat 75%, whereas in the first Kanban release the pass percentage rose to 86%\nand reached 95% in our second release using Kanban. The metrics also gave us a new direction in terms of release forecasting. By using historical Cycle Times we could perform Monte-Carlo simulation\nmodelling to provide likely completion date forecasts. If these forecasts\nproved reliable, we would no longer need to estimate. In our second Kanban\nrelease we adopted this practice along with our current points and velocity\nestimation planning methods and compared the results. Apart from the\nobvious difference in the use of metrics versus estimated points, the\nsimulation provides a distribution of likely completion timeframes instead of\nan average velocity linear based forecast -- such as a burn up chart. Likewise\nCycle Time metrics are not based on an average (such as average number of\npoints) but on distributions of actual Cycle Times. The Histogram in Figure\n17.10 is an example of actual historical Cycle Time distributions that\nSiemens uses as input to the modelling tool. In this example 30% of stories\naccounting for 410 actual stories had Cycle Times of 9 days or less, the next\n20% accounting for 225 stories had Cycle Times of 10 to 16 days and so\nforth.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nactions to prevent recurrence. The CFD also allowed us to track our average\nThroughput or departure-rate (the number of stories we were completing per\nday/week etc.) and calculate an end date based on the number of stories\nremaining in the backlog -- (similar to the way one uses points and velocity,\nbut more tangible). Furthermore by controlling WIP and managing flow we\nsaw continued clean builds in our continuous integration process, leading to\nstable testing environments, and the clearing of previously persistent testing\nbottlenecks. The results from the first release using Kanban were better than\nexpected. The release completed on schedule and below budget by over\n10%. The second release was even better: along with sustained\nimprovements in Cycle Time, we also became much faster. By reducing\nCycle Time we were increasing Throughput, enabling us to complete 33%\nmore stories than we had in the previous release, with even better quality in\nterms of number of defects and first pass yield -- meaning the percentage of\nformal integration and regression tests passing the first time they are\nexecuted. In the release prior to Kanban our first pass yield percentage was\nat 75%, whereas in the first Kanban release the pass percentage rose to 86%\nand reached 95% in our second release using Kanban. The metrics also gave us a new direction in terms of release forecasting. By using historical Cycle Times we could perform Monte-Carlo simulation\nmodelling to provide likely completion date forecasts. If these forecasts\nproved reliable, we would no longer need to estimate. In our second Kanban\nrelease we adopted this practice along with our current points and velocity\nestimation planning methods and compared the results. Apart from the\nobvious difference in the use of metrics versus estimated points, the\nsimulation provides a distribution of likely completion timeframes instead of\nan average velocity linear based forecast -- such as a burn up chart. Likewise\nCycle Time metrics are not based on an average (such as average number of\npoints) but on distributions of actual Cycle Times. The Histogram in Figure\n17.10 is an example of actual historical Cycle Time distributions that\nSiemens uses as input to the modelling tool. In this example 30% of stories\naccounting for 410 actual stories had Cycle Times of 9 days or less, the next\n20% accounting for 225 stories had Cycle Times of 10 to 16 days and so\nforth.", "tokens": 503, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 219, "segment_id": "00219", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000253"}
{"type": "chunk", "text": "Figure 17.10: Cycle Time Distributions\n\nWhat we learned was that velocity forecasts attempt to apply a\n\ndeterministic methodology to an inherently uncertain problem. That type of\napproach never works. By using the range or distributions of historical Cycle\nTimes from the best to worst cases and simulating the project hundreds of\ntimes, the modelling simulation provides a range of probabilistic completion\ndates at different percentiles. For example see Figure 17.11 below showing\nlikely completion date forecasts used in release planning. Our practice is to\ncommit to the date which is closest to the 85th percent likelihood as is\nhighlighted in the chart. As the chart shows we are also able to use the model\nto calculate likely costs at each percentile.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nFigure 17.10: Cycle Time Distributions\n\nWhat we learned was that velocity forecasts attempt to apply a\n\ndeterministic methodology to an inherently uncertain problem. That type of\napproach never works. By using the range or distributions of historical Cycle\nTimes from the best to worst cases and simulating the project hundreds of\ntimes, the modelling simulation provides a range of probabilistic completion\ndates at different percentiles. For example see Figure 17.11 below showing\nlikely completion date forecasts used in release planning. Our practice is to\ncommit to the date which is closest to the 85th percent likelihood as is\nhighlighted in the chart. As the chart shows we are also able to use the model\nto calculate likely costs at each percentile.", "tokens": 155, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 220, "segment_id": "00220", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000254"}
{"type": "chunk", "text": "Figure 17.11: Result of Monte-Carlo simulation showing probability forecast at different\npercentages\n\nOver the course of the release the model proved extremely predictive;\n\nmoreover, it also provided to Siemens the ability to perform ongoing risk\nanalysis and “what-if” scenarios with highly instructive and reliable results. For example, in one case, to meet an unexpected large scope increase on one\nof the teams, the Program Management Team was planning to add two new\nProgrammers. The modelling tool pointed to adding a Tester to the team\nrather than adding programming. The tool proved very accurate in terms of\nrecommending the right staffing capacity to successfully address this scope\nincrease. At the end of the day, it was an easy decision to discard story point\nvelocity based estimation and move to release completion date forecasts. The collection of historical Cycle Time metrics that were stable and\npredictable enabled Siemens to perform Monte-Carlo simulations, which\nprovided far more accurate and realistic release delivery forecasts. This was", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nFigure 17.11: Result of Monte-Carlo simulation showing probability forecast at different\npercentages\n\nOver the course of the release the model proved extremely predictive;\n\nmoreover, it also provided to Siemens the ability to perform ongoing risk\nanalysis and “what-if” scenarios with highly instructive and reliable results. For example, in one case, to meet an unexpected large scope increase on one\nof the teams, the Program Management Team was planning to add two new\nProgrammers. The modelling tool pointed to adding a Tester to the team\nrather than adding programming. The tool proved very accurate in terms of\nrecommending the right staffing capacity to successfully address this scope\nincrease. At the end of the day, it was an easy decision to discard story point\nvelocity based estimation and move to release completion date forecasts. The collection of historical Cycle Time metrics that were stable and\npredictable enabled Siemens to perform Monte-Carlo simulations, which\nprovided far more accurate and realistic release delivery forecasts. This was", "tokens": 204, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 221, "segment_id": "00221", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000255"}
{"type": "chunk", "text": "a huge gap in our Agile adoption closed. In analyzing the metrics, Siemens\nalso discovered that there was no correlation between story point estimates\nand actual Cycle Time. Siemens also gained the ability to more accurately track costs; as we\ndiscovered that we could in fact correlate Cycle Time to actual budgetary\nallocations. Siemens could now definitively calculate the unit costs of a\nstory, feature and/or a release. By using the modelling tool we could now\nforecast likely costs along with dates. Moreover, we could put an accurate\ndollar value on reductions or increases in Cycle Times. The metrics also improved communication with key non PLM stakeholders. It had always been difficult translating relative story points to\ncorporate stakeholders who were always looking for time based answers and\nwho found our responses based on relative story points confusing. Metrics\nsuch as Cycle Time and Throughput are very tangible and especially familiar\nin a company such as Siemens with a large manufacturing sector. Implementing Kanban also had a positive impact on employee morale. Within the first month, Scrum-masters reported more meaningful stand-ups. This sentiment was especially expressed and emphasized by our offshore\ncolleagues, who now felt a much higher sense of inclusion during the standup. Having the same board and visualization in front of everyone made a\nhuge difference on those long distant conference calls between colleagues in\ndiametrically opposed time zones. While there was some skepticism as\nexpected, overall comments from the teams were positive; people liked it. This was confirmed in an anonymous survey we did four months into the\nfirst release that we used Kanban: the results and comments from employees\nwere overwhelmingly positive. Furthermore, as we now understood the\nimpact of WIP and systemic variability, there was less blame on performance\nand skills of the team. The root of our problem lay not in our people or\nskills, but in the amount of Work In Progress. Conclusion\nKanban augmented and strengthened our key Agile practices such as crossfunctional Scrum teams, story driven development, continuous integration\ntesting, TDD, and most others. It has also opened the way to even greater\nagility through our current plan to transition to continuous delivery. Traditional Agile metrics had failed Siemens HS in that we did not\n\nprovide the level of transparency required to manage software product", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\na huge gap in our Agile adoption closed. In analyzing the metrics, Siemens\nalso discovered that there was no correlation between story point estimates\nand actual Cycle Time. Siemens also gained the ability to more accurately track costs; as we\ndiscovered that we could in fact correlate Cycle Time to actual budgetary\nallocations. Siemens could now definitively calculate the unit costs of a\nstory, feature and/or a release. By using the modelling tool we could now\nforecast likely costs along with dates. Moreover, we could put an accurate\ndollar value on reductions or increases in Cycle Times. The metrics also improved communication with key non PLM stakeholders. It had always been difficult translating relative story points to\ncorporate stakeholders who were always looking for time based answers and\nwho found our responses based on relative story points confusing. Metrics\nsuch as Cycle Time and Throughput are very tangible and especially familiar\nin a company such as Siemens with a large manufacturing sector. Implementing Kanban also had a positive impact on employee morale. Within the first month, Scrum-masters reported more meaningful stand-ups. This sentiment was especially expressed and emphasized by our offshore\ncolleagues, who now felt a much higher sense of inclusion during the standup. Having the same board and visualization in front of everyone made a\nhuge difference on those long distant conference calls between colleagues in\ndiametrically opposed time zones. While there was some skepticism as\nexpected, overall comments from the teams were positive; people liked it. This was confirmed in an anonymous survey we did four months into the\nfirst release that we used Kanban: the results and comments from employees\nwere overwhelmingly positive. Furthermore, as we now understood the\nimpact of WIP and systemic variability, there was less blame on performance\nand skills of the team. The root of our problem lay not in our people or\nskills, but in the amount of Work In Progress. Conclusion\nKanban augmented and strengthened our key Agile practices such as crossfunctional Scrum teams, story driven development, continuous integration\ntesting, TDD, and most others. It has also opened the way to even greater\nagility through our current plan to transition to continuous delivery. Traditional Agile metrics had failed Siemens HS in that we did not\n\nprovide the level of transparency required to manage software product", "tokens": 472, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 222, "segment_id": "00222", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000256"}
{"type": "chunk", "text": "development at this scale. Looking at a burn-down chart showing average\nvelocity does not scale to this level of complexity and risk. This had been a\nhuge gap in our Agile adoption which was now solved. Understanding flow---and more importantly understanding the metrics\n\nof flow---allowed Siemens to take specific action in order improve overall\npredictability and process performance. On this note, the biggest learning\nwas understanding that predictability was a systemic behavior that one has to\nmanage by understanding and acting in accordance with the assumptions of\nLittle’s law and the impacts of resource utilization. Achieving a stable and predictable system can be extremely powerful. Once you reach a highly predictable state by aligning capacity and demand;\nyou are able to see the levers to address systemic bottle-necks and other\nunintended variability. Continuous improvement in a system that is unstable\nalways runs the risk of improvement initiatives that result in suboptimizations. The extent of the improvement we achieved in terms of overall defect\n\nrates was better than expected. Along with the gains we achieved through\nmanaging WIP; we had placed significant focus on reinforcing and\nimproving our CI and quality management practices. Each column had its\nown doneness criteria and by incorporating “doneness procedures” into our\nexplicit policies we were able to ensure that all quality steps were followed\nbefore moving a story to the next column -- for example moving a story from\n“Specifying” to “Developing”. Most of these practices had predated Kanban;\nhowever the Kanban method provided more visibility and rigor. The metrics also magnified the need for further improvement steps: The\n\ncurrent Kanban implementation incorporates activities owned within the\nScrum Teams; but does not extend to the “backend process” -- regression\ntesting, beta testing, hosting, and customer implementation. Like many large\ncompanies Siemens continues to maintain a large batch release regression\nand beta testing process. Thus begging the question; what if we extended\nKanban across the whole value stream from inception to implementation at\nthe customer? Through the metrics, visualization, managing WIP and\ncontinuous delivery we could deliver value to our customers faster and with\nhigh quality. We could take advantage of Kanban to manage flow, drive\npredictable customer outcomes, identify bottle-necks and drive Lean\ncontinuous improvement through the testing, operations and implementation", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\ndevelopment at this scale. Looking at a burn-down chart showing average\nvelocity does not scale to this level of complexity and risk. This had been a\nhuge gap in our Agile adoption which was now solved. Understanding flow---and more importantly understanding the metrics\n\nof flow---allowed Siemens to take specific action in order improve overall\npredictability and process performance. On this note, the biggest learning\nwas understanding that predictability was a systemic behavior that one has to\nmanage by understanding and acting in accordance with the assumptions of\nLittle’s law and the impacts of resource utilization. Achieving a stable and predictable system can be extremely powerful. Once you reach a highly predictable state by aligning capacity and demand;\nyou are able to see the levers to address systemic bottle-necks and other\nunintended variability. Continuous improvement in a system that is unstable\nalways runs the risk of improvement initiatives that result in suboptimizations. The extent of the improvement we achieved in terms of overall defect\n\nrates was better than expected. Along with the gains we achieved through\nmanaging WIP; we had placed significant focus on reinforcing and\nimproving our CI and quality management practices. Each column had its\nown doneness criteria and by incorporating “doneness procedures” into our\nexplicit policies we were able to ensure that all quality steps were followed\nbefore moving a story to the next column -- for example moving a story from\n“Specifying” to “Developing”. Most of these practices had predated Kanban;\nhowever the Kanban method provided more visibility and rigor. The metrics also magnified the need for further improvement steps: The\n\ncurrent Kanban implementation incorporates activities owned within the\nScrum Teams; but does not extend to the “backend process” -- regression\ntesting, beta testing, hosting, and customer implementation. Like many large\ncompanies Siemens continues to maintain a large batch release regression\nand beta testing process. Thus begging the question; what if we extended\nKanban across the whole value stream from inception to implementation at\nthe customer? Through the metrics, visualization, managing WIP and\ncontinuous delivery we could deliver value to our customers faster and with\nhigh quality. We could take advantage of Kanban to manage flow, drive\npredictable customer outcomes, identify bottle-necks and drive Lean\ncontinuous improvement through the testing, operations and implementation", "tokens": 479, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 223, "segment_id": "00223", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000257"}
{"type": "chunk", "text": "areas as well. In late 2013 we began our current and very ambitious journey\nto extend the Kanban method across the whole value stream. Finally it is important to say that the use of metrics instead of\nestimation for forecasting has eliminated the emotion and recrimination\nassociated with estimation. Anyone wishing to go back to estimating sprints\nwould be few and far between, including even those who had previously\nbeen the most skeptical. Key Learnings and Takeaways\n\nTraditional Agile metrics were not working for Siemens HS as those\nmetrics did not provide the transparency and predictability required by\nSiemens HS’ customers and management. Siemens HS decided to dump Story Points and Velocity in favor of\nWIP, Cycle Time, and Throughput. After that shift, Siemens HS quickly discovered the root of their\nproblem was not people or skillsets but too much WIP. By controlling WIP, Siemens HS was able to reduce Cycle Time from\n71 days at the 85th percentile to 43 days at the 85th percentile. Controlling WIP also increased the quality of the HS releases\ndramatically. The second release after limiting WIP produced story Cycle Times of\n40 days at the 85th percentile. Having predictable Cycle Times allowed Siemens to mostly abandon\ntheir old estimation practices. The use of metrics instead of estimation for forecasting has eliminated\nthe emotion and recrimination associated with estimation. Predictable Cycle Times have also allowed Siemens HS to begin to\nutilize more advanced forecasting techniques like the Monte Carlo\nMethod.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nareas as well. In late 2013 we began our current and very ambitious journey\nto extend the Kanban method across the whole value stream. Finally it is important to say that the use of metrics instead of\nestimation for forecasting has eliminated the emotion and recrimination\nassociated with estimation. Anyone wishing to go back to estimating sprints\nwould be few and far between, including even those who had previously\nbeen the most skeptical. Key Learnings and Takeaways\n\nTraditional Agile metrics were not working for Siemens HS as those\nmetrics did not provide the transparency and predictability required by\nSiemens HS’ customers and management. Siemens HS decided to dump Story Points and Velocity in favor of\nWIP, Cycle Time, and Throughput. After that shift, Siemens HS quickly discovered the root of their\nproblem was not people or skillsets but too much WIP. By controlling WIP, Siemens HS was able to reduce Cycle Time from\n71 days at the 85th percentile to 43 days at the 85th percentile. Controlling WIP also increased the quality of the HS releases\ndramatically. The second release after limiting WIP produced story Cycle Times of\n40 days at the 85th percentile. Having predictable Cycle Times allowed Siemens to mostly abandon\ntheir old estimation practices. The use of metrics instead of estimation for forecasting has eliminated\nthe emotion and recrimination associated with estimation. Predictable Cycle Times have also allowed Siemens HS to begin to\nutilize more advanced forecasting techniques like the Monte Carlo\nMethod.", "tokens": 314, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 224, "segment_id": "00224", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000258"}
{"type": "chunk", "text": "Acknowledgements\n\nAs any author will tell you, there may be one name on the front cover, but a\nbook is only possible due to the hard work of numerous people. If I may, I’d\nlike to call your particular attention to the efforts of the few of those listed\nhere. First, I have to say there is no one in the software industry who\nunderstands the principles of flow and how to apply those principles to\nteams better than Frank Vega. If you want to know anything about flow\nmetrics and analytics, Frank is the guy to ask---which I did on way too\nmany occasions, I’m sure. When reviewing this book, his comments were\ninsightful, thought-provoking, and pragmatic. He is one of the few people\nwhose opinion I implicitly trust on this stuff. I’m not sure there is anyone in the Agile community who asks tougher\nquestions than Nannette Brown. She constantly challenged me to come up\nwith better answers and was (is) never satisfied until I did. To Mike Longin and Prateek Singh I have to say thanks for your\nwillingness to learn and provide valuable feedback on how to introduce\nthese concepts to teams. We’ve got much more work to do! Arin Sime is one of the few truly great minds in in all of Agile. Thanks for giving me the opportunity to share my ideas. Troy Tuttle has built one of the greatest Lean communities from\n\nscratch and, more importantly, has allowed me to contribute when I can. The whole Lean-Agile movement would be a much better place with more\npeople like Troy. Steve Reid refuses to allow his organization to stagnate. In his mind\nthere is always room for improvement and to his great credit he allows his\nteam members the room to experiment and innovate. Thanks, Steve, for\nletting me be a part of that ride. Dennis Kirlin is one of those guys who you can sit down with and\n\nsolve world hunger over a cup of coffee---or a whisky as the case may be. There is a reason his Agile teams are the envy of his whole city. For those of you who don’t know, Darren Davis is the true “Father of\nKanban”. It was his matter-of-fact approach to solving real-world problems", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nAcknowledgements\n\nAs any author will tell you, there may be one name on the front cover, but a\nbook is only possible due to the hard work of numerous people. If I may, I’d\nlike to call your particular attention to the efforts of the few of those listed\nhere. First, I have to say there is no one in the software industry who\nunderstands the principles of flow and how to apply those principles to\nteams better than Frank Vega. If you want to know anything about flow\nmetrics and analytics, Frank is the guy to ask---which I did on way too\nmany occasions, I’m sure. When reviewing this book, his comments were\ninsightful, thought-provoking, and pragmatic. He is one of the few people\nwhose opinion I implicitly trust on this stuff. I’m not sure there is anyone in the Agile community who asks tougher\nquestions than Nannette Brown. She constantly challenged me to come up\nwith better answers and was (is) never satisfied until I did. To Mike Longin and Prateek Singh I have to say thanks for your\nwillingness to learn and provide valuable feedback on how to introduce\nthese concepts to teams. We’ve got much more work to do! Arin Sime is one of the few truly great minds in in all of Agile. Thanks for giving me the opportunity to share my ideas. Troy Tuttle has built one of the greatest Lean communities from\n\nscratch and, more importantly, has allowed me to contribute when I can. The whole Lean-Agile movement would be a much better place with more\npeople like Troy. Steve Reid refuses to allow his organization to stagnate. In his mind\nthere is always room for improvement and to his great credit he allows his\nteam members the room to experiment and innovate. Thanks, Steve, for\nletting me be a part of that ride. Dennis Kirlin is one of those guys who you can sit down with and\n\nsolve world hunger over a cup of coffee---or a whisky as the case may be. There is a reason his Agile teams are the envy of his whole city. For those of you who don’t know, Darren Davis is the true “Father of\nKanban”. It was his matter-of-fact approach to solving real-world problems", "tokens": 475, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 225, "segment_id": "00225", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000259"}
{"type": "chunk", "text": "that got the movement off of the ground. I was fortunate enough to learn\nfrom him as he guided me through the process of shedding the shackles of\nsprints. Because of him I’ve never looked back. A special thanks to Troy Magennis for two reasons. First, for daring\n\nthe community to get out of its comfort zone and think about the world\nmore probabilistically; and, second, for his gracious permission to let me\nuse his Monte Carlo Simulation tool to run my crazy experiments. I’ve\nmentioned this before, but I’ll say it again: if you don’t know about Troy’s\nwork then you need to look him up. Bennet Vallet is one of those rare individuals who constantly---and I\n\nmean constantly---pushes himself to learn and get better. Combine that with\nhis willingness to do whatever is needed to get the correct result and you\nget a formidable force. He has been and continues to be a great mentor to\nme. Without his prodding this book may never have seen the light of day. True to form, he is already asking for the next version that covers the more\nadvanced topics. Vanessa Vacanti is the James Brown of knowledge work. She\nconstantly reminded me to keep this material in the realm of the practical. Thanks for all of your help, LEHjr! To my twin sister, Dina Vacanti. You don’t get to choose your\n\nsiblings, but if I could, I would choose you every time. Al and Pat Vacanti are the whole reason I was able to write this book. How do you ever say thanks enough for that? As always, Todd Conley remains my wizard behind the curtain. Todd\nnever wavered in his belief when I first pitched the idea of a flow analytics\ntool to him two years ago, and he has been tireless in his pursuit of\nperfection in developing that product ever since. Todd has a no-nonsense\napproach to building software and is without a doubt the best developer I\nhave ever known. He is a trusted advisor, invaluable colleague, and great\nfriend. Last, but absolutely not least, I’d like to thank my wife, Ann. For her\nrole in all of this, she deserves top billing and the “and”. She deserves the\nEGOT. For putting up with me, she deserves both the Nobel Prize and\nsainthood.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nthat got the movement off of the ground. I was fortunate enough to learn\nfrom him as he guided me through the process of shedding the shackles of\nsprints. Because of him I’ve never looked back. A special thanks to Troy Magennis for two reasons. First, for daring\n\nthe community to get out of its comfort zone and think about the world\nmore probabilistically; and, second, for his gracious permission to let me\nuse his Monte Carlo Simulation tool to run my crazy experiments. I’ve\nmentioned this before, but I’ll say it again: if you don’t know about Troy’s\nwork then you need to look him up. Bennet Vallet is one of those rare individuals who constantly---and I\n\nmean constantly---pushes himself to learn and get better. Combine that with\nhis willingness to do whatever is needed to get the correct result and you\nget a formidable force. He has been and continues to be a great mentor to\nme. Without his prodding this book may never have seen the light of day. True to form, he is already asking for the next version that covers the more\nadvanced topics. Vanessa Vacanti is the James Brown of knowledge work. She\nconstantly reminded me to keep this material in the realm of the practical. Thanks for all of your help, LEHjr! To my twin sister, Dina Vacanti. You don’t get to choose your\n\nsiblings, but if I could, I would choose you every time. Al and Pat Vacanti are the whole reason I was able to write this book. How do you ever say thanks enough for that? As always, Todd Conley remains my wizard behind the curtain. Todd\nnever wavered in his belief when I first pitched the idea of a flow analytics\ntool to him two years ago, and he has been tireless in his pursuit of\nperfection in developing that product ever since. Todd has a no-nonsense\napproach to building software and is without a doubt the best developer I\nhave ever known. He is a trusted advisor, invaluable colleague, and great\nfriend. Last, but absolutely not least, I’d like to thank my wife, Ann. For her\nrole in all of this, she deserves top billing and the “and”. She deserves the\nEGOT. For putting up with me, she deserves both the Nobel Prize and\nsainthood.", "tokens": 495, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 226, "segment_id": "00226", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000260"}
{"type": "chunk", "text": "Todd has a no-nonsense\napproach to building software and is without a doubt the best developer I\nhave ever known. He is a trusted advisor, invaluable colleague, and great\nfriend. Last, but absolutely not least, I’d like to thank my wife, Ann. For her\nrole in all of this, she deserves top billing and the “and”. She deserves the\nEGOT. For putting up with me, she deserves both the Nobel Prize and\nsainthood. No matter how preoccupied, absent-minded, or just plain stupid\nI’ve been she has always supported me. In the whole time that I’ve known\nher, whenever I’ve wanted to take risks both professionally and personally,\nshe has never said no. I can’t imagine a better partner. Nor would I want to.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nTodd has a no-nonsense\napproach to building software and is without a doubt the best developer I\nhave ever known. He is a trusted advisor, invaluable colleague, and great\nfriend. Last, but absolutely not least, I’d like to thank my wife, Ann. For her\nrole in all of this, she deserves top billing and the “and”. She deserves the\nEGOT. For putting up with me, she deserves both the Nobel Prize and\nsainthood. No matter how preoccupied, absent-minded, or just plain stupid\nI’ve been she has always supported me. In the whole time that I’ve known\nher, whenever I’ve wanted to take risks both professionally and personally,\nshe has never said no. I can’t imagine a better partner. Nor would I want to.", "tokens": 166, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 226, "segment_id": "00226", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000261"}
{"type": "chunk", "text": "Bibliography\n\nBertsimas, D., D. Nakazato. The distributional Little’s Law and its\napplications. Operations Research. 43(2) 298--310, 1995. Brumelle, S. On the relation between customer and time averages in\n\nqueues. J. Appl. Probab. 8 508--520, 1971. Deming, W. Edwards. The New Economics. 2nd Ed. The MIT Press,\n\n1994\n\nDeming, W. Edwards. Out of the Crisis. The MIT Press, 2000. Glynn, P. W., W. Whitt. Extensions of the queueing relations L = λ W\n\nand H = λ G. Operations Research. 37(4) 634--644, 1989. Goldratt, Eliyahu M., and Jeff Cox. The Goal. 2nd Rev. Ed. North\n\nRiver Press, 1992. Heyman, D. P., S. Stidham Jr. The relation between customer and time\n\naverages in queues. Oper. Res. 28(4) 983--994, 1980. Hopp, Wallace J., and Mark L. Spearman. Factory Physics. Irwin/McGraw-Hill, 2007. Hubbard, Douglas W. How to Measure Anything: Finding the Value of\n\nIntangibles In Business. John Wiley & Sons, Inc., 2009. Little, J. D. C. A proof for the queuing formula: L = λ W. Operations\n\nResearch. 9(3) 383--387, 1961. Little, J. D. C., and S. C. Graves. “Little’s Law.” D. Chhajed, T. J. Lowe, eds. Building Intuition: Insights from Basic Operations Management\nModels and Principles. Springer Science + Business Media LLC, New\nYork, 2008. Magennis, Troy. Forecasting and Simulating Software Development\n\nProjects. Self-published, 2011. Reinertsen, Donald G. Managing the Design Factory. Free Press,\n\n1997. Reinertsen, Donald G. The Principles of Product Development Flow. Celeritas Publishing, 2009. Ries, Eric. The Lean Startup. Crown Business, 2011.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nBibliography\n\nBertsimas, D., D. Nakazato. The distributional Little’s Law and its\napplications. Operations Research. 43(2) 298--310, 1995. Brumelle, S. On the relation between customer and time averages in\n\nqueues. J. Appl. Probab. 8 508--520, 1971. Deming, W. Edwards. The New Economics. 2nd Ed. The MIT Press,\n\n1994\n\nDeming, W. Edwards. Out of the Crisis. The MIT Press, 2000. Glynn, P. W., W. Whitt. Extensions of the queueing relations L = λ W\n\nand H = λ G. Operations Research. 37(4) 634--644, 1989. Goldratt, Eliyahu M., and Jeff Cox. The Goal. 2nd Rev. Ed. North\n\nRiver Press, 1992. Heyman, D. P., S. Stidham Jr. The relation between customer and time\n\naverages in queues. Oper. Res. 28(4) 983--994, 1980. Hopp, Wallace J., and Mark L. Spearman. Factory Physics. Irwin/McGraw-Hill, 2007. Hubbard, Douglas W. How to Measure Anything: Finding the Value of\n\nIntangibles In Business. John Wiley & Sons, Inc., 2009. Little, J. D. C. A proof for the queuing formula: L = λ W. Operations\n\nResearch. 9(3) 383--387, 1961. Little, J. D. C., and S. C. Graves. “Little’s Law.” D. Chhajed, T. J. Lowe, eds. Building Intuition: Insights from Basic Operations Management\nModels and Principles. Springer Science + Business Media LLC, New\nYork, 2008. Magennis, Troy. Forecasting and Simulating Software Development\n\nProjects. Self-published, 2011. Reinertsen, Donald G. Managing the Design Factory. Free Press,\n\n1997. Reinertsen, Donald G. The Principles of Product Development Flow. Celeritas Publishing, 2009. Ries, Eric. The Lean Startup. Crown Business, 2011.", "tokens": 490, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 228, "segment_id": "00228", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000262"}
{"type": "chunk", "text": "Roubini, Nouriel, and Stephen Mihm. Crisis Economics. Penguin\n\nBooks, 2010. Savage, Sam L. The Flaw of Averages. John Wiley & Sons, Inc., 2009. Shewhart, W. A. Economic Control of Quality of Manufactured\n\nProduct, 1931. Shewhart, W. A. Statistical Method from the Viewpoint of Quality\n\nControl, 1939. Stidham, S., Jr. L = λ W: A discounted analogue and a new proof. Operations Research. 20(6) 1115--1126, 1972. Stidham, S., Jr. A last word on L= λ W. Operations Research. 22(2)\n\n417--421, 1974. Vacanti, Daniel S. and Bennet Vallet. “Actionable Metrics at Siemens\n\nHealth Services”. AgileAlliance.com. 1 Aug 2014. Vallet, Bennet. “Kanban at Scale: A Siemens Success Story.”\n\nInfoq.com. 28 Feb 2014. Vega, Frank. “Are You Just an Average CFD User?” Vissinc.com. 21\n\nFeb 2014. Vega, Frank. “The Basics of Reading Cumulative Flow Diagrams”. Vissinc.com. 29 Sep 2011. Wheelan, Charles. Naked Statistics. W. W. Norton & Company, 2013. Wheeler, Donald J., and David S. Chambers. Understanding Statistical\n\nProcess Control. 2nd Ed. SPC Press, 1992. Wikipedia “Monte Carlo method.” Wikipedia.com. 01 Aug 2014. Wikipedia “Uniform Distribution.” Wikipedia.com. 01 Aug 2014. Wikipedia “Uniform Distribution (discrete).” Wikipedia.com. 01 Aug\n\n2014.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nRoubini, Nouriel, and Stephen Mihm. Crisis Economics. Penguin\n\nBooks, 2010. Savage, Sam L. The Flaw of Averages. John Wiley & Sons, Inc., 2009. Shewhart, W. A. Economic Control of Quality of Manufactured\n\nProduct, 1931. Shewhart, W. A. Statistical Method from the Viewpoint of Quality\n\nControl, 1939. Stidham, S., Jr. L = λ W: A discounted analogue and a new proof. Operations Research. 20(6) 1115--1126, 1972. Stidham, S., Jr. A last word on L= λ W. Operations Research. 22(2)\n\n417--421, 1974. Vacanti, Daniel S. and Bennet Vallet. “Actionable Metrics at Siemens\n\nHealth Services”. AgileAlliance.com. 1 Aug 2014. Vallet, Bennet. “Kanban at Scale: A Siemens Success Story.”\n\nInfoq.com. 28 Feb 2014. Vega, Frank. “Are You Just an Average CFD User?” Vissinc.com. 21\n\nFeb 2014. Vega, Frank. “The Basics of Reading Cumulative Flow Diagrams”. Vissinc.com. 29 Sep 2011. Wheelan, Charles. Naked Statistics. W. W. Norton & Company, 2013. Wheeler, Donald J., and David S. Chambers. Understanding Statistical\n\nProcess Control. 2nd Ed. SPC Press, 1992. Wikipedia “Monte Carlo method.” Wikipedia.com. 01 Aug 2014. Wikipedia “Uniform Distribution.” Wikipedia.com. 01 Aug 2014. Wikipedia “Uniform Distribution (discrete).” Wikipedia.com. 01 Aug\n\n2014.", "tokens": 384, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 229, "segment_id": "00229", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000263"}
{"type": "chunk", "text": "About the Author\n\nDaniel Vacanti is a 20-year software industry veteran who got his start as a\nJava Developer/Architect and who has spent most of the last 15 years\nfocusing on Lean and Agile practices. In 2007, he helped to develop the\nKanban Method for knowledge work. He managed the world’s first project\nimplementation of Kanban that year, and has been conducting Kanban\ntraining, coaching, and consulting ever since. In 2011 he founded Corporate\nKanban, Inc., which provides world-class Lean training and consulting to\nclients all over the globe--including several Fortune 100 companies. In 2013\nhe co-founded ActionableAgileTM which provides industry leading\npredictive analytics tools and services to any Lean-Agile process. Daniel\nholds a Masters in Business Administration and regularly teaches a class on\nlean principles for software management at the University of California\nBerkeley.", "full_text": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of\n\nAbout the Author\n\nDaniel Vacanti is a 20-year software industry veteran who got his start as a\nJava Developer/Architect and who has spent most of the last 15 years\nfocusing on Lean and Agile practices. In 2007, he helped to develop the\nKanban Method for knowledge work. He managed the world’s first project\nimplementation of Kanban that year, and has been conducting Kanban\ntraining, coaching, and consulting ever since. In 2011 he founded Corporate\nKanban, Inc., which provides world-class Lean training and consulting to\nclients all over the globe--including several Fortune 100 companies. In 2013\nhe co-founded ActionableAgileTM which provides industry leading\npredictive analytics tools and services to any Lean-Agile process. Daniel\nholds a Masters in Business Administration and regularly teaches a class on\nlean principles for software management at the University of California\nBerkeley.", "tokens": 195, "metadata": {"source_file": "Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf", "page_num": 230, "segment_id": "00230", "chapter_num": "17", "chapter_title": "Actionable Agile Metrics at Siemens", "section_num": "2.5", "section_title": "sprints! What’s worse is that Figure 17.3 shows us that over the course of", "has_table": false}, "context": "Source: Actionable_Agile_Metrics_for_Predictability_An_Introduction_-_Daniel_S_Vacanti.pdf | Chapter 17: Actionable Agile Metrics at Siemens | Section 2.5: sprints! What’s worse is that Figure 17.3 shows us that over the course of", "chunk_id": "00000264"}
{"type": "audit", "total_chunks": 265, "source_pages": 230, "chunks_per_page": 1.1521739130434783, "avg_tokens": 344.5, "min_tokens": 101, "max_tokens": 516, "chunks_with_context": 265, "context_coverage": 1.0, "stage": "chunk", "version": "2.0.0", "created_at": "2025-11-05T10:17:17Z"}
