# –ü–ª–∞–Ω —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞ Archivist Magika v2.0
# –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ —É–ª—É—á—à–µ–Ω–∏—è

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 2025-11-05
**–í–µ—Ä—Å–∏—è:** 1.0
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** –í–´–°–û–ö–ò–ô

---

## –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–µ–∑—é–º–µ

–ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –±–∞—Ç—á-–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ 20 –∫–Ω–∏–≥ –≤—ã—è–≤–ª–µ–Ω–æ 3 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º—ã –∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π.

**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å:**
- üî¥ **CRITICAL** - –±–ª–æ–∫–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö, —Ç—Ä–µ–±—É–µ—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
- üü° **HIGH** - —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –≤–ª–∏—è–µ—Ç –Ω–∞ —Ä–∞–±–æ—Ç—É, –∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Å–∫–æ—Ä–æ
- üü¢ **MEDIUM** - —É–ª—É—á—à–µ–Ω–∏–µ UX, –º–æ–∂–Ω–æ –æ—Ç–ª–æ–∂–∏—Ç—å

---

## 1. –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã

### üî¥ CRITICAL-1: LM Extraction –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç (hardcoded model fallback)

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P0 - –ë–ª–æ–∫–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ metadata
**–°—Ç–∞—Ç—É—Å:** NOT FIXED
**Impact:** 4,763 API errors, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç LM-extracted –ø–æ–ª—è —É –≤—Å–µ—Ö 20 –∫–Ω–∏–≥

#### –ü—Ä–æ–±–ª–µ–º–∞

**–§–∞–π–ª:** `am_extended.py:142`

```python
# –¢–ï–ö–£–©–ò–ô –ö–û–î (–ù–ï–ü–†–ê–í–ò–õ–¨–ù–û):
def __init__(self, config: dict):
    self.model = config.get('model', 'llama3.2:3b')  # ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª—é—á –∫–æ–Ω—Ñ–∏–≥–∞
```

**–ö–æ–Ω—Ñ–∏–≥ —É–∫–∞–∑—ã–≤–∞–µ—Ç:**
```yaml
extended:
  lm_model: "qwen2.5:7b"  # ‚úì –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª—é—á
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- –ö–æ–¥ –∏—â–µ—Ç –∫–ª—é—á `model` (–Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
- –ü–æ–ª—É—á–∞–µ—Ç fallback `llama3.2:3b` (–º–æ–¥–µ–ª—å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞)
- –í—Å–µ LM API –∑–∞–ø—Ä–æ—Å—ã –ø–æ–ª—É—á–∞—é—Ç 404
- Extended fields –ø–∞–¥–∞—é—Ç –Ω–∞ LM extraction
- –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ heuristic fallbacks

#### –†–µ—à–µ–Ω–∏–µ

**–§–∞–π–ª:** `am_extended.py`

```python
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ö–û–î:
def __init__(self, config: dict):
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª—é—á –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    self.model = config.get('lm_model', 'qwen2.5:7b')  # ‚úì –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
    self.provider = config.get('lm_provider', 'ollama')

    # –î–æ–±–∞–≤–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏—é
    logger.info(f"LM configured: provider={self.provider}, model={self.model}")
```

#### –ú–µ—Å—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è

1. **`am_extended.py:142`** - –æ—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞
2. **`am_extended.py:150-200`** - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Å–µ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ –∫–æ–Ω—Ñ–∏–≥—É LM
3. **`am_common.py`** - –¥–æ–±–∞–≤–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é –∫–æ–Ω—Ñ–∏–≥–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ

#### –ü–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π

1. ‚úÖ –ò—Å–ø—Ä–∞–≤–∏—Ç—å –∫–æ–¥ –≤ `am_extended.py`
2. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å logging –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ LM –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
3. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é: –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ Ollama API
4. ‚úÖ –¢–µ—Å—Ç—ã: unit test –¥–ª—è config loading
5. ‚è≥ –ü–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ 20 –∫–Ω–∏–≥ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º –∫–æ–¥–æ–º
6. ‚è≥ –°—Ä–∞–≤–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ metadata –¥–æ/–ø–æ—Å–ª–µ

#### Expected outcome

```
# –ü–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤ –ª–æ–≥–∞—Ö:
2025-11-05 - am_extended - INFO - LM configured: provider=ollama, model=qwen2.5:7b
2025-11-05 - am_extended - INFO - LM model check: OK (qwen2.5:7b responding)
2025-11-05 - am_extended - INFO - Extracted fields: content_type=technical, domain=management, complexity=advanced
```

**–ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—Ö–∞:**
- 0 Ollama 404 errors
- content_type, domain, complexity –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç —É –≤—Å–µ—Ö –∫–Ω–∏–≥
- key_concepts –∏–∑–≤–ª–µ—á–µ–Ω—ã

---

### üî¥ CRITICAL-2: –î–ª–∏–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P0 - –ë–ª–æ–∫–∏—Ä—É–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤
**–°—Ç–∞—Ç—É—Å:** PARTIALLY FIXED (–≤—Ä—É—á–Ω—É—é –¥–ª—è PMBOK)
**Impact:** PMBOK –±—ã–ª –ø—Ä–æ–ø—É—â–µ–Ω, —Ç—Ä–µ–±–æ–≤–∞–ª–∞—Å—å —Ä—É—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

#### –ü—Ä–æ–±–ª–µ–º–∞

**–°–∏–º–ø—Ç–æ–º—ã:**
1. Bash wildcard `*.pdf` –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç —Ñ–∞–π–ª—ã —Å –¥–ª–∏–Ω–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏
2. FAISS –Ω–µ –º–æ–∂–µ—Ç –∑–∞–ø–∏—Å–∞—Ç—å index —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π –≤ –∏–º–µ–Ω–∏ (147+ —Å–∏–º–≤–æ–ª–æ–≤)
3. Windows PATH_MAX –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

**–ü—Ä–∏–º–µ—Ä:**
```
# –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è (147 —Å–∏–º–≤–æ–ª–æ–≤):
Project Management Institute - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –∫ —Å–≤–æ–¥—É –∑–Ω–∞–Ω–∏–π –ø–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é –ø—Ä–æ–µ–∫—Ç–∞–º–∏ (–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ PMBOK) –∏ –°—Ç–∞–Ω–¥–∞—Ä—Ç —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–º. –°–µ–¥—å–º–æ–µ –∏–∑–¥–∞–Ω–∏–µ - 2021.pdf

# –û—à–∏–±–∫–∞ FAISS:
RuntimeError: could not open c:\scripts\1repo\data\indexes\faiss\project_management_institute_-_—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ_–∫_—Å–≤–æ–¥—É_–∑–Ω–∞–Ω–∏–π_–ø–æ_—É–ø—Ä–∞–≤–ª–µ–Ω–∏—é_–ø—Ä–æ–µ–∫—Ç–∞–º–∏_(—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ_pmbok)_–∏_—Å—Ç–∞–Ω–¥–∞—Ä—Ç_—É–ø—Ä–∞–≤–ª–µ–Ω–∏—è_–ø—Ä–æ–µ–∫—Ç–æ–º._—Å–µ–¥—å–º–æ–µ_–∏–∑–¥–∞–Ω–∏–µ_-_2021.dataset.faiss for writing: Invalid argument
```

#### –†–µ—à–µ–Ω–∏–µ

**–ü–æ–¥—Ö–æ–¥ 1: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ –∏–º–µ–Ω (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø)**

**–§–∞–π–ª:** `am_common.py` - –Ω–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è

```python
import hashlib
from pathlib import Path

def sanitize_filename(filename: str, max_length: int = 50) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è —Ñ–∞–π–ª–∞.

    Args:
        filename: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        max_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

    Returns:
        –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è (ASCII, –±–µ–∑ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤)

    Example:
        >>> sanitize_filename("Project Management Institute - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ...pdf")
        'project_management_institute_pmbok_a3f8b2.pdf'
    """
    # 1. –£–±—Ä–∞—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
    stem = Path(filename).stem
    ext = Path(filename).suffix

    # 2. –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
    transliterate_map = {
        '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e',
        '—ë': 'yo', '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k',
        '–ª': 'l', '–º': 'm', '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r',
        '—Å': 's', '—Ç': 't', '—É': 'u', '—Ñ': 'f', '—Ö': 'h', '—Ü': 'ts',
        '—á': 'ch', '—à': 'sh', '—â': 'sch', '—ä': '', '—ã': 'y', '—å': '',
        '—ç': 'e', '—é': 'yu', '—è': 'ya'
    }

    stem_lower = stem.lower()
    transliterated = ''
    for char in stem_lower:
        if char in transliterate_map:
            transliterated += transliterate_map[char]
        elif char.isalnum() or char in ['-', '_']:
            transliterated += char
        else:
            transliterated += '_'

    # 3. –£–±—Ä–∞—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ underscores
    while '__' in transliterated:
        transliterated = transliterated.replace('__', '_')

    # 4. –£–∫–æ—Ä–æ—Ç–∏—Ç—å –¥–æ max_length
    if len(transliterated) > max_length:
        # –î–æ–±–∞–≤–∏–º hash –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
        file_hash = hashlib.md5(stem.encode()).hexdigest()[:6]
        transliterated = transliterated[:max_length-7] + '_' + file_hash

    # 5. –£–±—Ä–∞—Ç—å trailing underscores
    transliterated = transliterated.strip('_')

    return transliterated + ext


# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ:
def get_safe_book_name(pdf_path: Path) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è –∫–Ω–∏–≥–∏ –¥–ª—è dataset —Ñ–∞–π–ª–æ–≤."""
    return sanitize_filename(pdf_path.name, max_length=50)
```

**–ì–¥–µ –ø—Ä–∏–º–µ–Ω–∏—Ç—å:**

1. **`run_mvp.py`** - –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ output paths
2. **`am_structural_robust.py`** - –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ datasets
3. **`am_embed.py`** - –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ FAISS index
4. **`batch_process_library.py`** - –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤

#### –ü–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π

1. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å `sanitize_filename()` –≤ `am_common.py`
2. ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–æ –≤—Å–µ —ç—Ç–∞–ø—ã –ø–∞–π–ø–ª–∞–π–Ω–∞
3. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å mapping —Ñ–∞–π–ª: `original_name ‚Üí safe_name`
4. ‚úÖ Unit tests –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö edge cases
5. ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: –∫–∞–∫–∏–µ —Å–∏–º–≤–æ–ª—ã –¥–æ–ø—É—Å—Ç–∏–º—ã

**–ü–æ–¥—Ö–æ–¥ 2: Fix bash —Å–∫—Ä–∏–ø—Ç–∞**

**–§–∞–π–ª:** `batch_simple.sh`

```bash
# –¢–ï–ö–£–©–ò–ô –ö–û–î:
for pdf in "$SOURCE_DIR"/*.pdf; do
    filename=$(basename "$pdf")
    # ...
done

# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ö–û–î:
# –ò—Å–ø–æ–ª—å–∑—É–µ–º find –≤–º–µ—Å—Ç–æ wildcard –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∏–º–µ–Ω
find "$SOURCE_DIR" -maxdepth 1 -name "*.pdf" -type f | while IFS= read -r pdf; do
    filename=$(basename "$pdf")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã –∏–º–µ–Ω–∏
    if [ ${#filename} -gt 100 ]; then
        echo "[WARN] Long filename detected: ${filename:0:50}..."
    fi

    # ...
done
```

#### Expected outcome

```
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ:
PMBOK 2021.pdf ‚Üí pmbok_2021.dataset.faiss

# Mapping —Å–æ—Ö—Ä–∞–Ω–µ–Ω:
data/filename_mappings.json:
{
  "project_management_institute_pmbok_a3f8b2": {
    "original": "Project Management Institute - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ...",
    "safe": "pmbok_2021",
    "created_at": "2025-11-05"
  }
}
```

---

### üî¥ CRITICAL-3: Unicode Encoding –≤ Windows –ª–æ–≥–∞—Ö

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P1 - –ú–µ—à–∞–µ—Ç debugging, –Ω–æ –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É
**–°—Ç–∞—Ç—É—Å:** PARTIALLY FIXED (–µ—Å—Ç—å workaround, –Ω–æ –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é)
**Impact:** –õ–æ–≥–∏ –∑–∞—Å–æ—Ä–µ–Ω—ã UnicodeEncodeError, –Ω–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è

#### –ü—Ä–æ–±–ª–µ–º–∞

**–°–∏–º–ø—Ç–æ–º:**
```python
UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f680' in position 5: character maps to <undefined>
```

**Root cause:**
- Windows Console –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç CP1251
- Python logging –ø—ã—Ç–∞–µ—Ç—Å—è –∑–∞–ø–∏—Å–∞—Ç—å emoji –∏ Unicode —Å—Ç—Ä–µ–ª–∫–∏
- Colorama –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É

**–ú–µ—Å—Ç–∞:**
- `am_logging.py` - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç emoji –≤ log_section, log_stage
- `run_mvp.py` - Unicode —Å—Ç—Ä–µ–ª–∫–∏ –≤ Pipeline –æ–ø–∏—Å–∞–Ω–∏—è—Ö

#### –†–µ—à–µ–Ω–∏–µ

**–í–∞—Ä–∏–∞–Ω—Ç A: –£–±—Ä–∞—Ç—å emoji –ø–æ–ª–Ω–æ—Å—Ç—å—é (–ü–†–û–°–¢–û–ï)**

**–§–∞–π–ª:** `am_logging.py`

```python
# –î–æ–±–∞–≤–∏—Ç—å —Ñ–ª–∞–≥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
USE_EMOJI = False  # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤ False –¥–ª—è Windows

STAGE_EMOJI = {
    'structural': 'üìÑ' if USE_EMOJI else '[PDF]',
    'structure_detect': 'üìñ' if USE_EMOJI else '[STRUCT]',
    'summarize': 'üìù' if USE_EMOJI else '[SUMMARY]',
    'extended': 'ü§ñ' if USE_EMOJI else '[EXTEND]',
    'finalize': '‚úÖ' if USE_EMOJI else '[FINAL]',
    'chunk': 'üß©' if USE_EMOJI else '[CHUNK]',
    'embed': 'üî¢' if USE_EMOJI else '[EMBED]'
}

# Unicode —Å—Ç—Ä–µ–ª–∫–∏ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ ASCII
# –ë—ã–ª–æ: "Pipeline: structural ‚Üí embed"
# –°—Ç–∞–ª–æ: "Pipeline: structural -> embed"
```

**–í–∞—Ä–∏–∞–Ω—Ç B: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è UTF-8 –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–ü–†–ê–í–ò–õ–¨–ù–û–ï)**

**–§–∞–π–ª:** `run_mvp.py` (–≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ)

```python
import sys
import os

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å UTF-8 –¥–ª—è Windows –∫–æ–Ω—Å–æ–ª–∏
if sys.platform == 'win32':
    # –î–ª—è stdout/stderr
    import io
    sys.stdout = io.TextIOWrapper(
        sys.stdout.buffer,
        encoding='utf-8',
        errors='replace',
        line_buffering=True
    )
    sys.stderr = io.TextIOWrapper(
        sys.stderr.buffer,
        encoding='utf-8',
        errors='replace',
        line_buffering=True
    )

    # –î–ª—è Windows Console API
    try:
        import ctypes
        kernel32 = ctypes.windll.kernel32
        kernel32.SetConsoleOutputCP(65001)  # UTF-8
    except Exception:
        pass
```

**–§–∞–π–ª:** `am_logging.py`

```python
def setup_logging(config: dict):
    """Setup logging with proper UTF-8 encoding."""
    log_config = config.get('logging', {})
    level = log_config.get('level', 'INFO')
    format_str = log_config.get('format', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # UTF-8 –¥–ª—è file handler
    file_handler = logging.FileHandler(
        log_file,
        encoding='utf-8',  # ‚úì –î–æ–±–∞–≤–∏—Ç—å encoding
        errors='replace'
    )
    file_handler.setFormatter(logging.Formatter(format_str))

    # Stream handler —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º fallback
    stream_handler = logging.StreamHandler(sys.stdout)
    stream_handler.setFormatter(logging.Formatter(format_str))

    # ...
```

#### –ü–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π

1. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å USE_EMOJI config flag
2. ‚úÖ –ó–∞–º–µ–Ω–∏—Ç—å Unicode —Å—Ç—Ä–µ–ª–∫–∏ –Ω–∞ ASCII
3. ‚úÖ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å UTF-8 –≤ –Ω–∞—á–∞–ª–µ run_mvp.py
4. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å encoding='utf-8' –∫–æ –≤—Å–µ–º file handlers
5. ‚úÖ CLI —Ñ–ª–∞–≥ `--no-emoji` –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è

#### Expected outcome

```
# –° emoji (Linux/Mac):
üìÑ Starting: STRUCTURAL
Pipeline: structural ‚Üí embed

# –ë–µ–∑ emoji (Windows):
[PDF] Starting: STRUCTURAL
Pipeline: structural -> embed

# –õ–æ–≥–∏ –±–µ–∑ –æ—à–∏–±–æ–∫:
2025-11-05 12:10:14 - am_structural - INFO - Processing PMBOK
```

---

## 2. –í–∞–∂–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

### üü° HIGH-1: WindowsPath subscriptable error

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P1
**–§–∞–π–ª:** `batch_process_library.py`
**Impact:** –í–µ—Å—å –ø–µ—Ä–≤—ã–π –±–∞—Ç—á —É–ø–∞–ª –∏–∑-–∑–∞ —ç—Ç–æ–π –æ—à–∏–±–∫–∏

#### –ü—Ä–æ–±–ª–µ–º–∞

```python
# –¢–ï–ö–£–©–ò–ô –ö–û–î (–ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ):
pdf_path = Path("some/file.pdf")
something = pdf_path[0]  # ‚ùå Path –æ–±—ä–µ–∫—Ç –Ω–µ subscriptable
```

#### –†–µ—à–µ–Ω–∏–µ

–ù—É–∂–Ω–æ –Ω–∞–π—Ç–∏ —Ç–æ—á–Ω–æ–µ –º–µ—Å—Ç–æ –æ—à–∏–±–∫–∏. –ó–∞–ø—Ä–æ—Å–∏—Ç—å —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
- –¢–æ—á–Ω—É—é —Å—Ç—Ä–æ–∫—É –∫–æ–¥–∞ –∏–∑ batch_process_library.py
- Stack trace –æ—à–∏–±–∫–∏

**–í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ:** –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è batch_simple.sh

---

### üü° HIGH-2: Metadata files –Ω–µ —Å–æ–∑–¥–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P2
**Impact:** –¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–æ–π fix_missing_metadata.py

#### –ü—Ä–æ–±–ª–µ–º–∞

–ü–æ—Å–ª–µ embedding —Å–æ–∑–¥–∞—é—Ç—Å—è FAISS –∏–Ω–¥–µ–∫—Å—ã, –Ω–æ `.pkl` metadata files –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.

#### –†–µ—à–µ–Ω–∏–µ

**–§–∞–π–ª:** `am_embed.py:420-430`

```python
# –ü–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è FAISS index:
faiss.write_index(index, str(index_path))
logger.info(f"Saved FAISS index: {index_path.name}")

# ‚úì –î–æ–±–∞–≤–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ metadata:
metadata = {
    "chunks": chunks,  # –í—Å–µ —á–∞–Ω–∫–∏
    "book_name": book_name,
    "total_chunks": len(chunks),
    "embedding_dim": vectors.shape[1],
    "created_at": datetime.now().isoformat(),
    "model": self.model_name
}

metadata_path = index_path.with_suffix('.pkl')
with open(metadata_path, 'wb') as f:
    pickle.dump(metadata, f)
logger.info(f"Saved metadata: {metadata_path.name}")
```

---

## 3. –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

### üü¢ MEDIUM-1: Progress bar –¥–ª—è –¥–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P3
**Library:** `tqdm`

```python
from tqdm import tqdm

# –í structural extraction:
for page_num in tqdm(range(total_pages), desc="Extracting pages"):
    # ...
```

### üü¢ MEDIUM-2: Config validation –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ

**–§–∞–π–ª:** `am_common.py`

```python
def validate_config(config: dict) -> List[str]:
    """–í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º."""
    errors = []

    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å LM –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    if config.get('extended', {}).get('use_lm'):
        if 'lm_model' not in config['extended']:
            errors.append("extended.lm_model not specified")
        if 'lm_provider' not in config['extended']:
            errors.append("extended.lm_provider not specified")

    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å embedding –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    if 'embedding' in config:
        if 'model' not in config['embedding']:
            errors.append("embedding.model not specified")

    return errors
```

### üü¢ MEDIUM-3: Batch processing resume capability

**–§–∞–π–ª:** `batch_simple.sh` –∏–ª–∏ –Ω–æ–≤—ã–π `batch_process_library_v2.py`

```python
# –°–æ—Ö—Ä–∞–Ω—è—Ç—å state –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π –∫–Ω–∏–≥–∏:
state_file = Path("data/.batch_state.json")

state = {
    "completed": ["book1.pdf", "book2.pdf"],
    "failed": ["book3.pdf"],
    "last_processed": "book2.pdf",
    "timestamp": "2025-11-05T12:00:00"
}

# –ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ - –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ
```

---

## 4. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### Unit Tests (–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ–±–∞–≤–∏—Ç—å)

```python
# tests/test_common.py
def test_sanitize_filename_cyrillic():
    assert sanitize_filename("–ö–∞–≥–∞–Ω –ú–∞—Ä—Ç–∏.pdf") == "kagan_marti.pdf"

def test_sanitize_filename_long():
    long_name = "a" * 200 + ".pdf"
    result = sanitize_filename(long_name)
    assert len(result) <= 57  # 50 + 7 for hash + .pdf

def test_sanitize_filename_special_chars():
    assert sanitize_filename("Test¬ÆBook‚Ñ¢.pdf") == "test_book.pdf"

# tests/test_extended.py
def test_lm_config_loading():
    config = {"extended": {"lm_model": "qwen2.5:7b"}}
    extractor = ExtendedFieldsExtractor(config)
    assert extractor.model == "qwen2.5:7b"
```

### Integration Tests

```bash
# –¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞ –º–∞–ª–µ–Ω—å–∫–æ–º PDF (1-2 —Å—Ç—Ä–∞–Ω–∏—Ü—ã):
python run_mvp.py -i tests/fixtures/test_mini.pdf -c config/test.yaml

# –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
# - –í—Å–µ 7 —ç—Ç–∞–ø–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã
# - FAISS index —Å–æ–∑–¥–∞–Ω
# - Metadata .pkl —Å–æ–∑–¥–∞–Ω
# - 0 Ollama 404 errors
# - –õ–æ–≥–∏ –±–µ–∑ UnicodeEncodeError
```

---

## 5. –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á

### Sprint 1: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è (1-2 –¥–Ω—è)

1. ‚úÖ **LM extraction fix** (2-3 —á–∞—Å–∞)
   - –ò–∑–º–µ–Ω–∏—Ç—å –∫–æ–¥ –≤ am_extended.py
   - –î–æ–±–∞–≤–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é –∫–æ–Ω—Ñ–∏–≥–∞
   - Unit tests

2. ‚úÖ **Filename sanitization** (3-4 —á–∞—Å–∞)
   - –î–æ–±–∞–≤–∏—Ç—å sanitize_filename()
   - –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ pipeline
   - –¢–µ—Å—Ç—ã –Ω–∞ edge cases

3. ‚úÖ **Unicode encoding fix** (1-2 —á–∞—Å–∞)
   - UTF-8 setup –≤ run_mvp.py
   - USE_EMOJI flag
   - –ó–∞–º–µ–Ω–∏—Ç—å Unicode —Å—Ç—Ä–µ–ª–∫–∏

### Sprint 2: –ü–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö (6-8 —á–∞—Å–æ–≤)

4. ‚è≥ **Reprocess –≤—Å–µ 20 –∫–Ω–∏–≥**
   - –° –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º LM extraction
   - –° –∫–æ—Ä–æ—Ç–∫–∏–º–∏ –∏–º–µ–Ω–∞–º–∏ —Ñ–∞–π–ª–æ–≤
   - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å quality metrics

5. ‚è≥ **–ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å unified index**
   - –° LM-extracted metadata
   - –°—Ä–∞–≤–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞

### Sprint 3: –£–ª—É—á—à–µ–Ω–∏—è (2-3 –¥–Ω—è)

6. ‚è≥ Metadata auto-save
7. ‚è≥ Config validation
8. ‚è≥ Progress bars
9. ‚è≥ Batch resume capability

---

## 6. –ß–µ–∫–ª–∏—Å—Ç –ø–µ—Ä–µ–¥ –¥–µ–ø–ª–æ–µ–º

### –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ:
- [ ] LM extraction —Ä–∞–±–æ—Ç–∞–µ—Ç (0 Ollama 404 errors)
- [ ] –î–ª–∏–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
- [ ] Unicode –≤ –ª–æ–≥–∞—Ö –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–æ–∫
- [ ] Metadata files —Å–æ–∑–¥–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
- [ ] Unit tests –ø—Ä–æ—Ö–æ–¥—è—Ç

### –ñ–µ–ª–∞—Ç–µ–ª—å–Ω–æ:
- [ ] Config validation –¥–æ–±–∞–≤–ª–µ–Ω–∞
- [ ] Progress bars –¥–æ–±–∞–≤–ª–µ–Ω—ã
- [ ] Batch resume —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞

---

## 7. –†–∏—Å–∫–∏ –∏ –º–∏—Ç–∏–≥–∞—Ü–∏—è

| –†–∏—Å–∫ | –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å | –í–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ | –ú–∏—Ç–∏–≥–∞—Ü–∏—è |
|------|-------------|-------------|-----------|
| –ü–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–π–º–µ—Ç > 8 —á–∞—Å–æ–≤ | –°—Ä–µ–¥–Ω—è—è | –°—Ä–µ–¥–Ω—è—è | –ó–∞–ø—É—Å–∫–∞—Ç—å overnight |
| LM –º–æ–¥–µ–ª—å qwen2.5:7b –º–µ–¥–ª–µ–Ω–Ω–∞—è | –°—Ä–µ–¥–Ω—è—è | –ù–∏–∑–∫–∞—è | –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å lighter model |
| –ù–æ–≤—ã–µ –±–∞–≥–∏ –ø–æ—Å–ª–µ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞ | –ù–∏–∑–∫–∞—è | –í—ã—Å–æ–∫–∞—è | Extensive testing –Ω–∞ test.pdf |
| Sanitized –∏–º–µ–Ω–∞ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—Ç | –ù–∏–∑–∫–∞—è | –°—Ä–µ–¥–Ω—è—è | Hash –≤ –∫–æ–Ω—Ü–µ –∏–º–µ–Ω–∏ |

---

## 8. –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—Ö–∞

**–ü–æ—Å–ª–µ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å:**

| –ú–µ—Ç—Ä–∏–∫–∞ | –¢–µ–∫—É—â–µ–µ | –¶–µ–ª–µ–≤–æ–µ |
|---------|---------|---------|
| Ollama 404 errors | 4,763 | 0 |
| LM-extracted fields | 0% | 100% |
| Files skipped by batch | 1 (PMBOK) | 0 |
| UnicodeEncodeError –≤ –ª–æ–≥–∞—Ö | ~50 | 0 |
| Manual interventions | 3 (rename, fix, reindex) | 0 |
| Books successfully processed | 20/21 (95%) | 21/21 (100%) |

---

## 9. –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

### –®–∞–≥ 1: Backup
```bash
# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
cp -r data data_backup_20251105
git add -A
git commit -m "Snapshot before refactoring"
```

### –®–∞–≥ 2: –ü—Ä–∏–º–µ–Ω–∏—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
```bash
# –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã —Å–æ–≥–ª–∞—Å–Ω–æ –ø–ª–∞–Ω—É
# am_extended.py, am_common.py, run_mvp.py, am_logging.py
```

### –®–∞–≥ 3: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
```bash
# Unit tests
python -m pytest tests/ -v

# Integration test
python run_mvp.py -i tests/fixtures/test_mini.pdf -c config/test.yaml
```

### –®–∞–≥ 4: –ü–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∞
```bash
# –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
rm -rf data/datasets/*
rm -rf data/indexes/faiss/*

# –ó–∞–ø—É—Å—Ç–∏—Ç—å batch
./batch_simple.sh

# –ò–ª–∏ —Å –Ω–æ–≤—ã–º —Å–∫—Ä–∏–ø—Ç–æ–º:
python batch_process_library_v2.py --config config/batch_full.yaml
```

---

**–ö–æ–Ω–µ—Ü –ø–ª–∞–Ω–∞**

*–ì–æ—Ç–æ–≤ –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é: 2025-11-05*
*–û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: 3-5 –¥–Ω–µ–π*
*–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π: Developer*
